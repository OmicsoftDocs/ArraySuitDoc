{
    "docs": [
        {
            "location": "/",
            "text": "Home\n\u00b6\n\n\nOmicsoft believes that besides providing the best products, it is important to provide the best support as well.  From our rapidly expanding knowledge base to the ability to easily get one-on-one personal web meetings, Omicsoft aims to provide the user with a top support experience.\n\n\nTutorials\n\u00b6\n\n\nThe Omicsoft website offers tutorials for the various Array Studio modules including SNP Data Analysis, Affymetrix Data Analysis, CNV Analysis, ExonArray Data Analysis as well as Next Generation Sequencing (NGS) modules such as RNA-seq, DNA-seq and miRNA-seq. These tutorials are a great beginning guide to use Array Studio. They include links to download sample datasets, along with step-by-step directions for carrying out the various analysis methods.\n\n\nhttp://www.arrayserver.com/wiki/index.php?title=Tutorials\n\n\nArraySuite Wiki\n\u00b6\n\n\nThe Omicsoft wiki site is a user-friendly information center. Our support team keeps the wiki articles up-to-date with common and complex questions that we receive from our customers. If you need a place to start when you have questions or for troubleshooting, you can start searching there with a term of interest or you can browse by pre-defined categories. Moreover, in addition to our tutorials on individual modules available in Array Studio, we provide videos to demonstrate the usage and simplicity of Array Studio in exploring Land data.\n\n\nhttp://arrayserver.com/wiki/\n\n\nHelp Documents\n\u00b6\n\n\nHelp documents are available to provide context for many of the analysis modules in Array Studio and can be accessed by simply selecting the \"Help\" button on each analysis menu.\n\n\nContact Us\n\u00b6\n\n\nOur regular support hours are Monday through Friday 9:00 AM through 5:00 PM Eastern Time.  Emailed technical support requests are responded to on the same business day, and in most cases within a few hours.\n\n\nEmail: \nsupport@omicsoft.com\n\n\nPhone: 1-888-259-OMIC (1-888-259-6642) Option 1",
            "title": "Home"
        },
        {
            "location": "/#home",
            "text": "Omicsoft believes that besides providing the best products, it is important to provide the best support as well.  From our rapidly expanding knowledge base to the ability to easily get one-on-one personal web meetings, Omicsoft aims to provide the user with a top support experience.",
            "title": "Home"
        },
        {
            "location": "/#tutorials",
            "text": "The Omicsoft website offers tutorials for the various Array Studio modules including SNP Data Analysis, Affymetrix Data Analysis, CNV Analysis, ExonArray Data Analysis as well as Next Generation Sequencing (NGS) modules such as RNA-seq, DNA-seq and miRNA-seq. These tutorials are a great beginning guide to use Array Studio. They include links to download sample datasets, along with step-by-step directions for carrying out the various analysis methods.  http://www.arrayserver.com/wiki/index.php?title=Tutorials",
            "title": "Tutorials"
        },
        {
            "location": "/#arraysuite-wiki",
            "text": "The Omicsoft wiki site is a user-friendly information center. Our support team keeps the wiki articles up-to-date with common and complex questions that we receive from our customers. If you need a place to start when you have questions or for troubleshooting, you can start searching there with a term of interest or you can browse by pre-defined categories. Moreover, in addition to our tutorials on individual modules available in Array Studio, we provide videos to demonstrate the usage and simplicity of Array Studio in exploring Land data.  http://arrayserver.com/wiki/",
            "title": "ArraySuite Wiki"
        },
        {
            "location": "/#help-documents",
            "text": "Help documents are available to provide context for many of the analysis modules in Array Studio and can be accessed by simply selecting the \"Help\" button on each analysis menu.",
            "title": "Help Documents"
        },
        {
            "location": "/#contact-us",
            "text": "Our regular support hours are Monday through Friday 9:00 AM through 5:00 PM Eastern Time.  Emailed technical support requests are responded to on the same business day, and in most cases within a few hours.  Email:  support@omicsoft.com  Phone: 1-888-259-OMIC (1-888-259-6642) Option 1",
            "title": "Contact Us"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/",
            "text": "Introduction\n\u00b6\n\n\nWhat is Array Studio?\n\u00b6\n\n\nArray Studio is a software package that provides state of the art statistics and visualization for the analysis of high dimensional quantification data (e.g. Microarray or RT-PCR/Taqman data), genotype data (e.g. SNP or Copy Number data) and Next Generation Sequencing data. It provides the fastest, easiest and most powerful solution for \"-omic\" and \"NGS\" data analysis on the market. More than 400 features have been implemented based on feedback provided by industrial and academic users. \n\n\nFeatures\n\n\n\n\nArray Studio includes over 40 unique views, all of which are fully interactive (e.g. selection, zoom, etc.) and highly customizable (e.g. change axis, colors, shapes, etc.). Most of these views also have trellis support. All the views can be exported as images or PowerPoint slides by a single mouse click. \n\n\nMore than 50 analytical modules were designed for ease of use so that biologists can function at near the level of informatics specialists. The high dimensional linear modeling module provides the complete statistical analysis for multiple ANOVA, ANCOVA, repeated measure, split plot and a variety of other experimental designs. Non-negative matrix factorization and spectral map analysis are two of the many data exploration modules in the software. Data mining modules provide comprehensive support for classification (e.g. SVM and KNN) and regression (e.g. LASSO and Neural Network), with built-in variable selection and honest cross validation. Takes seconds or minutes instead of hours to do an analysis on a regular laptop computer!\n\n\nArray Studio also provides comprehensive support for project management, data manipulation, quality control, pathway analysis, gene ontology analysis, and power analysis. For industrial users, an internal audit trail and scripting are useful for data integration and customized analysis pipeline. Array Studio will automatically save all analysis logs to text file and provide a link to this file  in the \"Audit Trail Description\" tab.\n\n\nArray Studio integrates with Array Server, Omicsoft's enterprise solution for Microarray/CNV/SNP/NGS data storage, search and integration.  Easily retrieve projects from Array Server, and/or publish back to the server for storage and searching purposes.\n\n\n\n\nBenefits\n\n\n\n\nFastest data analysis and visualization on the market\n\n\nGeneral linear model benchmarked with SAS\n\n\nAutomatic project management, annotation support and script generation\n\n\nOne-Click exporting of tables to Excel and all visualizations to PowerPoint\n\n\nOne-Click downloading of data from the Gene Expression Omnibus (GEO) website, including the ability to automatically parse both design (sample information) and annotation, so that the project is immediately in the correct form for further analysis and visualization.\n\n\nOne-Click downloading of data from the Sequence Read Archive (SRA) website, including the ability to automatically convert sra files into fastq files.\n\n\nVariableView, for looking at expression values on a per-gene basis\n\n\nGeneral Linear Model for performing complicated analysis, including the ability to analyze mixed models, continuous and class covariates, nested factors, etc.\n\n\nQuality Control Modules, including generating Correlation Heatmap, Kernel density views, Principal Component Analysis, and more.\n\n\nStunning performance: Most modules in Array Studio take seconds, not minutes to run. Array Studio has been shown to handle 20,000 samples and millions of rows on an average laptop computer. A top-tier workstation is not necessary to run Array Studio effectively.\n\n\nInteractive GenomeView and RegionView for visualizing CNV segmentation results.\n\n\nAbility to easily import 1000s of microarray, SNP, or CNV chips on a regular computer\n\n\nFast and powerful segmentation algorithm for Copy Number analysis. GenomeView allows easy editing of copy number segments, as well as visualization of segments in relationship to Log2Ratio and AlleleDifference (B Allele Frequency)\n\n\nThe Taqman/RT-PCR Import and Normalization wizard is industry leading. The module was designed for use by top statisticians and bioinformaticians at a leading pharmaceutical company, and includes the ability to import directly from ABI Result Text files, normalize the data using a number of statistical methods, and visualize the results using the same visualizations used elsewhere in Array Studio.\n\n\nComprehensive statistical support for SNP, Genotyping, and Copy Number analysis, including the analysis of basic association studies, quantitative traits, categorical traits, survival trait analysis, repeated measure traits, Linkage disequilibrium analysis, Dose data association, probability association analysis, and more.\n\n\nAutomatic annotation support and built-in annotation browser-For most leading microarray and genetic products, Array Studio automatically downloads gene annotation and links it to every dataset and result created by users. Web Details on Demand allows users to quickly link to public resources that relate to selected probe sets or markers in a dataset.\n\n\nSingle deployment with automatic update support ensures that users will always be running the latest version. With Omicsoft's commitment to implementing reasonable user requests, this allows users to always have the newest software, including any and all modules released since users purchased the software.\n\n\nNGS workflows for DNA-seq, RNA-seq and miRNA-seq. The workflows include our high performance alignment modules (works for both single end and paired end) and many downstream analysis. For oncology users, we also developed the full gene fusion modules for both single-end and paired end modes. Papers and white papers on NGS are available upon request for existing users.\n\n\n\n\nArray Studio provides an integrated environment for analyzing and visualizing high-dimensional data.  It is convenient for organizing and visualizing data with its Solution Explorer, which organizes each project into two main sections (-Omic data and Table data), as well as different folders:, QC, Inference, List, Cluster, Text, Attachments and other categories.  The Solution Explorer can contain multiple projects, and data can be shared among projects.  Each view is controlled by a View Controller, which performs view customization, applies filtering, and displays legends; Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details Window.\n\n\nInstallation\n\u00b6\n\n\nRequirements\n\u00b6\n\n\nArray Studio requires Microsoft .NET 3.5 framework.  As a result, most versions of Array Studio require that users have administrative privileges to install .NET 3.5 Framework, or the ability to do so before installing Array Studio. By default, the installation page for Array Studio will automatically install .NET 3.5 Framework if users do not have this installed previously. \n\n\nWhile Array Studio does not have any specific requirements for memory or processor speed, it is recommended that users have at least 1gb of RAM for microarray analysis, and at least 2gb of RAM for ExonArray, SNP/Genotyping, and CNV analysis.\n\n\nFor microarray analysis, hard drive space is not an issue, however users should ensure that they have sufficient hard drive space for larger ExonArray, SNP/Genotyping, and CNV analysis.  Extremely large datasets, such as Dose or Probability SNP data, utilize a large amount of hard drive space. The user should ensure that there is sufficient space on the hard drive for such analyses.\n\n\nFor NGS analysis in 64-bit mode 8 GB of RAM is recommended, for 32-bit mode 2 GB of RAM is recommended. For hard drive space, both your Omicsoft temp folder and the data for the analysis must reside on a hard drive that has 3-times the amount of free space as the size of the raw data files.\n\n\nThe Omicsoft software home directory is typically located in users' My Documents folder, under the Omicsoft folder.  This folder contains all of users' annotations, favorites, Ontology, Refseq, Ensembl, Hapmap data, and more.  In addition, this folder is used as the temporary working directory.  If users are concerned about space on the hard drive containing this folder, the \nOmicsoft home directory\n can be changed by going to  \nTools  | Preferences | Advanced | Omicsoft\n.\n\n\nInstalling Array Studio\n\u00b6\n\n\nBioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The software is updated frequently. We do have a stable Array Studio version 10.0. Please contact \nsupport@omicsoft.com\n if you wish to use the stable version for data analysis.\n\n\nArrayStudio can be installed/launched using ArrayStudio Launcher. Launcher is installed through ClickOnce deployment. On an an internet-connected computer, open the following link in \nInternet Explorer, click install in the page below:\n\n\nhttp://omicsoft.com/software/ArrayStudioLauncher/publish.htm\n\n\nIt will create a desktop icon \"ArrayStudio Launcher\". User can then click the icon and launch ArrayStudio regardless which default internet browser has been set on your computer. The Launcher will check whether there is any software update available and ask user to decide whether to update studio or not.\n\n\nArray Studio GUI\n\u00b6\n\n\nWhen Array Studio is first installed, it will look similar to below.\nIf you have previously opened projects in Array Studio, you will see the Last Opened Projects window.  If so, just click \ncancel\n so that Array Studio looks similar to below.\n\n\nNotice at the top there will be four tabs: Analysis, Server, Land, and Browser.",
            "title": "Array Studio"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#what-is-array-studio",
            "text": "Array Studio is a software package that provides state of the art statistics and visualization for the analysis of high dimensional quantification data (e.g. Microarray or RT-PCR/Taqman data), genotype data (e.g. SNP or Copy Number data) and Next Generation Sequencing data. It provides the fastest, easiest and most powerful solution for \"-omic\" and \"NGS\" data analysis on the market. More than 400 features have been implemented based on feedback provided by industrial and academic users.   Features   Array Studio includes over 40 unique views, all of which are fully interactive (e.g. selection, zoom, etc.) and highly customizable (e.g. change axis, colors, shapes, etc.). Most of these views also have trellis support. All the views can be exported as images or PowerPoint slides by a single mouse click.   More than 50 analytical modules were designed for ease of use so that biologists can function at near the level of informatics specialists. The high dimensional linear modeling module provides the complete statistical analysis for multiple ANOVA, ANCOVA, repeated measure, split plot and a variety of other experimental designs. Non-negative matrix factorization and spectral map analysis are two of the many data exploration modules in the software. Data mining modules provide comprehensive support for classification (e.g. SVM and KNN) and regression (e.g. LASSO and Neural Network), with built-in variable selection and honest cross validation. Takes seconds or minutes instead of hours to do an analysis on a regular laptop computer!  Array Studio also provides comprehensive support for project management, data manipulation, quality control, pathway analysis, gene ontology analysis, and power analysis. For industrial users, an internal audit trail and scripting are useful for data integration and customized analysis pipeline. Array Studio will automatically save all analysis logs to text file and provide a link to this file  in the \"Audit Trail Description\" tab.  Array Studio integrates with Array Server, Omicsoft's enterprise solution for Microarray/CNV/SNP/NGS data storage, search and integration.  Easily retrieve projects from Array Server, and/or publish back to the server for storage and searching purposes.   Benefits   Fastest data analysis and visualization on the market  General linear model benchmarked with SAS  Automatic project management, annotation support and script generation  One-Click exporting of tables to Excel and all visualizations to PowerPoint  One-Click downloading of data from the Gene Expression Omnibus (GEO) website, including the ability to automatically parse both design (sample information) and annotation, so that the project is immediately in the correct form for further analysis and visualization.  One-Click downloading of data from the Sequence Read Archive (SRA) website, including the ability to automatically convert sra files into fastq files.  VariableView, for looking at expression values on a per-gene basis  General Linear Model for performing complicated analysis, including the ability to analyze mixed models, continuous and class covariates, nested factors, etc.  Quality Control Modules, including generating Correlation Heatmap, Kernel density views, Principal Component Analysis, and more.  Stunning performance: Most modules in Array Studio take seconds, not minutes to run. Array Studio has been shown to handle 20,000 samples and millions of rows on an average laptop computer. A top-tier workstation is not necessary to run Array Studio effectively.  Interactive GenomeView and RegionView for visualizing CNV segmentation results.  Ability to easily import 1000s of microarray, SNP, or CNV chips on a regular computer  Fast and powerful segmentation algorithm for Copy Number analysis. GenomeView allows easy editing of copy number segments, as well as visualization of segments in relationship to Log2Ratio and AlleleDifference (B Allele Frequency)  The Taqman/RT-PCR Import and Normalization wizard is industry leading. The module was designed for use by top statisticians and bioinformaticians at a leading pharmaceutical company, and includes the ability to import directly from ABI Result Text files, normalize the data using a number of statistical methods, and visualize the results using the same visualizations used elsewhere in Array Studio.  Comprehensive statistical support for SNP, Genotyping, and Copy Number analysis, including the analysis of basic association studies, quantitative traits, categorical traits, survival trait analysis, repeated measure traits, Linkage disequilibrium analysis, Dose data association, probability association analysis, and more.  Automatic annotation support and built-in annotation browser-For most leading microarray and genetic products, Array Studio automatically downloads gene annotation and links it to every dataset and result created by users. Web Details on Demand allows users to quickly link to public resources that relate to selected probe sets or markers in a dataset.  Single deployment with automatic update support ensures that users will always be running the latest version. With Omicsoft's commitment to implementing reasonable user requests, this allows users to always have the newest software, including any and all modules released since users purchased the software.  NGS workflows for DNA-seq, RNA-seq and miRNA-seq. The workflows include our high performance alignment modules (works for both single end and paired end) and many downstream analysis. For oncology users, we also developed the full gene fusion modules for both single-end and paired end modes. Papers and white papers on NGS are available upon request for existing users.   Array Studio provides an integrated environment for analyzing and visualizing high-dimensional data.  It is convenient for organizing and visualizing data with its Solution Explorer, which organizes each project into two main sections (-Omic data and Table data), as well as different folders:, QC, Inference, List, Cluster, Text, Attachments and other categories.  The Solution Explorer can contain multiple projects, and data can be shared among projects.  Each view is controlled by a View Controller, which performs view customization, applies filtering, and displays legends; Furthermore, its interactive visualization technique provides the details of data with the Details Window and the Web Details Window.",
            "title": "What is Array Studio?"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#installation",
            "text": "",
            "title": "Installation"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#requirements",
            "text": "Array Studio requires Microsoft .NET 3.5 framework.  As a result, most versions of Array Studio require that users have administrative privileges to install .NET 3.5 Framework, or the ability to do so before installing Array Studio. By default, the installation page for Array Studio will automatically install .NET 3.5 Framework if users do not have this installed previously.   While Array Studio does not have any specific requirements for memory or processor speed, it is recommended that users have at least 1gb of RAM for microarray analysis, and at least 2gb of RAM for ExonArray, SNP/Genotyping, and CNV analysis.  For microarray analysis, hard drive space is not an issue, however users should ensure that they have sufficient hard drive space for larger ExonArray, SNP/Genotyping, and CNV analysis.  Extremely large datasets, such as Dose or Probability SNP data, utilize a large amount of hard drive space. The user should ensure that there is sufficient space on the hard drive for such analyses.  For NGS analysis in 64-bit mode 8 GB of RAM is recommended, for 32-bit mode 2 GB of RAM is recommended. For hard drive space, both your Omicsoft temp folder and the data for the analysis must reside on a hard drive that has 3-times the amount of free space as the size of the raw data files.  The Omicsoft software home directory is typically located in users' My Documents folder, under the Omicsoft folder.  This folder contains all of users' annotations, favorites, Ontology, Refseq, Ensembl, Hapmap data, and more.  In addition, this folder is used as the temporary working directory.  If users are concerned about space on the hard drive containing this folder, the  Omicsoft home directory  can be changed by going to   Tools  | Preferences | Advanced | Omicsoft .",
            "title": "Requirements"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#installing-array-studio",
            "text": "Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The software is updated frequently. We do have a stable Array Studio version 10.0. Please contact  support@omicsoft.com  if you wish to use the stable version for data analysis.  ArrayStudio can be installed/launched using ArrayStudio Launcher. Launcher is installed through ClickOnce deployment. On an an internet-connected computer, open the following link in \nInternet Explorer, click install in the page below:  http://omicsoft.com/software/ArrayStudioLauncher/publish.htm  It will create a desktop icon \"ArrayStudio Launcher\". User can then click the icon and launch ArrayStudio regardless which default internet browser has been set on your computer. The Launcher will check whether there is any software update available and ask user to decide whether to update studio or not.",
            "title": "Installing Array Studio"
        },
        {
            "location": "/tutorials/ArrayStudio/ArrayStudio/#array-studio-gui",
            "text": "When Array Studio is first installed, it will look similar to below.\nIf you have previously opened projects in Array Studio, you will see the Last Opened Projects window.  If so, just click  cancel  so that Array Studio looks similar to below.  Notice at the top there will be four tabs: Analysis, Server, Land, and Browser.",
            "title": "Array Studio GUI"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArrayServer\n\u00b6\n\n\nArray Server is an enterprise solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. Easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server:\n\n\n\n\nServer-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS/Omics data.\n\n\nAll the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces are almost the same.\n\n\nServer Project\n\u00b6\n\n\nA \"Server Project\" is a project that is created on the server, rather than on the user's client machine.\nThis project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button.\nThe cache is stored in the user s home folder, typically \nMy Documents/Omicsoft/ServerProjects\n.\nA Server Project, when stored locally in the cache folder, has a different filename suffix (\n.ossprj\n) compared to a regular project (\n.osprj\n) and can only be opened when the user is connected to the server.\n\n\nThe concept behind the Server Project is that any data that is added to a project must first be stored on the server.\nWhen the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Server instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the server file system. Most of companies are storing data in network drives, they can map these drives directly in Array Server and all users will be able to access data easily during server analysis.\n\n\nAll data addition and extraction is done on the server side, by Array Server, instead of the users client machine.\nIt allows the user to use the power of the server, instead of their individual client machine for the importing of data. This is extremely important for some memory/CPU intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server.\n\n\nTest Dataset\n\u00b6\n\n\nIn this tutorial, we will show how to create a server project for server-based analysis. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL: \nlink",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Introduction/#arrayserver",
            "text": "Array Server is an enterprise solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. Easily share analyzed data with clients and colleagues. ArrayServer also hosts shared genome browsers. The following diagram demonstrates the functionality of Array Server:   Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, Array Server has a built-in scheduling system that supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS/Omics data.  All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces are almost the same.",
            "title": "ArrayServer"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Introduction/#server-project",
            "text": "A \"Server Project\" is a project that is created on the server, rather than on the user's client machine.\nThis project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the save button.\nThe cache is stored in the user s home folder, typically  My Documents/Omicsoft/ServerProjects .\nA Server Project, when stored locally in the cache folder, has a different filename suffix ( .ossprj ) compared to a regular project ( .osprj ) and can only be opened when the user is connected to the server.  The concept behind the Server Project is that any data that is added to a project must first be stored on the server.\nWhen the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Server instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the server file system. Most of companies are storing data in network drives, they can map these drives directly in Array Server and all users will be able to access data easily during server analysis.  All data addition and extraction is done on the server side, by Array Server, instead of the users client machine.\nIt allows the user to use the power of the server, instead of their individual client machine for the importing of data. This is extremely important for some memory/CPU intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc. Anytime the user saves the project, it is synchronized with the version on the server.",
            "title": "Server Project"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Introduction/#test-dataset",
            "text": "In this tutorial, we will show how to create a server project for server-based analysis. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be accessed from the following URL:  link",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/",
            "text": "Connecting to a Server and Uploading Files\n\u00b6\n\n\nConnecting to a Server\n\u00b6\n\n\nBefore creating a server project, first connect to a server by clicking the \nServer\n tab on the top of Array Studio.\n\n\n\n\nFill in the server information (where \nServer name\n can be anything given by the user to help remember the server) and log-in credentials. Select the \nConnect\n button. Depending on the server setup, another window may appear prompting the user to choose which analytical server to connect to.\n\n\n\n\nUpon successful login, the default \nWizard\n window will appear in the Server window:\n\n\n\n\nUploading Files\n\u00b6\n\n\nOne requirement for performing server-bases analysis is that the raw data (\ne.g.\n cel, fastq or bam files) has to be located on the server. One can use Array Studio to transfer local files to the server easily.\n\n\nIn the \nServer\n tab, go to \nServer File | Browse Files\n:\n\n\n\n\nThe \nServerFiles\n tab will appear with a listing of the current folders in the /Users/username directory:\n\n\n\n\nIn the example above, we are in the user folder (\n/Users/admin\n) and with the user id as \nadmin\n. The User folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting \nCreate New Folder\n from the dropdown menu.\n\n\nCreate a new folder and name it \nSampleData\n.\n\n\nEnter the \nSampleData\n folder and click \nUpload\n to transfer files from local computer to the server.\n\n\n\n\nSelect the \nServerTest.bam\n file and click \nOpen\n. As the files load, the progress is monitored in the lower portion of the \nServerFiles\n window:\n\n\n\n\nOnce the uploading has finished and the ftp transfer is complete, the files will appear in the \nSampleData\n folder.",
            "title": "Connecting to a Server and Uploading Files"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#connecting-to-a-server-and-uploading-files",
            "text": "",
            "title": "Connecting to a Server and Uploading Files"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#connecting-to-a-server",
            "text": "Before creating a server project, first connect to a server by clicking the  Server  tab on the top of Array Studio.   Fill in the server information (where  Server name  can be anything given by the user to help remember the server) and log-in credentials. Select the  Connect  button. Depending on the server setup, another window may appear prompting the user to choose which analytical server to connect to.   Upon successful login, the default  Wizard  window will appear in the Server window:",
            "title": "Connecting to a Server"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Connecting_to_a_Server_and_Uploading_Files/#uploading-files",
            "text": "One requirement for performing server-bases analysis is that the raw data ( e.g.  cel, fastq or bam files) has to be located on the server. One can use Array Studio to transfer local files to the server easily.  In the  Server  tab, go to  Server File | Browse Files :   The  ServerFiles  tab will appear with a listing of the current folders in the /Users/username directory:   In the example above, we are in the user folder ( /Users/admin ) and with the user id as  admin . The User folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting  Create New Folder  from the dropdown menu.  Create a new folder and name it  SampleData .  Enter the  SampleData  folder and click  Upload  to transfer files from local computer to the server.   Select the  ServerTest.bam  file and click  Open . As the files load, the progress is monitored in the lower portion of the  ServerFiles  window:   Once the uploading has finished and the ftp transfer is complete, the files will appear in the  SampleData  folder.",
            "title": "Uploading Files"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/",
            "text": "Creating and Publishing a Server Project\n\u00b6\n\n\nCreating A Server Project\n\u00b6\n\n\nTo create a server project, in \nAnalysis\n tab go to \nFile | New Server Project\n.\n\n\n\n\nThe user will be prompted to enter some basic meta data about the project, including an option to categorize the project using the \nCategory\n tab. \nAfter filling in the required information (indicated by asterisks), click \nCreate\n button.\n\n\n\n\nNow an empty project will be created (below):\n\n\n\n\nNotice that the project name includes \nServer Project - Distributed\n in the name so that the user can quickly see that this is a server project and the type is \nDistributed\n. \nDistributed\n indicates that data objects are saved in separate files.\n\n\nFrom here, we can perform all the analysis tasks on the server using the interface of Array Studio. For example, we can add the alignment analysis file (that we loaded to the server earlier) by going to the toolbar \nAdd Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads\n:\n\n\n\n\nthen choose the file uploaded in previous section (\nServerTest.bam\n).\n\n\n\n\nThen click \nSend to Queue\n.\n\n\nA \nServerJobs\n window will show, listing all the jobs on the server.\n\n\n\n\nNow switch back to the Analysis tab. Once the job is completed, the user will see an \nUpdate Project\n on the far right in the menu selection of Array Studio (below):\n\n\n\n\nClick \nUpdate Project\n to show the results of finished job: one \nNgsData\n is created for this BAM file.\n\n\n\n\nIf the user would like to see the parameters used for the alignment, select the data set name \nNgsData\n and right click, then choose \nView Source\n \n\n\n\n\nUsers can run all data analysis based on this \nNgsData\n in the same way as they run in Array Studio locally. \nThey will see \nSend to Queue\n button and all analyses will be done on server.\n\n\nPublishing a Server Project\n\u00b6\n\n\nAt this point, the project that we are working on is stored in our \nServerProject\n folder on the server (along with a cache on the local machine). \nNote: BAM files are not cached in local machine. The data object of \nNgsData\n only stores the link to the BAM file. \nThe server project is only accessible to the user who created it. \nThe user can also publish this project to the server to allow other users to access it. \nThis will also make it searchable in the \nWizard\n on the server.\n\n\nIf the project is active in Array Studio, simply select from the menu \nFile | Publish\n. If the project is not active, the user first has to select \nOpen | Open Server Project\n which will then make it active:\n\n\n\n\nSelecting \nPublish\n will open the \nPublish Project\n window.\n\n\n\n\nThe user has the options to \nChoose data/items to publish\n and \nChoose data to enable full text search\n.\nMeta data fields (some required and some optional) are filled in and indexed when published.\n\n\nGo into the \nServer\n tab of Array Studio and select the \nWizard\n tab and select \nSearch Server\n; the newly published \nTutorialServerProject\n will be visible in autofill:\n\n\n\n\nIf you leave the search fields empty and click \nSearch Server\n, all published server projects will be listed including the \nTutorialServerProject\n.\n\n\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.",
            "title": "Creating and Publishing a Server Project"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#creating-and-publishing-a-server-project",
            "text": "",
            "title": "Creating and Publishing a Server Project"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#creating-a-server-project",
            "text": "To create a server project, in  Analysis  tab go to  File | New Server Project .   The user will be prompted to enter some basic meta data about the project, including an option to categorize the project using the  Category  tab. \nAfter filling in the required information (indicated by asterisks), click  Create  button.   Now an empty project will be created (below):   Notice that the project name includes  Server Project - Distributed  in the name so that the user can quickly see that this is a server project and the type is  Distributed .  Distributed  indicates that data objects are saved in separate files.  From here, we can perform all the analysis tasks on the server using the interface of Array Studio. For example, we can add the alignment analysis file (that we loaded to the server earlier) by going to the toolbar  Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads :   then choose the file uploaded in previous section ( ServerTest.bam ).   Then click  Send to Queue .  A  ServerJobs  window will show, listing all the jobs on the server.   Now switch back to the Analysis tab. Once the job is completed, the user will see an  Update Project  on the far right in the menu selection of Array Studio (below):   Click  Update Project  to show the results of finished job: one  NgsData  is created for this BAM file.   If the user would like to see the parameters used for the alignment, select the data set name  NgsData  and right click, then choose  View Source     Users can run all data analysis based on this  NgsData  in the same way as they run in Array Studio locally. \nThey will see  Send to Queue  button and all analyses will be done on server.",
            "title": "Creating A Server Project"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Creating_and_Publishing_a_Server_Project/#publishing-a-server-project",
            "text": "At this point, the project that we are working on is stored in our  ServerProject  folder on the server (along with a cache on the local machine). \nNote: BAM files are not cached in local machine. The data object of  NgsData  only stores the link to the BAM file. \nThe server project is only accessible to the user who created it. \nThe user can also publish this project to the server to allow other users to access it. \nThis will also make it searchable in the  Wizard  on the server.  If the project is active in Array Studio, simply select from the menu  File | Publish . If the project is not active, the user first has to select  Open | Open Server Project  which will then make it active:   Selecting  Publish  will open the  Publish Project  window.   The user has the options to  Choose data/items to publish  and  Choose data to enable full text search .\nMeta data fields (some required and some optional) are filled in and indexed when published.  Go into the  Server  tab of Array Studio and select the  Wizard  tab and select  Search Server ; the newly published  TutorialServerProject  will be visible in autofill:   If you leave the search fields empty and click  Search Server , all published server projects will be listed including the  TutorialServerProject .   Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.",
            "title": "Publishing a Server Project"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/",
            "text": "Array Server on Cluster\n\u00b6\n\n\nArray Server can run jobs on clusters. It only requires ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cluster jobs.\n\n\nActually, Array Server on Cluster is pretty similar with that on a common server.\nThe underlying difference is that running jobs are automatically assigned to different nodes of the cluster,\ngreatly utilizing the power of a cluster that enhances computing speed and saves time.\nTo configure a Server on Cluster, please contact Omicsoft Support to get the manual for Server deployment on Cluster. After ArrayServer admin configures the Server on Cluster, standard users do not need to set up Cluster Preferences but only need to connect to the ArrayServer:\n\n\n\n\nTo run server jobs on Cluster, users just follow the tutorial of running Array server on common server to upload data files, create project and run server project as in Chapter 3 of this tutorial.\n\n\nRun Multiple Jobs on Cluster\n\u00b6\n\n\nWhen running multiple jobs (For example, multiple samples sequencing data alignment), multiple Cluster nodes will be used. This makes it much faster to perform the analyses.\n\n\nTo test this, please download the RNA-seq demo dataset from: \nlink\n\n\nMore detailed description of the dataset can be found in the accompanied RNA-Seq Analysis Tutorial.\n\n\nHere, we will only use two samples to save the process time. Make sure to load the data in the right Cluster folder and then, in the \nAnalysis\n tab, choose: \nAdd Data | Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina)\n. Click \nAdd\n and navigate to your downloaded RNA-seq demo dataset. Select all four fastq files and click OK.\n\n\n\n\nThe demo dataset is paired-end sequencing data; please check the \nReads are paired\n check box and \nSend to Queue\n:\n\n\n\n\nThe job can be monitored in the \nServer | Server Jobs\n tab:\n\n\n\n\nThe users can right click on the job and select \nView Full Log\n or \nCancel Job\n:\n\n\n\n\nIn the \nLog\n window, the jobs are being submitted to Cluster, 2 Cluster nodes (users can check qsub on cluster if they have permission) will be started with job IDs as we have two samples to align. Right-clicking on the job and viewing the log, we can see that SRR521461 and SRR521462 have been submitted as two separate jobs:\n\n\n\n\nOnce the job finishes, user could go back to Analysis tab to update the project as above and continue any downstream analyses and visualization (Clicking Update Project in the analysis tab to see the results):",
            "title": "Array Server on Cluster"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/#array-server-on-cluster",
            "text": "Array Server can run jobs on clusters. It only requires ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cluster jobs.  Actually, Array Server on Cluster is pretty similar with that on a common server.\nThe underlying difference is that running jobs are automatically assigned to different nodes of the cluster,\ngreatly utilizing the power of a cluster that enhances computing speed and saves time.\nTo configure a Server on Cluster, please contact Omicsoft Support to get the manual for Server deployment on Cluster. After ArrayServer admin configures the Server on Cluster, standard users do not need to set up Cluster Preferences but only need to connect to the ArrayServer:   To run server jobs on Cluster, users just follow the tutorial of running Array server on common server to upload data files, create project and run server project as in Chapter 3 of this tutorial.",
            "title": "Array Server on Cluster"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cluster/#run-multiple-jobs-on-cluster",
            "text": "When running multiple jobs (For example, multiple samples sequencing data alignment), multiple Cluster nodes will be used. This makes it much faster to perform the analyses.  To test this, please download the RNA-seq demo dataset from:  link  More detailed description of the dataset can be found in the accompanied RNA-Seq Analysis Tutorial.  Here, we will only use two samples to save the process time. Make sure to load the data in the right Cluster folder and then, in the  Analysis  tab, choose:  Add Data | Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) . Click  Add  and navigate to your downloaded RNA-seq demo dataset. Select all four fastq files and click OK.   The demo dataset is paired-end sequencing data; please check the  Reads are paired  check box and  Send to Queue :   The job can be monitored in the  Server | Server Jobs  tab:   The users can right click on the job and select  View Full Log  or  Cancel Job :   In the  Log  window, the jobs are being submitted to Cluster, 2 Cluster nodes (users can check qsub on cluster if they have permission) will be started with job IDs as we have two samples to align. Right-clicking on the job and viewing the log, we can see that SRR521461 and SRR521462 have been submitted as two separate jobs:   Once the job finishes, user could go back to Analysis tab to update the project as above and continue any downstream analyses and visualization (Clicking Update Project in the analysis tab to see the results):",
            "title": "Run Multiple Jobs on Cluster"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/",
            "text": "Array Server on Cloud\n\u00b6\n\n\nArray Server can also run jobs on the cloud.\nIt only requires the ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cloud jobs.\n\n\nThis tutorial is drafted for standard users. To configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin.\nAfter ArrayServer admin has configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through the \nServer\n tab:\n\n\n\n\nWhen connected, the window looks the same as the server window.\n\n\nNotice that the \nCloud\n tab will not appear.\n\n\n\n\nUploading Files to Server cloud\n\u00b6\n\n\nBefore running server jobs on cloud, the users should upload the data files on the specific cloud folder they have been assigned. Go to \nServer File | Browse Files\n window:\n\n\n\n\nThen go to the \ncloud folder\n configured in advance.\nPlease contact the admin if the user does not know where their cloud folder can be found.\nIn the folder, users can create their own folder and upload the data the same way as running a server project:\n\n\n\n\nRun Server Project on Cloud\n\u00b6\n\n\nOnce files are uploaded to the cloud folder, users can not run a server project on the cloud.\nPlease create a server project in the \nAnalysis\n tab first.\nThe analysis window and analysis steps are the same as running a server project. When adding data to a project, remember to browse the right cloud folder for your files:\n\n\n\n\nAfter sending the data to queue, the job progress could be monitored the same way as server project:\n\n\n\n\nRun Multiple Jobs on Cloud\n\u00b6\n\n\nWhen running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated.\nThis makes it much faster to perform the analyses.\n\n\nTo test this, users can use the RNA-seq data downloaded in the previous chapter. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to load the data to the correct cloud folder prior to starting the project:\n\n\n\n\n\n\nThe demo dataset is paired-end sequencing data; please check the \nReads are paired\n check box. For Server project to run on cloud, the users must specify output folder. The directory has to be under the cloud folder (not necessary to be the same cloud folder as the raw data). The principle is that all data, including raw and analyzed data, are on the cloud, while users' local machines and company server only store small data objects linking to the files on cloud. Upon job submission, again, the job could be monitored:\n\n\n\n\nThe users can right click on the job and select \nView Full Log\n:\n\n\n\n\nIn the \nLog\n window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align:\n\n\n\n\nAs a general user, you cannot monitor the Cloud Instances for Server Cloud.\n\n\nThe users can go back to the \nAnalysis\n tab and continue any downstream analyses and visualization:\n\n\n\n\nCongratulations! Now you can successfully run server projects on cloud!",
            "title": "Array Server on Cloud"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#array-server-on-cloud",
            "text": "Array Server can also run jobs on the cloud.\nIt only requires the ArrayServer administrator to perform a simple one-time set up. To other users, it is a transparent process. They do not need to do any extra setup, nor will they find any differences with other non-cloud jobs.  This tutorial is drafted for standard users. To configure Server with Cloud, please contact Omicsoft Support to get the manual for Server on Cloud admin.\nAfter ArrayServer admin has configured the Server with Cloud, standard users do not need to set up Cloud Preferences but only need to connect to the server with cloud integration through the  Server  tab:   When connected, the window looks the same as the server window.  Notice that the  Cloud  tab will not appear.",
            "title": "Array Server on Cloud"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#uploading-files-to-server-cloud",
            "text": "Before running server jobs on cloud, the users should upload the data files on the specific cloud folder they have been assigned. Go to  Server File | Browse Files  window:   Then go to the  cloud folder  configured in advance.\nPlease contact the admin if the user does not know where their cloud folder can be found.\nIn the folder, users can create their own folder and upload the data the same way as running a server project:",
            "title": "Uploading Files to Server cloud"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#run-server-project-on-cloud",
            "text": "Once files are uploaded to the cloud folder, users can not run a server project on the cloud.\nPlease create a server project in the  Analysis  tab first.\nThe analysis window and analysis steps are the same as running a server project. When adding data to a project, remember to browse the right cloud folder for your files:   After sending the data to queue, the job progress could be monitored the same way as server project:",
            "title": "Run Server Project on Cloud"
        },
        {
            "location": "/tutorials/ServerAnalysisBasics/Array_Server_on_Cloud/#run-multiple-jobs-on-cloud",
            "text": "When running multiple jobs (For example, multiple samples sequencing data alignment), multiple cloud instances will be allocated.\nThis makes it much faster to perform the analyses.  To test this, users can use the RNA-seq data downloaded in the previous chapter. For illustration purpose, we will only use two samples to reduce the process time. Again, remember to go to load the data to the correct cloud folder prior to starting the project:    The demo dataset is paired-end sequencing data; please check the  Reads are paired  check box. For Server project to run on cloud, the users must specify output folder. The directory has to be under the cloud folder (not necessary to be the same cloud folder as the raw data). The principle is that all data, including raw and analyzed data, are on the cloud, while users' local machines and company server only store small data objects linking to the files on cloud. Upon job submission, again, the job could be monitored:   The users can right click on the job and select  View Full Log :   In the  Log  window, as you can see, the jobs are being submitted to cloud NGS instances, 2 cloud instances will be started as we have two samples to align:   As a general user, you cannot monitor the Cloud Instances for Server Cloud.  The users can go back to the  Analysis  tab and continue any downstream analyses and visualization:   Congratulations! Now you can successfully run server projects on cloud!",
            "title": "Run Multiple Jobs on Cloud"
        },
        {
            "location": "/tutorials/ServerExplorer/Getting_Started/",
            "text": "Getting Started\n\u00b6\n\n\nServer explorer contains functions to search and display data stored in Array Server. Both Array Studio and Array Viewer contain the Server tab. Array Viewer is a separate product to view data shared in Array Server, having the same functionalities as ones in \nServer/Land/Browser\n tabs in ArrayStudio.\n\n\nIn this tutorial, we focus on modules in the Server tab in Array Viewer. They are the same in Array Studio Server tab. The tutorial is based on published projects in Array Server.\n\n\nInstallation and Setup\n\u00b6\n\n\nTo start Array Viewer for the first time, click on the following link: \nlink\n\n\nMake sure to use \nInternet Explorer\n for this process.\nArray Viewer in Internet Explorer requires the installation of the .NET 3.5 framework. For users with the .NET framework already installed, clicking Install will proceed to login and launch of Array Viewer, as shown below.\n\n\n\n\nClick the Edit button to edit the Omicsoft server of your choice and enter username and password information, or for internal servers, click the Add button to add a new server to the list.\n\n\nThis opens the Server Information window. The user has the ability to edit the name of the server, server address, as well as User ID and Password. At this point, the user should enter the User ID and Password provided to them by their Array Server Administrator. Some internal servers may not require \nuser authorization\n, and this should also be indicated by the Administrator. Click OK to save the Server Information.\n\n\n\n\nAfter editing the server, click the \nConnect\n button to connect to the server of your choice. After a successful login to the server, Array Viewer should look similar to the following screenshot:\n\n\n\n\nClick on the Server tab where the default view will be the Wizard.\n\n\nWizard\n\u00b6\n\n\nWhen the user initially opens the Server tab in Array Viewer, a wizard is shown, that allows the user to quickly get started. All search functionality can be done from the wizard.\n\n\n\n\nAt this point, the user can click the \nSearch Server\n button and should see a window similar to the following (note: the number of projects and name of tabs may not match exactly).\n\n\n\n\nProject Browser, Tagging, and Meta Data\n\u00b6\n\n\nThe left hand side of the screen provides the user a way to manually browse projects, either by Category, or using the advanced Filter option for projects.\n\n\nArrayStudio makes filtering projects very easy. Users can use the check box to filter projects.\n\n\n\n\nBesides using the check box, users can click on the icons\n\n\n\n\nand\n\n\n\nlocated besides each filtering column. In the popup window, users can search for projects and make single or multiple selections.\n\n\n\n\nSingle clicking on a project in the \nProject Browser\n will show the meta data related to this project in the main view window. Click on any project. The Project tab of the main view window is updated with the published information for this project. The Project tab contains a number of meta data tabs, including General, Platform, Contact, Custom, Content, Design, Inference Report, Category, and Publish. Click on each of these tabs now to see the different meta data that can be seen for each project.\n\n\n\n\nNotice the \nCategory\n tab, which contains meta data on the category to which the project belongs. This is the tab that is used to populate the Category browser. When uploading a project (only if the user has write access to a project), this information can be edited.\n\n\n\n\nNotice that the \nPublish\n tab shows information about how the project was published, including Published by, Publish date, Readers, Editors, and Contributors. Readers and Editors show the user groups that have read and write access to this particular project. In addition, for users connected to internal servers, there is the option to upload private projects, which cannot be viewed by other users (other than administrators). There is also an option to \nView Project Audit Trail\n, which will show the Audit Trail, in OmicScript form, of every major action taken by the analyst when analyzing the project (or the steps performed by Omicsoft to analyze the public projects).\n\n\n\n\nNotice that the \nContent\n tab contains a list of all data that was uploaded with the project, as well as the index status of the data. If a dataset or table is \nIndexed\n, it can be searched within Array Viewer. This would mean that the testing results contain rows that are indexed (probesets) that can be searched, while the summary Table does not, and thus it cannot be searched.\n\n\n\n\nThe \nDesign\n tab shows the design table information (sample information) for each project. For projects with multiple datasets, there will be multiple dataset names available in the Data name dropdown box. This is useful in getting information about the samples contained in each project, without having to download data for that project. Note that any of these tables can be easily exported to Excel or saved as text using the toolbar above the table.\n\n\n\n\nThe \nInferenceReport\n tab contains information on any inference reports created. For each tests table in the Data name dropdown box, each comparison is shown, with information as to whether Raw p-value, Adjusted p-value, Estimate, Fold change, and Max(LSMean) (to be used as an intensity filter ) are available. Contrasts can be categorized into a Test type, and this can be shown here as well (and used for filtering with the Search Inference Report module). A description of each contrast (or test) can also be entered by the user upon uploading a project (or edited by a user with write access to that project). For users not familiar with the concept of a  contrast  or  test , think of it as a  ratio , complete with p-value and fold change information, as well as the maximum intensity for each group in the test.",
            "title": "Getting Started"
        },
        {
            "location": "/tutorials/ServerExplorer/Getting_Started/#getting-started",
            "text": "Server explorer contains functions to search and display data stored in Array Server. Both Array Studio and Array Viewer contain the Server tab. Array Viewer is a separate product to view data shared in Array Server, having the same functionalities as ones in  Server/Land/Browser  tabs in ArrayStudio.  In this tutorial, we focus on modules in the Server tab in Array Viewer. They are the same in Array Studio Server tab. The tutorial is based on published projects in Array Server.",
            "title": "Getting Started"
        },
        {
            "location": "/tutorials/ServerExplorer/Getting_Started/#installation-and-setup",
            "text": "To start Array Viewer for the first time, click on the following link:  link  Make sure to use  Internet Explorer  for this process.\nArray Viewer in Internet Explorer requires the installation of the .NET 3.5 framework. For users with the .NET framework already installed, clicking Install will proceed to login and launch of Array Viewer, as shown below.   Click the Edit button to edit the Omicsoft server of your choice and enter username and password information, or for internal servers, click the Add button to add a new server to the list.  This opens the Server Information window. The user has the ability to edit the name of the server, server address, as well as User ID and Password. At this point, the user should enter the User ID and Password provided to them by their Array Server Administrator. Some internal servers may not require  user authorization , and this should also be indicated by the Administrator. Click OK to save the Server Information.   After editing the server, click the  Connect  button to connect to the server of your choice. After a successful login to the server, Array Viewer should look similar to the following screenshot:   Click on the Server tab where the default view will be the Wizard.",
            "title": "Installation and Setup"
        },
        {
            "location": "/tutorials/ServerExplorer/Getting_Started/#wizard",
            "text": "When the user initially opens the Server tab in Array Viewer, a wizard is shown, that allows the user to quickly get started. All search functionality can be done from the wizard.   At this point, the user can click the  Search Server  button and should see a window similar to the following (note: the number of projects and name of tabs may not match exactly).",
            "title": "Wizard"
        },
        {
            "location": "/tutorials/ServerExplorer/Getting_Started/#project-browser-tagging-and-meta-data",
            "text": "The left hand side of the screen provides the user a way to manually browse projects, either by Category, or using the advanced Filter option for projects.  ArrayStudio makes filtering projects very easy. Users can use the check box to filter projects.   Besides using the check box, users can click on the icons   and  located besides each filtering column. In the popup window, users can search for projects and make single or multiple selections.   Single clicking on a project in the  Project Browser  will show the meta data related to this project in the main view window. Click on any project. The Project tab of the main view window is updated with the published information for this project. The Project tab contains a number of meta data tabs, including General, Platform, Contact, Custom, Content, Design, Inference Report, Category, and Publish. Click on each of these tabs now to see the different meta data that can be seen for each project.   Notice the  Category  tab, which contains meta data on the category to which the project belongs. This is the tab that is used to populate the Category browser. When uploading a project (only if the user has write access to a project), this information can be edited.   Notice that the  Publish  tab shows information about how the project was published, including Published by, Publish date, Readers, Editors, and Contributors. Readers and Editors show the user groups that have read and write access to this particular project. In addition, for users connected to internal servers, there is the option to upload private projects, which cannot be viewed by other users (other than administrators). There is also an option to  View Project Audit Trail , which will show the Audit Trail, in OmicScript form, of every major action taken by the analyst when analyzing the project (or the steps performed by Omicsoft to analyze the public projects).   Notice that the  Content  tab contains a list of all data that was uploaded with the project, as well as the index status of the data. If a dataset or table is  Indexed , it can be searched within Array Viewer. This would mean that the testing results contain rows that are indexed (probesets) that can be searched, while the summary Table does not, and thus it cannot be searched.   The  Design  tab shows the design table information (sample information) for each project. For projects with multiple datasets, there will be multiple dataset names available in the Data name dropdown box. This is useful in getting information about the samples contained in each project, without having to download data for that project. Note that any of these tables can be easily exported to Excel or saved as text using the toolbar above the table.   The  InferenceReport  tab contains information on any inference reports created. For each tests table in the Data name dropdown box, each comparison is shown, with information as to whether Raw p-value, Adjusted p-value, Estimate, Fold change, and Max(LSMean) (to be used as an intensity filter ) are available. Contrasts can be categorized into a Test type, and this can be shown here as well (and used for filtering with the Search Inference Report module). A description of each contrast (or test) can also be entered by the user upon uploading a project (or edited by a user with write access to that project). For users not familiar with the concept of a  contrast  or  test , think of it as a  ratio , complete with p-value and fold change information, as well as the maximum intensity for each group in the test.",
            "title": "Project Browser, Tagging, and Meta Data"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/",
            "text": "Searching Projects\n\u00b6\n\n\nArray Viewer/Server Explorer offers the ability to quickly search meta data for particular terms.\nFor instance, if the user wants to search all projects for the term  cancer , this can easily be done.\nAll searches in Array Viewer can be done using the \nSearch\n dropdown box at the top of the screen and choosing \nWizard\n.\n\n\nIn Array Viewer/Server Explorer, it s possible to search the Project, the Variable, and the Observation (sample information).\nFirst, we will demonstrate searching just the project meta data, but you will soon see that both projects and variables can be searched.\n\n\n\n\nNote\n\n\nIn Array Viewer, searching variables is equivalent to searching genes, SNPs, CNVs, etc.\n\n\n\n\nSearching Project Meta Data\n\u00b6\n\n\nTo search project meta data, use the Filter Project tab.\nOptions for this tab include searching by full text search, or sub setting the data via the Disease, Organism, Platform, or Custom tabs.\n\n\nType \nneoplasms\n into the search field for Project (full text search).\n\n\nNotice that Array Viewer has an auto-fill feature, that attempts to fill in known meta data information as you type (This is a good indicator of terms contained on the server, and can be helpful when searching).\n\n\nThis is extremely helpful for finding projects of interest. For instance, in the example below, typing \"cancer\" into the search box will either search all project meta data fields for cancer, or search particular columns or levels for the term. The user can choose to return, for instance, any project where the column DiseaseState, contains \"cancer\". Another common search would be searching for projects that contain Age, Ethnicity, Gender, etc.\n\n\nThe best way to search for projects related to cancer would be to use the disease classifications built into the GEO data in Array Server, and to search for a term like neoplasms. Choose  Category neoplasms , as shown below, pertaining to any project that belongs to the category of neoplasms. Click OK to save the pattern (Array Server uses its own pattern system to tell the server how to search, although this never has to be learned by the user).\n\n\n\n\nClick \nSearch Server\n to begin the search.\n\n\nThe server will search for all projects with the disease classification of \nneoplasms\n.\n\n\nThe Report Tab\n\u00b6\n\n\nAfter every search in Array Viewer, a new tab is opened, containing all the search information and results for each search. These are named incrementally, from Project, Project_2, Project_3, etc. Notice that after performing the search for cancer, a new tab is created, called Project_2.\n\n\n\n\nSelecting \nAll Tasks | Show Project Report\n will return the report of all projects returned from that search. Click this now.\n\n\n\n\nThis opens a floating window with a table of the projects that matched the results of the search.\n\n\nThis table contains the list of projects that have meta data that match the results of the search, as well as a link to Download the data (demonstrated later), Organism, Study Type, Sample #, Platform, PublishDate, Category information, PublishedBy information, Title of project, and the number of rows that match the symbol searched. As we did not search a symbol, the Matched column should return the total number of rows (or variables/markers/probesets) in each project.\n\n\n\n\nThe floating report can be sorted by right-clicking on any header in the table. In addition, it can be exported to Excel or saved as a text file by using the toolbar above the report (this is standard in any table view in Array Viewer).\n\n\n\n\nProject tab meta data\n\u00b6\n\n\nNow, let s take a look at which projects were returned by our search. If the floating report window is still open, close it now.\n\n\nScroll to and click on gse10063, to see the meta data for this particular project.\n\n\n\n\nSwitching to the \nCategory\n tab will show that this project belongs to the Neoplasm disease classification, specifically Leukoplakia, Oral.\n\n\n\n\nDownloading Project for Analysis in Array Studio\n\u00b6\n\n\nFor users with internal servers and licensed copies of Array Studio, projects can be downloaded to be further analyzed and refined by the user.\n\n\nThis can be done by clicking on any of the returned projects in the Project Browser and clicking the \nAll Tasks\n dropdown menu at the top of the Project Browser. Then, choose \nDownload Filtered Project To Local\n from this menu.\n\n\n\n\nThis opens a dialog box for saving the project, which will be downloaded in its entirety to the user s local machine in the specified folder. For the purposes of this tutorial, this is not necessary, but it should be noted that the project is downloaded in the exact state that it was originally uploaded, including any views, analyses, etc.\n\n\nAlternatively, users can double-click the selected project. Multiple options are provided for downloading the project:\n\n\n\n\nFiltering Variables\n\u00b6\n\n\nOne of the real powers of Array Viewer lies in its ability to visualize analysis results and views that were uploaded by the original analyst, as well as the ability to add new views for projects. While it is possible to view all the rows in a project in the server, this is not always recommended. Sometimes the recommended option is to do a search for a particular Variable (Gene names or Probe/ProbeSet names). The result will be a list of projects in the Project Browser containing the number of rows matching the Variable we have searched.\n\n\nLet s do a search again, but this time, we will look for projects containing category neoplasms, and the gene symbol \negr1\n.\n\n\n\n\nClick \nSearch Server\n to begin the search. Matching projects are returned in the Results window.\n\n\n\n\nNow, let s take a look at one of these projects. Scroll to and click on gse10063. By taking a look at the meta data, we can see that this is a project looking at the effects of tobacco smoke on gene expression and cellular pathways in a cellular model of oral leukoplakia.\n\n\n\n\nTo take a closer look at the data for this project, we have four options. Double-click on \ngse10063\n now. The user will be prompted with multiple options for downloading the project:\n\n\n\n\nSelect the second option and click \nOK\n.\n\n\n(The first time an annotation-type is downloaded as cache to your machine, the binary annotation will be downloaded as well. Each subsequent time will be faster as the annotation will not need to be re-downloaded).\n\n\nThis returns all of the data related to the ID \negr1\n for this project. In the Project Browser, notice that there is now a tree, containing a number of datasets and results tables. These are the exact datasets and results tables that were uploaded by the original analyst, containing all of the observations (60 chips) and 3 of the rows (expand the nodes of the explorer to see similar to below).\n\n\n\n\nOpen up the \n.Tests\n table, containing the results of any statistical tests performed on this project, and double-click on the Report view.\n\n\n\n\nBefore we delve too far into this project, note the Gene Symbol column. We ve returned only symbols that are EGR1, as we might have expected.\n\n\n\n\nViews and Customizations\n\u00b6\n\n\nCustomizing a view\n\u00b6\n\n\nNow expand the dataset GSE10063 HG-U133_Plus_2 and double-click on the view \nVariable\n to see the view created by the user that uploaded the data.\n\n\n\n\nThis view shows all of the 60 chips from this experiment and their expression. For many projects, this will be automatically grouped using BiologicalGroup, which is the group that was used for the creation of any analysis and inference report. There are 3 charts, one for each variable representing \negr1\n.\nThe important point to take home from this is that this view was created by the analyst.\nAny and all views created by the analyst are visible in Array Viewer.\n\n\n\n\nNotice the Task tab on the right-hand side of the screen. This is the exact same Task tab that is contained in Array Studio, and allows the user of Array Viewer to further customize a view. In addition, the user has the option to further filter the view using the Observation and Variable tabs as well. The screenshot above is after \nflip X/Y\n. Click on \nChange Profile Gallery\n in the Task tab (under Customize) now.\n\n\n\n\nChange the gallery type to \nBoxplot\n and click \nOK\n.\n\n\nNotice that the view has been updated to show a boxplot plot representation of this particular probeset s expression across all of its chips in each group. This view can be further customized, if needed in \nchange symbol properties\n for dot color, shape, jitter and etc.\n\n\n\n\nFiltering a View\n\u00b6\n\n\nBesides using the Task tab, the user has the option of customizing a view, by using the \nVariable\n and\n\nObservation\n tabs in view \ncontroller\n to further filter the data.\n\n\nClick on the \nObservation\n tab to see the available filters for this dataset.\n\n\n\n\nExpand the filter Treatment to see the treatments that can be filtered. Click on Tobacco smoke to see only those samples that were treated with tobacco smoke.\n\n\n\n\nNotice that the main view window is updated to now only show those chips associated with tobacco smoke treatment. The available filters in the \nObservation\n tab are from the \nDesign\n table of this project, and are dependent on what the analyst uploaded when uploading the project.\n\n\n\n\nRight-clicking on a filter column will usually allow the user to change the type of filter, from a \nRadio filter\n (allowing selection of one group or all groups), a \nCheckbox filter\n (allowing the selection of multiple groups, all, or none), and a \nString filter\n (allowing the entering of a string for filtering). Sometimes not all of these options are available, as it is dependent on the column type for that column (i.e. numeric, factor, character, etc.). Change the filter back to (all) before continuing.\n\n\n\n\nNote that all the views can be saved as pictures/texts, or opened in Excel or PowerPoint by using the toolbar contained over the views.\n\n\n\n\nCreating A New View\n\u00b6\n\n\nBesides the ability to look at views that were created by the original analyst, the user has the ability to add new views for their own purposes. These views are not saved back to the server with the project (unless the user shares the view in which case a static representation of the view is saved to the server), but can be opened and saved as pictures, in Excel, or in PowerPoint.\n\n\nTo add a new view, click the \nView\n menu and then \nAdd View\n.\n\n\n\n\nThen, choose the dataset or table to which you want to add the view (in this case GSE10063 HG-U133_Plus_2). Array Viewer and Array Studio always give the user the choice as to which dataset or table to add a view.\n\n\n\n\nAlternatively, you can right-click on the dataset of which you want to add a view, and click Add View.\n\n\n\n\nThis opens the \nAdd View\n dialog box. Click \nHeatmapView\n and click OK to add a \nHeatmapView\n to the dataset. This window is context-sensitive and contains all the views available for that type of data or table. Inference tables have different views available than MicroArray data, which has different views available than copy number data, etc.\n\n\n\n\nThe \nHeatmapView\n is created and can be further customized, filtered, etc., and then be saved by the user in Excel, PowerPoint, or as a picture.\n\n\n\n\nData Menu\n\u00b6\n\n\nWhen using Array Viewer, you cannot perform additional analysis on the data. Analysis can only be performed by using Array Studio. However, Array Viewer does offer the user the option to perform some manipulation features on datasets and tables. These manipulations are not permanent, and are not uploaded to the server. However, they can be used for temporary purposes. For  OMIC datasets, the Data menu is available for manipulations. Also, for manipulation of table data, the Table menu can be used.\n\n\nClick the \nOmicData\n menu now to see the list of manipulation options available for microarray data. Options include subsetting data, splitting data, merging data, concatenating data, deleting data, sort variables, sort observations, generating contrast data, exporting data, and uploading the results of an inference report to GeneGo.\n\n\nChoose Split now to split the dataset into multiple parts, using the design table.\n\n\n\n\nThis opens the Select Data window. Choose the dataset we have been working with, and click OK. Note, it is possible to have multiple projects data downloaded at the same time, and thus you may be given the option of which project and dataset upon which to perform the split. In this case, there was only one  dataset  downloaded (although there were other tables and inference reports).\n\n\n\n\nThis opens the \nSplit Data\n window. Choose Split observations, and choose Treatment from the drop-down menu. Click \nCheck All\n to split the data into all 3 of the Groups. Click \nOK\n to continue.\n\n\n\n\nNotice that after splitting, 2 new datasets have been created and views are now accessible in the project browser. Note: These changes are not permanent, and are not stored on the server, but are for temporary purposes only.\n\n\n\n\nSharing a View\n\u00b6\n\n\nOne of the key features of Array Viewer is the ability to share any customized view with another user. This view is saved statically (like a snapshot of the data), so even if the original data changes, this view is still the same.\n\n\nLet s share the view we just created (the HeatmapView). If this view is not the current view, switch to it now. You can switch the open view using the list of views at the top of the main section of the window, or by finding it again and double-clicking in the Project Browser. To share a view, click the \nShare\n dropdown box and choose \nShare View\n.\n\n\n\n\nThis opens the Share View window. The user has the ability to create a Title and Description for the view, as well as to set the User groups and/or individual Users that can see the view.\n\n\nEnter a \nTitle\n and a \nDescription\n now, and then click OK to continue.\n\n\n\n\nArray Viewer will inform you that the view has been shared, and assign it a view ID.\n\n\nClick OK.\n\n\n\n\nIn addition, Array Viewer will automatically open up your default email program, containing a link to the shared view, which you can use to send to a colleague, similar to the screenshot below.\n\n\n\n\nOther options regarding \nShared Views\n include opening a previously shared view, re-sharing a view (to once again create an email link), and un-sharing a previously shared view, all available from the Share dropdown menu.\n\n\nBatch Searching Projects\n\u00b6\n\n\nBesides being able to search for a project using a single project search term and single symbol term, Array Studio offers the ability to do a batch search.\n\n\nThis time, instead of filtering projects by full-text search, we will use the tabs for Organism, Platform, and Custom. These tabs allow the user to filter by predefined fields, specified by the administrator. Click on the \nCustom\n tab to see the options for filtering by multiple projects in a customized manner.\n\n\n\n\nAdd Criterion\n can be used to add a filter for a specific field to the batch search. Alternatively, \nAdd List\n can be used to filter by a general criterion, or a project list.\n\n\nClick \nAdd List\n to add a filter criterion to the batch search.\n\n\n\n\nThis opens the \nInput Project List\n window. Change Input list is to (anything) and enter hypoxia, heart failure, and cholesterol in the search box. Click \nOK\n to continue.\n\n\n\n\nThe Custom tab is updated to reflect the added filters.\n\n\n\n\nHere, we specify the field to be anything. We can explicitly specify the field to be ProjectID and other metadata design columns.",
            "title": "Searching Projects"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#searching-projects",
            "text": "Array Viewer/Server Explorer offers the ability to quickly search meta data for particular terms.\nFor instance, if the user wants to search all projects for the term  cancer , this can easily be done.\nAll searches in Array Viewer can be done using the  Search  dropdown box at the top of the screen and choosing  Wizard .  In Array Viewer/Server Explorer, it s possible to search the Project, the Variable, and the Observation (sample information).\nFirst, we will demonstrate searching just the project meta data, but you will soon see that both projects and variables can be searched.   Note  In Array Viewer, searching variables is equivalent to searching genes, SNPs, CNVs, etc.",
            "title": "Searching Projects"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#searching-project-meta-data",
            "text": "To search project meta data, use the Filter Project tab.\nOptions for this tab include searching by full text search, or sub setting the data via the Disease, Organism, Platform, or Custom tabs.  Type  neoplasms  into the search field for Project (full text search).  Notice that Array Viewer has an auto-fill feature, that attempts to fill in known meta data information as you type (This is a good indicator of terms contained on the server, and can be helpful when searching).  This is extremely helpful for finding projects of interest. For instance, in the example below, typing \"cancer\" into the search box will either search all project meta data fields for cancer, or search particular columns or levels for the term. The user can choose to return, for instance, any project where the column DiseaseState, contains \"cancer\". Another common search would be searching for projects that contain Age, Ethnicity, Gender, etc.  The best way to search for projects related to cancer would be to use the disease classifications built into the GEO data in Array Server, and to search for a term like neoplasms. Choose  Category neoplasms , as shown below, pertaining to any project that belongs to the category of neoplasms. Click OK to save the pattern (Array Server uses its own pattern system to tell the server how to search, although this never has to be learned by the user).   Click  Search Server  to begin the search.  The server will search for all projects with the disease classification of  neoplasms .",
            "title": "Searching Project Meta Data"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#the-report-tab",
            "text": "After every search in Array Viewer, a new tab is opened, containing all the search information and results for each search. These are named incrementally, from Project, Project_2, Project_3, etc. Notice that after performing the search for cancer, a new tab is created, called Project_2.   Selecting  All Tasks | Show Project Report  will return the report of all projects returned from that search. Click this now.   This opens a floating window with a table of the projects that matched the results of the search.  This table contains the list of projects that have meta data that match the results of the search, as well as a link to Download the data (demonstrated later), Organism, Study Type, Sample #, Platform, PublishDate, Category information, PublishedBy information, Title of project, and the number of rows that match the symbol searched. As we did not search a symbol, the Matched column should return the total number of rows (or variables/markers/probesets) in each project.   The floating report can be sorted by right-clicking on any header in the table. In addition, it can be exported to Excel or saved as a text file by using the toolbar above the report (this is standard in any table view in Array Viewer).",
            "title": "The Report Tab"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#project-tab-meta-data",
            "text": "Now, let s take a look at which projects were returned by our search. If the floating report window is still open, close it now.  Scroll to and click on gse10063, to see the meta data for this particular project.   Switching to the  Category  tab will show that this project belongs to the Neoplasm disease classification, specifically Leukoplakia, Oral.",
            "title": "Project tab meta data"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#downloading-project-for-analysis-in-array-studio",
            "text": "For users with internal servers and licensed copies of Array Studio, projects can be downloaded to be further analyzed and refined by the user.  This can be done by clicking on any of the returned projects in the Project Browser and clicking the  All Tasks  dropdown menu at the top of the Project Browser. Then, choose  Download Filtered Project To Local  from this menu.   This opens a dialog box for saving the project, which will be downloaded in its entirety to the user s local machine in the specified folder. For the purposes of this tutorial, this is not necessary, but it should be noted that the project is downloaded in the exact state that it was originally uploaded, including any views, analyses, etc.  Alternatively, users can double-click the selected project. Multiple options are provided for downloading the project:",
            "title": "Downloading Project for Analysis in Array Studio"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#filtering-variables",
            "text": "One of the real powers of Array Viewer lies in its ability to visualize analysis results and views that were uploaded by the original analyst, as well as the ability to add new views for projects. While it is possible to view all the rows in a project in the server, this is not always recommended. Sometimes the recommended option is to do a search for a particular Variable (Gene names or Probe/ProbeSet names). The result will be a list of projects in the Project Browser containing the number of rows matching the Variable we have searched.  Let s do a search again, but this time, we will look for projects containing category neoplasms, and the gene symbol  egr1 .   Click  Search Server  to begin the search. Matching projects are returned in the Results window.   Now, let s take a look at one of these projects. Scroll to and click on gse10063. By taking a look at the meta data, we can see that this is a project looking at the effects of tobacco smoke on gene expression and cellular pathways in a cellular model of oral leukoplakia.   To take a closer look at the data for this project, we have four options. Double-click on  gse10063  now. The user will be prompted with multiple options for downloading the project:   Select the second option and click  OK .  (The first time an annotation-type is downloaded as cache to your machine, the binary annotation will be downloaded as well. Each subsequent time will be faster as the annotation will not need to be re-downloaded).  This returns all of the data related to the ID  egr1  for this project. In the Project Browser, notice that there is now a tree, containing a number of datasets and results tables. These are the exact datasets and results tables that were uploaded by the original analyst, containing all of the observations (60 chips) and 3 of the rows (expand the nodes of the explorer to see similar to below).   Open up the  .Tests  table, containing the results of any statistical tests performed on this project, and double-click on the Report view.   Before we delve too far into this project, note the Gene Symbol column. We ve returned only symbols that are EGR1, as we might have expected.",
            "title": "Filtering Variables"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#views-and-customizations",
            "text": "",
            "title": "Views and Customizations"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#customizing-a-view",
            "text": "Now expand the dataset GSE10063 HG-U133_Plus_2 and double-click on the view  Variable  to see the view created by the user that uploaded the data.   This view shows all of the 60 chips from this experiment and their expression. For many projects, this will be automatically grouped using BiologicalGroup, which is the group that was used for the creation of any analysis and inference report. There are 3 charts, one for each variable representing  egr1 .\nThe important point to take home from this is that this view was created by the analyst.\nAny and all views created by the analyst are visible in Array Viewer.   Notice the Task tab on the right-hand side of the screen. This is the exact same Task tab that is contained in Array Studio, and allows the user of Array Viewer to further customize a view. In addition, the user has the option to further filter the view using the Observation and Variable tabs as well. The screenshot above is after  flip X/Y . Click on  Change Profile Gallery  in the Task tab (under Customize) now.   Change the gallery type to  Boxplot  and click  OK .  Notice that the view has been updated to show a boxplot plot representation of this particular probeset s expression across all of its chips in each group. This view can be further customized, if needed in  change symbol properties  for dot color, shape, jitter and etc.",
            "title": "Customizing a view"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#filtering-a-view",
            "text": "Besides using the Task tab, the user has the option of customizing a view, by using the  Variable  and Observation  tabs in view  controller  to further filter the data.  Click on the  Observation  tab to see the available filters for this dataset.   Expand the filter Treatment to see the treatments that can be filtered. Click on Tobacco smoke to see only those samples that were treated with tobacco smoke.   Notice that the main view window is updated to now only show those chips associated with tobacco smoke treatment. The available filters in the  Observation  tab are from the  Design  table of this project, and are dependent on what the analyst uploaded when uploading the project.   Right-clicking on a filter column will usually allow the user to change the type of filter, from a  Radio filter  (allowing selection of one group or all groups), a  Checkbox filter  (allowing the selection of multiple groups, all, or none), and a  String filter  (allowing the entering of a string for filtering). Sometimes not all of these options are available, as it is dependent on the column type for that column (i.e. numeric, factor, character, etc.). Change the filter back to (all) before continuing.   Note that all the views can be saved as pictures/texts, or opened in Excel or PowerPoint by using the toolbar contained over the views.",
            "title": "Filtering a View"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#creating-a-new-view",
            "text": "Besides the ability to look at views that were created by the original analyst, the user has the ability to add new views for their own purposes. These views are not saved back to the server with the project (unless the user shares the view in which case a static representation of the view is saved to the server), but can be opened and saved as pictures, in Excel, or in PowerPoint.  To add a new view, click the  View  menu and then  Add View .   Then, choose the dataset or table to which you want to add the view (in this case GSE10063 HG-U133_Plus_2). Array Viewer and Array Studio always give the user the choice as to which dataset or table to add a view.   Alternatively, you can right-click on the dataset of which you want to add a view, and click Add View.   This opens the  Add View  dialog box. Click  HeatmapView  and click OK to add a  HeatmapView  to the dataset. This window is context-sensitive and contains all the views available for that type of data or table. Inference tables have different views available than MicroArray data, which has different views available than copy number data, etc.   The  HeatmapView  is created and can be further customized, filtered, etc., and then be saved by the user in Excel, PowerPoint, or as a picture.",
            "title": "Creating A New View"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#data-menu",
            "text": "When using Array Viewer, you cannot perform additional analysis on the data. Analysis can only be performed by using Array Studio. However, Array Viewer does offer the user the option to perform some manipulation features on datasets and tables. These manipulations are not permanent, and are not uploaded to the server. However, they can be used for temporary purposes. For  OMIC datasets, the Data menu is available for manipulations. Also, for manipulation of table data, the Table menu can be used.  Click the  OmicData  menu now to see the list of manipulation options available for microarray data. Options include subsetting data, splitting data, merging data, concatenating data, deleting data, sort variables, sort observations, generating contrast data, exporting data, and uploading the results of an inference report to GeneGo.  Choose Split now to split the dataset into multiple parts, using the design table.   This opens the Select Data window. Choose the dataset we have been working with, and click OK. Note, it is possible to have multiple projects data downloaded at the same time, and thus you may be given the option of which project and dataset upon which to perform the split. In this case, there was only one  dataset  downloaded (although there were other tables and inference reports).   This opens the  Split Data  window. Choose Split observations, and choose Treatment from the drop-down menu. Click  Check All  to split the data into all 3 of the Groups. Click  OK  to continue.   Notice that after splitting, 2 new datasets have been created and views are now accessible in the project browser. Note: These changes are not permanent, and are not stored on the server, but are for temporary purposes only.",
            "title": "Data Menu"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#sharing-a-view",
            "text": "One of the key features of Array Viewer is the ability to share any customized view with another user. This view is saved statically (like a snapshot of the data), so even if the original data changes, this view is still the same.  Let s share the view we just created (the HeatmapView). If this view is not the current view, switch to it now. You can switch the open view using the list of views at the top of the main section of the window, or by finding it again and double-clicking in the Project Browser. To share a view, click the  Share  dropdown box and choose  Share View .   This opens the Share View window. The user has the ability to create a Title and Description for the view, as well as to set the User groups and/or individual Users that can see the view.  Enter a  Title  and a  Description  now, and then click OK to continue.   Array Viewer will inform you that the view has been shared, and assign it a view ID.  Click OK.   In addition, Array Viewer will automatically open up your default email program, containing a link to the shared view, which you can use to send to a colleague, similar to the screenshot below.   Other options regarding  Shared Views  include opening a previously shared view, re-sharing a view (to once again create an email link), and un-sharing a previously shared view, all available from the Share dropdown menu.",
            "title": "Sharing a View"
        },
        {
            "location": "/tutorials/ServerExplorer/Searching_Projects/#batch-searching-projects",
            "text": "Besides being able to search for a project using a single project search term and single symbol term, Array Studio offers the ability to do a batch search.  This time, instead of filtering projects by full-text search, we will use the tabs for Organism, Platform, and Custom. These tabs allow the user to filter by predefined fields, specified by the administrator. Click on the  Custom  tab to see the options for filtering by multiple projects in a customized manner.   Add Criterion  can be used to add a filter for a specific field to the batch search. Alternatively,  Add List  can be used to filter by a general criterion, or a project list.  Click  Add List  to add a filter criterion to the batch search.   This opens the  Input Project List  window. Change Input list is to (anything) and enter hypoxia, heart failure, and cholesterol in the search box. Click  OK  to continue.   The Custom tab is updated to reflect the added filters.   Here, we specify the field to be anything. We can explicitly specify the field to be ProjectID and other metadata design columns.",
            "title": "Batch Searching Projects"
        },
        {
            "location": "/tutorials/ServerExplorer/Publishing_Data/",
            "text": "Publishing Data\n\u00b6\n\n\nAny Array Studio user has the ability to publish data to the server.\n\n\n\n\nThis can also be done through Array Viewer, and only requires the user to have access to a project file.\nIf the user of this tutorial does not have access to a project file, and to an internal server, this section can be skipped.\n\n\nClick \nPublish Project\n from the Publish dropdown box.\n\n\n\n\nChoose the \nproject\n \n.osprj\n file that you have saved and are ready to publish. The project cannot be opened while being published in Server Explorer.\n\n\n\n\nThis opens the Publish Project window. In this window, you must first choose the data/items to publish. Any number of data, tables, and lists can be published.\n\n\nNext, you must choose which of these published data and tables will be enabled for full-text search. This is an extremely important step, as only those selected data and tables will be searchable (those not chosen will be uploaded, and available for download, but not searchable).\n\n\nNext, the Meta Data needs to be entered. If you are replacing an existing project, you can use the Load Meta Data From Existing Project button to choose an existing project s meta data.\n\n\nMeta data tabs include General, Platform, Contact, Custom, Category, and Publish (Note: For internal servers, the administrator has the ability to completely customize meta data, so this may look different).\n\n\nThe ProjectID field can be used to replace a project. If a project with a particular ProjectID already exists on the server, the user will receive a warning message asking if they want to replace that project. Leaving the ProjectID field blank will generate an automatic ProjectID for that project.\n\n\n\n\nClick the Publish tab, as this tab contains important information. This allows the user to select which User Groups will have Read and Editor Access to a project. A Project is Private checkbox allows the user to upload a project for private use only.\n\n\n\n\nClicking the Publish button will upload your Array Studio project to the server, where it will be fully searchable and available to the selected User Groups.\n\n\nNote: Certain fields may be required in order to publish a project (when it is not private). These fields may differ depending on the administrator.\n\n\nMore information on options for publishing can be found in the individual help module.",
            "title": "Publishing Data"
        },
        {
            "location": "/tutorials/ServerExplorer/Publishing_Data/#publishing-data",
            "text": "Any Array Studio user has the ability to publish data to the server.   This can also be done through Array Viewer, and only requires the user to have access to a project file.\nIf the user of this tutorial does not have access to a project file, and to an internal server, this section can be skipped.  Click  Publish Project  from the Publish dropdown box.   Choose the  project   .osprj  file that you have saved and are ready to publish. The project cannot be opened while being published in Server Explorer.   This opens the Publish Project window. In this window, you must first choose the data/items to publish. Any number of data, tables, and lists can be published.  Next, you must choose which of these published data and tables will be enabled for full-text search. This is an extremely important step, as only those selected data and tables will be searchable (those not chosen will be uploaded, and available for download, but not searchable).  Next, the Meta Data needs to be entered. If you are replacing an existing project, you can use the Load Meta Data From Existing Project button to choose an existing project s meta data.  Meta data tabs include General, Platform, Contact, Custom, Category, and Publish (Note: For internal servers, the administrator has the ability to completely customize meta data, so this may look different).  The ProjectID field can be used to replace a project. If a project with a particular ProjectID already exists on the server, the user will receive a warning message asking if they want to replace that project. Leaving the ProjectID field blank will generate an automatic ProjectID for that project.   Click the Publish tab, as this tab contains important information. This allows the user to select which User Groups will have Read and Editor Access to a project. A Project is Private checkbox allows the user to upload a project for private use only.   Clicking the Publish button will upload your Array Studio project to the server, where it will be fully searchable and available to the selected User Groups.  Note: Certain fields may be required in order to publish a project (when it is not private). These fields may differ depending on the administrator.  More information on options for publishing can be found in the individual help module.",
            "title": "Publishing Data"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_FileManagement/",
            "text": "Server File Management\n\u00b6\n\n\nThe user has the option of accessing the raw data management system via Server Explorer in Array Studio.\nThey can do so by choosing \nServer Files | Browse Files\n in the Server Explorer.\n\n\nBrowse Files\n\u00b6\n\n\n\n\nIn the screenshot below, notice that there are two levels to the ServerFiles tab that is opened when you choose Browse Files. On the top level is a browser. The user can go up or down a level, create new folders (where appropriate), download files, or upload files. The user can also refresh the FTP folder they were previously viewing.\n\n\n\n\nWhen uploading or downloading from the raw data management system, progress for the transfer is shown on the lower part of the screen. This FTP transfer system supports a queue, so one file is transferred at a time until the queue is completed. The user can right click to stop and start a file in the queue.\n\n\nThe user can also right-click on individual files to Download the file, Create New Folder, Refresh, Delete (only allowed by administrators), Rename (only allowed by administrators), Copy URLs (to get a copy of the exact location of the file of interest), or move the file to other locations in the server.\n\n\n\n\nBrowse Files in Windows Explorer\n\u00b6\n\n\nThe user can also access the FTP site using \nWindows Explorer\n by choosing \nServer File | Browse Files in Windows Explorer\n from the Server Explorer menu. This can be useful for quickly uploading data by  drag and drop  from folders in Windows.\n\n\nBrowse Files in Master Server\n\u00b6\n\n\nIf ArrayServer has been set up using Master-Analytic setting, users can only browse the analytic server they are logged into with \nBrowse Files\n. The user can choose to browse contents in Master server by \nServer File | Browse Files\n \n(Master Server)\n from the \nServer Explorer\n menu.\n\n\n\n\nFor more details regarding master and analytic server, please read the following wiki article:\n\nlink",
            "title": "Server File Management"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_FileManagement/#server-file-management",
            "text": "The user has the option of accessing the raw data management system via Server Explorer in Array Studio.\nThey can do so by choosing  Server Files | Browse Files  in the Server Explorer.",
            "title": "Server File Management"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_FileManagement/#browse-files",
            "text": "In the screenshot below, notice that there are two levels to the ServerFiles tab that is opened when you choose Browse Files. On the top level is a browser. The user can go up or down a level, create new folders (where appropriate), download files, or upload files. The user can also refresh the FTP folder they were previously viewing.   When uploading or downloading from the raw data management system, progress for the transfer is shown on the lower part of the screen. This FTP transfer system supports a queue, so one file is transferred at a time until the queue is completed. The user can right click to stop and start a file in the queue.  The user can also right-click on individual files to Download the file, Create New Folder, Refresh, Delete (only allowed by administrators), Rename (only allowed by administrators), Copy URLs (to get a copy of the exact location of the file of interest), or move the file to other locations in the server.",
            "title": "Browse Files"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_FileManagement/#browse-files-in-windows-explorer",
            "text": "The user can also access the FTP site using  Windows Explorer  by choosing  Server File | Browse Files in Windows Explorer  from the Server Explorer menu. This can be useful for quickly uploading data by  drag and drop  from folders in Windows.",
            "title": "Browse Files in Windows Explorer"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_FileManagement/#browse-files-in-master-server",
            "text": "If ArrayServer has been set up using Master-Analytic setting, users can only browse the analytic server they are logged into with  Browse Files . The user can choose to browse contents in Master server by  Server File | Browse Files   (Master Server)  from the  Server Explorer  menu.   For more details regarding master and analytic server, please read the following wiki article: link",
            "title": "Browse Files in Master Server"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_Sample_Management/",
            "text": "Server Sample Management\n\u00b6\n\n\nSamples and sample sets are registered and managed on the server, along with their corresponding meta data.\nAn -Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic element for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria.\n\n\nPlease read more details in the \nSample Management\n tutorial.",
            "title": "Server Sample Management"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_Sample_Management/#server-sample-management",
            "text": "Samples and sample sets are registered and managed on the server, along with their corresponding meta data.\nAn -Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic element for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria.  Please read more details in the  Sample Management  tutorial.",
            "title": "Server Sample Management"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_Administration/",
            "text": "Server Administration\n\u00b6\n\n\nIf you are administrator, you can manage server jobs, user profile, pipeline scripts, chip/gene annotation\nand other predefined list/sets in the Manage dropdown list menu:",
            "title": "Server Administration"
        },
        {
            "location": "/tutorials/ServerExplorer/Server_Administration/#server-administration",
            "text": "If you are administrator, you can manage server jobs, user profile, pipeline scripts, chip/gene annotation\nand other predefined list/sets in the Manage dropdown list menu:",
            "title": "Server Administration"
        },
        {
            "location": "/tutorials/GenomeBrowser/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nGenome Browser\n\u00b6\n\n\nOmicSoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). The Genome Browser tab can be found in Array Studio and Array Viewer software:\n\n\n\n\nThe OmicSoft Genome Browser can visualize NGS data in 32-bit mode on a Windows 32-bit computer with 2GB of RAM minimum, or in 64-bit mode on a Windows 64-bit computer with 8GB of RAM.\n64-bit mode can run much faster than 32-bit mode, and is highly recommended when there is no Array Server connection and alignment files are not indexed.\n\n\nIt is highly recommended that the users complete the prerequisite for this tutorial: RNA-Seq and DNA-Seq tutorial, as a way to learn the basics in sequencing data analysis.\n\n\nTest Dataset\n\u00b6\n\n\nThis Genome Browser tutorial will cover the importing and visualizing six NGS alignment files generated from RNA-Seq and DNA-Seq tutorial.\n\n\n\n\n\n\n\n\nSample ID\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSRR064173.subset\n\n\nDNA-Seq alignment BAM\n\n\n\n\n\n\nSRR064173.FusionSE\n\n\nDNA fusion junction spanning reads detected by ArrayStudio\n\n\n\n\n\n\nSRR064173.FusionPE\n\n\nDNA inter gene fusion read pairs detected by ArrayStudio\n\n\n\n\n\n\nSRR521462.subset\n\n\nRNA-Seq alignment BAM\n\n\n\n\n\n\nSRR521462.FusionSE\n\n\nRNA fusion junction spanning reads detected by ArrayStudio\n\n\n\n\n\n\nSRR521462.FusionPE\n\n\nRNA inter transcript fusion read pairs detected by ArrayStudio\n\n\n\n\n\n\n\n\nTo minimize the file size, we provide a subset of the alignment files containing regions of four genes: BCR, ABL1, NUP214 and XKR3:\n\nlink\n\n\nThis tutorial mainly focuses on browsing next generation sequencing data and its integration with the analytical tools of Array Studio.\nFor more details on general functions and usage of the Genome Browser, please refer to the Genome Browser online help:\n\nlink",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/GenomeBrowser/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/GenomeBrowser/Introduction/#genome-browser",
            "text": "OmicSoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio). The Genome Browser tab can be found in Array Studio and Array Viewer software:   The OmicSoft Genome Browser can visualize NGS data in 32-bit mode on a Windows 32-bit computer with 2GB of RAM minimum, or in 64-bit mode on a Windows 64-bit computer with 8GB of RAM.\n64-bit mode can run much faster than 32-bit mode, and is highly recommended when there is no Array Server connection and alignment files are not indexed.  It is highly recommended that the users complete the prerequisite for this tutorial: RNA-Seq and DNA-Seq tutorial, as a way to learn the basics in sequencing data analysis.",
            "title": "Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Introduction/#test-dataset",
            "text": "This Genome Browser tutorial will cover the importing and visualizing six NGS alignment files generated from RNA-Seq and DNA-Seq tutorial.     Sample ID  Description      SRR064173.subset  DNA-Seq alignment BAM    SRR064173.FusionSE  DNA fusion junction spanning reads detected by ArrayStudio    SRR064173.FusionPE  DNA inter gene fusion read pairs detected by ArrayStudio    SRR521462.subset  RNA-Seq alignment BAM    SRR521462.FusionSE  RNA fusion junction spanning reads detected by ArrayStudio    SRR521462.FusionPE  RNA inter transcript fusion read pairs detected by ArrayStudio     To minimize the file size, we provide a subset of the alignment files containing regions of four genes: BCR, ABL1, NUP214 and XKR3: link  This tutorial mainly focuses on browsing next generation sequencing data and its integration with the analytical tools of Array Studio.\nFor more details on general functions and usage of the Genome Browser, please refer to the Genome Browser online help: link",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/GenomeBrowser/Create_Genome_Browser/",
            "text": "Create Genome Browser\n\u00b6\n\n\nA new browser can be created by choosing the \nNew\n \n\nbutton on the toolbar, or by going to \nFile | New Browser\n.\n\n\nA window will appear and allow the user to specify a reference genome build and gene model track to be loaded into the new browser. If the Reference or Gene model is not listed, the user can build one using Array Studio tools (\nNGS | Build Reference or Gene Model\n). Select the Human.B37.3 Reference and the OmicsoftGene20130723 gene model.\n\n\nClicking the \nBrowse\n button allows the user to specify a location to save the Genome Browser:\n\n\n\n\nNote:\n\n\n\n\n\n\nIf one intends to load a BAM alignment track, the reference in BAM headers has to match the one in the Genome Browser. \n   The version of reference genome in the BAM file can be checked using Array Studio (\nNGS | Tools | Bam Tools | Extract header and infer reference\n).\n\n\n\n\n\n\nIf the user has connected to a server, the newly created genome browser will be a server genome browser, \n   the window for creating a genome browser will be slightly different from creating a local genome browser, \n   and the server genome browser will use reference genome from server (if your server already has that genome reference, \n   you won't need to download it again).\n\n\n\n\n\n\nFor server genome browser, users can still add tracks from local files, but alignment file can't be shared (users can only share the genome browser when they are connected to the server).\n\n\n\n\n\n\nAfter creating a new browser, the default browser window for the chromosome 1 is shown.",
            "title": "Create Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Create_Genome_Browser/#create-genome-browser",
            "text": "A new browser can be created by choosing the  New   \nbutton on the toolbar, or by going to  File | New Browser .  A window will appear and allow the user to specify a reference genome build and gene model track to be loaded into the new browser. If the Reference or Gene model is not listed, the user can build one using Array Studio tools ( NGS | Build Reference or Gene Model ). Select the Human.B37.3 Reference and the OmicsoftGene20130723 gene model.  Clicking the  Browse  button allows the user to specify a location to save the Genome Browser:   Note:    If one intends to load a BAM alignment track, the reference in BAM headers has to match the one in the Genome Browser. \n   The version of reference genome in the BAM file can be checked using Array Studio ( NGS | Tools | Bam Tools | Extract header and infer reference ).    If the user has connected to a server, the newly created genome browser will be a server genome browser, \n   the window for creating a genome browser will be slightly different from creating a local genome browser, \n   and the server genome browser will use reference genome from server (if your server already has that genome reference, \n   you won't need to download it again).    For server genome browser, users can still add tracks from local files, but alignment file can't be shared (users can only share the genome browser when they are connected to the server).    After creating a new browser, the default browser window for the chromosome 1 is shown.",
            "title": "Create Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Adding_Tracks/",
            "text": "Adding Tracks\n\u00b6\n\n\nA number of data types can be added as tracks including:\n\n\n\n\nAlignment files, e.g. BAM, SAM\n\n\nFiles with standard format, e.g. BED, bedGraph, GTF, VCF, BigWig\n\n\nTab-delimited text files containing genomic coordinate information columns (chromosome, start, end)\n\n\nPre-built mapping tracks by Omicsoft, e.g. Affymetrix probes and probesets track, SNP\n\n\nData sets in Analysis tab of Array Studio, e.g. NGS data sets, variable view of -omic data sets\n\n\n\n\nThis section focuses on adding next generation sequencing data files (BAM files). A common task is to add alignment tracks, e.g. BAM files. The BAM alignment track can display a variety of information such as coverage, exon junctions, pileup, profiles, sequences, and variations.\n\n\nIn this tutorial we will add BAM files from a server drive. First, go to \nAdd Track | Add Track From Server File\n.\n\n\n\n\nAdding BAM Files As Single Tracks\n\u00b6\n\n\nIn the \nSpecify Track Source\n window, select \nAlignment track | Sorted BAM file\n.\n\n\n\n\nChoose the two BAM files, \nSRR064173.subset.bam\n (RNA-Seq alignment) and \nSRR521462.subset.bam\n (DNA-Seq alignment). Click \nOpen\n.\n\n\n\n\nThe two new BAM tracks will appear at the bottom of the browser. The first time that tracks are added, it may take a few minutes while indexing is performed. This only occurs once.  \n\n\nThe user can zoom in and out using the mouse wheel or zoom tool at the top right of the tool bar.\n\n\n\n\nWe can navigate to a gene region by typing a gene symbol, e.g. \nabl1\n, in the search box (on the top-left corner, arrow). The coverage will be displayed in red in exon region and blue in intron/intergenic regions.\n\n\n\n\nAdding BAM Files As Combined Tracks\n\u00b6\n\n\nThe user can choose to merge multiple BAM files into a single track. In the Specify Track Source window, select \nAlignment track | multiple sorted BAM files\n.\n\n\n\n\nChoose the four fusion BAM files and click \nOpen\n.\n\n\n\n\nA new track from four BAM files is created in Genome Browser:",
            "title": "Adding Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Adding_Tracks/#adding-tracks",
            "text": "A number of data types can be added as tracks including:   Alignment files, e.g. BAM, SAM  Files with standard format, e.g. BED, bedGraph, GTF, VCF, BigWig  Tab-delimited text files containing genomic coordinate information columns (chromosome, start, end)  Pre-built mapping tracks by Omicsoft, e.g. Affymetrix probes and probesets track, SNP  Data sets in Analysis tab of Array Studio, e.g. NGS data sets, variable view of -omic data sets   This section focuses on adding next generation sequencing data files (BAM files). A common task is to add alignment tracks, e.g. BAM files. The BAM alignment track can display a variety of information such as coverage, exon junctions, pileup, profiles, sequences, and variations.  In this tutorial we will add BAM files from a server drive. First, go to  Add Track | Add Track From Server File .",
            "title": "Adding Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Adding_Tracks/#adding-bam-files-as-single-tracks",
            "text": "In the  Specify Track Source  window, select  Alignment track | Sorted BAM file .   Choose the two BAM files,  SRR064173.subset.bam  (RNA-Seq alignment) and  SRR521462.subset.bam  (DNA-Seq alignment). Click  Open .   The two new BAM tracks will appear at the bottom of the browser. The first time that tracks are added, it may take a few minutes while indexing is performed. This only occurs once.    The user can zoom in and out using the mouse wheel or zoom tool at the top right of the tool bar.   We can navigate to a gene region by typing a gene symbol, e.g.  abl1 , in the search box (on the top-left corner, arrow). The coverage will be displayed in red in exon region and blue in intron/intergenic regions.",
            "title": "Adding BAM Files As Single Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Adding_Tracks/#adding-bam-files-as-combined-tracks",
            "text": "The user can choose to merge multiple BAM files into a single track. In the Specify Track Source window, select  Alignment track | multiple sorted BAM files .   Choose the four fusion BAM files and click  Open .   A new track from four BAM files is created in Genome Browser:",
            "title": "Adding BAM Files As Combined Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/",
            "text": "Browsing Data\n\u00b6\n\n\nNavigation Tools\n\u00b6\n\n\nThere are tools at the top of the genome browser to help the user browse data in Genome Browser:\n\n\n\n\nBrowsing Alignment Tracks\n\u00b6\n\n\nInput \nabl1\n in the gene search box and jump to the ABL1 region. Hovering the mouse pointer over the track labels (e.g. SRR521462) will bring up additional options\n\n\n\n\n\n\n\n\nCoverage\n:  By default, coverage is shown in red for each track added. User can \nHide Coverage\n if desired.\n\n\n\n\n\n\nExon Junction\n: This track displays the number of supporting junctions spanning reads. By default, \nexon junctions\n will be displayed when the current region is <200,000bp. Click \nShow Exon Junction\n.\n\n\n\n\n\n\n\n\n\n\n\n\nVariation\n: This track will display all variations with respect to the reference. This track is useful when examining BAM files from mutation analyses in the Genome Browser. By default, \nVariation\n is only displayed when the display window is <2,000bp. If any alignment track is gray in menu, press Shift and use the left mouse button to select an area to zoom in to a region quickly.\n\n\n\n\n\n\nAlignment profile\n:  Displays blue (positive strand) and green (negative strand) lines for alignment. If the alignment profile is not visible, it can be displayed by clicking the track name and selecting \"Show Alignment Profile\".  The gray lines are those mapping to multiple genomic locations. By default, \nAlignment Profile\n will be visible when the display window is <20,000 bp. \nNote\n: If coverage is high, genome browser will randomly select only 50 reads to show at the same position. The maximal level to display can be specified in the track properties. Click the \n+\n button on the right hand side of the track (arrow) to show all reads.\n\n\n\n\n\n\n\n\n\n\nRead Sequence\n: Will display sequence of individual reads mapped to reference. By default, the \nread sequence\n will be displayed when the current region is < 250bp. Press Shift and use the left mouse button to select an area to zoom in to a region quickly. Click \nShow Read Sequences\n. The user should see the \nread sequences\n colored in blue and green representing the reads on the positive and negative strand, respectively. Mutated nucleotides are in red and low-quality nucleotides are shaded in grey.\n\n\n\n\n\n\n\n\n\n\nAdditional Track Options\n:  \n\n\n\n\n\n\nIf an option is in gray, the user needs to zoom in further.\n\n\n\n\n\n\nThe cutoffs to activate these options are defined in the track properties. These options can be modified by right-clicking on the track, and selecting \"Set Track Properties\":\n\n\n\n\n\n\n\n\nFor instance, change the longest length of when to show exon junctions:\n\n\n\n\nOr change the length when to show the read sequence (just keep in mind the higher the number goes, the more memory required):\n\n\n\n\nIntron Trimming\n\u00b6\n\n\n: For RNA-Seq data, most reads are in exon regions.\nThe genome browser wastes a lot of space by displaying intron and intergenic regions.\nClick the intron trimming button in the toolbar to collapse introns and intergenic regions, so that only exonic regions are displayed.\n\n\n\n\nBrowser Fusion BAM Files\n\u00b6\n\n\nIn this module, we will examine fusion events. When we imported four fusion BAM files, we combined them into a single track. Here, we will look at the individual fusion events that were identified in the DNA-seq file SRR064173. Right click on the BAM fusion track and \nsplit it\n into \nmultiple tracks\n.\n\n\n\n\nIt will show the fusion supporting reads from four sources:\n\n\n\n\nSRR064173.FusionSE: DNA fusion junction spanning reads\n\n\nSRR064173.FusionPE: DNA inter gene fusion read pairs\n\n\nSRR521462.FusionSE: RNA fusion junction spanning reads\n\n\nSRR521462.FusionPE: RNA inter transcript fusion read pairs\n\n\n\n\n\n\nBe sure to remove the option \"Trim intron reads\" as the BCR-ABL1 fusion event occurs within a non-coding breakpoint. To examine fusion reads, use your mouse to left-click and zoom in on the region shown above (within intron 1 of ABL1). \nShow Alignment Profile\n for \nSRR064173.FusionSE\n and you will see reads that are only part green (mapping to ABL1). To determine where the other portion of the read maps, right-click on the green portion of a read from \nSRR064173.FusionSE\n then select \nShow Mate In Next Pane\n\n\n\n\nIt will show the fusion genome browser view (where both ends of the read are shown - see arrows):\n\n\n\n\nThe user can zoom in to show the exact fusion position at genomic level in both genes:\n\n\n\n\nThe user can practice browsing the fusion breakpoints at transcript level on SRR521462.FusionSE and SRR521462.FusionPE tracks. Hint: it is easier to browse predicted RNA-Seq fusion results using intron trimming mode. For further practice, try using this module to identify fusions between the other two genes included in the provided BAM files (XKR3-NUP214).\n\n\nThe user can also return to a one panel mode by simply choosing the drop-down option from the navigation toolbar and selecting 1:",
            "title": "Browsing Data"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/#browsing-data",
            "text": "",
            "title": "Browsing Data"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/#navigation-tools",
            "text": "There are tools at the top of the genome browser to help the user browse data in Genome Browser:",
            "title": "Navigation Tools"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/#browsing-alignment-tracks",
            "text": "Input  abl1  in the gene search box and jump to the ABL1 region. Hovering the mouse pointer over the track labels (e.g. SRR521462) will bring up additional options     Coverage :  By default, coverage is shown in red for each track added. User can  Hide Coverage  if desired.    Exon Junction : This track displays the number of supporting junctions spanning reads. By default,  exon junctions  will be displayed when the current region is <200,000bp. Click  Show Exon Junction .       Variation : This track will display all variations with respect to the reference. This track is useful when examining BAM files from mutation analyses in the Genome Browser. By default,  Variation  is only displayed when the display window is <2,000bp. If any alignment track is gray in menu, press Shift and use the left mouse button to select an area to zoom in to a region quickly.    Alignment profile :  Displays blue (positive strand) and green (negative strand) lines for alignment. If the alignment profile is not visible, it can be displayed by clicking the track name and selecting \"Show Alignment Profile\".  The gray lines are those mapping to multiple genomic locations. By default,  Alignment Profile  will be visible when the display window is <20,000 bp.  Note : If coverage is high, genome browser will randomly select only 50 reads to show at the same position. The maximal level to display can be specified in the track properties. Click the  +  button on the right hand side of the track (arrow) to show all reads.      Read Sequence : Will display sequence of individual reads mapped to reference. By default, the  read sequence  will be displayed when the current region is < 250bp. Press Shift and use the left mouse button to select an area to zoom in to a region quickly. Click  Show Read Sequences . The user should see the  read sequences  colored in blue and green representing the reads on the positive and negative strand, respectively. Mutated nucleotides are in red and low-quality nucleotides are shaded in grey.      Additional Track Options :      If an option is in gray, the user needs to zoom in further.    The cutoffs to activate these options are defined in the track properties. These options can be modified by right-clicking on the track, and selecting \"Set Track Properties\":     For instance, change the longest length of when to show exon junctions:   Or change the length when to show the read sequence (just keep in mind the higher the number goes, the more memory required):",
            "title": "Browsing Alignment Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/#intron-trimming",
            "text": ": For RNA-Seq data, most reads are in exon regions.\nThe genome browser wastes a lot of space by displaying intron and intergenic regions.\nClick the intron trimming button in the toolbar to collapse introns and intergenic regions, so that only exonic regions are displayed.",
            "title": "Intron Trimming"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data/#browser-fusion-bam-files",
            "text": "In this module, we will examine fusion events. When we imported four fusion BAM files, we combined them into a single track. Here, we will look at the individual fusion events that were identified in the DNA-seq file SRR064173. Right click on the BAM fusion track and  split it  into  multiple tracks .   It will show the fusion supporting reads from four sources:   SRR064173.FusionSE: DNA fusion junction spanning reads  SRR064173.FusionPE: DNA inter gene fusion read pairs  SRR521462.FusionSE: RNA fusion junction spanning reads  SRR521462.FusionPE: RNA inter transcript fusion read pairs    Be sure to remove the option \"Trim intron reads\" as the BCR-ABL1 fusion event occurs within a non-coding breakpoint. To examine fusion reads, use your mouse to left-click and zoom in on the region shown above (within intron 1 of ABL1).  Show Alignment Profile  for  SRR064173.FusionSE  and you will see reads that are only part green (mapping to ABL1). To determine where the other portion of the read maps, right-click on the green portion of a read from  SRR064173.FusionSE  then select  Show Mate In Next Pane   It will show the fusion genome browser view (where both ends of the read are shown - see arrows):   The user can zoom in to show the exact fusion position at genomic level in both genes:   The user can practice browsing the fusion breakpoints at transcript level on SRR521462.FusionSE and SRR521462.FusionPE tracks. Hint: it is easier to browse predicted RNA-Seq fusion results using intron trimming mode. For further practice, try using this module to identify fusions between the other two genes included in the provided BAM files (XKR3-NUP214).  The user can also return to a one panel mode by simply choosing the drop-down option from the navigation toolbar and selecting 1:",
            "title": "Browser Fusion BAM Files"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/",
            "text": "Browsing Data from Analyses\n\u00b6\n\n\nArray Studio provides convenient views of -omic and NGS data in genome browser. The Analysis tab has been fully integrated with the Browser tab in Array Studio.\n\n\n\n\nOpen NGS Data in Genome Browser\n\u00b6\n\n\nWe created the \nTutorialRNASeq\n and \nTutorialDNASeq\n projects in the RNA-Seq and DNA-Seq tutorials. The user can open both projects in Analysis Tab.\n\n\nNGS data sets in Analysis projects can be directly loaded into a Genome Browser by going to the Browser tab and clicking \nAdd Track | Add Track from Analysis | Alignment track: NGS data\n.\nIt will ask user to select NgsData loaded in any open (Local and Server) projects.\n\n\n\n\nAlternatively, in the Analysis tab, user can add new genome browser on NgsData directly:\n\n\n\n\nOpen OmicData/Table in Genome Browser\n\u00b6\n\n\nBy using \nAdd Track | Add Track from Analysis\n, user can add Omic Data, such as CNV and MicroArray data, and table data directly to genome browser, as long as they have the chromosome, start, end annotation columns. In this module, we will load data from the CNV Tutorial analysis performed as part of the training module. In the \nAnalysis\n tab at the top of the screen, click \nFile | Open Local Project\n and open the CNV Tutorial. Next, try adding this data to the \nGenome Browser\n.\n\n\n\n\nFirst, try choosing the option \nSegment track: segment data\n and click \"OK\".\n\n\n\n\nFind your open segment table from the CNV tutorial and click \nOK\n:\n\n\n\n\nChoose the default options and click \"OK\" again:\n\n\n\n\nYou will see two additional tracks appear in your \nGenome Browser\n: \nLog2RatioMean\n and \nCNStatus\n. Browse to chromosome 13 within the toolbar and you will find that the \"Beta2\" sample has a \nlog2RatioMean\n of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome:\n\n\n\n\nUsers can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding \nShift\n and left-clicking to highlight a region.\n\n\nIn addition to the segment tracks, one can upload additional CNV tracks. Go to \nAdd Track | Add Track from Analysis\n:\n\n\n\n\nThis time, choose the option \nNumeric track with multiple series: CNV data\n:\n\n\n\n\nFind your CNV analysis output and click \nOK\n. Select the data you want to visualize and click \nOK\n. Here, we choose all the data and set all other parameters to default:\n\n\n\n\nIn this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view:\n\n\n\n\nAs you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:\n\n\n\n\nUsers are encouraged to explore additional features of the genome browser with their own data.\n\n\nViewing ENCODE Data in the Genome Browser\n\u00b6\n\n\nCurrently, nearly 20,000 ENCODE tracks are available for the OmicSoft Genome Browser for Human Genome Reference version 37.3, over 30,000 tracks for Human Genome Reference version38, and over 12,000 tracks for Mouse Genome Reference version 38. These tracks include alignment (bam), coverage (bigWig/gcf), and feature annotation (broadPeak/narrowPeak/gtf/gff3) files. To find tracks of interest, use the Filter Window on the left to subset available tracks by Data Type, Output Type, Assay Terminology Name, Organ, etc.\n\n\nUsers can quickly add genome coverage and annotation data for thousands of ENCODE project experiments, to compare to their data in the Genome Browser. To add ENCODE data, \nclick Add Track | Add Track from ENCODE\n\n\n\n\nENCODE Filters and Data Types\n\u00b6\n\n\nBecause of the sheer abundance in ENCODE tracks (almost 20,000), users will need to filter tracks based on different attributes to find tracks they are specifically interested in. When you add an ENCODE track, you will see a view listing all ENCODE tracks available. On the left side of the window, you should see a number of filters:\n\n\n\n\nSome of the most commonly-used filter columns for assay type are described below:\n\n\n\n\nData Type: The display track type:\n\n\nAligned sequence data - bam\n\n\nBAM tracks load from the actual .bam files, so exon junction, variation, and sequence data for individual reads can be displayed. However, these data are quite large, so BAM tracks can take a long time to update.\n\n\n\n\n\n\n\n\nCoverage track - gcf, bigWig\n\n\n\n\nBigWig tracks are genome coverage data generated by ENCODE.\n\n\nGCF tracks use OmicSoft's custom binary coverage format, enabling extremely fast streaming of genome coverage data. OmicSoft has processed every ENCODE .bam file into a .gcf file, to dramatically improve load times for these data.\n\n\n\n\nBAM, GCF, and BigWig tracks are displayed as coverage files. When you only want genome coverage for a sample, GCF files will load much faster than .bam or BigWig files\n\n\n\n\n\n\nPeak calls - broadPeak, narrowPeak\n\n\n\n\nBroadPeak/NarrowPeak tracks are usually generated by peak-calling algorithms, using different settings, and usually mark high-confidence regions of increased signal (e.g. chromatin accessibility, ChIP signal, etc).\n\n\nFeature annotations - gff3, gtf\n\n\n\n\n\n\nGTF/GFF tracks display feature annotations, such as predicted promoter sites based on CAGE or RAMPAGE assays.\n\n\nOutput Type: The measurement represented by the track\n\n\nAssay Terminology Name: Experimental procedure to generate data (categorized by Assay Category)\n\n\nTranscription - RNA-seq, CAGE, RNA-PET, RAMPAGE\n\n\nDNA accessibility - DNAse-seq, FAIRE-seq, MNase-seq\n\n\nProtein/RNA/DNA binding - ChIP-seq, RIP-seq, eCLIP, iCLIP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdding ENCODE Tracks\n\u00b6\n\n\nIn this module, we will select additional RNA-seq tracks from ENCODE performed on the K562 and MCF-7 cell lines used in the RNA-seq tutorial. To identify these tracks, we will use the following filters/features: \nFile | Data Type | gcf\n, \nExperiment | Assay Title | RNA-seq\n, and \nBiosample | Term\n. For the \nTerm\n filter, create an entry for \"K562 OR MCF-7\". In total, these filters will select RNA-seq alignment coverage from the same cell lines used in the RNA-seq tutorial:\n\n\n\n\nNotice in the upper right hand corner of the window that the number of files available to view reduces with the addition of each filter. For this tutorial, we will load just four of the tracks (2 files from each cell line). Find the four files at the bottom of the table - they should have a description under the column \"Biosample Description\" that reads: \"RNA Evalution (K562 or MCF-7) Long Total from Graveley. Left-click and select all four files (holding down \nShift\n or \nControl\n to select multiple files). Click \nAdd Tracks\n on the bottom of the window. One can also combine tracks by using \nAdd Grouped Tracks\n while multiple files are selected. This will function similar to grouping .gcf files when adding tracks in the beginning of this tutorial.\n\n\n\n\nClick \nClose\n to return to the \nGenome Browser\n. You will find that the four new tracks have been added to your view.\n\n\nCustomizing and Viewing ENCODE Tracks\n\u00b6\n\n\n\n\nOnce tracks have been added, the Genome Browser is fully customizable to better visualize the data. For instance, the track name is not an easy to understand identification, so the user can change this by going to \nOrganize Tracks\n and clicking on the \nMetadata\n tab. As you scroll from left to right, the \nAssay Title\n and \nTerm\n column headers are good indicators of what these samples are. Highlight the four new ENCODE tracks, and click \nSet Labels\n. Choose the \nTerm\n and \nAssay Title\n columns to be listed and click \nOK\n twice.\n\n\n\n\nThe new ENCODE tracks now have simpler identifiers:\n\n\n\n\nNow the user can examine these tracks and compare them to their own data. In this example, we have zoomed in on the 5' end of ABL1. As you can see below, there is a pileup of reads spanning the region of intron 1 where the BCR-ABL1 fusion has occured in K562, while there are no such reads in the MCF-7 cells line.\n\n\n\n\nUsers are encouraged to explore the many ENCODE tracks available to enhance their analyses. Once the tracks of interest have been loaded and identification changed in the genome browser, use \nTrack Properties\n to adjust track heights, colors, and more. For example, in the image above, notice that the track height is set to 0-100 for all four ENCODE BAM files that were added. This allows us to visualize the alignment coverage at the same scale for each of these four tracks.",
            "title": "Browsing Data from Local Analysis"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#browsing-data-from-analyses",
            "text": "Array Studio provides convenient views of -omic and NGS data in genome browser. The Analysis tab has been fully integrated with the Browser tab in Array Studio.",
            "title": "Browsing Data from Analyses"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#open-ngs-data-in-genome-browser",
            "text": "We created the  TutorialRNASeq  and  TutorialDNASeq  projects in the RNA-Seq and DNA-Seq tutorials. The user can open both projects in Analysis Tab.  NGS data sets in Analysis projects can be directly loaded into a Genome Browser by going to the Browser tab and clicking  Add Track | Add Track from Analysis | Alignment track: NGS data .\nIt will ask user to select NgsData loaded in any open (Local and Server) projects.   Alternatively, in the Analysis tab, user can add new genome browser on NgsData directly:",
            "title": "Open NGS Data in Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#open-omicdatatable-in-genome-browser",
            "text": "By using  Add Track | Add Track from Analysis , user can add Omic Data, such as CNV and MicroArray data, and table data directly to genome browser, as long as they have the chromosome, start, end annotation columns. In this module, we will load data from the CNV Tutorial analysis performed as part of the training module. In the  Analysis  tab at the top of the screen, click  File | Open Local Project  and open the CNV Tutorial. Next, try adding this data to the  Genome Browser .   First, try choosing the option  Segment track: segment data  and click \"OK\".   Find your open segment table from the CNV tutorial and click  OK :   Choose the default options and click \"OK\" again:   You will see two additional tracks appear in your  Genome Browser :  Log2RatioMean  and  CNStatus . Browse to chromosome 13 within the toolbar and you will find that the \"Beta2\" sample has a  log2RatioMean  of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome:   Users can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding  Shift  and left-clicking to highlight a region.  In addition to the segment tracks, one can upload additional CNV tracks. Go to  Add Track | Add Track from Analysis :   This time, choose the option  Numeric track with multiple series: CNV data :   Find your CNV analysis output and click  OK . Select the data you want to visualize and click  OK . Here, we choose all the data and set all other parameters to default:   In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view:   As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:   Users are encouraged to explore additional features of the genome browser with their own data.",
            "title": "Open OmicData/Table in Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#viewing-encode-data-in-the-genome-browser",
            "text": "Currently, nearly 20,000 ENCODE tracks are available for the OmicSoft Genome Browser for Human Genome Reference version 37.3, over 30,000 tracks for Human Genome Reference version38, and over 12,000 tracks for Mouse Genome Reference version 38. These tracks include alignment (bam), coverage (bigWig/gcf), and feature annotation (broadPeak/narrowPeak/gtf/gff3) files. To find tracks of interest, use the Filter Window on the left to subset available tracks by Data Type, Output Type, Assay Terminology Name, Organ, etc.  Users can quickly add genome coverage and annotation data for thousands of ENCODE project experiments, to compare to their data in the Genome Browser. To add ENCODE data,  click Add Track | Add Track from ENCODE",
            "title": "Viewing ENCODE Data in the Genome Browser"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#encode-filters-and-data-types",
            "text": "Because of the sheer abundance in ENCODE tracks (almost 20,000), users will need to filter tracks based on different attributes to find tracks they are specifically interested in. When you add an ENCODE track, you will see a view listing all ENCODE tracks available. On the left side of the window, you should see a number of filters:   Some of the most commonly-used filter columns for assay type are described below:   Data Type: The display track type:  Aligned sequence data - bam  BAM tracks load from the actual .bam files, so exon junction, variation, and sequence data for individual reads can be displayed. However, these data are quite large, so BAM tracks can take a long time to update.     Coverage track - gcf, bigWig   BigWig tracks are genome coverage data generated by ENCODE.  GCF tracks use OmicSoft's custom binary coverage format, enabling extremely fast streaming of genome coverage data. OmicSoft has processed every ENCODE .bam file into a .gcf file, to dramatically improve load times for these data.   BAM, GCF, and BigWig tracks are displayed as coverage files. When you only want genome coverage for a sample, GCF files will load much faster than .bam or BigWig files    Peak calls - broadPeak, narrowPeak   BroadPeak/NarrowPeak tracks are usually generated by peak-calling algorithms, using different settings, and usually mark high-confidence regions of increased signal (e.g. chromatin accessibility, ChIP signal, etc).  Feature annotations - gff3, gtf    GTF/GFF tracks display feature annotations, such as predicted promoter sites based on CAGE or RAMPAGE assays.  Output Type: The measurement represented by the track  Assay Terminology Name: Experimental procedure to generate data (categorized by Assay Category)  Transcription - RNA-seq, CAGE, RNA-PET, RAMPAGE  DNA accessibility - DNAse-seq, FAIRE-seq, MNase-seq  Protein/RNA/DNA binding - ChIP-seq, RIP-seq, eCLIP, iCLIP",
            "title": "ENCODE Filters and Data Types"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#adding-encode-tracks",
            "text": "In this module, we will select additional RNA-seq tracks from ENCODE performed on the K562 and MCF-7 cell lines used in the RNA-seq tutorial. To identify these tracks, we will use the following filters/features:  File | Data Type | gcf ,  Experiment | Assay Title | RNA-seq , and  Biosample | Term . For the  Term  filter, create an entry for \"K562 OR MCF-7\". In total, these filters will select RNA-seq alignment coverage from the same cell lines used in the RNA-seq tutorial:   Notice in the upper right hand corner of the window that the number of files available to view reduces with the addition of each filter. For this tutorial, we will load just four of the tracks (2 files from each cell line). Find the four files at the bottom of the table - they should have a description under the column \"Biosample Description\" that reads: \"RNA Evalution (K562 or MCF-7) Long Total from Graveley. Left-click and select all four files (holding down  Shift  or  Control  to select multiple files). Click  Add Tracks  on the bottom of the window. One can also combine tracks by using  Add Grouped Tracks  while multiple files are selected. This will function similar to grouping .gcf files when adding tracks in the beginning of this tutorial.   Click  Close  to return to the  Genome Browser . You will find that the four new tracks have been added to your view.",
            "title": "Adding ENCODE Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Browsing_Data_from_Local_Analysis/#customizing-and-viewing-encode-tracks",
            "text": "Once tracks have been added, the Genome Browser is fully customizable to better visualize the data. For instance, the track name is not an easy to understand identification, so the user can change this by going to  Organize Tracks  and clicking on the  Metadata  tab. As you scroll from left to right, the  Assay Title  and  Term  column headers are good indicators of what these samples are. Highlight the four new ENCODE tracks, and click  Set Labels . Choose the  Term  and  Assay Title  columns to be listed and click  OK  twice.   The new ENCODE tracks now have simpler identifiers:   Now the user can examine these tracks and compare them to their own data. In this example, we have zoomed in on the 5' end of ABL1. As you can see below, there is a pileup of reads spanning the region of intron 1 where the BCR-ABL1 fusion has occured in K562, while there are no such reads in the MCF-7 cells line.   Users are encouraged to explore the many ENCODE tracks available to enhance their analyses. Once the tracks of interest have been loaded and identification changed in the genome browser, use  Track Properties  to adjust track heights, colors, and more. For example, in the image above, notice that the track height is set to 0-100 for all four ENCODE BAM files that were added. This allows us to visualize the alignment coverage at the same scale for each of these four tracks.",
            "title": "Customizing and Viewing ENCODE Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/",
            "text": "Additional Browser Options\n\u00b6\n\n\nIn this chapter, we will explore additional features users can utilize to change the display on the browser, mark specific genome locations, search specific sequences, and share browser views with others.\n\n\nOrganize Tracks\n\u00b6\n\n\nClick \nOrganize Track\n on top.\nIt will allow user to add meta data for tracks.\n\n\n\n\nIn the \nMetaData\n tab, user can import meta data for track. Click \nLoad Meta | Import Table | Tab delimited file | OK\n and find the file \"Design.txt\" you downloaded with the BAM files. Click \nOK\n to load the design.\n\n\n\n\nThe Track label can be switched to any column in the meta data. For example, select the column header \"Sample Name\" and click \nSet Labels\n:\n\n\n\n\nMove the column SampleName to the \"\"Listed columns\" and click \nOK\n twice:\n\n\n\n\nNotice the track names have now changed to reflect this transformation:\n\n\n\n\nTrack Properties\n\u00b6\n\n\nClick \nTrack Properties\n on top or right click select \nSet Track Properties\n.\nIt shows all properties that the user can specify, such as color, font, cutoffs to hide/show coverage, exon junctions, mutations and read sequences.\n\n\n\n\nGenomeMark\n\u00b6\n\n\nGenomeMark is a bookmark-like utility in genome browser. Adding regions into GenomeMark will record genomic regions.\nThe user can jump back to marked regions by a single click on the GenomeMark.\n\n\nClick \nfavorite star\n icon to bookmark the current region:\n\n\n\n\nUser can open GenomeMark and jump to marked regions:\n\n\n\n\nLeft click on the color line to modify the GenomeMark properties.\n\n\nThe user can also import GenomeMark regions via \nFile | Import Custom Regions\n from gene lists or bed files.\n\n\nSequence searching\n\u00b6\n\n\nThe OmicSoft GenomeBrowser also allows searching for DNA and RNA sequences.\n\n\nFirst, click the \"Show/Hide Sequence Search Toolbar\", which will add a new toolbar below the main toolbar.\n\n\n\n\nEnter a DNA or RNA sequence string in the \"Sequence\" search window (shortest sequence for search is 15nt), and click the green arrow to the right.\n\n\n\n\nThe user can specify whether DNA or RNA sequence should be searched, which specifies whether genomic or transcript sequences (including inter-exonic sequences) should be searched.\n\n\nIn addition, the user can specify whether partial or full alignments should be searched, and whether to search only the visible region. Genomic coordinates to Sequence Searches will be saved in the GenomeMark navigator, under the SequenceMatch sub-heading.\n\n\n\n\n\n\nNote\n\n\nIf running ArrayStudio and logged into ArrayServer, a user will get the following message when ArrayServer has not been used to perform an aligment with the chosen \nGenome Reference\n and \nGene Model\n used to start a Genome Browser:\n\n\n\n\n\n\nIf this occurs, there are two solutions to this error and they are outline here:\n\nlink\n\n\nSharing Genome Browser\n\u00b6\n\n\nIf user has ArrayServer and the Genome Browser was created using server components (reference and server BAM files), the Genome Browser is sharable on the server where others can then access it (provided that they have the necessary privileges).\n\n\nClick \nShare | Share Genome Browser\n, specify the genome browser title and privileges.\n\n\n\n\nClick \nOK\n\n\n\n\nIf user has Outlook opened, an email draft with a link will be created.\n\n\n\n\nOther users can open the Genome Browser by clicking the link or open it based on genome browser id (gb000016) in \nShare | Open Shared Genome Browser\n.",
            "title": "Others"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#additional-browser-options",
            "text": "In this chapter, we will explore additional features users can utilize to change the display on the browser, mark specific genome locations, search specific sequences, and share browser views with others.",
            "title": "Additional Browser Options"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#organize-tracks",
            "text": "Click  Organize Track  on top.\nIt will allow user to add meta data for tracks.   In the  MetaData  tab, user can import meta data for track. Click  Load Meta | Import Table | Tab delimited file | OK  and find the file \"Design.txt\" you downloaded with the BAM files. Click  OK  to load the design.   The Track label can be switched to any column in the meta data. For example, select the column header \"Sample Name\" and click  Set Labels :   Move the column SampleName to the \"\"Listed columns\" and click  OK  twice:   Notice the track names have now changed to reflect this transformation:",
            "title": "Organize Tracks"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#track-properties",
            "text": "Click  Track Properties  on top or right click select  Set Track Properties .\nIt shows all properties that the user can specify, such as color, font, cutoffs to hide/show coverage, exon junctions, mutations and read sequences.",
            "title": "Track Properties"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#genomemark",
            "text": "GenomeMark is a bookmark-like utility in genome browser. Adding regions into GenomeMark will record genomic regions.\nThe user can jump back to marked regions by a single click on the GenomeMark.  Click  favorite star  icon to bookmark the current region:   User can open GenomeMark and jump to marked regions:   Left click on the color line to modify the GenomeMark properties.  The user can also import GenomeMark regions via  File | Import Custom Regions  from gene lists or bed files.",
            "title": "GenomeMark"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#sequence-searching",
            "text": "The OmicSoft GenomeBrowser also allows searching for DNA and RNA sequences.  First, click the \"Show/Hide Sequence Search Toolbar\", which will add a new toolbar below the main toolbar.   Enter a DNA or RNA sequence string in the \"Sequence\" search window (shortest sequence for search is 15nt), and click the green arrow to the right.   The user can specify whether DNA or RNA sequence should be searched, which specifies whether genomic or transcript sequences (including inter-exonic sequences) should be searched.  In addition, the user can specify whether partial or full alignments should be searched, and whether to search only the visible region. Genomic coordinates to Sequence Searches will be saved in the GenomeMark navigator, under the SequenceMatch sub-heading.    Note  If running ArrayStudio and logged into ArrayServer, a user will get the following message when ArrayServer has not been used to perform an aligment with the chosen  Genome Reference  and  Gene Model  used to start a Genome Browser:    If this occurs, there are two solutions to this error and they are outline here: link",
            "title": "Sequence searching"
        },
        {
            "location": "/tutorials/GenomeBrowser/Others/#sharing-genome-browser",
            "text": "If user has ArrayServer and the Genome Browser was created using server components (reference and server BAM files), the Genome Browser is sharable on the server where others can then access it (provided that they have the necessary privileges).  Click  Share | Share Genome Browser , specify the genome browser title and privileges.   Click  OK   If user has Outlook opened, an email draft with a link will be created.   Other users can open the Genome Browser by clicking the link or open it based on genome browser id (gb000016) in  Share | Open Shared Genome Browser .",
            "title": "Sharing Genome Browser"
        },
        {
            "location": "/tutorials/SampleManagement/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nOverview\n\u00b6\n\n\nSamples and sample sets are registered and managed on the server, along with their corresponding meta data. An Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic elements for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria.\n\n\nTest Dataset\n\u00b6\n\n\nThis tutorial will cover sample and sampleset registration, and integration to pipeline using a mock dataset. You can download the same tutorial dataset and registration text files on our website:\n\nlink",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/SampleManagement/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/SampleManagement/Introduction/#overview",
            "text": "Samples and sample sets are registered and managed on the server, along with their corresponding meta data. An Omic sample is associated with one or more raw data files, while an NGS sample can be associated with 1-2 raw data file(s), a BAM file, and/or a VCF file. A sample set is a collection of samples and usually is associated with an experiment. Samples and samplesets are the basic elements for pipelines and visualizations. Users can organize and search samples/samplesets by any meta data field, and create new sample sets by any criteria.",
            "title": "Overview"
        },
        {
            "location": "/tutorials/SampleManagement/Introduction/#test-dataset",
            "text": "This tutorial will cover sample and sampleset registration, and integration to pipeline using a mock dataset. You can download the same tutorial dataset and registration text files on our website: link",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/",
            "text": "Sample Management\n\u00b6\n\n\nSample Registration\n\u00b6\n\n\nArray Server provides a simple way to allow users to register, annotate and manage the samples through one one-click submission of a text file. Sample registration is limited to the LabManager user group or higher.\n\n\nBelow is a sample input file for sample registration:\n\n\n\n\nUser can get this text file from downloaded tutorial data.\n\n\nThe input file has one required section and one optional section:\n\n\nSamples\n: this required section lists samples, associated file path, and meta data for the samples. Fields are tab delimited. First row must be column headers, and the first two columns must be SampleID and FilePath. SampleID must be unique across the full database, and FilePath must be a relative path that s exposed by the Array Server FTP server (usually it points to a mapped folder). Multiple files, separated by \"|\", can be specified for each sample. The user can contain as many additional columns (e.g. LIMS fields, treatments and other grouping information, etc.) as needed, but it is recommended to control the vocabulary for both the column name and column value.\n\n\nDepending on server configurations, certain columns in your input file are set to \nMANDATORY\n. These settings can be viewed by the server administrator under \nManage | Server Information | Show Sample Template\n. This will open a Table where users can see which columns are needed in the \nSamples\n section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial.\n\n\nArraySuite supports multiple file types in FilePath, including CEL, FASTQ, BAM and etc. For more details, please read the following wiki page:\n\nlink\n\n\nSampleSet\n: this section is optional and lists the meta data for the sample set that will be automatically generated based on the listed samples in the \nSamples\n section. The user can set \nEditor\n and \nReader\n for the sample set but these two fields are not required.\n\n\nTo register the sample, go to \nServer | Server Sample | Register Samples\n:\n\n\n\n\nUsers can choose to register samples using a file located in server or local:\n\n\n\n\nChoose the sample registration file prepared as shown above and click \nOK\n. Once finished, you will get\n\n\n\n\nSome users might encounter an error like this:\n\n\n\n\nThe error hints users that information including Organism, Platform, and Platform type has not been defined ahead by the server admin. In this situation, users should contact the server admin.\n\n\nTo define these fields, the server admin can go to \nManage => Manage Predefined list\n:\n\n\n\n\n\n\nNext, add corresponding information from lists of Organism, Platform, and Platform type. Be sure to add one item per line in the lists.\n\n\n\n\n\n\nAnother error that may be encountered appears like this:\n\n\n\n\nDepending on server configurations, certain columns in your input file are set to \nMANDATORY\n. These settings can be viewed by the server administrator under \nManage | Server Information | Show Sample Template\n. This \nSample Template\n is discussed further below in the \nBrowse Samples\n section. This will open a Table where users can see which columns are needed in the \nSamples\n section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial.  \n\n\nBrowse Samples\n\u00b6\n\n\nTo browse samples, go to \nServer Sample | Browse Samples\n\n\n\n\n\n\nCategories used in the tree for \nSampleSets\n are ones defined as Organizable=TRUE in the server configuration file: \ndefault.template\n. Here is the wiki page for more details about \ndefault.template\n:\n\nlink\n\n\n\n\nCategories used in the tree for \nSamples\n are ones defined as Organizable=TRUE in the server configuration file: \nsample.template\n. Here is the wiki page for more details about \nsample.template\n:\n\nlink\n\n\nUsers can always check the predefined sample and sampleset columns in \nServer | Manage | Show Sample\n or \nSampleSet Template\n:\n\n\n\n\nCreate New SampleSets\n\u00b6\n\n\nNew sample sets can be created from registered samples that are belong to existing sample Sets. User can select samples of interest and right-click to \nCreate SampleSet\n.\n\n\n\n\nUser can also create sampleset using sample registration file with Sample ID only:\n\n\n\n\nRegister this sample using \nAdd SampleSet\n function:\n\n\n\n\n\n\nSearch Samples\n\u00b6\n\n\nTo search sample or sample set, go to \nServer Sample | Search Samples\n. The search function has the power of full text search.\n\n\n\n\nType  Bone  and select  tissue bone marrow  in the autofill. Click \nOK\n and then \nAdd\n to the search criteria field:\n\n\n\n\nUser can narrow down the search space by adding more search criteria. Click \nOK\n to search samples.\n\n\nA new sample tab will appear with a table of identified samples:",
            "title": "Sample Management"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/#sample-management",
            "text": "",
            "title": "Sample Management"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/#sample-registration",
            "text": "Array Server provides a simple way to allow users to register, annotate and manage the samples through one one-click submission of a text file. Sample registration is limited to the LabManager user group or higher.  Below is a sample input file for sample registration:   User can get this text file from downloaded tutorial data.  The input file has one required section and one optional section:  Samples : this required section lists samples, associated file path, and meta data for the samples. Fields are tab delimited. First row must be column headers, and the first two columns must be SampleID and FilePath. SampleID must be unique across the full database, and FilePath must be a relative path that s exposed by the Array Server FTP server (usually it points to a mapped folder). Multiple files, separated by \"|\", can be specified for each sample. The user can contain as many additional columns (e.g. LIMS fields, treatments and other grouping information, etc.) as needed, but it is recommended to control the vocabulary for both the column name and column value.  Depending on server configurations, certain columns in your input file are set to  MANDATORY . These settings can be viewed by the server administrator under  Manage | Server Information | Show Sample Template . This will open a Table where users can see which columns are needed in the  Samples  section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial.  ArraySuite supports multiple file types in FilePath, including CEL, FASTQ, BAM and etc. For more details, please read the following wiki page: link  SampleSet : this section is optional and lists the meta data for the sample set that will be automatically generated based on the listed samples in the  Samples  section. The user can set  Editor  and  Reader  for the sample set but these two fields are not required.  To register the sample, go to  Server | Server Sample | Register Samples :   Users can choose to register samples using a file located in server or local:   Choose the sample registration file prepared as shown above and click  OK . Once finished, you will get   Some users might encounter an error like this:   The error hints users that information including Organism, Platform, and Platform type has not been defined ahead by the server admin. In this situation, users should contact the server admin.  To define these fields, the server admin can go to  Manage => Manage Predefined list :    Next, add corresponding information from lists of Organism, Platform, and Platform type. Be sure to add one item per line in the lists.    Another error that may be encountered appears like this:   Depending on server configurations, certain columns in your input file are set to  MANDATORY . These settings can be viewed by the server administrator under  Manage | Server Information | Show Sample Template . This  Sample Template  is discussed further below in the  Browse Samples  section. This will open a Table where users can see which columns are needed in the  Samples  section. Please check this setting and, if necessary, add mandatory columns to the table provided with this tutorial.",
            "title": "Sample Registration"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/#browse-samples",
            "text": "To browse samples, go to  Server Sample | Browse Samples    Categories used in the tree for  SampleSets  are ones defined as Organizable=TRUE in the server configuration file:  default.template . Here is the wiki page for more details about  default.template : link   Categories used in the tree for  Samples  are ones defined as Organizable=TRUE in the server configuration file:  sample.template . Here is the wiki page for more details about  sample.template : link  Users can always check the predefined sample and sampleset columns in  Server | Manage | Show Sample  or  SampleSet Template :",
            "title": "Browse Samples"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/#create-new-samplesets",
            "text": "New sample sets can be created from registered samples that are belong to existing sample Sets. User can select samples of interest and right-click to  Create SampleSet .   User can also create sampleset using sample registration file with Sample ID only:   Register this sample using  Add SampleSet  function:",
            "title": "Create New SampleSets"
        },
        {
            "location": "/tutorials/SampleManagement/SampleManagement/#search-samples",
            "text": "To search sample or sample set, go to  Server Sample | Search Samples . The search function has the power of full text search.   Type  Bone  and select  tissue bone marrow  in the autofill. Click  OK  and then  Add  to the search criteria field:   User can narrow down the search space by adding more search criteria. Click  OK  to search samples.  A new sample tab will appear with a table of identified samples:",
            "title": "Search Samples"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/",
            "text": "Integration\n\u00b6\n\n\nPipeline Integration\n\u00b6\n\n\nPipeline Scripts\n\u00b6\n\n\nUser can run a pre-configured pipeline on a sample set. Pipeline can be as simple as raw data QC, alignment and then do quantification analysis on NGS data. Pipeline scripts are managed by ArrayServer administrators in \nServer | Manage | Manage Scripts\n:\n\n\n\n\n\n\nRun Pipeline Script in Analysis\n\u00b6\n\n\nTo run a pipeline on a SampleSet, open or create a server project in the \nAnalysis\n tab. Then go to \nAdd Data | Add Data From Server\n:\n\n\n\n\nSelect a SampleSet\n\n\n\n\nSelect a pipeline script:\n\n\n\n\nFill required parameter values and click \nOK\n to run:\n\n\n\n\nRun Pipeline Script during Sample Registration\n\u00b6\n\n\nUser can run pipeline script during sample registration process by adding \n[Pipeline]\n section in sample registration file.\n\n\n\n\nBy using the sample registration file above, a server job will be submitted at the end of sample registration to create a server project with ID \nTutorialRNASeq1\n, using pipeline script \nTutorial.RNASeq.v1.pscript\n and specified parameter values.\n\n\nGenome Browser Integration\n\u00b6\n\n\nAs we mentioned above, sample registration supports multiple file formats, including BAM (NGS alignment) files. User can modify the old registration file, adding a file path to BAM files:\n\n\n\n\nRegistering this file (\nServer Sample | Register Samples\n) will update samples with BAM path.\n\n\n\n\nNow, the alignment files (BAM files) of samples can be loaded in the Genome Browser tab directly through \nAdd Track | Add Track From Server Samples\n:\n\n\n\n\nUser can add individual samples or the whole sample set. Here we choose the \nTutorialRNASeq.fullData\n sampleset:\n\n\n\n\nUser has the option to add one sample as one genome browser track:\n\n\n\n\nOr create tracks for groups defined by sample registration meta data:\n\n\n\n\nChoose \nCellline\n as group which will create two genome browser tracks: K562 and MCF7.\n\n\n\n\nUser can split the combined tracks to individual samples by right click and select \nSplit Into Multiple Tracks\n:\n\n\n\n\nFor more information and features available in the genome browser, please read the \nGenome Browser Tutorial\n.",
            "title": "Integration"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#integration",
            "text": "",
            "title": "Integration"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#pipeline-integration",
            "text": "",
            "title": "Pipeline Integration"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#pipeline-scripts",
            "text": "User can run a pre-configured pipeline on a sample set. Pipeline can be as simple as raw data QC, alignment and then do quantification analysis on NGS data. Pipeline scripts are managed by ArrayServer administrators in  Server | Manage | Manage Scripts :",
            "title": "Pipeline Scripts"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#run-pipeline-script-in-analysis",
            "text": "To run a pipeline on a SampleSet, open or create a server project in the  Analysis  tab. Then go to  Add Data | Add Data From Server :   Select a SampleSet   Select a pipeline script:   Fill required parameter values and click  OK  to run:",
            "title": "Run Pipeline Script in Analysis"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#run-pipeline-script-during-sample-registration",
            "text": "User can run pipeline script during sample registration process by adding  [Pipeline]  section in sample registration file.   By using the sample registration file above, a server job will be submitted at the end of sample registration to create a server project with ID  TutorialRNASeq1 , using pipeline script  Tutorial.RNASeq.v1.pscript  and specified parameter values.",
            "title": "Run Pipeline Script during Sample Registration"
        },
        {
            "location": "/tutorials/SampleManagement/Integration/#genome-browser-integration",
            "text": "As we mentioned above, sample registration supports multiple file formats, including BAM (NGS alignment) files. User can modify the old registration file, adding a file path to BAM files:   Registering this file ( Server Sample | Register Samples ) will update samples with BAM path.   Now, the alignment files (BAM files) of samples can be loaded in the Genome Browser tab directly through  Add Track | Add Track From Server Samples :   User can add individual samples or the whole sample set. Here we choose the  TutorialRNASeq.fullData  sampleset:   User has the option to add one sample as one genome browser track:   Or create tracks for groups defined by sample registration meta data:   Choose  Cellline  as group which will create two genome browser tracks: K562 and MCF7.   User can split the combined tracks to individual samples by right click and select  Split Into Multiple Tracks :   For more information and features available in the genome browser, please read the  Genome Browser Tutorial .",
            "title": "Genome Browser Integration"
        },
        {
            "location": "/tutorials/SampleManagement/Others/",
            "text": "Others\n\u00b6\n\n\nRegister Multiple Sequence Files for One Sample\n\u00b6\n\n\nIn next generation sequencing (NGS) experiments, user may have multiple files from multiple lanes for one NGS sample. They should be considered as a single sample during NGS analysis. In sample registration, multiple files can be specified in FilePath using the same file type name, separated by |. For more details, please read the following wiki page:\n\nlink",
            "title": "Others"
        },
        {
            "location": "/tutorials/SampleManagement/Others/#others",
            "text": "",
            "title": "Others"
        },
        {
            "location": "/tutorials/SampleManagement/Others/#register-multiple-sequence-files-for-one-sample",
            "text": "In next generation sequencing (NGS) experiments, user may have multiple files from multiple lanes for one NGS sample. They should be considered as a single sample during NGS analysis. In sample registration, multiple files can be specified in FilePath using the same file type name, separated by |. For more details, please read the following wiki page: link",
            "title": "Register Multiple Sequence Files for One Sample"
        },
        {
            "location": "/tutorials/Cloud/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nOmicsoft Cloud\n\u00b6\n\n\nStudio/Server On Cloud is OmicSoft's solution to manage and analyze large Omics data using cloud computing. The standalone edition of Array Studio on the Cloud allows you to seamlessly run all Array Studio analytics from Amazon, combining the storage of S3 with the analytical power of EC2. Easily scale up any number of instances for every analysis. Array Server with Cloud will handle security credentials on server and submit/manage cloud files/jobs as seamlessly as running on ArrayServer.\n\n\nThis tutorial only covers the Array Studio on the Cloud. For Server on Cloud, please read \"Server Analysis (Basics)\" tutorial.\n\n\nArray Studio on the Cloud\n\u00b6\n\n\nArray Studio on the Cloud is a cloud solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. The users can easily share analyzed data with clients and colleagues. Cloud computing can remove the limitation of on-site computing capacity and dramatically improve computing efficacy. Array Studio can handle:\n\n\n\n\n\n\npinning up the correct number of instances\n\n\n\n\n\n\nAccessing the data from S3\n\n\n\n\n\n\nRunning the analysis with the optimal EC2 configuration (storage, memory, and CPUs)\n\n\n\n\n\n\nSpinning down the instances\n\n\n\n\n\n\nStoring the generated data back on S3\n\n\n\n\n\n\nGenome browser integration with S3\n\n\n\n\n\n\nCloud-based analysis allows the user to run jobs on cloud, which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the cloud.\nTasks such as job submission, monitoring, file transfer and data visualization can be done through the client software.\n\n\nAll the Array Studio modules available for local analysis are also accessible for\ncould-based analysis. The graphic interfaces are almost the same.\n\n\nCloud Project\n\u00b6\n\n\nA \"Cloud Project\" is a project that is created on the cloud, rather than on the user\u2019s client machine. This project is cached locally on the client machine, in case of loss of connection to the cloud, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user\u2019s home folder, typically My Documents/Omicsoft/Cloud Projects?. A Server Project, when stored locally in the cache folder, has a different filename suffix (.oscprj) as compared to a regular project (.osprj) and can only be opened when the user is connected to the cloud.\n\n\nThe concept behind the Cloud Project is that any data that is added to a project, must first be stored on the cloud. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Studio on Cloud instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the cloud file system.\n\n\nAll data addition and extraction is done on the cloud, instead of the users client machine. It allows the user to use the power of the cloud, instead of their individual client machine for the importing of data. This is extremely important for some memory/cpu intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, minimal data will be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc.\n\n\nTest Dataset\n\u00b6\n\n\nIn this tutorial, we will show how to create a cloud project for cloud-based analysis. To demonstrate, we will use the same dataset for server testing to test cloud. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be access from \nhere",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Cloud/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Cloud/Introduction/#omicsoft-cloud",
            "text": "Studio/Server On Cloud is OmicSoft's solution to manage and analyze large Omics data using cloud computing. The standalone edition of Array Studio on the Cloud allows you to seamlessly run all Array Studio analytics from Amazon, combining the storage of S3 with the analytical power of EC2. Easily scale up any number of instances for every analysis. Array Server with Cloud will handle security credentials on server and submit/manage cloud files/jobs as seamlessly as running on ArrayServer.  This tutorial only covers the Array Studio on the Cloud. For Server on Cloud, please read \"Server Analysis (Basics)\" tutorial.",
            "title": "Omicsoft Cloud"
        },
        {
            "location": "/tutorials/Cloud/Introduction/#array-studio-on-the-cloud",
            "text": "Array Studio on the Cloud is a cloud solution, allowing users to store, share, search, and integrate their microarray/SNP/CNV/NGS projects and data. The users can easily share analyzed data with clients and colleagues. Cloud computing can remove the limitation of on-site computing capacity and dramatically improve computing efficacy. Array Studio can handle:    pinning up the correct number of instances    Accessing the data from S3    Running the analysis with the optimal EC2 configuration (storage, memory, and CPUs)    Spinning down the instances    Storing the generated data back on S3    Genome browser integration with S3    Cloud-based analysis allows the user to run jobs on cloud, which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the cloud.\nTasks such as job submission, monitoring, file transfer and data visualization can be done through the client software.  All the Array Studio modules available for local analysis are also accessible for\ncould-based analysis. The graphic interfaces are almost the same.",
            "title": "Array Studio on the Cloud"
        },
        {
            "location": "/tutorials/Cloud/Introduction/#cloud-project",
            "text": "A \"Cloud Project\" is a project that is created on the cloud, rather than on the user\u2019s client machine. This project is cached locally on the client machine, in case of loss of connection to the cloud, but is automatically updated each time the user logs in or clicks the save button. The cache is stored in the user\u2019s home folder, typically My Documents/Omicsoft/Cloud Projects?. A Server Project, when stored locally in the cache folder, has a different filename suffix (.oscprj) as compared to a regular project (.osprj) and can only be opened when the user is connected to the cloud.  The concept behind the Cloud Project is that any data that is added to a project, must first be stored on the cloud. When the user adds a new dataset (whether it be Gene Expression, CNV, or NextGen sequencing), they will be prompted with the folder structure of the Array Studio on Cloud instead of their local file system. If the user wishes to use a file from their local file system, they must first upload the file to the cloud file system.  All data addition and extraction is done on the cloud, instead of the users client machine. It allows the user to use the power of the cloud, instead of their individual client machine for the importing of data. This is extremely important for some memory/cpu intensive importing operations (such as alignment of a fastq file to the genome for NextGen sequencing data). After data extraction, alignment or data summarization, minimal data will be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc.",
            "title": "Cloud Project"
        },
        {
            "location": "/tutorials/Cloud/Introduction/#test-dataset",
            "text": "In this tutorial, we will show how to create a cloud project for cloud-based analysis. To demonstrate, we will use the same dataset for server testing to test cloud. The user should first download the demo data file for use in the tutorial and save it to the local machine. The file can be access from  here",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/",
            "text": "Connecting to Cloud and Uploading Files\n\u00b6\n\n\nConnecting to Cloud\n\u00b6\n\n\nBefore creating a cloud project, first the user needs to connect to the cloud. Go to \nAnalysis | Tools\n tab on the top of Array Studio and click on \nCloud Preferences\n.\n\n\n\n\nIn the \nCloud Preferences\n window, type in the \nAccess/API key, Secret key, Omicsoft cloud directory, Cloud user name and Email\n:\n\n\n\n\nNow, a new tab, \nCloud\n, should appear on top of the Array Studio:\n\n\n\n\nUpon successful login, the default \nCloud\n window will look like this:\n\n\n\n\nUploading Files\n\u00b6\n\n\nOne requirement for performing cloud-based analysis is that the raw data (\ne.g.\n cel, fastq or bam files) has to be located on the cloud. One can use Array Studio to transfer local files to the cloud easily, similar to uploading file to Server, if one is familiar with running Server projects.\n\n\nClick on \nCloud Files\n. The window will appear with a listing of the current folders in the \n/Users/username\n directory:\n\n\n\n\nIn the example above, we are in the user folder \n/omicsoft.test.vivian/OmicsoftHome/Vivianzh\n and with the user id as \nVivianzh\n. The user folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting \nCreate New Folder\n from the dropdown menu.\n\n\nCreate a new folder and name it \nSampleData\n.\n\n\nEnter the \nSampleData\n folder and click \nUpload\n to transfer files from local computer to the cloud.\n\n\n\n\nSelect the \nServerTest.bam\n file and click \nOpen\n. As the files load, the progress is monitored in the lower portion of the \nServerFiles\n window. Once the uploading has finished, the files will appear in the \nSampleData\n folder:",
            "title": "Cloud Connection"
        },
        {
            "location": "/tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#connecting-to-cloud-and-uploading-files",
            "text": "",
            "title": "Connecting to Cloud and Uploading Files"
        },
        {
            "location": "/tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#connecting-to-cloud",
            "text": "Before creating a cloud project, first the user needs to connect to the cloud. Go to  Analysis | Tools  tab on the top of Array Studio and click on  Cloud Preferences .   In the  Cloud Preferences  window, type in the  Access/API key, Secret key, Omicsoft cloud directory, Cloud user name and Email :   Now, a new tab,  Cloud , should appear on top of the Array Studio:   Upon successful login, the default  Cloud  window will look like this:",
            "title": "Connecting to Cloud"
        },
        {
            "location": "/tutorials/Cloud/Connecting_to_Cloud_and_Uploading_Files/#uploading-files",
            "text": "One requirement for performing cloud-based analysis is that the raw data ( e.g.  cel, fastq or bam files) has to be located on the cloud. One can use Array Studio to transfer local files to the cloud easily, similar to uploading file to Server, if one is familiar with running Server projects.  Click on  Cloud Files . The window will appear with a listing of the current folders in the  /Users/username  directory:   In the example above, we are in the user folder  /omicsoft.test.vivian/OmicsoftHome/Vivianzh  and with the user id as  Vivianzh . The user folder is one place to hold your personal data files. New folders can be created by right-clicking the mouse and selecting  Create New Folder  from the dropdown menu.  Create a new folder and name it  SampleData .  Enter the  SampleData  folder and click  Upload  to transfer files from local computer to the cloud.   Select the  ServerTest.bam  file and click  Open . As the files load, the progress is monitored in the lower portion of the  ServerFiles  window. Once the uploading has finished, the files will appear in the  SampleData  folder:",
            "title": "Uploading Files"
        },
        {
            "location": "/tutorials/Cloud/Creatinga_Cloud_Project/",
            "text": "Creating a Cloud Project\n\u00b6\n\n\nTo create a cloud project, in \nAnalysis\n tab go to \nFile | New Cloud Project\n. A \nCloud Project Information\n window should appear:\n\n\n\n\nEnter \nProject ID and Title\n, and an optional description. Click the \nCreate\n button.\n\n\nNow an empty project will be created (below):\n\n\n\n\nNotice that the project name includes \nCloud Project - Distributed\n in the name so that the user can quickly see that this is a cloud project and the type is \nDistributed\n. \nDistributed\n indicates that data objects are saved in separate files. By default, a cloud project is a distributed project.\n\n\nFrom here, we can perform all the analysis tasks on the cloud using the interface of Array Studio. For example, we can add the alignment analysis file(the test dataset) by going to the toolbar \nAdd Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads\n:\n\n\n\n\nChoose the file uploaded in previous section (\nServerTest.bam\n).\n\n\n\n\nThen click \nSend to Queue\n.\nAfter a few seconds to minutes, depending on the project, CloudQueue window will show up, listing all the jobs running on cloud by the user:\n\n\n\n\nNow we switch back to the Analysis tab. Once the job is completed, we will see an \nUpdate Project\n on the far right in the menu selection of Array Studio (below):\n\n\n\n\nClicking \nUpdate Project\n will show the results of finished job: one \nNgsData\n object is created for this BAM file.\n\n\n\n\nIf we would like to see the parameters used for the alignment, select the data set name \nNgsData\n and right click, then choose \nView Source\n\n\n\n\nUsers can run all data analysis based on this \nNgsData\n in the same way as they run in Array Studio locally.\n\n\nCongratulations! You have successfully created a cloud project. Remember to \nsave\n the project through the \nSave\n button:\n\n\n\n\nYou can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc..",
            "title": "Cloud Project"
        },
        {
            "location": "/tutorials/Cloud/Creatinga_Cloud_Project/#creating-a-cloud-project",
            "text": "To create a cloud project, in  Analysis  tab go to  File | New Cloud Project . A  Cloud Project Information  window should appear:   Enter  Project ID and Title , and an optional description. Click the  Create  button.  Now an empty project will be created (below):   Notice that the project name includes  Cloud Project - Distributed  in the name so that the user can quickly see that this is a cloud project and the type is  Distributed .  Distributed  indicates that data objects are saved in separate files. By default, a cloud project is a distributed project.  From here, we can perform all the analysis tasks on the cloud using the interface of Array Studio. For example, we can add the alignment analysis file(the test dataset) by going to the toolbar  Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads :   Choose the file uploaded in previous section ( ServerTest.bam ).   Then click  Send to Queue .\nAfter a few seconds to minutes, depending on the project, CloudQueue window will show up, listing all the jobs running on cloud by the user:   Now we switch back to the Analysis tab. Once the job is completed, we will see an  Update Project  on the far right in the menu selection of Array Studio (below):   Clicking  Update Project  will show the results of finished job: one  NgsData  object is created for this BAM file.   If we would like to see the parameters used for the alignment, select the data set name  NgsData  and right click, then choose  View Source   Users can run all data analysis based on this  NgsData  in the same way as they run in Array Studio locally.  Congratulations! You have successfully created a cloud project. Remember to  save  the project through the  Save  button:   You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc..",
            "title": "Creating a Cloud Project"
        },
        {
            "location": "/tutorials/Cloud/Managing_Cloud_Instance_and_Proxy/",
            "text": "Managing Cloud Instances and Proxy\n\u00b6\n\n\nManaging cloud Instances is similar to managing server jobs. For Studio on the Cloud, the user can manage proxy instances in\u00a0\nCloud tab | Cloud Instances\n\nif the cloud is enabled as standalone upgrade. The user can Stop/Terminate cloud instances:\n\n\n\n\nAdmin can SSH to running instances directly by clicking \"Open SSH\". Before you use it for the first time, please put the cloud key file \"Omicsoft.Launching.pem\" in the following folder:\n\n\nC:\\Users\\<UserID>\\Documents\\Omicsoft\\Cloud\\Amazon\n\n\n\n\n\nFor Array Server with cloud integration, only admin can manage proxy instance in \nServer tab | Manage | Manage Cloud Instances\n.\n\n\nThe users can also manage proxy through \nCloud Tools\n tab:",
            "title": "Proxy Instance"
        },
        {
            "location": "/tutorials/Cloud/Managing_Cloud_Instance_and_Proxy/#managing-cloud-instances-and-proxy",
            "text": "Managing cloud Instances is similar to managing server jobs. For Studio on the Cloud, the user can manage proxy instances in\u00a0 Cloud tab | Cloud Instances \nif the cloud is enabled as standalone upgrade. The user can Stop/Terminate cloud instances:   Admin can SSH to running instances directly by clicking \"Open SSH\". Before you use it for the first time, please put the cloud key file \"Omicsoft.Launching.pem\" in the following folder:  C:\\Users\\<UserID>\\Documents\\Omicsoft\\Cloud\\Amazon  For Array Server with cloud integration, only admin can manage proxy instance in  Server tab | Manage | Manage Cloud Instances .  The users can also manage proxy through  Cloud Tools  tab:",
            "title": "Managing Cloud Instances and Proxy"
        },
        {
            "location": "/tutorials/Oscript/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray Studio\n provides an integrated OmicSoft Project Environment for analyzing, visualizing and organizing high dimensional data. Its well-designed graphic user interface is convenient for complicated bioinformatics data processing. Besides running analysis within graphic user interface, advanced Array Studio users can also run analysis with OmicScript (Oscript). By building Oscript pipelines, user can run batch jobs automatically.\n\n\nArray Studio\n allows users to build two kinds of scripts: OmicScript (Oscript) and Pipeline Server Script (Pscript). Oscript is normally created, used and managed by individual advanced users to process their own data. Users may run oscripts either in a local machine or a server. Pscript is normally created by an administor of Array Server, and used by users as pipeline tools to work on large scale data processing on a server (as a standalone server or in cluster). The users may submit samples to the pscript pipelines via Array Server's sample registration system, and monitor the job status in Array Studio GUI. This tutorial will introduce both Oscript and Pscript in individual sections.\n\n\nIt is highly recommended that the user complete the prerequisite for this tutorial: \nthe RNA-Seq Tutorial\n, as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, data structure, and different modules within the software.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Oscript/Introduction/#introduction",
            "text": "Array Studio  provides an integrated OmicSoft Project Environment for analyzing, visualizing and organizing high dimensional data. Its well-designed graphic user interface is convenient for complicated bioinformatics data processing. Besides running analysis within graphic user interface, advanced Array Studio users can also run analysis with OmicScript (Oscript). By building Oscript pipelines, user can run batch jobs automatically.  Array Studio  allows users to build two kinds of scripts: OmicScript (Oscript) and Pipeline Server Script (Pscript). Oscript is normally created, used and managed by individual advanced users to process their own data. Users may run oscripts either in a local machine or a server. Pscript is normally created by an administor of Array Server, and used by users as pipeline tools to work on large scale data processing on a server (as a standalone server or in cluster). The users may submit samples to the pscript pipelines via Array Server's sample registration system, and monitor the job status in Array Studio GUI. This tutorial will introduce both Oscript and Pscript in individual sections.  It is highly recommended that the user complete the prerequisite for this tutorial:  the RNA-Seq Tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, data structure, and different modules within the software.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/",
            "text": "Run Oscript\n\u00b6\n\n\nOSCRIPT\n\u00b6\n\n\nOscript file (file extension .oscript) contains a list of omicsoft procs that can be sequentially excecuted to process user's data in a local or server project. A proc is a script corresponding to a data process operation in \nArray Studio\n GUI. A proc starts with keyword BEGIN and the name of the proc, and end with keyword END and semicolon ;. Users may obtain a template of the procs by following the Export Oscript from GUI section.\n\n\nA Oscript may include procs for macro definition, initiation of project, analysis modules, saving and closing project. The figure below provides a simplified example showing the structure of an Oscript.\n\n\n\n\nAs shown in the example, a local Omicsoft project is created and saved as an OSPRJ file (see line 9-12 in the figure below). The OSPRJ file records all analysis steps and results (or links to large result files such as BAM files) as the analysis modules are performed. NGS projects are specified as  distributed  projects, which save different analysis results in separate files. Undistributed projects save all results in a single file. Input for analysis modules can be either raw sequence files (specified by  Files ) or intermediate data objects (specified by  Project  and  Data ). One advantage of working in the OSPRJ environment is that all data objects generated in preceding modules can be passed onto downstream modules smoothly by calling the data object name. For example, the output data object in AnalysisModuleA is defined as  ResultA , which can be directly used by AnalysisModuleB as input (see line 13-26 in the figure below). Whenever new analysis results need to be saved in the OSPRJ file, SaveProject is called, which usually happens before closing a project (see line 27-30 in the figure below). Details of options used in each module can be found in our online collection of Oscript templates.\n\n\nMacro proc are used for parameters that are frequently called in the Oscript, including project-specific parameters (project name, project folder and input files) and parameters shared across modules (thread number, paired-end or single-end layout, reference genome and gene model). Macros are defined as @ParameterName@ Value (see line 1-8 in the figure below).\n\n\nA full example OScript can be found at\n\nlink\n\n\nOscripts may be launched from Array Studio or from a linux or windows Oshell command line.\n\n\nExport Oscript Procs from GUI\n\u00b6\n\n\nEach analysis module in the GUI corresponds to a unique proc section in human-readable Oscript, for instance MapRnaSeqReadsToGenome for RNA-Seq alignment and NgsQCWizard for raw NGS data quality control. The OScript proc can be obtained by clicking on  Show Script  button after setting all parameters in GUI. In RNA-Seq alignment module, for example, after setting all parameters, user can click  Show Script  to get MapRnaSeqReadsToGenome OScript proc. The user can modify input, analysis parameters and output directly in the OScript for other jobs.\n\n\n\n\nA text file will open with the full OScript:\n\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib;\n Files\n \"D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_1.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_2.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_1.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_2.fastq.gz\";\n Reference Human.B37.3;\n GeneModel OmicsoftGene20130723;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options /ParallelJobNumber=4 /PairedEnd=True /FileFormat=AUTO /AutoPenalty=True /FixedPenalty=2\n /Greedy=false /IndelPenalty=2 /DetectIndels=True /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /OutputFolder=\"D:\\Tutorial\\RNASeq\" /ThreadNumber=2 /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic\n /CompressionMethod=Gzip /Gzip=True /SearchNovelExonJunction=True\n /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False\n /Platform=ILLUMINA /CompressBam=False;\n Output ;\n End;\n\n\n\n\n\nRun Oscript from Array Studio Tools | Run Script\n\u00b6\n\n\nUsers can submit an oscript via Array Studio GUI \nTools | Run Script\n. It is typically used to work on local projects and less frequently in server projects. For large-scale server projects, we recommend to use pscript that has an optimized workflow for sample registration, job submission and job monitoring (see next chapter for more details).\n\n\n\n\nOnce an oscript is saved with extension .oscript, users may click on \nTools | Run Script\n to open the window to submit the .oscript file. Run Script may submit jobs to a local machine for a local project, and a server (and HPC cluster) for a server project, depending on the procs used in the oscript.\n\n\nIf an oscript does not contain a connectServer proc, the oscript submitted via \nTools | Run Script\n will run in the local machine where Array Studio resides. One example is the oscript in the figure at the begining of this chapter. Another example is shown below to create an local project, map DnaSeq reads, save and close the project:\n\n\n Begin Macro;\n @ThreadNum@ 6;\n @ProjectName@ \"testProject\";\n @ProjectFolder@ \"/local/data/support/test\";\n\n @FileNames@\n \"/workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_1.fastq.gz\n /workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_2.fastq.gz\";\n\n @CompressionMethod@ None;\n @Gzip@ False;\n @PairedEnd@ True;\n @ReferenceName@ Human.B37.3;\n End;\n\n Begin NewProject;\n File \"@ProjectFolder@/@ProjectName@.osprj\";\n Options /Distributed=True;\n End;\n\n Begin MapDnaSeqReads /Namespace=NgsLib; Files\n \"@FileNames@\";\n Reference @ReferenceName@;\n Trimming /Mode=Composite /LeftTrimming=0 /RightTrimming=0 /ReadTrimQuality=2 /ReadTrimSize=65536;\n AdapterStripping 3'End /AdapterSequence=CTGTCTCTTATA /ExcludeUnmatched=False;\n Options /PairedEnd=@PairedEnd@ /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /IndelPenalty=2\n /DetectIndels=False /Greedy=False /IndexMode=14Mer /ExcludeNonUniqueMapping=True /ReportCutoff=2\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@ProjectFolder@/BAMOutput\"\n /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=1000 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3  \n /GenerateSamFiles=False /ThreadNumber=@ThreadNum@ /ExpectedInsertSize=300\n /InsertSizeStandardDeviation=40 /QualityEncoding=Automatic /CompressionMethod=@CompressionMethod@\n /Gzip=@Gzip@ /ExcludeUnmappedInBam=True\n /KeepFullRead=False /MapRead=True /MapReverseComplement=True /Version=4 /ParallelJobNumber=1\n /BamSubFolder= /Platform=ILLUMINA /Replace=False /LocalAlignment=True;\n Output Alignment;\n End;\n \u00a0\n Begin SaveProject;\n Project @ProjectName@;\n File \"@ProjectFolder@/@ProjectName@.osprj\";\n End;\n \u00a0\n Begin CloseProject;\n Project @ProjectName@;\n End;\n\n\n\n\n\nTo run jobs on a server and cluster via \nTools | Run Script\n, a connectServer proc is required to connect to an array server. The procs that are intended to run on server are also required to be compatible to server jobs. Please refer to the proc documentation for server job compatability. In some cases, a statement /RunOnServer=True is required in a proc in order for the proc to be excecuted on the server.\n\n\nHere is an example of an oscript that was submitted via \nTools | Run Script\n to work on a server project. The script defined some parameters in a Macro proc, connected to an array server, created a new project in the server, performed RnaSeq alignment in a cluster, saved and closed the project in the server.\n\n\n Begin Macro;\n @ThreadNum@ 6;\n @ProjectName@ \"AlignmentProject10\";\n @ProjectFolder@ \"/local_data/TestDataSets/tem/tem_20170720\";\n @FileNames@\n \"\n /local_data/TestDataSets/SRR521462_1.fastq\n /local_data/TestDataSets/SRR521462_2.fastq\n \";\n @JobNumber@ 4;\n @ThreadNumber@ 4;\n @DesignFile@ \"/local_data/TestDataSets/tem/tem_20170720/design3.txt\";\n End;\n\n Begin ConnectServer;\n Server \"tcp://192.168.3.226:9065\" /User=xxx /Password=xxxxx;\n End;\n\n Begin NewProject;\n ServerProject \"@ProjectName@\";\n Options /Distributed=True;\n End;\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \"@FileNames@\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10 MaxEndInsertionSize=10\n /MaxEndDeletionSize=10 /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=Tru  /OutputFolder=\"@ProjectFolder@/@ProjectName@/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=@JobNumber@ /ThreadNumber=@ThreadNumber@\n /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False\n /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n Project @ProjectName@;\n Options /Distributed=True;\n End;\n\n Begin CloseProject;\n Project @ProjectName@;\n End;\n\n\n\n\n\nRun Oscript from Array Studio \nTools | Run Script (Send To Queue)\n\u00b6\n\n\nIf a user has logged into Array Server from Array Studio, the user may click on \nRun Script (Send To Queue)\n to submit an oscript to work on a server project and run jobs in HPC cluster. Users may monitor the job status in \nServer | Manage Server Jobs\n.\n\n\nPlease note that the connectServer proc is not required in the oscript in this case since the user has logged into Array Server. Please also note that the Macro proc can not currently be used for constructing paths if the oscript is submitted via \nTools | Run Script (Send To Queue)\n.\n\n\nBelow is an example oscript that can be submit via Run Script (Send To Queue) to run on a server:\n\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \" /local_data/TestDataSets/SRR521462_1.fastq\n /local_data/TestDataSets/SRR521462_2.fastq\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True  /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false\n /IndelPenalty=2 /DetectIndels=False /MaxMiddleInsertionSize=10  \n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10\n /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"/local_data/TestDataSets/tem/tem_20170720/AlignmentProject/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=4 /ThreadNumber=6\n /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False\n /InsertOnSameStrand=False /InsertOnDifferentStrand=True\n /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False\n /Replace=False /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n Project AlignmentProject;\n Options /Distributed=True;\n End;\n\n\n\n\n\nRun Oscript from Windows or Linux Oshell Commandline\n\u00b6\n\n\nUsers may also run an oscript from a single windows or linux command line (oshell commandline) by using Omicsoft's oshell.exe function in Omicsoft Oshell environment. The Oshell Environment is another Omicsoft package that is independent from Array Server and Array Studio. Users may need to obtain a license from Omicsoft to install the package. Please contact \nsupport@omicsoft.com\n for more information.\n\n\nBy running with OShell command line, users do not need to interact with the GUI. The Oshell Environment can work on a local project as a commandline version of Array Studio GUI, and also can interact with an Array Server to work on a server project.\n\n\nThe requirements of the oscripts for Oshell commandline is the same as the oscript for \nTools | Run Script (Send To Queue)\n. Specifically, Marco proc allows for path construction. The oscript will be ran in a server (and cluster) if it has connectServer proc and server job compatible procs, and would run in the local machine if otherwise. In fact, the example oscripts in \nRun Oscript from Array Studio Tools | Run Script\n can be directly launched from the oshell commandline.\n\n\nUsers may save the file as test.oscript and run using command line:\n\n\nIf OShell is installed on Windows (one line command):\n\n\n C:\\Oshell\\oshell.exe --runscript C:\\Users\\user\\Documents\\Omicsoft C:\\tmp\\test.oscript\n C:\\Users\\user\\Documents\\OmicsoftTmpDirectory > C:\\tmp\\testrun.log\n\n\n\n\n\nIf Oshell is installed on Linux and can be run using mono (one line command):\n\n\n /opt/mono-2.10.9/bin/mono /home/user/Oshell/oshell.exe --runscript /home/user/OmicsoftHome\n /tmp/test.oscript /home/user/OmicsoftTmp /opt/mono-2.10.9/bin/mono > /tmp/testrun.log\n\n\n\n\n\nWrapping External Tools into Oscript\n\u00b6\n\n\nOmicsoft has implemented external script (EScript) integration to build pipelines/workflows using public bioinformatics tools. Since most third-party tools are Linux-only, users should run Escript in Oshell or ArrayServer on a Linux machine.\n\n\nEscript can wrap and run public bioinformatics tools, such as BWA, Bowtie, Tophat, and Cufflink, in OmicSoft Project Environment. The results from public tools can be imported as a table in Array Studio seamlessly. Escript runs can be submitted to the job queue in ArrayServer and run in Grid Engine if the server has been configured. Escript jobs are monitored and tracked in ArrayServer.\n\n\nHere is a local (as opposed to server) Escript using a simple example wrapping Bowtie. The script assumes that:\n\n\n\n\nBowtie is installed and can be found in PATH\n\n\nebwt indexes are located in /idx\n\n\n\n\nExample Script:\n\n\n Begin RunEScript;\n Files\n \"/home/user/Test/_Raw/SRR243575.s.1.fastq\n /home/user/Test/_Raw/SRR243575.s.2.fastq\";  \n EScriptName Bowtie;\n Command mkdir \"/tmp/testRun\";\n Command bowtie \"/idx/hg19\" -1 \"%Path1%\" -2 \"%Path2%\" -p 8 -a -m 1 -v 2 -t -S \"/tmp/test.sam\";\n Options /ParallelJobNumber=1 /ThreadNumberPerJob=8 /Mode=Paired /ErrorOnStdErr=False;\n End;\n\n Begin AddMappedDnaSeqReads /Namespace=NgsLib;\n Files\n \"/tmp/test.sam\";\n Reference Human.hg19;\n Options /FileFormat=SAM /ThreadNumber=4 /NoCopy=True;\n Output BAMFile;\n End;",
            "title": "Run Oscript"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#run-oscript",
            "text": "",
            "title": "Run Oscript"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#oscript",
            "text": "Oscript file (file extension .oscript) contains a list of omicsoft procs that can be sequentially excecuted to process user's data in a local or server project. A proc is a script corresponding to a data process operation in  Array Studio  GUI. A proc starts with keyword BEGIN and the name of the proc, and end with keyword END and semicolon ;. Users may obtain a template of the procs by following the Export Oscript from GUI section.  A Oscript may include procs for macro definition, initiation of project, analysis modules, saving and closing project. The figure below provides a simplified example showing the structure of an Oscript.   As shown in the example, a local Omicsoft project is created and saved as an OSPRJ file (see line 9-12 in the figure below). The OSPRJ file records all analysis steps and results (or links to large result files such as BAM files) as the analysis modules are performed. NGS projects are specified as  distributed  projects, which save different analysis results in separate files. Undistributed projects save all results in a single file. Input for analysis modules can be either raw sequence files (specified by  Files ) or intermediate data objects (specified by  Project  and  Data ). One advantage of working in the OSPRJ environment is that all data objects generated in preceding modules can be passed onto downstream modules smoothly by calling the data object name. For example, the output data object in AnalysisModuleA is defined as  ResultA , which can be directly used by AnalysisModuleB as input (see line 13-26 in the figure below). Whenever new analysis results need to be saved in the OSPRJ file, SaveProject is called, which usually happens before closing a project (see line 27-30 in the figure below). Details of options used in each module can be found in our online collection of Oscript templates.  Macro proc are used for parameters that are frequently called in the Oscript, including project-specific parameters (project name, project folder and input files) and parameters shared across modules (thread number, paired-end or single-end layout, reference genome and gene model). Macros are defined as @ParameterName@ Value (see line 1-8 in the figure below).  A full example OScript can be found at link  Oscripts may be launched from Array Studio or from a linux or windows Oshell command line.",
            "title": "OSCRIPT"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#export-oscript-procs-from-gui",
            "text": "Each analysis module in the GUI corresponds to a unique proc section in human-readable Oscript, for instance MapRnaSeqReadsToGenome for RNA-Seq alignment and NgsQCWizard for raw NGS data quality control. The OScript proc can be obtained by clicking on  Show Script  button after setting all parameters in GUI. In RNA-Seq alignment module, for example, after setting all parameters, user can click  Show Script  to get MapRnaSeqReadsToGenome OScript proc. The user can modify input, analysis parameters and output directly in the OScript for other jobs.   A text file will open with the full OScript:   Begin MapRnaSeqReadsToGenome /Namespace=NgsLib;\n Files\n \"D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_1.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521523_2.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_1.fastq.gz\n D:\\Tutorial\\RNASeq\\RNASeq\\SRR521524_2.fastq.gz\";\n Reference Human.B37.3;\n GeneModel OmicsoftGene20130723;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options /ParallelJobNumber=4 /PairedEnd=True /FileFormat=AUTO /AutoPenalty=True /FixedPenalty=2\n /Greedy=false /IndelPenalty=2 /DetectIndels=True /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /OutputFolder=\"D:\\Tutorial\\RNASeq\" /ThreadNumber=2 /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic\n /CompressionMethod=Gzip /Gzip=True /SearchNovelExonJunction=True\n /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False\n /Platform=ILLUMINA /CompressBam=False;\n Output ;\n End;",
            "title": "Export Oscript Procs from GUI"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#run-oscript-from-array-studio-tools-run-script",
            "text": "Users can submit an oscript via Array Studio GUI  Tools | Run Script . It is typically used to work on local projects and less frequently in server projects. For large-scale server projects, we recommend to use pscript that has an optimized workflow for sample registration, job submission and job monitoring (see next chapter for more details).   Once an oscript is saved with extension .oscript, users may click on  Tools | Run Script  to open the window to submit the .oscript file. Run Script may submit jobs to a local machine for a local project, and a server (and HPC cluster) for a server project, depending on the procs used in the oscript.  If an oscript does not contain a connectServer proc, the oscript submitted via  Tools | Run Script  will run in the local machine where Array Studio resides. One example is the oscript in the figure at the begining of this chapter. Another example is shown below to create an local project, map DnaSeq reads, save and close the project:   Begin Macro;\n @ThreadNum@ 6;\n @ProjectName@ \"testProject\";\n @ProjectFolder@ \"/local/data/support/test\";\n\n @FileNames@\n \"/workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_1.fastq.gz\n /workspace/ws03/IData/TestDataSets/HumanDNASeqPaired/test_2.fastq.gz\";\n\n @CompressionMethod@ None;\n @Gzip@ False;\n @PairedEnd@ True;\n @ReferenceName@ Human.B37.3;\n End;\n\n Begin NewProject;\n File \"@ProjectFolder@/@ProjectName@.osprj\";\n Options /Distributed=True;\n End;\n\n Begin MapDnaSeqReads /Namespace=NgsLib; Files\n \"@FileNames@\";\n Reference @ReferenceName@;\n Trimming /Mode=Composite /LeftTrimming=0 /RightTrimming=0 /ReadTrimQuality=2 /ReadTrimSize=65536;\n AdapterStripping 3'End /AdapterSequence=CTGTCTCTTATA /ExcludeUnmatched=False;\n Options /PairedEnd=@PairedEnd@ /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /IndelPenalty=2\n /DetectIndels=False /Greedy=False /IndexMode=14Mer /ExcludeNonUniqueMapping=True /ReportCutoff=2\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@ProjectFolder@/BAMOutput\"\n /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=1000 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10 /MinDistalEndSize=3  \n /GenerateSamFiles=False /ThreadNumber=@ThreadNum@ /ExpectedInsertSize=300\n /InsertSizeStandardDeviation=40 /QualityEncoding=Automatic /CompressionMethod=@CompressionMethod@\n /Gzip=@Gzip@ /ExcludeUnmappedInBam=True\n /KeepFullRead=False /MapRead=True /MapReverseComplement=True /Version=4 /ParallelJobNumber=1\n /BamSubFolder= /Platform=ILLUMINA /Replace=False /LocalAlignment=True;\n Output Alignment;\n End;\n \u00a0\n Begin SaveProject;\n Project @ProjectName@;\n File \"@ProjectFolder@/@ProjectName@.osprj\";\n End;\n \u00a0\n Begin CloseProject;\n Project @ProjectName@;\n End;  To run jobs on a server and cluster via  Tools | Run Script , a connectServer proc is required to connect to an array server. The procs that are intended to run on server are also required to be compatible to server jobs. Please refer to the proc documentation for server job compatability. In some cases, a statement /RunOnServer=True is required in a proc in order for the proc to be excecuted on the server.  Here is an example of an oscript that was submitted via  Tools | Run Script  to work on a server project. The script defined some parameters in a Macro proc, connected to an array server, created a new project in the server, performed RnaSeq alignment in a cluster, saved and closed the project in the server.   Begin Macro;\n @ThreadNum@ 6;\n @ProjectName@ \"AlignmentProject10\";\n @ProjectFolder@ \"/local_data/TestDataSets/tem/tem_20170720\";\n @FileNames@\n \"\n /local_data/TestDataSets/SRR521462_1.fastq\n /local_data/TestDataSets/SRR521462_2.fastq\n \";\n @JobNumber@ 4;\n @ThreadNumber@ 4;\n @DesignFile@ \"/local_data/TestDataSets/tem/tem_20170720/design3.txt\";\n End;\n\n Begin ConnectServer;\n Server \"tcp://192.168.3.226:9065\" /User=xxx /Password=xxxxx;\n End;\n\n Begin NewProject;\n ServerProject \"@ProjectName@\";\n Options /Distributed=True;\n End;\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \"@FileNames@\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10 MaxEndInsertionSize=10\n /MaxEndDeletionSize=10 /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=Tru  /OutputFolder=\"@ProjectFolder@/@ProjectName@/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=@JobNumber@ /ThreadNumber=@ThreadNumber@\n /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False /Replace=False\n /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n Project @ProjectName@;\n Options /Distributed=True;\n End;\n\n Begin CloseProject;\n Project @ProjectName@;\n End;",
            "title": "Run Oscript from Array Studio Tools | Run Script"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#run-oscript-from-array-studio-tools-run-script-send-to-queue",
            "text": "If a user has logged into Array Server from Array Studio, the user may click on  Run Script (Send To Queue)  to submit an oscript to work on a server project and run jobs in HPC cluster. Users may monitor the job status in  Server | Manage Server Jobs .  Please note that the connectServer proc is not required in the oscript in this case since the user has logged into Array Server. Please also note that the Macro proc can not currently be used for constructing paths if the oscript is submitted via  Tools | Run Script (Send To Queue) .  Below is an example oscript that can be submit via Run Script (Send To Queue) to run on a server:   Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \" /local_data/TestDataSets/SRR521462_1.fastq\n /local_data/TestDataSets/SRR521462_2.fastq\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True  /FileFormat=FASTQ /AutoPenalty=True /FixedPenalty=2 /Greedy=false\n /IndelPenalty=2 /DetectIndels=False /MaxMiddleInsertionSize=10  \n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10 /MaxEndDeletionSize=10\n /MinDistalEndSize=3 /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"/local_data/TestDataSets/tem/tem_20170720/AlignmentProject/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=4 /ThreadNumber=6\n /InsertSizeStandardDeviation=40 /ExpectedInsertSize=300 /MatePair=False\n /InsertOnSameStrand=False /InsertOnDifferentStrand=True\n /QualityEncoding=Automatic /CompressionMethod=Gzip /Gzip=True\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False /KeepFullRead=False\n /Replace=False /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n Project AlignmentProject;\n Options /Distributed=True;\n End;",
            "title": "Run Oscript from Array Studio Tools | Run Script (Send To Queue)"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#run-oscript-from-windows-or-linux-oshell-commandline",
            "text": "Users may also run an oscript from a single windows or linux command line (oshell commandline) by using Omicsoft's oshell.exe function in Omicsoft Oshell environment. The Oshell Environment is another Omicsoft package that is independent from Array Server and Array Studio. Users may need to obtain a license from Omicsoft to install the package. Please contact  support@omicsoft.com  for more information.  By running with OShell command line, users do not need to interact with the GUI. The Oshell Environment can work on a local project as a commandline version of Array Studio GUI, and also can interact with an Array Server to work on a server project.  The requirements of the oscripts for Oshell commandline is the same as the oscript for  Tools | Run Script (Send To Queue) . Specifically, Marco proc allows for path construction. The oscript will be ran in a server (and cluster) if it has connectServer proc and server job compatible procs, and would run in the local machine if otherwise. In fact, the example oscripts in  Run Oscript from Array Studio Tools | Run Script  can be directly launched from the oshell commandline.  Users may save the file as test.oscript and run using command line:  If OShell is installed on Windows (one line command):   C:\\Oshell\\oshell.exe --runscript C:\\Users\\user\\Documents\\Omicsoft C:\\tmp\\test.oscript\n C:\\Users\\user\\Documents\\OmicsoftTmpDirectory > C:\\tmp\\testrun.log  If Oshell is installed on Linux and can be run using mono (one line command):   /opt/mono-2.10.9/bin/mono /home/user/Oshell/oshell.exe --runscript /home/user/OmicsoftHome\n /tmp/test.oscript /home/user/OmicsoftTmp /opt/mono-2.10.9/bin/mono > /tmp/testrun.log",
            "title": "Run Oscript from Windows or Linux Oshell Commandline"
        },
        {
            "location": "/tutorials/Oscript/RunOscript/#wrapping-external-tools-into-oscript",
            "text": "Omicsoft has implemented external script (EScript) integration to build pipelines/workflows using public bioinformatics tools. Since most third-party tools are Linux-only, users should run Escript in Oshell or ArrayServer on a Linux machine.  Escript can wrap and run public bioinformatics tools, such as BWA, Bowtie, Tophat, and Cufflink, in OmicSoft Project Environment. The results from public tools can be imported as a table in Array Studio seamlessly. Escript runs can be submitted to the job queue in ArrayServer and run in Grid Engine if the server has been configured. Escript jobs are monitored and tracked in ArrayServer.  Here is a local (as opposed to server) Escript using a simple example wrapping Bowtie. The script assumes that:   Bowtie is installed and can be found in PATH  ebwt indexes are located in /idx   Example Script:   Begin RunEScript;\n Files\n \"/home/user/Test/_Raw/SRR243575.s.1.fastq\n /home/user/Test/_Raw/SRR243575.s.2.fastq\";  \n EScriptName Bowtie;\n Command mkdir \"/tmp/testRun\";\n Command bowtie \"/idx/hg19\" -1 \"%Path1%\" -2 \"%Path2%\" -p 8 -a -m 1 -v 2 -t -S \"/tmp/test.sam\";\n Options /ParallelJobNumber=1 /ThreadNumberPerJob=8 /Mode=Paired /ErrorOnStdErr=False;\n End;\n\n Begin AddMappedDnaSeqReads /Namespace=NgsLib;\n Files\n \"/tmp/test.sam\";\n Reference Human.hg19;\n Options /FileFormat=SAM /ThreadNumber=4 /NoCopy=True;\n Output BAMFile;\n End;",
            "title": "Wrapping External Tools into Oscript"
        },
        {
            "location": "/tutorials/Oscript/PipelineScript/",
            "text": "Pipeline Script\n\u00b6\n\n\nA pipeline script (Pscript) is created and managed by ArrayServer administrators. Once a pscript is installed in Array Server, it becomes a pipeline tool. Users can submit large amount of samples to the pipelines to process the samples and analyze data. The input and output for the pipeline can also be pre-configured and exposed to GUI.\n\n\nA Pscript includes three blocks: \nInfo\n, \nInput\n and \nScript\n.\n\n\nInfo\n block allows the administrator to specify a label for the script, a description of the script, as well as a category (separated by \\ for multiple levels) for the pscript, as in the example below:\n\n\n <Info>\n Label=Illumina RNA-Seq Alignment\n Description=Import Illumina reads with B37/R62\n Category=NGS\\RNA-Seq\\Illumina\n\n\n\n\n\nInput\n block allows the user to specify variables (also defined as Parameters) that will be used by the script. Variables are named by using the @VariableName@ pattern. These variables can be substituted at appropriate places within the script. Each variable should follow this pattern:\n\n\n @VariableName@=DefaultOption\n ~@VariableName@=Variable description\n ~@VariableName@Levels=Level1, Level\n ~@VariableName@ExclusiveLevels=True\n\n\n\n\n\nScript\n block contains the Ocript procs that perform data analysis in the pipeline. User may refer to Oscript that was introduced in the previous chapter in this tutorial.\n\n\nBelow is an example of a pscript (RnaSeq Alignment Pscript Pipeline) that align RnaSeq reads and save the output bam files to a specified folder:\n\n\n <Info>\n Label=RnaSeq Alignment Pscript Pipeline\n Description= Align RnaSeq reads and export Bam to a folder\n Category=NGS\\RNA-Seq\\Illumina\n\n <Input>\n @JobNumber@=4\n ~@JobNumber@=Number of threads to run for each of the steps.\n ~@JobNumber@Levels=1,2,3,4,5,6,7,8\n ~@JobNumber@ExclusiveLevels=True\n\n @ThreadNumber@=4\n ~@ThreadNumber@=Number of threads to run for each of the steps.\n ~@ThreadNumer@Levels=1,2,3,4,5,6,7,8\n ~@ThreadNumber@ExclusiveLevels=True\n\n @ProjectFolder@=\n ~@ProjectFolder@Type=FilePath\n ~@ProjectFolder@=Output folder for ALV and BAM files\n ~@ProjectFolder@Type=FilePath\n\n\n <Script>\n Begin OpenProject;\n ServerProject @ProjectName@;\n End;\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \"@FileNames@\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True\n /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10\n /MaxEndDeletionSize=10 /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@ProjectFolder@/@ProjectName@/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=@JobNumber@\n /ThreadNumber=@ThreadNumber@ /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /MatePair=False\n /InsertOnSameStrand=False /InsertOnDifferentStrand=True\n /QualityEncoding=Automatic /CompressionMethod=Gzip\n /Gzip=True /SearchNovelExonJunction=True\n /ExcludeUnmappedInBam=False /KeepFullRead=False\n /Replace=False /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n End;\n\n Begin CloseProject;\n Project @ProjectName@;\n End;\n\n\n\n\n\nThe Pscript may be saved as RnaSeqAlignmentPipeline.pscript, and installed in Array Server in \nManage | Manage Scripts\n as shown in the next section.\n\n\nManage Pscript in Array Server\n\u00b6\n\n\nArrayServer administrators can manage (add, edit and remove) PScripts in Array Server. The pscript management is in \nManage | Manage Scripts\n:\n\n\n\n\n\n\nAdministrators may install new pscript as a pipeline in Array Server by clicking on \nAdd | Download script from Omicsoft | Load From File\n, and select the .pscript file (for example RnaSeqAlignmentPipeline.pscript).\n\n\nAdministrators may install pre-configured pscript pipelines prepared by Omicsoft by clicking on \nAdd | Download script from Omicsoft\n.\n\n\n\n\nChoose one script, for example \nIlluminaDNASeqBAMFullPipeline\n, and click \nOK\n to show the details of the script, including description, required input, oscript for each analysis module. Click on \nOK\n to install this script on Array Server.\n\n\n\n\nSubmit Samples To Pscript Pipeline to Run Jobs on Array Server\n\u00b6\n\n\nUsers may submit samples to Pscript pipeline to perform large scale data analysis on array server.\n\n\nThe most typical way for users run samples in a pipeline is to upload a sample registration file (file extension .osreg) to the user's Instruction folder in Array Server.\n\n\nArray Server automatically scans the Instruction folder, picks up any sample registration files (osreg files) in the folder, and submits the samples in the osreg file to the pscript pipeline that is specified in the osreg file. The pscript pipeline will process samples in Array Server.\n\n\n\n\nHere is an \nosreg\n file example that provides input sample and parameters for the RnaSeq Alignment Pscript Pipeline shown in the begining of this chapter:\n\n\n [Samples]\n SampleID   FilePath    SampleName\n SRR521462  FASTQ1=/path1/test1.fastq|FASTQ2=/path1/test1.fastq Sample1\n\n [SampleSet]\n ID=Alignment_test\n Title=Alignment_test\n Reader=standard users\n Editor=standard users\n ExperimentSource=Test\n ExperimentTitle=Test Experiment1\n ExperimentDescription=Test Pscript for a customer\n ExperimentDesignDate=07/24/2017\n PrincipalInvestigator=Test\n Project=test 1\n\n [Pipeline]\n Project.Readers=standard users\n Project.ID=AlignmentTest\n UserID=omicsoft\n ScriptID=RnaSeqAlignmentPipeline.pscript\n Project.Editors=omicsoft\n Parameters.JobNumber=2\n Parameters.ThreadNumber=4\n Parameters.ProjectFolder=/Users/omicsoft/20170724_pscript_user_v1\n\n\n\n\n\nUsers may refer to the Sample Registration Chapter in Sample Management tutorial for more details on the osreg file.\n\n\nUsers may also submit samples to pscript pipeline by browsing server samples and right click on any SampleSet to \nRun Server Pipeline\n. Users may then choose one of the installed scripts to process their samples.\n\n\n\n\nCustomize Pscript and Expose it to Array Studio GUI\n\u00b6\n\n\nServer administrators have the capability to make a Pscript available in the Analysis tab of Array Studio. This option would allow users to automate analyses without registering the samples on the server, similar to our built-in analysis pipelines under the \nAdd Data | Add NGS Data\n menu option. To expose a Pscript to GUI, the Pscript author needs to include the following in \n section.\n\n\n <Input>\n ExternalScriptInputType=Files\n ExternalScriptMenuText=Customized Function Name\n ExternalScriptMenuStructure=NGS\\RNA-Seq\\Alignment\n ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz\n\n\n\n\n\nExample of the full script allowing GUI input:\n\n\n <Info>\n Label=RNA-Seq Custom Pipeline (with save after each step)\n Description=Raw data QC, Align to B37.3 with RefGene, Post Alignment QC with Ensembl\n Category=NGS\\RNA-Seq\\Illumina\n\n <Input>\n ExternalScriptInputType=Files\n ExternalScriptMenuText= RNA-Seq Custom Pipeline\n ExternalScriptMenuStructure=NGS\\RNA-Seq\\Pipeline\n ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz\n\n @PairedSamples@=True\n ~@PairedSamples@=Data is paired. Options are True or False (True by default)\n ~@PairedSamples@Levels=True,False\n ~@PairedSamples@ExclusiveLevels=True\n\n @ThreadNumberPerJob@=4\n ~@ThreadNumberPerJob@=Number of threads to run for each of the steps.\n ~@ThreadNumerPerJob@Levels=1,2,3,4,5,6,7,8\n ~@ThreadNumberPerJob@ExclusiveLevels=False\n\n @ParallelJobNumber@=8\n ~@ParallelJobNumber@=Number of parallel jobs to run for each of the steps\n\n @PreviewMode@=True\n ~@PreviewMode@=Set to true to run raw data QC in preview mode\n ~@PreviewMode@Levels=True,False\n ~@PreviewMode@ExclusiveLevels=True\n\n @Gzip@=Gzip\n ~@Gzip@=Set to Gzip if input files are gzipped or None\n ~@Gzip@Levels=Gzip,None\n ~@Gzip@ExclusiveLevels=True\n\n @OutputFolderName@=\n ~@OutputFolderName@Type=FilePath\n ~@OutputFolderName@=Output folder for results and BAM files\n\n <Script>\n //Raw data QC section\n Begin NgsQCWizard /Namespace=NgsLib;\n Files\n \"@FileNames@\";\n Options /FileFormat=AUTO /QualityEncoding=Automatic /CompressionMethod=@Gzip@\n /PreviewMode=@PreviewMode@ /ParallelJobNumber=@ParallelJobNumber@\n /BasicStatistics=True  /BaseDistribution=True /QualityBoxPlot=True\n /KMerAnalysis=True  /SequenceDuplication=True /IgnoreFF=True\n /OutputFolder=\"@OutputFolderName@\";\n Output ;\n End;\n\n Begin SaveProject;\n End;\n\n //Mapping Section\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib;\n Files\n \"@FileNames@\";\n Reference Human.B37.3;\n GeneModel RefGene;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options /ParallelJobNumber=@ParallelJobNumber@ /PairedEnd=@PairedSamples@\n /FileFormat=AUTO  /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False  /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10\n /MaxEndInsertionSize=10 /MaxEndDeletionSize=10  /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10 /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@OutputFolderName@\" /GenerateSamFiles=False\n /ThreadNumberPerJob=@ThreadNumberPerJob@  /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=@Gzip@\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False;\n Output ;\n End;\n\n Begin SaveProject;\n End;\n\n\n\n\n\n\n\nAfter installing the PScript on Array Server, any Array Server user can open a server project and open this PScript in \nScripts\n (click on \nUpdate Scripts\n first). \nRNA-Seq Custom Pipeline PScript\n example with full script.\n\n\n\n\n\n\nUsers can simply input their files and parameters and perform their analyses using the customized PScript.",
            "title": "Pipeline Script"
        },
        {
            "location": "/tutorials/Oscript/PipelineScript/#pipeline-script",
            "text": "A pipeline script (Pscript) is created and managed by ArrayServer administrators. Once a pscript is installed in Array Server, it becomes a pipeline tool. Users can submit large amount of samples to the pipelines to process the samples and analyze data. The input and output for the pipeline can also be pre-configured and exposed to GUI.  A Pscript includes three blocks:  Info ,  Input  and  Script .  Info  block allows the administrator to specify a label for the script, a description of the script, as well as a category (separated by \\ for multiple levels) for the pscript, as in the example below:   <Info>\n Label=Illumina RNA-Seq Alignment\n Description=Import Illumina reads with B37/R62\n Category=NGS\\RNA-Seq\\Illumina  Input  block allows the user to specify variables (also defined as Parameters) that will be used by the script. Variables are named by using the @VariableName@ pattern. These variables can be substituted at appropriate places within the script. Each variable should follow this pattern:   @VariableName@=DefaultOption\n ~@VariableName@=Variable description\n ~@VariableName@Levels=Level1, Level\n ~@VariableName@ExclusiveLevels=True  Script  block contains the Ocript procs that perform data analysis in the pipeline. User may refer to Oscript that was introduced in the previous chapter in this tutorial.  Below is an example of a pscript (RnaSeq Alignment Pscript Pipeline) that align RnaSeq reads and save the output bam files to a specified folder:   <Info>\n Label=RnaSeq Alignment Pscript Pipeline\n Description= Align RnaSeq reads and export Bam to a folder\n Category=NGS\\RNA-Seq\\Illumina\n\n <Input>\n @JobNumber@=4\n ~@JobNumber@=Number of threads to run for each of the steps.\n ~@JobNumber@Levels=1,2,3,4,5,6,7,8\n ~@JobNumber@ExclusiveLevels=True\n\n @ThreadNumber@=4\n ~@ThreadNumber@=Number of threads to run for each of the steps.\n ~@ThreadNumer@Levels=1,2,3,4,5,6,7,8\n ~@ThreadNumber@ExclusiveLevels=True\n\n @ProjectFolder@=\n ~@ProjectFolder@Type=FilePath\n ~@ProjectFolder@=Output folder for ALV and BAM files\n ~@ProjectFolder@Type=FilePath\n\n\n <Script>\n Begin OpenProject;\n ServerProject @ProjectName@;\n End;\n\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib /RunOnServer=True;\n Files\n \"@FileNames@\";\n Reference Human.B38;\n GeneModel Ensembl.R82;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options\n /PairedEnd=True /FileFormat=FASTQ /AutoPenalty=True\n /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False /MaxMiddleInsertionSize=10\n /MaxMiddleDeletionSize=10 /MaxEndInsertionSize=10\n /MaxEndDeletionSize=10 /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10\n /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@ProjectFolder@/@ProjectName@/BAM\"\n /GenerateSamFiles=False /ParallelJobNumber=@JobNumber@\n /ThreadNumber=@ThreadNumber@ /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /MatePair=False\n /InsertOnSameStrand=False /InsertOnDifferentStrand=True\n /QualityEncoding=Automatic /CompressionMethod=Gzip\n /Gzip=True /SearchNovelExonJunction=True\n /ExcludeUnmappedInBam=False /KeepFullRead=False\n /Replace=False /Platform=ILLUMINA /CompressBam=False;\n Output RNASeqAlignment;\n End;\n\n Begin SaveProject;\n End;\n\n Begin CloseProject;\n Project @ProjectName@;\n End;  The Pscript may be saved as RnaSeqAlignmentPipeline.pscript, and installed in Array Server in  Manage | Manage Scripts  as shown in the next section.",
            "title": "Pipeline Script"
        },
        {
            "location": "/tutorials/Oscript/PipelineScript/#manage-pscript-in-array-server",
            "text": "ArrayServer administrators can manage (add, edit and remove) PScripts in Array Server. The pscript management is in  Manage | Manage Scripts :    Administrators may install new pscript as a pipeline in Array Server by clicking on  Add | Download script from Omicsoft | Load From File , and select the .pscript file (for example RnaSeqAlignmentPipeline.pscript).  Administrators may install pre-configured pscript pipelines prepared by Omicsoft by clicking on  Add | Download script from Omicsoft .   Choose one script, for example  IlluminaDNASeqBAMFullPipeline , and click  OK  to show the details of the script, including description, required input, oscript for each analysis module. Click on  OK  to install this script on Array Server.",
            "title": "Manage Pscript in Array Server"
        },
        {
            "location": "/tutorials/Oscript/PipelineScript/#submit-samples-to-pscript-pipeline-to-run-jobs-on-array-server",
            "text": "Users may submit samples to Pscript pipeline to perform large scale data analysis on array server.  The most typical way for users run samples in a pipeline is to upload a sample registration file (file extension .osreg) to the user's Instruction folder in Array Server.  Array Server automatically scans the Instruction folder, picks up any sample registration files (osreg files) in the folder, and submits the samples in the osreg file to the pscript pipeline that is specified in the osreg file. The pscript pipeline will process samples in Array Server.   Here is an  osreg  file example that provides input sample and parameters for the RnaSeq Alignment Pscript Pipeline shown in the begining of this chapter:   [Samples]\n SampleID   FilePath    SampleName\n SRR521462  FASTQ1=/path1/test1.fastq|FASTQ2=/path1/test1.fastq Sample1\n\n [SampleSet]\n ID=Alignment_test\n Title=Alignment_test\n Reader=standard users\n Editor=standard users\n ExperimentSource=Test\n ExperimentTitle=Test Experiment1\n ExperimentDescription=Test Pscript for a customer\n ExperimentDesignDate=07/24/2017\n PrincipalInvestigator=Test\n Project=test 1\n\n [Pipeline]\n Project.Readers=standard users\n Project.ID=AlignmentTest\n UserID=omicsoft\n ScriptID=RnaSeqAlignmentPipeline.pscript\n Project.Editors=omicsoft\n Parameters.JobNumber=2\n Parameters.ThreadNumber=4\n Parameters.ProjectFolder=/Users/omicsoft/20170724_pscript_user_v1  Users may refer to the Sample Registration Chapter in Sample Management tutorial for more details on the osreg file.  Users may also submit samples to pscript pipeline by browsing server samples and right click on any SampleSet to  Run Server Pipeline . Users may then choose one of the installed scripts to process their samples.",
            "title": "Submit Samples To Pscript Pipeline to Run Jobs on Array Server"
        },
        {
            "location": "/tutorials/Oscript/PipelineScript/#customize-pscript-and-expose-it-to-array-studio-gui",
            "text": "Server administrators have the capability to make a Pscript available in the Analysis tab of Array Studio. This option would allow users to automate analyses without registering the samples on the server, similar to our built-in analysis pipelines under the  Add Data | Add NGS Data  menu option. To expose a Pscript to GUI, the Pscript author needs to include the following in   section.   <Input>\n ExternalScriptInputType=Files\n ExternalScriptMenuText=Customized Function Name\n ExternalScriptMenuStructure=NGS\\RNA-Seq\\Alignment\n ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz  Example of the full script allowing GUI input:   <Info>\n Label=RNA-Seq Custom Pipeline (with save after each step)\n Description=Raw data QC, Align to B37.3 with RefGene, Post Alignment QC with Ensembl\n Category=NGS\\RNA-Seq\\Illumina\n\n <Input>\n ExternalScriptInputType=Files\n ExternalScriptMenuText= RNA-Seq Custom Pipeline\n ExternalScriptMenuStructure=NGS\\RNA-Seq\\Pipeline\n ExternalScriptFileFilter=FASTQ files|*.fastq|.gz|*.gz\n\n @PairedSamples@=True\n ~@PairedSamples@=Data is paired. Options are True or False (True by default)\n ~@PairedSamples@Levels=True,False\n ~@PairedSamples@ExclusiveLevels=True\n\n @ThreadNumberPerJob@=4\n ~@ThreadNumberPerJob@=Number of threads to run for each of the steps.\n ~@ThreadNumerPerJob@Levels=1,2,3,4,5,6,7,8\n ~@ThreadNumberPerJob@ExclusiveLevels=False\n\n @ParallelJobNumber@=8\n ~@ParallelJobNumber@=Number of parallel jobs to run for each of the steps\n\n @PreviewMode@=True\n ~@PreviewMode@=Set to true to run raw data QC in preview mode\n ~@PreviewMode@Levels=True,False\n ~@PreviewMode@ExclusiveLevels=True\n\n @Gzip@=Gzip\n ~@Gzip@=Set to Gzip if input files are gzipped or None\n ~@Gzip@Levels=Gzip,None\n ~@Gzip@ExclusiveLevels=True\n\n @OutputFolderName@=\n ~@OutputFolderName@Type=FilePath\n ~@OutputFolderName@=Output folder for results and BAM files\n\n <Script>\n //Raw data QC section\n Begin NgsQCWizard /Namespace=NgsLib;\n Files\n \"@FileNames@\";\n Options /FileFormat=AUTO /QualityEncoding=Automatic /CompressionMethod=@Gzip@\n /PreviewMode=@PreviewMode@ /ParallelJobNumber=@ParallelJobNumber@\n /BasicStatistics=True  /BaseDistribution=True /QualityBoxPlot=True\n /KMerAnalysis=True  /SequenceDuplication=True /IgnoreFF=True\n /OutputFolder=\"@OutputFolderName@\";\n Output ;\n End;\n\n Begin SaveProject;\n End;\n\n //Mapping Section\n Begin MapRnaSeqReadsToGenome /Namespace=NgsLib;\n Files\n \"@FileNames@\";\n Reference Human.B37.3;\n GeneModel RefGene;\n Trimming /Mode=TrimByQuality /ReadTrimQuality=2;\n Options /ParallelJobNumber=@ParallelJobNumber@ /PairedEnd=@PairedSamples@\n /FileFormat=AUTO  /AutoPenalty=True /FixedPenalty=2 /Greedy=false /IndelPenalty=2\n /DetectIndels=False  /MaxMiddleInsertionSize=10 /MaxMiddleDeletionSize=10\n /MaxEndInsertionSize=10 /MaxEndDeletionSize=10  /MinDistalEndSize=3\n /ExcludeNonUniqueMapping=False /ReportCutoff=10 /WriteReadsInSeparateFiles=True\n /OutputFolder=\"@OutputFolderName@\" /GenerateSamFiles=False\n /ThreadNumberPerJob=@ThreadNumberPerJob@  /InsertSizeStandardDeviation=40\n /ExpectedInsertSize=300 /InsertOnSameStrand=False\n /InsertOnDifferentStrand=True /QualityEncoding=Automatic /CompressionMethod=@Gzip@\n /SearchNovelExonJunction=True /ExcludeUnmappedInBam=False;\n Output ;\n End;\n\n Begin SaveProject;\n End;   After installing the PScript on Array Server, any Array Server user can open a server project and open this PScript in  Scripts  (click on  Update Scripts  first).  RNA-Seq Custom Pipeline PScript  example with full script.    Users can simply input their files and parameters and perform their analyses using the customized PScript.",
            "title": "Customize Pscript and Expose it to Array Studio GUI"
        },
        {
            "location": "/tutorials/Microarray/Installing_Array_Studio/",
            "text": "Installing Array Studio\n\u00b6\n\n\nIntroduction update\n\u00b6\n\n\nArray Studio\n provides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient for organizing and visualizing data with its \nSolution Explorer\n,\nwhich organizes each project into two main sections ( \n-Omic data\n and \nTable data\n),\nas well as different folders: \nQC, Inference, List, Cluster, Text, Attachments\n and other categories.\nMultiple projects can be opened simultaneously in the \nSolution Explorer\n,\nand data can be shared among projects.\nEach view is controlled by a \nView Controller\n,\nwhich performs view customization, applies filtering, and displays legends.\nFurthermore, its interactive visualization technique provides the details of data with the \nDetails Window\n and the \nWeb Details On-Demand\n.\n\n\nThis chapter will cover installation of Array Studio.\nThe next chapter will cover downloading of the data and chip normalization.\nIn the process, the user will become familiar with some of the features of the \nWorkflow Window\n and \nSolution Explorer\n, as well as getting acquainted with the \nTableView\n in \nArray Studio\n.\n\n\nPrerequisites and installation of Array Studio\n\u00b6\n\n\nWhile Array Studio does not have any specific requirements for memory or processor speed, the following are suggested for successfully finishing this tutorial:\n\n\n\n\n\n\n2.0GHz 32-bit (x86) or 64-bit (x64) processor\n\n\n\n\n\n\n512MB of RAM (1GB recommended)\n\n\n\n\n2GB of RAM for ExonArray, SNP/Genotyping, and CNV analysis\n\n\n\n\n\n\n\n\n2GB hard drive (4GB recommended)\n\n\n\n\n\n\n800*600 display resolution (1024*768 recommended)\n\n\n\n\n\n\nTo install Array Studio, (in Internet Explorer) proceed to \nlink\n\n\n\n\nClick \nInstall\n to install \nArray Studio Launcher\n.\n\n\nNote:\n\n\n\n\n\n\nThe version number listed here is  for Array Studio Launcher, not the Array Studio program. Array Studio Launcher is a tool to download Array Studio online.\n\n\n\n\n\n\nIf you have not previously installed the .NET Framework Version 3.5 on your machine, the website will prompt you to do so.\n\n\n\n\n\n\nThe next time you would like to access Array Studio, you can double click the Array Studio Launcher icon file that was automatically created on your desktop (and in the start menu). Alternatively, you can go to the same website (you can easily bookmark the page) and click the \nInstall\n button again. If the Array Studio has been updated since your last use, the software will automatically update itself before launching. In other words, you will be able to immediately access the software. \nNote\n: Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The latest version is updated frequently.\n\n\nIf the installation of the .NET Framework 3.5 is required, a dialog box will appear with a security warning after installing .NET Framework. Click \nRun\n again to proceed and the application will install. Next time you use Array Studio, you can easily launch the program by just clicking the \nRun\n button.\n\n\n\n\nMicroarray Data and other Data types\n\u00b6\n\n\nIn Bioinformatics research, there are many different data sources such as microarray, sequence data, CNV data, etc. In Array Studio, we divide genetic data into two groups:\nOne is called -Omic data, which is basically a data matrix with annotation for both columns (sample information) and rows (gene/probe set/transcript information),\nand NGS data, which contains reads data. Microarray data is a standard example of -Omic data.\n\n\nWe have provided additional tutorials to analyze the multiple types of data that users may obtain, but in this tutorial we will focus on microarray data. Microarray data can be further categorized into many sub-classes according to the chip or platform. It is also important to know that many methods mentioned in this tutorial can also be applied to other -Omic data, such as RNAseq quantification data. For example, when users load RNAseq data as NGS data, Array Studio provides modules to compute gene/transcription quantification, which is also stored as -Omic data.  It shares the same views as microarray data, and users can apply many methods mentioned in this tutorial to such -Omic data. Therefore, we recommend all users begin with this microarray tutorial to understand the basics of how to analyze -Omic data in Array Studio before exploring other tutorials.",
            "title": "Installing Array Studio"
        },
        {
            "location": "/tutorials/Microarray/Installing_Array_Studio/#installing-array-studio",
            "text": "",
            "title": "Installing Array Studio"
        },
        {
            "location": "/tutorials/Microarray/Installing_Array_Studio/#introduction-update",
            "text": "Array Studio  provides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient for organizing and visualizing data with its  Solution Explorer ,\nwhich organizes each project into two main sections (  -Omic data  and  Table data ),\nas well as different folders:  QC, Inference, List, Cluster, Text, Attachments  and other categories.\nMultiple projects can be opened simultaneously in the  Solution Explorer ,\nand data can be shared among projects.\nEach view is controlled by a  View Controller ,\nwhich performs view customization, applies filtering, and displays legends.\nFurthermore, its interactive visualization technique provides the details of data with the  Details Window  and the  Web Details On-Demand .  This chapter will cover installation of Array Studio.\nThe next chapter will cover downloading of the data and chip normalization.\nIn the process, the user will become familiar with some of the features of the  Workflow Window  and  Solution Explorer , as well as getting acquainted with the  TableView  in  Array Studio .",
            "title": "Introduction update"
        },
        {
            "location": "/tutorials/Microarray/Installing_Array_Studio/#prerequisites-and-installation-of-array-studio",
            "text": "While Array Studio does not have any specific requirements for memory or processor speed, the following are suggested for successfully finishing this tutorial:    2.0GHz 32-bit (x86) or 64-bit (x64) processor    512MB of RAM (1GB recommended)   2GB of RAM for ExonArray, SNP/Genotyping, and CNV analysis     2GB hard drive (4GB recommended)    800*600 display resolution (1024*768 recommended)    To install Array Studio, (in Internet Explorer) proceed to  link   Click  Install  to install  Array Studio Launcher .  Note:    The version number listed here is  for Array Studio Launcher, not the Array Studio program. Array Studio Launcher is a tool to download Array Studio online.    If you have not previously installed the .NET Framework Version 3.5 on your machine, the website will prompt you to do so.    The next time you would like to access Array Studio, you can double click the Array Studio Launcher icon file that was automatically created on your desktop (and in the start menu). Alternatively, you can go to the same website (you can easily bookmark the page) and click the  Install  button again. If the Array Studio has been updated since your last use, the software will automatically update itself before launching. In other words, you will be able to immediately access the software.  Note : Bioinformatics is a fast evolving field. We are developing new analysis functions and options every day. The latest version is updated frequently.  If the installation of the .NET Framework 3.5 is required, a dialog box will appear with a security warning after installing .NET Framework. Click  Run  again to proceed and the application will install. Next time you use Array Studio, you can easily launch the program by just clicking the  Run  button.",
            "title": "Prerequisites and installation of Array Studio"
        },
        {
            "location": "/tutorials/Microarray/Installing_Array_Studio/#microarray-data-and-other-data-types",
            "text": "In Bioinformatics research, there are many different data sources such as microarray, sequence data, CNV data, etc. In Array Studio, we divide genetic data into two groups:\nOne is called -Omic data, which is basically a data matrix with annotation for both columns (sample information) and rows (gene/probe set/transcript information),\nand NGS data, which contains reads data. Microarray data is a standard example of -Omic data.  We have provided additional tutorials to analyze the multiple types of data that users may obtain, but in this tutorial we will focus on microarray data. Microarray data can be further categorized into many sub-classes according to the chip or platform. It is also important to know that many methods mentioned in this tutorial can also be applied to other -Omic data, such as RNAseq quantification data. For example, when users load RNAseq data as NGS data, Array Studio provides modules to compute gene/transcription quantification, which is also stored as -Omic data.  It shares the same views as microarray data, and users can apply many methods mentioned in this tutorial to such -Omic data. Therefore, we recommend all users begin with this microarray tutorial to understand the basics of how to analyze -Omic data in Array Studio before exploring other tutorials.",
            "title": "Microarray Data and other Data types"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/",
            "text": "Importing a Dataset\n\u00b6\n\n\nDownloading the DBPTS dataset\n\u00b6\n\n\nFor this tutorial, the following materials will be required: 24 .CEL files from the DBPTS Time Series dataset (Platform: Affymetrix RAE230A), as well as the included dbpts.design file, derived from the sample information for this dataset. The DBPTS dataset is available at:\n\nlink\n\n\nAfter downloading the single .zip file, unzip the file to a folder to be used for this tutorial. The DBP Time Series data set contains information for 15923 probesets in a 2 by 4 factorial experiment. There are treatment (DBP) and control groups, measured at four different times (1 hr, 3 hr, 6 hr, and 18 hr). The experiment measures the intensity of gene expression level of 15923 probesets, with three replicates for each combination of treatment and time. This is NOT a repeated measure experiment, as different samples were used for different time points. The primary interest of this experiment is to find probesets that are differentially expressed under two conditions (treatment and control) at the 4 different time points.\n\n\nThe dbpts.design file contains the design information for the study, including columns for \nchip, time, treatment, and group.\n A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed \nChip\n for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extensions. Additional columns usually include \ntreatment, time, etc.\n (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it can be edited later on.\n\n\n\n\nThe Workflow Window/ The Solution Explorer\n\u00b6\n\n\nWhen Array Studio is first installed, it will be similar to below.\n\n\nIf you have previously opened projects in Array Studio, you will see the \nLast Opened Projects\n window. If so, just click cancel so that Array Studio looks similar to below.\n\n\nNotice at the top there will be four tabs: Analysis, Server, Land and Browser. This tutorial will focus on Analysis.\n\n\nThe \nWorkflow Window\n should be visible on the left side of the screen. If the \nWorkflow Window\n is not visible, go to the \nView Menu | Show Workflow\n or click on \nWorkflow\n at the bottom left. The \nWorkflow Window\n should appear similar to the screenshot below.\n\n\n\n\nTips: One can always go back to windows in the original setting by selecting the Menu \nView | Reset Windows\n.\n\n\n\n\nThe \nWorkflow Window\n provides users, especially new users, with a  guide  to running different types of analysis. Clicking the \nWorkflow\n dropdown box shows all available workflows (Microarray, Single Channel Expression, Two Channel Expression, Exon Array, RT-PCR, Genotype, CNV, DNA-Seq, RNA-Seq, and miRNA-Seq:\n\n\n\n\nMake sure that Microarray is selected now.\n\n\nNotice that the Microarray Workflow is separated into different categories, including \nGetting started\n, \nManage data\n, \nPreprocess\n, \nQuality control\n, \nStatistical inference\n, and \nPattern recognition\n.\n\n\nWhile it is possible to access all of these functions via the menu commands in \nArray Studio\n, the \nWorkflows\n are designed to make it easier for new users to work through their data.\n\n\nThe first section of the Microarray Workflow is the \nGetting Started\n section. In this section, it is suggested that the user either create a new project or open a previously created project.\n\n\nTo create a new project, click the \nNew Project\n button in the Workflow, or the \nNew\n button on the toolbar, or go to \nFile\n Menu, then click \nNew Project\n. This opens the \nNew Project\n window:\n\n\n\n\nArray Studio\n allows the user to create two different project types. A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects).\n\n\nSince this project is a microarray project, choose \nCreate a simple project\n now. Then, click the \nBrowse\n button to select a location and enter the name for the project. Once this is complete, click \nOK\n to continue.\n\n\nBesides the \nWorkflow Window\n on the left hand side of the screen, \nArray Studio\n also contains the \nSolution Explorer\n. The \nSolution Explorer\n is used to organize each project, and within each project, dataset, results table, etc., that is generated while analyzing and visualizing a project.\n\n\nAnother way to create a new project is by this icon in the Analysis tab:\n\n\n\n\nNote that users can choose to create different projects: Local project as mentioned above and server project. A server project is a distributed project saved on server. Once the user is connected to server, the option of creating a new server project will become available.\n\n\nWhen users want to create a server project, some basic metadata need to be provided:\n\n\n\n\nThe interface of creating of new local project is different from creating a new server project, but the rest of the steps such as data import, data analysis share the same interface. Different project types would tell Array Studio where to run the analysis, if it is a local project, Array Studio would run the analysis in local machine; if it is a server project, Array Studio would run the analysis on server. Server projects are recommended when dealing with larger datasets as server-based analyses allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\n\n\nThe analyses in this tutorial are performed under local project, but can also be followed as a server project if connected to ArrayServer.\n\n\nTo switch to the \nSolution Explorer\n, choose the \nSolution Explorer\n tab, which should be found at the bottom of the \nWorkflow Window\n . If the \nSolution Explorer\n tab is not visible, switch to it by going to the \nView Menu | Show Solution Explorer\n.\n\n\n\n\nThe \nSolution Explorer\n will be empty, containing slots for \nList, Cluster, Text\n and \nAttachment\n. You can right-click on \nList, Cluster, Text\n and \nAttachment\n for additional options for each. For instance, right-clicking on \nList\n will bring up options to add a new List, add list from file, etc. A \nList\n can be used to filter the data, by either \nVariables\n (in the case of microarray data, this would be probesets), or \nObservations\n (in the case of microarray data, this would be chips or samples).\n\n\n\n\nRight Clicking on List brings up this menu:\n\n\n\n\nAdding Microarray Data/Chip Normalization\n\u00b6\n\n\nAt this point, we are ready to add microarray data to the \nSolution Explorer\n. This can be done in a variety of ways, but the easiest way is to first switch back to the \nWorkflow Window\n, by selecting the \nWorkflow\n tab at the bottom of the \nSolution Explorer\n. Alternatively, go to \nView Menu | Show Workflow\n to show the \nWorkflow Window\n.\n\n\n\n\nNext, choose \nAdd Expression Data\n, from the \nManage Data\n section of the workflow. Alternatively, data can be added by going to the \nFile Menu | Add Data |Add Omic Data | Add Expression Data\n or by clicking the \nAdd Data\n button on the tool strip, and choosing \nAdd Omic Data | Add Expression Data\n.\n\n\nA dialog box will open asking the user to specify the expression data source. Many different sources of data are available to choose from in Array Studio and can be seen in the dialog window below.\n\n\nFor this tutorial, the 24 Affymetrix .CEL files downloaded earlier will be used. Select \nAffymetrix .CEL files (3 IVT, or Gene Arrays)\n and click \nOK\n.\n\n\n\n\nThe \nExtract Affymetrix CEL file\n window appears:\n\n\n\n\nClick the \nAdd\n button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click \nOpen\n to continue.\n\n\n\n\nCheck that there are 24 .CEL files listed for extraction by looking in the upper left corner of the dialog box.\n\n\n\n\nUnder \nOptions\n , the user will be shown the \nArray type\n of the CEL files that are being imported. The user has the option to select an alternative CDF (Affymetrix Library) file.\n\n\nThe user can also select from the following Options:\n\n\n\n\n\n\nThe choice of analysis methods include: \nRMA, GCRMA2, MAS5\n and \nOMICSOFT\n (see reference for details).\n\n\n\n\n\n\nFor experiments performed at different times, the \nScale RMA/GCRMA signals\n can be used to scale all chips to a particular \nTarget intensity\n.\n\n\n\n\n\n\nFor MAS5 extractions, as well as when the \nScale RMA/GCRMA signals\n box is checked, a number can be entered into the \nTarget intensity\n box.\n\n\n\n\n\n\nA log-2 transformation can be performed on the signal matrix data upon extraction. If the user unchecks the \nPerform log-2 transformation on the signal matrix\n box, a log-2 transformation can still be performed at a later stage.\n\n\n\n\n\n\nIf checked, the \nImport Sample Information from ARR files\n option will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files if they were generated by Affymetrix's \nExpression Console\n.\n\n\n\n\n\n\nThe \nGenerate MAS5 QC Report\n checkbox (available after adding CEL files), allows the user to automatically generate a MAS5 Report, without going through the separate menu option (\nTools |Affymetrix | Generate Affymetrix MAS5 QC Report\n), however it offers fewer options than the regular menu item. The \nSelect controls\n button allows the user to select the control genes for calculating 3 /5  ratios in the report (i.e. GAPDH, beta-actin, etc.).\n\n\n\n\n\n\nThe \nGenerate detection flag with p-value <\n checkbox allows the user to automatically generate a detection flag value based on a cutoff value specified (default of <0.05). Selecting this option will generate a table with values of 0 (meaning not present with a p-value <0.05) or 1 (present with a p-value <0.05). The resulting \"FlagTable\" view is hidden, but can be added by right click on \nMicroArrayData | Add View | FlagTableView\n. The detection flag table can be used in \nMicroArray | Preprocess | Filter By Flags\n.\n\n\n\n\n\n\nSelecting \nReport intensity + detection p-values\n will automatically generate an \"IntensityReport\" data object with an associated \"Intensity_Detection\" view and table.\n\n\n\n\n\n\nA CEL Report (Probe level) can also be generated, if Generate CEL Report box is checked. This can be done with the separate menu option \nTools | Affymetrix |Generate Affymetrix CEL report\n.\n\n\n\n\n\n\nOptionally, a model based QC report can be generated as well. This is discussed further in the online help.\n\n\n\n\n\n\nFinally, the user can generate CHP files while extraction takes place, using the \nWrite CHP files\n checkbox.\n\n\n\n\n\n\nClick on the \nHelp\n button on the bottom left of the window to open the wiki page for \nExtract Affymetrix CEL Files\n. The wiki page describes the function input and output of this module, and explains all the options and parameters used in this module. Every analysis module in Array Studio has this \nHelp\n button to link to the corresponding wiki page.\n\n\nWhen complete, the window should look similar to the following screenshot.\n\n\n\n\nClick \nSubmit\n to start the RMA intensity signal matrix extraction. Data extraction will begin and take approximately 30 seconds.\n\n\nWhen complete, \nArray Studio\n will prompt the user to attach a design table. Click \nYes\n now to attach the design table that was packaged with the CEL files. If \nNo\n was selected instead, the design table can always be attached by right clicking on the design node for the project in the \nSolution Explorer\n and choosing \nImport\n to attach/reattach the design.\n\n\n\n\nThe \nSpecify Table Source\n window will open. As \ndbpts.design.txt\n is a tab-delimited text file, choose \nTab delimited file\n and click \nOK\n to continue.\n\n\n\n\nChoose \ndbpts.design\n and click \nOpen\n to continue the attachment process.\n\n\n\n\nSpecify the location of the Design table file. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to \nAppend to the existing covariate table\n (if one exists) and to \nUse the name order in the new covariate table\n. Leave these options as default.\n\n\n\n\nSelecting \"OK\" will then proceed with the data parsing and creation of the Design table.\n\n\nThe TableView\n\u00b6\n\n\nAt this point, the screen should look similar to below. On the left, the \nSolution Explorer\n will show an Annotation (automatically downloaded according to chip type) and Design Table (just imported) along with the Microarray Data type in Table format. Also, in the Table Data type, there will be a Mas5Report (under QC) and IntensityReport as chosen in the output of the previous command. In the center of the screen, a table view called \nTable\n should be visible. Scroll through the dataset to see how quickly \nArray Studio\n is able to scroll. \nArray Studio\n is able to easily handle millions of rows and columns in the \nTableView\n.\n\n\n\n\nNow switch back to the \nSolution Explorer\n.\n\n\nIn Array Studio, the Solution Explorer will contain two types of data (-Omic data and Table data). These are organized separately in the Solution Explorer for each project. Open the  Omic data node now, followed by the MicroArrayData node.\n\n\nIn the main view window, click on the \n button on the right top corner to close the current view, \nMicroarrayData|Table.\n Then double-click in the \nSolution Explorer | Tutorial | -Omic Data |MicroArrayData | Table\n to reopen the \nTableView\n.\n\n\n\n\nMoving the mouse over any of the icons in the toolbar will give a short description of the button.\n\n\n\n\nOpen as Text\n: will open current visible table in the default text editor (e.g. Notepad)\n\n\n\n\nOpen in Excel\n: will open current visible table in Microsoft Excel\n\n\n\n\nSave as Text/object\n: will open dialog box to save current visible table as Text, Excel or Omicsoft object\n\n\n\n\nSort Table\n: will sort the view, opening the Sort window. The Sort window allows the user to sort by up to four different columns, in either ascending or descending order.\n\n\n\n\nNote that the sorting mentioned above only applies to the current view, and not the actual data. So if the current Table View is closed, it would need to be sorted again.\n\n\nFor more advanced features including sorting of the actual data instead of the view, use the menu, \nOmic\n \nData | Manipulation | Sort Variables\n.\n\n\n\n\nFilter\n: Filter table by different rows\n\n\n\n\nCopy Table to Clipboard\n: will copy current visible table to clipboard.\n\n\n\n\nAdditional Tools\n: contains a popup menu for additional tools:\n\n\nFind/Replace\n: find or replace cells in the table (this is not allowed with  Omic data but can be used with regular table data.\n\n\nMatch Selected Cells\n: select one or multiple cells in the table. Then click Match Selected Cells to find all of the other cells in the table that match the selected cells.\n\n\nNext Selected Row\n: finds the next row in the table from that of the currently selected row.\n\n\nPrevious Selected Row\n: finds the previous row in the table from that of the previously selected row.\n\n\nGo to Row\n: allows the user to input either the row name or the row index (starting from 1) and Array Studio will automatically scroll to the row in the table.\n\n\n\n\nZoom out\n: will zoom out the table.\n\n\n\n\nSpecify Zoom Factor\n: click to specific zoom factor\n\n\n\n\nZoom in\n: will zoom in the table.\n\n\n\n\nFit window to full screen\n\n\nDetails Window/Web Details\n\u00b6\n\n\nThe \nTableView\n, and all other views in \nArray Studio\n, are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the \nDetails Window\n.\n\n\nIn the \nTableView\n, click the column header cell for 02A. The green color here shows that this field has been selected. To remove the selection, click the toolbar \"Clear\" \n\n\n\n\nIf the \nDetails Window\n is not shown at the bottom of the screen, go to \nView Menu | Show Details Window\n now to show it.\n\n\nOnce visible, the \nDetails Window\n should update with information about the selected observation, 02A.\n\n\n\n\nThe user can also click on the header cell for any variable. Do this now, and notice that the \nDetails Window\n updates with the automatically downloaded gene annotation for that particular probeset.\n\n\n\n\nBesides the \nDetails Window\n, \nArray Studio\n also contains \nWeb Details On-Demand\n. \nWeb Details\n allow the user to connect to online websites for further information about a particular variable or probeset.\n\n\nIn the \nDetails Window\n, right-click on the row header cell that was previously selected.\n\n\nThis should bring up a list of different \nWeb Details\n that are available. Depending on the probeset picked, this list could be longer or shorter than that shown below.\n\n\nScroll to a probeID that does not begin with AFFX, right click and choose the UCSC link.\n\n\n\n\nThis should open a new window in \nInternet Explorer\n.\n\n\n\n\nThe MAS5 Report and Intensity Report\n\u00b6\n\n\nUnder the \nTable | QC\n folder of the \nSolution Explorer\n, there is a MAS5 report telling us the \nRawQ, ScaleFactor, Background, BackgroundStdDev, PresentPercentage\n and \nAverageSignal\n of each chip.\n\n\n\n\nThe \nIntensityReport\n under \nTable\n folder of the \nSolution Explorer\n gives a visualization of detection pvalue against probe set intensity.\n\n\n\n\nThe View Controller\n\u00b6\n\n\nThe \nView Controller\n is an extremely important feature for the visualizations in Array Studio. Its purpose is to allow the user to customize the views on the screen. If you do not see \nView Controller\n, go to the menu \nView | Show View Controller\n.\n\n\n\n\nThe view controller should now be visible on the right side of the screen.\n\n\n\n\nClick the pin button \n so that it is facing downwards. \n This ensures that the \nView Controller\n remains in constant view. If the pin is facing to the left, the \nView Controller\n (and any other window i.e. \nSolution Explorer, Details Window, etc.\n ) will auto hide itself when it loses the mouse focus. When the user rolls the mouse pointer over the hidden view, it will reappear. Keep the \nView Controller\n with the pin facing downwards so that the \nView Controller\n is visible at all times.\n\n\nAs can be seen from the picture above, the \nView Controller\n contains three tabs. The \nTask\n tab contains all the settings for modifying the properties of the current view. For the \nTableView\n, this includes \nShow Row Numbers\n, \nSpecify Columns\n, \nReset Columns\n, \nGenerate Data From View and Export With Customized Column Headers\n. Click \nSpecify Columns\n to specify which columns of the dataset are visible.\n\n\n\n\nMove columns to the left or right using the left and right arrows, and organize the order that the columns appear by using the up and down arrows. Click \nOK\n to return to \nView Controller | Task\n.\n\n\nClick on the \nObservation\n tab.\n\n\n\n\nFor the \nTableView\n, the \nObservation\n tab contains the name of every column in the attached Design Table by default. The toolbar icons for the Variable and Observation views are defined as follows:\n\n\n\n\nCollapse All\n: will collapse all the filters to return the user to the view above.\n\n\n\n\nExpand All\n: will expand all the filters.\n\n\n\n\nReset All Filters\n: will reset all filters to the default states (no filter).\n\n\n\n\nClear All Filters\n: will clear all filters, including removing any added filters.\n\n\n\n\nShow/Hide Columns\n: will bring up a dialog box to determine which columns, and in what order, will be displayed in the \nFilter\n tab.\n\n\n\n\nAdd List Filter\n: will add a list filter to the currently selected column in the \nFilter\n tab. At this point in the tutorial, the user does not yet have a \nList\n so this will be discussed in more detail later.\n\n\n\n\nOptions\n - allows the user to group the filters. This is useful when looking at filters for an \nInference Report\n, but has no real use for the \nObservation\n tab of a data object.\n\n\nIn addition, the user can set Match All Columns (default) or Match Any Columns for the filters (this is the equivalent of AND or OR for multiple filters).\n\n\n\n\nThe \"+\"\n icon will expand the entire filter group.\n\n\nThe \"-\"\n icon will collapse the filter group.\n\n\nAt this point, click the \nExpand All\n button to expand all column filters.\n\n\n\n\nThere are four different types of filters visible in this view. The first type is referred as a \nString Filter\n. Clicking there allows the user to type in a filter for the column.\n\n\nFor instance, typing in \n2A\n under chip column will filter the \nchip\n column for any row that contains \n2A\n.\n\n\n\n\nWhen a filter is selected, it is highlighted by the radio checkbox next to it. In addition, the filter informs the user how many variables or observations passed filtering.\n\n\n. \n\n\nTaking a look at the \nTableView\n in the center of the screen, it is clear that the only observations remaining visible are those containing \n2A\n.\n\n\n\n\nThe second type of filter visible with this table can be seen with the \ntreatment\n and \ngroup\n columns. This is referred to as the \nRadio filter\n in which the filters are automatically created, each with its own button. Array Studio defaults to the \nRadio filter\n when there are a limited number of choices (if that does not appear to be the case, the column type will need to be set to \nFactor\n; the user can change any columns to a factor column by choosing \nTable | Columns | Column Properties\n Next, right click on the factor in the \nView Controller\n and select \nRadio Filter\n). The \nRadio filter\n is not available on columns with larger numbers of options than limit.\n\n\nFirst, remove the previous filter by switching it from \n02A\n to \n(no filter)\n.\n\n\nNext, the data can be filtered with the \nRadio filter\n by clicking on the desired filter. Select \ncontrol\n from the options under the \ntreatment\n filter.\n\n\n\n\nAgain, take a look at the \nTableView\n and select the column headers to see that the only samples in the table are in control group.\n\n\nA third type of filter is the \nCheckbox\n filter. If this type of filter is not shown, it can easily be added by changing the filter type. Simply right-click on the name of the column filter and choose the \"CheckBox\" option as shown below:\n\n\n\n\nClicking \nCheckBox\n will then allow the user to check off each option available for filtering. In the example below, only those rows that contain a \ngroup\n control.t3 or DBP.t3 will be visible in the \nTableView\n.\n\n\n\n\nThere is a fourth type of filter: \nnumeric filter\n, which is available only for numeric columns. This type of filter will be discussed later in the inference report view.\n\n\nAt this point, clear all filters by clicking the \nClear All\n button.\n\n\n\n\nClick on the \nVariable\n tab in the \nView Controller\n. Notice that Array Studio automatically adds potential filters for every column of chip annotation. The buttons on the \nView Controller | Variable\n are exactly the same as that found in the \nView Controller | Observation\n. Expand the \nGene Symbol\n filter, and type \n^Egr1$\n, or \n\"Egr1\"\n (with quote) to find all \nVariables\n that match exactly \nEgr1\n (the ^ and $ symbols are used in the same way as regular expression).\n\n\nSupported filter syntax in Array Studio:\n\n\n\n\n\n\n\n\nSyntax\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n>N\n\n\nGreater than N\n\n\n\n\n\n\n<N\n\n\nLess than N\n\n\n\n\n\n\n=N\n\n\nEqual to N\n\n\n\n\n\n\n>=N\n\n\nGreater than or equal to N\n\n\n\n\n\n\n<=N\n\n\nLess than or equal to N\n\n\n\n\n\n\na&b\n\n\nMatching a and b\n\n\n\n\n\n\na\n\n\nMatching a a\n\n\n\n\n\n\na AND b\n\n\na and b\n\n\n\n\n\n\na\n\n\nb\n\n\n\n\n\n\na OR b\n\n\nMatching a or b\n\n\n\n\n\n\n^abc\n\n\nStarts with abc\n\n\n\n\n\n\nabc$\n\n\nEnds with abc\n\n\n\n\n\n\nabc\n\n\nMatches exactly abc\n\n\n\n\n\n\n^abc$\n\n\nMatches exactly abc\n\n\n\n\n\n\nNOT\n\n\nIncludes everything not in the filter\n\n\n\n\n\n\n\n\nTo keep only empty strings\n\n\n\n\n\n\n~\n\n\nTo keep only non-empty strings\n\n\n\n\n\n\n\n\n\n\nNotice that this then filters the dataset. 1 row is found that exactly matches \nEgr1\n for \nGene Symbol\n. Again, dimensions of the filtered table can be found by looking at the top right of the center \ntable view\n\n\n\n\nNotice that when a filter is applied to a parameter, it changes to a red color in the \nView Controller\n. This can be used to quickly track what filters are in place on a heavily filtered dataset.\n\n\n\n\nRemove the filter by either clicking the \nClear All\n button or right-clicking on the \nGene Symbol\n Filter \n^Egr1$\n and clicking \nRemove Filter\n.\n\n\n\n\nClick on \nSave\n button from the toolbar to save the current project.\n\n\n\n\nCongratulations! The dataset from DBPTS is successfully loaded into Array Studio and is ready for downstream visualization and analysis.",
            "title": "Importing a Dataset"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#importing-a-dataset",
            "text": "",
            "title": "Importing a Dataset"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#downloading-the-dbpts-dataset",
            "text": "For this tutorial, the following materials will be required: 24 .CEL files from the DBPTS Time Series dataset (Platform: Affymetrix RAE230A), as well as the included dbpts.design file, derived from the sample information for this dataset. The DBPTS dataset is available at: link  After downloading the single .zip file, unzip the file to a folder to be used for this tutorial. The DBP Time Series data set contains information for 15923 probesets in a 2 by 4 factorial experiment. There are treatment (DBP) and control groups, measured at four different times (1 hr, 3 hr, 6 hr, and 18 hr). The experiment measures the intensity of gene expression level of 15923 probesets, with three replicates for each combination of treatment and time. This is NOT a repeated measure experiment, as different samples were used for different time points. The primary interest of this experiment is to find probesets that are differentially expressed under two conditions (treatment and control) at the 4 different time points.  The dbpts.design file contains the design information for the study, including columns for  chip, time, treatment, and group.  A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed  Chip  for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the .CEL file extensions. Additional columns usually include  treatment, time, etc.  (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it can be edited later on.",
            "title": "Downloading the DBPTS dataset"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#the-workflow-window-the-solution-explorer",
            "text": "When Array Studio is first installed, it will be similar to below.  If you have previously opened projects in Array Studio, you will see the  Last Opened Projects  window. If so, just click cancel so that Array Studio looks similar to below.  Notice at the top there will be four tabs: Analysis, Server, Land and Browser. This tutorial will focus on Analysis.  The  Workflow Window  should be visible on the left side of the screen. If the  Workflow Window  is not visible, go to the  View Menu | Show Workflow  or click on  Workflow  at the bottom left. The  Workflow Window  should appear similar to the screenshot below.   Tips: One can always go back to windows in the original setting by selecting the Menu  View | Reset Windows .   The  Workflow Window  provides users, especially new users, with a  guide  to running different types of analysis. Clicking the  Workflow  dropdown box shows all available workflows (Microarray, Single Channel Expression, Two Channel Expression, Exon Array, RT-PCR, Genotype, CNV, DNA-Seq, RNA-Seq, and miRNA-Seq:   Make sure that Microarray is selected now.  Notice that the Microarray Workflow is separated into different categories, including  Getting started ,  Manage data ,  Preprocess ,  Quality control ,  Statistical inference , and  Pattern recognition .  While it is possible to access all of these functions via the menu commands in  Array Studio , the  Workflows  are designed to make it easier for new users to work through their data.  The first section of the Microarray Workflow is the  Getting Started  section. In this section, it is suggested that the user either create a new project or open a previously created project.  To create a new project, click the  New Project  button in the Workflow, or the  New  button on the toolbar, or go to  File  Menu, then click  New Project . This opens the  New Project  window:   Array Studio  allows the user to create two different project types. A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects).  Since this project is a microarray project, choose  Create a simple project  now. Then, click the  Browse  button to select a location and enter the name for the project. Once this is complete, click  OK  to continue.  Besides the  Workflow Window  on the left hand side of the screen,  Array Studio  also contains the  Solution Explorer . The  Solution Explorer  is used to organize each project, and within each project, dataset, results table, etc., that is generated while analyzing and visualizing a project.  Another way to create a new project is by this icon in the Analysis tab:   Note that users can choose to create different projects: Local project as mentioned above and server project. A server project is a distributed project saved on server. Once the user is connected to server, the option of creating a new server project will become available.  When users want to create a server project, some basic metadata need to be provided:   The interface of creating of new local project is different from creating a new server project, but the rest of the steps such as data import, data analysis share the same interface. Different project types would tell Array Studio where to run the analysis, if it is a local project, Array Studio would run the analysis in local machine; if it is a server project, Array Studio would run the analysis on server. Server projects are recommended when dealing with larger datasets as server-based analyses allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.  The analyses in this tutorial are performed under local project, but can also be followed as a server project if connected to ArrayServer.  To switch to the  Solution Explorer , choose the  Solution Explorer  tab, which should be found at the bottom of the  Workflow Window  . If the  Solution Explorer  tab is not visible, switch to it by going to the  View Menu | Show Solution Explorer .   The  Solution Explorer  will be empty, containing slots for  List, Cluster, Text  and  Attachment . You can right-click on  List, Cluster, Text  and  Attachment  for additional options for each. For instance, right-clicking on  List  will bring up options to add a new List, add list from file, etc. A  List  can be used to filter the data, by either  Variables  (in the case of microarray data, this would be probesets), or  Observations  (in the case of microarray data, this would be chips or samples).   Right Clicking on List brings up this menu:",
            "title": "The Workflow Window/ The Solution Explorer"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#adding-microarray-datachip-normalization",
            "text": "At this point, we are ready to add microarray data to the  Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the  Workflow Window , by selecting the  Workflow  tab at the bottom of the  Solution Explorer . Alternatively, go to  View Menu | Show Workflow  to show the  Workflow Window .   Next, choose  Add Expression Data , from the  Manage Data  section of the workflow. Alternatively, data can be added by going to the  File Menu | Add Data |Add Omic Data | Add Expression Data  or by clicking the  Add Data  button on the tool strip, and choosing  Add Omic Data | Add Expression Data .  A dialog box will open asking the user to specify the expression data source. Many different sources of data are available to choose from in Array Studio and can be seen in the dialog window below.  For this tutorial, the 24 Affymetrix .CEL files downloaded earlier will be used. Select  Affymetrix .CEL files (3 IVT, or Gene Arrays)  and click  OK .   The  Extract Affymetrix CEL file  window appears:   Click the  Add  button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click  Open  to continue.   Check that there are 24 .CEL files listed for extraction by looking in the upper left corner of the dialog box.   Under  Options  , the user will be shown the  Array type  of the CEL files that are being imported. The user has the option to select an alternative CDF (Affymetrix Library) file.  The user can also select from the following Options:    The choice of analysis methods include:  RMA, GCRMA2, MAS5  and  OMICSOFT  (see reference for details).    For experiments performed at different times, the  Scale RMA/GCRMA signals  can be used to scale all chips to a particular  Target intensity .    For MAS5 extractions, as well as when the  Scale RMA/GCRMA signals  box is checked, a number can be entered into the  Target intensity  box.    A log-2 transformation can be performed on the signal matrix data upon extraction. If the user unchecks the  Perform log-2 transformation on the signal matrix  box, a log-2 transformation can still be performed at a later stage.    If checked, the  Import Sample Information from ARR files  option will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files if they were generated by Affymetrix's  Expression Console .    The  Generate MAS5 QC Report  checkbox (available after adding CEL files), allows the user to automatically generate a MAS5 Report, without going through the separate menu option ( Tools |Affymetrix | Generate Affymetrix MAS5 QC Report ), however it offers fewer options than the regular menu item. The  Select controls  button allows the user to select the control genes for calculating 3 /5  ratios in the report (i.e. GAPDH, beta-actin, etc.).    The  Generate detection flag with p-value <  checkbox allows the user to automatically generate a detection flag value based on a cutoff value specified (default of <0.05). Selecting this option will generate a table with values of 0 (meaning not present with a p-value <0.05) or 1 (present with a p-value <0.05). The resulting \"FlagTable\" view is hidden, but can be added by right click on  MicroArrayData | Add View | FlagTableView . The detection flag table can be used in  MicroArray | Preprocess | Filter By Flags .    Selecting  Report intensity + detection p-values  will automatically generate an \"IntensityReport\" data object with an associated \"Intensity_Detection\" view and table.    A CEL Report (Probe level) can also be generated, if Generate CEL Report box is checked. This can be done with the separate menu option  Tools | Affymetrix |Generate Affymetrix CEL report .    Optionally, a model based QC report can be generated as well. This is discussed further in the online help.    Finally, the user can generate CHP files while extraction takes place, using the  Write CHP files  checkbox.    Click on the  Help  button on the bottom left of the window to open the wiki page for  Extract Affymetrix CEL Files . The wiki page describes the function input and output of this module, and explains all the options and parameters used in this module. Every analysis module in Array Studio has this  Help  button to link to the corresponding wiki page.  When complete, the window should look similar to the following screenshot.   Click  Submit  to start the RMA intensity signal matrix extraction. Data extraction will begin and take approximately 30 seconds.  When complete,  Array Studio  will prompt the user to attach a design table. Click  Yes  now to attach the design table that was packaged with the CEL files. If  No  was selected instead, the design table can always be attached by right clicking on the design node for the project in the  Solution Explorer  and choosing  Import  to attach/reattach the design.   The  Specify Table Source  window will open. As  dbpts.design.txt  is a tab-delimited text file, choose  Tab delimited file  and click  OK  to continue.   Choose  dbpts.design  and click  Open  to continue the attachment process.   Specify the location of the Design table file. Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to  Append to the existing covariate table  (if one exists) and to  Use the name order in the new covariate table . Leave these options as default.   Selecting \"OK\" will then proceed with the data parsing and creation of the Design table.",
            "title": "Adding Microarray Data/Chip Normalization"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#the-tableview",
            "text": "At this point, the screen should look similar to below. On the left, the  Solution Explorer  will show an Annotation (automatically downloaded according to chip type) and Design Table (just imported) along with the Microarray Data type in Table format. Also, in the Table Data type, there will be a Mas5Report (under QC) and IntensityReport as chosen in the output of the previous command. In the center of the screen, a table view called  Table  should be visible. Scroll through the dataset to see how quickly  Array Studio  is able to scroll.  Array Studio  is able to easily handle millions of rows and columns in the  TableView .   Now switch back to the  Solution Explorer .  In Array Studio, the Solution Explorer will contain two types of data (-Omic data and Table data). These are organized separately in the Solution Explorer for each project. Open the  Omic data node now, followed by the MicroArrayData node.  In the main view window, click on the   button on the right top corner to close the current view,  MicroarrayData|Table.  Then double-click in the  Solution Explorer | Tutorial | -Omic Data |MicroArrayData | Table  to reopen the  TableView .   Moving the mouse over any of the icons in the toolbar will give a short description of the button.   Open as Text : will open current visible table in the default text editor (e.g. Notepad)   Open in Excel : will open current visible table in Microsoft Excel   Save as Text/object : will open dialog box to save current visible table as Text, Excel or Omicsoft object   Sort Table : will sort the view, opening the Sort window. The Sort window allows the user to sort by up to four different columns, in either ascending or descending order.   Note that the sorting mentioned above only applies to the current view, and not the actual data. So if the current Table View is closed, it would need to be sorted again.  For more advanced features including sorting of the actual data instead of the view, use the menu,  Omic   Data | Manipulation | Sort Variables .   Filter : Filter table by different rows   Copy Table to Clipboard : will copy current visible table to clipboard.   Additional Tools : contains a popup menu for additional tools:  Find/Replace : find or replace cells in the table (this is not allowed with  Omic data but can be used with regular table data.  Match Selected Cells : select one or multiple cells in the table. Then click Match Selected Cells to find all of the other cells in the table that match the selected cells.  Next Selected Row : finds the next row in the table from that of the currently selected row.  Previous Selected Row : finds the previous row in the table from that of the previously selected row.  Go to Row : allows the user to input either the row name or the row index (starting from 1) and Array Studio will automatically scroll to the row in the table.   Zoom out : will zoom out the table.   Specify Zoom Factor : click to specific zoom factor   Zoom in : will zoom in the table.   Fit window to full screen",
            "title": "The TableView"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#details-windowweb-details",
            "text": "The  TableView , and all other views in  Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the  Details Window .  In the  TableView , click the column header cell for 02A. The green color here shows that this field has been selected. To remove the selection, click the toolbar \"Clear\"    If the  Details Window  is not shown at the bottom of the screen, go to  View Menu | Show Details Window  now to show it.  Once visible, the  Details Window  should update with information about the selected observation, 02A.   The user can also click on the header cell for any variable. Do this now, and notice that the  Details Window  updates with the automatically downloaded gene annotation for that particular probeset.   Besides the  Details Window ,  Array Studio  also contains  Web Details On-Demand .  Web Details  allow the user to connect to online websites for further information about a particular variable or probeset.  In the  Details Window , right-click on the row header cell that was previously selected.  This should bring up a list of different  Web Details  that are available. Depending on the probeset picked, this list could be longer or shorter than that shown below.  Scroll to a probeID that does not begin with AFFX, right click and choose the UCSC link.   This should open a new window in  Internet Explorer .",
            "title": "Details Window/Web Details"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#the-mas5-report-and-intensity-report",
            "text": "Under the  Table | QC  folder of the  Solution Explorer , there is a MAS5 report telling us the  RawQ, ScaleFactor, Background, BackgroundStdDev, PresentPercentage  and  AverageSignal  of each chip.   The  IntensityReport  under  Table  folder of the  Solution Explorer  gives a visualization of detection pvalue against probe set intensity.",
            "title": "The MAS5 Report and Intensity Report"
        },
        {
            "location": "/tutorials/Microarray/Importing_a_Dataset/#the-view-controller",
            "text": "The  View Controller  is an extremely important feature for the visualizations in Array Studio. Its purpose is to allow the user to customize the views on the screen. If you do not see  View Controller , go to the menu  View | Show View Controller .   The view controller should now be visible on the right side of the screen.   Click the pin button   so that it is facing downwards.   This ensures that the  View Controller  remains in constant view. If the pin is facing to the left, the  View Controller  (and any other window i.e.  Solution Explorer, Details Window, etc.  ) will auto hide itself when it loses the mouse focus. When the user rolls the mouse pointer over the hidden view, it will reappear. Keep the  View Controller  with the pin facing downwards so that the  View Controller  is visible at all times.  As can be seen from the picture above, the  View Controller  contains three tabs. The  Task  tab contains all the settings for modifying the properties of the current view. For the  TableView , this includes  Show Row Numbers ,  Specify Columns ,  Reset Columns ,  Generate Data From View and Export With Customized Column Headers . Click  Specify Columns  to specify which columns of the dataset are visible.   Move columns to the left or right using the left and right arrows, and organize the order that the columns appear by using the up and down arrows. Click  OK  to return to  View Controller | Task .  Click on the  Observation  tab.   For the  TableView , the  Observation  tab contains the name of every column in the attached Design Table by default. The toolbar icons for the Variable and Observation views are defined as follows:   Collapse All : will collapse all the filters to return the user to the view above.   Expand All : will expand all the filters.   Reset All Filters : will reset all filters to the default states (no filter).   Clear All Filters : will clear all filters, including removing any added filters.   Show/Hide Columns : will bring up a dialog box to determine which columns, and in what order, will be displayed in the  Filter  tab.   Add List Filter : will add a list filter to the currently selected column in the  Filter  tab. At this point in the tutorial, the user does not yet have a  List  so this will be discussed in more detail later.   Options  - allows the user to group the filters. This is useful when looking at filters for an  Inference Report , but has no real use for the  Observation  tab of a data object.  In addition, the user can set Match All Columns (default) or Match Any Columns for the filters (this is the equivalent of AND or OR for multiple filters).   The \"+\"  icon will expand the entire filter group.  The \"-\"  icon will collapse the filter group.  At this point, click the  Expand All  button to expand all column filters.   There are four different types of filters visible in this view. The first type is referred as a  String Filter . Clicking there allows the user to type in a filter for the column.  For instance, typing in  2A  under chip column will filter the  chip  column for any row that contains  2A .   When a filter is selected, it is highlighted by the radio checkbox next to it. In addition, the filter informs the user how many variables or observations passed filtering.  .   Taking a look at the  TableView  in the center of the screen, it is clear that the only observations remaining visible are those containing  2A .   The second type of filter visible with this table can be seen with the  treatment  and  group  columns. This is referred to as the  Radio filter  in which the filters are automatically created, each with its own button. Array Studio defaults to the  Radio filter  when there are a limited number of choices (if that does not appear to be the case, the column type will need to be set to  Factor ; the user can change any columns to a factor column by choosing  Table | Columns | Column Properties  Next, right click on the factor in the  View Controller  and select  Radio Filter ). The  Radio filter  is not available on columns with larger numbers of options than limit.  First, remove the previous filter by switching it from  02A  to  (no filter) .  Next, the data can be filtered with the  Radio filter  by clicking on the desired filter. Select  control  from the options under the  treatment  filter.   Again, take a look at the  TableView  and select the column headers to see that the only samples in the table are in control group.  A third type of filter is the  Checkbox  filter. If this type of filter is not shown, it can easily be added by changing the filter type. Simply right-click on the name of the column filter and choose the \"CheckBox\" option as shown below:   Clicking  CheckBox  will then allow the user to check off each option available for filtering. In the example below, only those rows that contain a  group  control.t3 or DBP.t3 will be visible in the  TableView .   There is a fourth type of filter:  numeric filter , which is available only for numeric columns. This type of filter will be discussed later in the inference report view.  At this point, clear all filters by clicking the  Clear All  button.   Click on the  Variable  tab in the  View Controller . Notice that Array Studio automatically adds potential filters for every column of chip annotation. The buttons on the  View Controller | Variable  are exactly the same as that found in the  View Controller | Observation . Expand the  Gene Symbol  filter, and type  ^Egr1$ , or  \"Egr1\"  (with quote) to find all  Variables  that match exactly  Egr1  (the ^ and $ symbols are used in the same way as regular expression).  Supported filter syntax in Array Studio:     Syntax  Description      >N  Greater than N    <N  Less than N    =N  Equal to N    >=N  Greater than or equal to N    <=N  Less than or equal to N    a&b  Matching a and b    a  Matching a a    a AND b  a and b    a  b    a OR b  Matching a or b    ^abc  Starts with abc    abc$  Ends with abc    abc  Matches exactly abc    ^abc$  Matches exactly abc    NOT  Includes everything not in the filter     To keep only empty strings    ~  To keep only non-empty strings      Notice that this then filters the dataset. 1 row is found that exactly matches  Egr1  for  Gene Symbol . Again, dimensions of the filtered table can be found by looking at the top right of the center  table view   Notice that when a filter is applied to a parameter, it changes to a red color in the  View Controller . This can be used to quickly track what filters are in place on a heavily filtered dataset.   Remove the filter by either clicking the  Clear All  button or right-clicking on the  Gene Symbol  Filter  ^Egr1$  and clicking  Remove Filter .   Click on  Save  button from the toolbar to save the current project.   Congratulations! The dataset from DBPTS is successfully loaded into Array Studio and is ready for downstream visualization and analysis.",
            "title": "The View Controller"
        },
        {
            "location": "/tutorials/Microarray/Data_Visualization_and_Quality_Control/",
            "text": "Data Visualization and Quality Control\n\u00b6\n\n\nArray Studio\n contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.\n\n\nThe VariableView\n\u00b6\n\n\nOnce a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular gene or genes. This can be accomplished in a number of different ways in \nArray Studio\n, but the most unique way is \nVariableView\n.\n\n\nThe \nVariableView\n allows the user to visualize one chart for each variable in the dataset. So, for this dataset, there will be 15,923 charts available for visualization. However, this view can be used to visualize millions of variables.\n\n\nTo add a \nVariableView\n, go to the \nSolution Explorer\n. For the \nMicroArrayData\n dataset, right-click on \nMicroArrayData\n and select \nAdd View\n from the dropdown box.\n\n\n\n\nAlternatively, click \nAdd View\n from the toolbar.\n\n\nThis opens the \nAdd View\n window, which lists all the different types of views available for a \nData\n object.\n\n\nChoose \nVariableView\n from the \nChoose View Type\n box. Notice that a preview of the view is shown in the \nPreview\n box. Click \nOK\n to add the view.\n\n\n\n\nAfter adding it, a new view will appear in the main view window. In addition, this new view will appear in the \nSolution Explorer\n, as shown below.\n\n\n\n\nScroll through all 15,923 charts in the \nVariableView\n to see that \nArray Studio\n can easily handle the visualization for all the variables in the dataset.\n\n\nOn the X-Axis, each of the 24 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset).\n\n\nHowever, the power of the \nVariableView\n lies in its ability to be customized. By itself, the view picture below is somewhat non-informative. Unless the user knows what group each chip belongs to, and what gene each probeset represents, further customization is required.\n\n\n\n\nThe \nTask\n tab in the \nView Controller\n of the \nVariableView\n (pictured below), will be used to customize this view. The first step in customizing the view is to start from the top of the \nTask\n tab and work downwards, completing the customization. In the \nData\n section of the \nTask\n tab of the \nView Controller\n, click \nSpecify Title Columns\n now.\n\n\n\n\nThis opens the \nSpecify Title Columns\n window:\n\n\n\n\nThis window allows the user to specify which columns from the attached \nAnnotation table\n should be used to identify each chart. Scroll through the \nAvailable columns\n to find \nGene Title\n and \nGene Symbol\n . Move these two columns to the \nListed columns\n box, so that \nProbe Set ID, Gene Title, and Gene Symbol\n are all listed. Click \nOK\n to continue.\n\n\nNotice that the charts have been updated to reflect the additional title information, from the \nGene Title\n and \nGene Symbol\n columns ( if there is no associated gene for a probe set, the fields show up as \"-,-\").\n\n\n\n\nFor the purposes of this tutorial, go to the \nVariable\n tab of the \nView Controller\n, and once again filter \nGene Symbol\n, using \n^EGR1$\n as the filter, as shown below. Note: All of the customizations performed on this view will apply to all variables, however we will concentrate on visualizing \nEGR1\n for demonstration purposes.\n\n\n\n\nNotice that the view is now updated to reflect the filter, and only shows one chart. The number of charts currently visible is shown directly above the view.\n\n\n\n\nNow go back to the \nTask\n tab of the \nView Controller\n.\n\n\nThe next step is to \nSpecify Profile Column\n . This allows the user to group the data points by a particular column of the \nDesign Table\n. Remember, the \nDesign Table\n contained columns for \nTime, Treatment\n , and \nGroup\n . So, theoretically, it might be good to specify profile column as \nGroup\n . However, looking ahead one step, notice that there is another option, called \nSpecify Split Column\n. This allows the user to split their grouping twice, and is what will occur in this case.\n\n\n\n\nClicking \nSpecify Profile Column\n opens the \nChoose Profile Column\n window. Choose \ntime\n and click \nOK\n.\n\n\n\n\nThe chart is updated so that each \ntime\n is shown on the X-Axis. However, notice that the X-Axis does not look quite right. \nTime\n, in this case, should be a category, rather than a numeric value.\n\n\n\n\nArray Studio\n has parsed the \ntime\n column as a numeric value, whereas the intended use was that of a \nFactor\n.\n\n\nThis can be changed by editing the column type for the \ntime\n column in the \nDesign Table\n.\n\n\nTo do this, first open the \nTableView\n for the \nDesign Table\n by expanding the \nDesign\n node of the Microarray dataset, and double-clicking on the \nTable\n for the \nDesign\n. The main view window is updated to show the \nDesign Table\n\n\n\n\nRight click on the \ntime\n column, and choose \nColumn Properties\n (this can also be accessed by going to the \nTable Menu | Columns | Column Properties\n.\n\n\n\n\nIn this window, properties can be set for each column in the \nDesign Table\n. Click on the \ntime\n column, and then change the \nColumn Type\n from \nInteger\n to \nFactor\n, as shown below.\n\n\nClose the window when finished.\n\n\n\n\nSwitch back to the \nVariableView\n by clicking the tab in the main view window\n\n\n\n\nor by double-clicking on it in the \nSolution Explorer\n.\n\n\nNotice that the view is automatically updated, and that the X-Axis now uses a category scale, so that the 4 time points in the experiment are laid out in order along the X-Axis.\n\n\n\n\nNow click \nSpecify Split Column\n from the \nTask\n tab of the \nView Controller\n. This opens the \nChoose Split Column\n window.\n\n\n\n\nThe purpose of the \nSplit Column\n is to further split the data, so that each \nProfile Column\n is split by the \nSplit Column\n. Thus, for this tutorial, each time point will be split into the two levels of treatment (DBP and Control).\n\n\nClick \nOK\n to return to the chart.\n\n\nThe \nVariableView\n is updated to reflect the splitting of the data. Notice that for each time point, there are now two colors (green and blue). To find out what the colors represent, go to  \nView Controller\n.\n\n\n\n\nNote that the blue color represents the control group, the green color represents the DBP treatment group.\n\n\n\n\nThe user can always open the charts in PowerPoint by clicking the \nOpen in PowerPoint\n button in the main view window, above the chart. The number of charts that can be opened is determined by the maximum number of slides allowed in a single PowerPoint file.\n\n\n\n\nClick the \nOpen in PowerPoint\n button now, and then select \nOpen Current View in PowerPoint\n. This will open the view, along with the legend, in PowerPoint. \nNote:\n if the user already has a PowerPoint presentation open, \nArray Studio\n will prompt the user as to whether it should create a new presentation, or append the chart to an older presentation.\n\n\n\n\nThe color of the legend (or shapes, fill properties, etc..) can be changed in the \nView Controller\n by right clicking on items.\n\n\n\n\nThe \nTask\n tab of the \nView Controller\n can be used to further customize the \nVariableView\n.\n\n\nSelect the Task tab, and click the \nSpecify Transformation\n option to open the \nList\n window. This window will specify the type of transformation that is performed on the values shown in the chart. By default, no transformation is performed on the values. However, because the values are Log2 transformed, the user may wish to see the un-logged values. Select \nExp2\n to un-log the data.\n\n\n\n\nClick \nOK\n to return to the \nVariableView\n.\n\n\nNotice the scale is now an unlogged (linear) scale.\n\n\n\n\nThere are a number of further customizations that can be done to the chart, so Omicsoft encourages the user to try some of the customizations on their own.\n\n\nBut first, click the \nChange Profile Gallery\n button, in the \nCustomize\n section of the \nTask\n tab of the \nView Controller\n to open the \nChange Profile Gallery\n window.\n\n\nThe \nChange Gallery\n window allows the user to specify the type of gallery shown for the \nVariableView\n. By default, the view we have been looking at so far is \nScatter\n. Other available options include \nLine, Scatter, LineScatter, Bar, BoxPlot, DotPlot, RBoxPlot\n, and \nColorBar\n.\n\n\nChoose \nBar\n now and click \nOK\n to return to the \nVariableView\n.\n\n\n\n\nThe chart is updated to show a mean summarization, via a bar graph, of each group, as shown below. The user may be interested to know that the type of summarization can be changed by selecting \nSpecify Mean Summarization\n in the \nData\n section of the \nTask\n tab of the \nView Controller\n.\n\n\n\n\nError bars can be shown for each bar on the chart, by selecting \nShow Error Bars\n from the \nCustomize\n section in the \nTask\n tab of the \nView Controller\n.\n\n\nSelect this now, and notice that the chart is updated to reflect the error bars. The type of error bar summarization can also be changed by selecting \nSpecify Error Summarization\n in the \nData\n section of the \nTask\n tab in the \nView Controller\n. The bar graph can be further customized using the customizations in the \nTask\n tab of the \nView Controller\n. For example, to better visualize the error bars, select \nView Controller | Task | Properties | Change Fill Properties\n and adjust the opacity:\n\n\n\n\nArray Studio\n also includes the ability to generate on-the-fly p-values for every variable in the \nVariableView\n.\n\n\nThis can be accomplished by choosing \nShow Summary Information\n from the \nCustomize section\n in the \nTask\n tab of the \nView Controller\n. Click this now, and see that the chart now shows multiple on-the-fly p-values.\n\n\n\n\nBecause the user has specified both a \nProfile Column\n and a \nSplit Column\n, \nArray Studio\n runs a two-way ANOVA on each variable, and generates p-values for each factor (time, treatment), as well as the interaction between the two treatments.\n\n\nIt is clear from the p-values generated for this chart that this variable has significantly changing data for all three tests (time, treatment, and time*treatment).\n\n\nWhile this on-the-fly generation of p-values should not be used as a substitute for a full analysis, it can be used to get a quick read on whether or not a particular gene of interest is significantly changing in an experiment.\n\n\nBefore continuing, make sure to \nClear all filters\n in the \nVariable\n tab of the \nView Controller\n.\n\n\nThe Pairwise ScatterView\n\u00b6\n\n\nAfter the initial visualization of the data, the user may be interested in looking at some quality control parameters. (The previous generated views can be used later on, after more detailed analyses, in order to look at differentially expressed genes)\n\n\nThe \nPairwiseScatterView\n provides a way for the user to easily visualize replicates.\n\n\nTo add a \nPairwiseScatterView\n, go to the \nSolution Explorer\n, and right-click on the Microarray dataset.\n\n\nClick \nAdd View\n and select \nPairwiseScatterView\n from the list of views. Once added, the main view window should look similar to the following screenshot. Note: If plots are blank, clear any applied filters from the View Controller.\n\n\n\n\nIn this screenshot, 3 chips are shown by default (in the example below 01A, 02A and 03A). This view provides a way for the user to look at both a ScatterView of the chips against each other, as well as an MA Plot for each chip against each other.\n\n\nThe MA Plots are contained in the upper-right of the \nPairwiseScatterView\n, and the regular \nScatterViews\n are contained in the lower-left of the \nPairwiseScatterView\n.\n\n\nAn \nr\n value (Pearson correlation) for each chip-to-chip comparison is shown on each chart.\n\n\nGo to the \nObservation\n tab of the \nView Controller\n.\n\n\nExpand the \ngroup\n column, and choose \ndbp.t18\n.\n\n\n\n\nThe chart is updated to only show the 3 chips belonging to the \ndbp.t18\n group. Notice that, unlike the first group we visualized, the correlation of chip 22A to the other chips in its group is not as good. This is the first indication that this group may be a technical outlier.\n\n\n\n\nFinally, remove or reset the checkBox filter so that the analysis workflow can continue.\n\n\nPrincipal component analysis of RMA signals\n\u00b6\n\n\nAfter looking at the correlation of biological replicates, the next step in quality control could be principal component analysis.\n\n\nPrincipal component analysis can be used to detect outliers in a dataset, to detect outliers among treatment groups, and to get a general idea of the distribution for the data. To run a principal component analysis on a MicroArray dataset, go to the \nMicroarray Workflow\n, and select \nPrincipal component analysis\n from the \nQuality control\n section of the \nWorkflow\n window. Alternatively, go to the \nOmicData Menu | QC | Principal Component Analysis\n to open the \nPrincipal Component Analysis\n window.\n\n\n\n\nThe \nPrincipal Component Analysis\n window, like most analysis windows in \nArray Studio\n, contains an \nInput/Output\n section. In this section, the user picks the \nProject\n and \nData\n on which to run the analysis, as well as the \nVariables\n and \nObservations\n on which to run the analysis. This allows the user to specify if analyses should be run on all, selected, visible, or particular \nCustomized Lists\n of \nVariables\n or \nObservations\n.\n\n\nEnsure that the correct project (\nTutorialMicroArray\n in this example) is selected under the \nInput/Output | Project\n drop-down box and \nMicroArrayData\n is selected under \nData\n drop-down box. Ensure that \nAll variables\n is selected for \nVariables\n. Ensure that \nAll observations\n is selected for \nObservations\n. Leave \nOutput Name\n blank, as by default the outputted plots will be called \nMicroarray.PcaScores\n.\n\n\nUnder options, change the \nGroup\n to \n'group'\n to indicate the biological group information.\n\n\nArray Studio can generate 2D(3D) PCA plots if \nComponent number\n is set to 2(3). Setting the Component number to 4 or more will generate a pairwise scatterview plot of the PCA. For this example, we will generate a 3D plot by setting this value to 3.\n\n\nEnsure that \nScale variables\n, \nOutput scores\n, and \nCalculate Hotelling T2\n are selected, with an \nAlpha level\n of 0.05. Click \nSubmit\n. Remember that all the details about this module, including input, output and parameter explanations can be retrieved by clicking the \nHelp\n button.\n\n\n\n\nA dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 seconds.\n\n\nWhen complete, a new view will be created, as well as a new \nTable object\n in the \nQC\n folder of the \nSolution Explorer\n with associated views.\n\n\n\n\nThe \nTable\n section of the Solution Explorer will need to be expanded, as well as the automatically generated QC folder and the new table. This is an example of a type of Table data, as opposed to the  Omic data that we have been working with before. Table data has a flat two-way structure (rows and columns), while  Omic data contains multiple levels (Data, Design, and Annotation).\n\n\nSwitch to the view \nMicroArray.PcaScores|PcaScores\n to look at the score plot. First, notice that on the X and Y axis, the variance of each component is explained (equivalent of R 2 value). Component 1 (x-axis) explains 36.43 % of the variance in the data. Component 2 represents 11.77% of the variance in the data. And Component 3 represents an additional 8.41%.\n\n\nUsers can use the \nTrackball\n button \n to rotate the 3D plot. At first glance, it is clear that there is one outlier in the chart.\n\n\n\n\nClick on the \nChange Symbol Properties\n in the task tab.\n\n\n\n\nChange the \nLabels\n section to \nAll\n, then the \nBy\n drop-down box to \nchip\n. Then close the dialog box.\n\n\n\n\nThe labels reveal that chip 22A is the outlier sample.\n\n\n\n\nCheck the \nView Controller\n to see the legend for the chart. This \nLegend\n will also be included if the user chooses to open the view of this chart in PowerPoint or Excel. Again, remember that right-clicking on an item in the Legend allows the user to \"Change Color\".\n\n\n\n\nArray Studio\n supports a unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, use the \nSelect\n button \n to select sample 22A (either click directly on the data point, or left-click and drag, or right-click and use the \nLasso\n to drag around the sample). When selected, the point will turn red.\n\n\n\n\nIn the \nView Controller\n, select the \nTask\n tab. Then, under the \nUpdate\n tab, select the \nExclude Selection\n button.\n\n\n\n\nThis triggers the principal component analysis to re-run, with newly generated \nPCAScores\n in the \nSolution Explorer\n.\n\n\n\n\nThe newly generated \nPcaScores\n plot is shown below.\n\n\n\n\nImportant:\n \nArray Studio\n has also added a new \nList\n, called MicroArrayData.Observation23. This is a list of the remaining 23 chips (after the outlier, 22A, has been removed). This \nList\n can be used for all further downstream analysis, to automatically exclude chip 22A.\n\n\nExpand the \nList\n section in \nSolution Explorer\n now to see the newly generated list.",
            "title": "Data Visualization and Quality Control"
        },
        {
            "location": "/tutorials/Microarray/Data_Visualization_and_Quality_Control/#data-visualization-and-quality-control",
            "text": "Array Studio  contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.",
            "title": "Data Visualization and Quality Control"
        },
        {
            "location": "/tutorials/Microarray/Data_Visualization_and_Quality_Control/#the-variableview",
            "text": "Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular gene or genes. This can be accomplished in a number of different ways in  Array Studio , but the most unique way is  VariableView .  The  VariableView  allows the user to visualize one chart for each variable in the dataset. So, for this dataset, there will be 15,923 charts available for visualization. However, this view can be used to visualize millions of variables.  To add a  VariableView , go to the  Solution Explorer . For the  MicroArrayData  dataset, right-click on  MicroArrayData  and select  Add View  from the dropdown box.   Alternatively, click  Add View  from the toolbar.  This opens the  Add View  window, which lists all the different types of views available for a  Data  object.  Choose  VariableView  from the  Choose View Type  box. Notice that a preview of the view is shown in the  Preview  box. Click  OK  to add the view.   After adding it, a new view will appear in the main view window. In addition, this new view will appear in the  Solution Explorer , as shown below.   Scroll through all 15,923 charts in the  VariableView  to see that  Array Studio  can easily handle the visualization for all the variables in the dataset.  On the X-Axis, each of the 24 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed). Each point on the chart represents the intensity value of that chip for that variable (probeset).  However, the power of the  VariableView  lies in its ability to be customized. By itself, the view picture below is somewhat non-informative. Unless the user knows what group each chip belongs to, and what gene each probeset represents, further customization is required.   The  Task  tab in the  View Controller  of the  VariableView  (pictured below), will be used to customize this view. The first step in customizing the view is to start from the top of the  Task  tab and work downwards, completing the customization. In the  Data  section of the  Task  tab of the  View Controller , click  Specify Title Columns  now.   This opens the  Specify Title Columns  window:   This window allows the user to specify which columns from the attached  Annotation table  should be used to identify each chart. Scroll through the  Available columns  to find  Gene Title  and  Gene Symbol  . Move these two columns to the  Listed columns  box, so that  Probe Set ID, Gene Title, and Gene Symbol  are all listed. Click  OK  to continue.  Notice that the charts have been updated to reflect the additional title information, from the  Gene Title  and  Gene Symbol  columns ( if there is no associated gene for a probe set, the fields show up as \"-,-\").   For the purposes of this tutorial, go to the  Variable  tab of the  View Controller , and once again filter  Gene Symbol , using  ^EGR1$  as the filter, as shown below. Note: All of the customizations performed on this view will apply to all variables, however we will concentrate on visualizing  EGR1  for demonstration purposes.   Notice that the view is now updated to reflect the filter, and only shows one chart. The number of charts currently visible is shown directly above the view.   Now go back to the  Task  tab of the  View Controller .  The next step is to  Specify Profile Column  . This allows the user to group the data points by a particular column of the  Design Table . Remember, the  Design Table  contained columns for  Time, Treatment  , and  Group  . So, theoretically, it might be good to specify profile column as  Group  . However, looking ahead one step, notice that there is another option, called  Specify Split Column . This allows the user to split their grouping twice, and is what will occur in this case.   Clicking  Specify Profile Column  opens the  Choose Profile Column  window. Choose  time  and click  OK .   The chart is updated so that each  time  is shown on the X-Axis. However, notice that the X-Axis does not look quite right.  Time , in this case, should be a category, rather than a numeric value.   Array Studio  has parsed the  time  column as a numeric value, whereas the intended use was that of a  Factor .  This can be changed by editing the column type for the  time  column in the  Design Table .  To do this, first open the  TableView  for the  Design Table  by expanding the  Design  node of the Microarray dataset, and double-clicking on the  Table  for the  Design . The main view window is updated to show the  Design Table   Right click on the  time  column, and choose  Column Properties  (this can also be accessed by going to the  Table Menu | Columns | Column Properties .   In this window, properties can be set for each column in the  Design Table . Click on the  time  column, and then change the  Column Type  from  Integer  to  Factor , as shown below.  Close the window when finished.   Switch back to the  VariableView  by clicking the tab in the main view window   or by double-clicking on it in the  Solution Explorer .  Notice that the view is automatically updated, and that the X-Axis now uses a category scale, so that the 4 time points in the experiment are laid out in order along the X-Axis.   Now click  Specify Split Column  from the  Task  tab of the  View Controller . This opens the  Choose Split Column  window.   The purpose of the  Split Column  is to further split the data, so that each  Profile Column  is split by the  Split Column . Thus, for this tutorial, each time point will be split into the two levels of treatment (DBP and Control).  Click  OK  to return to the chart.  The  VariableView  is updated to reflect the splitting of the data. Notice that for each time point, there are now two colors (green and blue). To find out what the colors represent, go to   View Controller .   Note that the blue color represents the control group, the green color represents the DBP treatment group.   The user can always open the charts in PowerPoint by clicking the  Open in PowerPoint  button in the main view window, above the chart. The number of charts that can be opened is determined by the maximum number of slides allowed in a single PowerPoint file.   Click the  Open in PowerPoint  button now, and then select  Open Current View in PowerPoint . This will open the view, along with the legend, in PowerPoint.  Note:  if the user already has a PowerPoint presentation open,  Array Studio  will prompt the user as to whether it should create a new presentation, or append the chart to an older presentation.   The color of the legend (or shapes, fill properties, etc..) can be changed in the  View Controller  by right clicking on items.   The  Task  tab of the  View Controller  can be used to further customize the  VariableView .  Select the Task tab, and click the  Specify Transformation  option to open the  List  window. This window will specify the type of transformation that is performed on the values shown in the chart. By default, no transformation is performed on the values. However, because the values are Log2 transformed, the user may wish to see the un-logged values. Select  Exp2  to un-log the data.   Click  OK  to return to the  VariableView .  Notice the scale is now an unlogged (linear) scale.   There are a number of further customizations that can be done to the chart, so Omicsoft encourages the user to try some of the customizations on their own.  But first, click the  Change Profile Gallery  button, in the  Customize  section of the  Task  tab of the  View Controller  to open the  Change Profile Gallery  window.  The  Change Gallery  window allows the user to specify the type of gallery shown for the  VariableView . By default, the view we have been looking at so far is  Scatter . Other available options include  Line, Scatter, LineScatter, Bar, BoxPlot, DotPlot, RBoxPlot , and  ColorBar .  Choose  Bar  now and click  OK  to return to the  VariableView .   The chart is updated to show a mean summarization, via a bar graph, of each group, as shown below. The user may be interested to know that the type of summarization can be changed by selecting  Specify Mean Summarization  in the  Data  section of the  Task  tab of the  View Controller .   Error bars can be shown for each bar on the chart, by selecting  Show Error Bars  from the  Customize  section in the  Task  tab of the  View Controller .  Select this now, and notice that the chart is updated to reflect the error bars. The type of error bar summarization can also be changed by selecting  Specify Error Summarization  in the  Data  section of the  Task  tab in the  View Controller . The bar graph can be further customized using the customizations in the  Task  tab of the  View Controller . For example, to better visualize the error bars, select  View Controller | Task | Properties | Change Fill Properties  and adjust the opacity:   Array Studio  also includes the ability to generate on-the-fly p-values for every variable in the  VariableView .  This can be accomplished by choosing  Show Summary Information  from the  Customize section  in the  Task  tab of the  View Controller . Click this now, and see that the chart now shows multiple on-the-fly p-values.   Because the user has specified both a  Profile Column  and a  Split Column ,  Array Studio  runs a two-way ANOVA on each variable, and generates p-values for each factor (time, treatment), as well as the interaction between the two treatments.  It is clear from the p-values generated for this chart that this variable has significantly changing data for all three tests (time, treatment, and time*treatment).  While this on-the-fly generation of p-values should not be used as a substitute for a full analysis, it can be used to get a quick read on whether or not a particular gene of interest is significantly changing in an experiment.  Before continuing, make sure to  Clear all filters  in the  Variable  tab of the  View Controller .",
            "title": "The VariableView"
        },
        {
            "location": "/tutorials/Microarray/Data_Visualization_and_Quality_Control/#the-pairwise-scatterview",
            "text": "After the initial visualization of the data, the user may be interested in looking at some quality control parameters. (The previous generated views can be used later on, after more detailed analyses, in order to look at differentially expressed genes)  The  PairwiseScatterView  provides a way for the user to easily visualize replicates.  To add a  PairwiseScatterView , go to the  Solution Explorer , and right-click on the Microarray dataset.  Click  Add View  and select  PairwiseScatterView  from the list of views. Once added, the main view window should look similar to the following screenshot. Note: If plots are blank, clear any applied filters from the View Controller.   In this screenshot, 3 chips are shown by default (in the example below 01A, 02A and 03A). This view provides a way for the user to look at both a ScatterView of the chips against each other, as well as an MA Plot for each chip against each other.  The MA Plots are contained in the upper-right of the  PairwiseScatterView , and the regular  ScatterViews  are contained in the lower-left of the  PairwiseScatterView .  An  r  value (Pearson correlation) for each chip-to-chip comparison is shown on each chart.  Go to the  Observation  tab of the  View Controller .  Expand the  group  column, and choose  dbp.t18 .   The chart is updated to only show the 3 chips belonging to the  dbp.t18  group. Notice that, unlike the first group we visualized, the correlation of chip 22A to the other chips in its group is not as good. This is the first indication that this group may be a technical outlier.   Finally, remove or reset the checkBox filter so that the analysis workflow can continue.",
            "title": "The Pairwise ScatterView"
        },
        {
            "location": "/tutorials/Microarray/Data_Visualization_and_Quality_Control/#principal-component-analysis-of-rma-signals",
            "text": "After looking at the correlation of biological replicates, the next step in quality control could be principal component analysis.  Principal component analysis can be used to detect outliers in a dataset, to detect outliers among treatment groups, and to get a general idea of the distribution for the data. To run a principal component analysis on a MicroArray dataset, go to the  Microarray Workflow , and select  Principal component analysis  from the  Quality control  section of the  Workflow  window. Alternatively, go to the  OmicData Menu | QC | Principal Component Analysis  to open the  Principal Component Analysis  window.   The  Principal Component Analysis  window, like most analysis windows in  Array Studio , contains an  Input/Output  section. In this section, the user picks the  Project  and  Data  on which to run the analysis, as well as the  Variables  and  Observations  on which to run the analysis. This allows the user to specify if analyses should be run on all, selected, visible, or particular  Customized Lists  of  Variables  or  Observations .  Ensure that the correct project ( TutorialMicroArray  in this example) is selected under the  Input/Output | Project  drop-down box and  MicroArrayData  is selected under  Data  drop-down box. Ensure that  All variables  is selected for  Variables . Ensure that  All observations  is selected for  Observations . Leave  Output Name  blank, as by default the outputted plots will be called  Microarray.PcaScores .  Under options, change the  Group  to  'group'  to indicate the biological group information.  Array Studio can generate 2D(3D) PCA plots if  Component number  is set to 2(3). Setting the Component number to 4 or more will generate a pairwise scatterview plot of the PCA. For this example, we will generate a 3D plot by setting this value to 3.  Ensure that  Scale variables ,  Output scores , and  Calculate Hotelling T2  are selected, with an  Alpha level  of 0.05. Click  Submit . Remember that all the details about this module, including input, output and parameter explanations can be retrieved by clicking the  Help  button.   A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 seconds.  When complete, a new view will be created, as well as a new  Table object  in the  QC  folder of the  Solution Explorer  with associated views.   The  Table  section of the Solution Explorer will need to be expanded, as well as the automatically generated QC folder and the new table. This is an example of a type of Table data, as opposed to the  Omic data that we have been working with before. Table data has a flat two-way structure (rows and columns), while  Omic data contains multiple levels (Data, Design, and Annotation).  Switch to the view  MicroArray.PcaScores|PcaScores  to look at the score plot. First, notice that on the X and Y axis, the variance of each component is explained (equivalent of R 2 value). Component 1 (x-axis) explains 36.43 % of the variance in the data. Component 2 represents 11.77% of the variance in the data. And Component 3 represents an additional 8.41%.  Users can use the  Trackball  button   to rotate the 3D plot. At first glance, it is clear that there is one outlier in the chart.   Click on the  Change Symbol Properties  in the task tab.   Change the  Labels  section to  All , then the  By  drop-down box to  chip . Then close the dialog box.   The labels reveal that chip 22A is the outlier sample.   Check the  View Controller  to see the legend for the chart. This  Legend  will also be included if the user chooses to open the view of this chart in PowerPoint or Excel. Again, remember that right-clicking on an item in the Legend allows the user to \"Change Color\".   Array Studio  supports a unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, use the  Select  button   to select sample 22A (either click directly on the data point, or left-click and drag, or right-click and use the  Lasso  to drag around the sample). When selected, the point will turn red.   In the  View Controller , select the  Task  tab. Then, under the  Update  tab, select the  Exclude Selection  button.   This triggers the principal component analysis to re-run, with newly generated  PCAScores  in the  Solution Explorer .   The newly generated  PcaScores  plot is shown below.   Important:   Array Studio  has also added a new  List , called MicroArrayData.Observation23. This is a list of the remaining 23 chips (after the outlier, 22A, has been removed). This  List  can be used for all further downstream analysis, to automatically exclude chip 22A.  Expand the  List  section in  Solution Explorer  now to see the newly generated list.",
            "title": "Principal component analysis of RMA signals"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/",
            "text": "Differential Expression\n\u00b6\n\n\nArray Studio\n contains a number of different modules for performing univariate analysis/differential expression, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others.\n\n\nTwo-Way ANOVA\n\u00b6\n\n\nTwo-Way ANOVA\n can be used to research the effects of multiple factors on expression data. The design of the experiment in this tutorial is set-up so that the user will perform a \nTwo-Way ANOVA\n.\n\n\nFor this tutorial, we are interested in generating contrasts for each time point, in comparing the DBP (treatment) group to the control group. The first factor in the ANOVA is \ntime\n while the second factor is \ntreatment\n. Thus, we should be able to generate four contrasts, and associating fold changes, p-values, estimates, etc.\n\n\nWhile the \nGeneral Linear Model\n could easily be used instead (and provide more customization of the results), it is a much more straightforward process for the novice user to use the \nTwo-way ANOVA\n module.\n\n\nTo run the \nDifferential Expression-Two Way ANOVA\n module, go to the \nStatistical Inference\n section of the workflow, and select \nTwo-Way ANOVA\n. Alternatively, the same module can be selected by going to the \nOmicData Menu | Inference | Standard Tests | Two-way ANOVA\n.\n\n\n\n\nThis opens the \nTwo-way Analysis of Variance\n window:\n\n\n\n\nAs with other analysis windows, the user must first set the \nProject\n and \nData\n on which to run the analysis, in the \nInput/Output\n section.\n\n\n\n\n\n\nMake sure \nTutorialMicroArray\n is chosen as the project and \nMicroArrayData\n is chosen as the input data.\n\n\n\n\n\n\nFor \nVariables\n , ensure that \nAll Variables\n is selected.\n\n\n\n\n\n\nFor \nObservations\n, choose \nCustomized observations\n , then click the \nSelect\n button to choose the list \nMicroArrayData.Observation23\n. This ensures that the statistical tests are only run on the 23 observations that passed the PCA quality control.\n\n\n\n\n\n\n\n\nArray Studio\n will attempt to automatically populate the \nFactor 1\n and \nFactor 2\n dropdown boxes, using the first two \nFactor\n type columns in the design table. For this tutorial, this should correctly populate \nFactor 1\n as \ntime\n and \nFactor 2\n as \ntreatment\n.\n\n\n\n\n\n\nFor generating the comparisons, the \nFor each\n box is used. The factor chosen for \nFactor 1\n will automatically be populated into the \nFor each\n box, and cannot be changed, unless the user changes the \nFactor 1\n column.\n\n\n\n\n\n\nTo figure out what comparisons will be generated, read the \nFor each\n, \nCompare to\n boxes together. So, \nFor each: time\u00b8 Compare to\n: control will generate a contrast comparing DBP to control at each time point.\n\n\n\n\n\n\nEnsure that the \nCompare to\n dropdown box is set to \ncontrol\n.\n\n\n\n\n\n\nThe option to \nInclude interaction term\n should be enabled, however if users wish to run a two-way ANOVA without the interaction, this is available here as well.\n\n\n\n\n\n\nComparison\n specifies the multiple comparison procedure. Options include \nControl\n, \nDunnett\n and \nTukey\n.\n\n\n\n\n\n\nBy\n - Allows the user to select an additional categorical variable to subset the data set before running ANOVA.\n\n\n\n\n\n\nMultiplicity\n adjustments for the comparisons can be set as well, with the default adjustment being FDR_BH (options include \nNone\n, \nFDR_BH\n, \nFDR_BY\n, \nBonferonni\n, \nSidak\n, \nStepDownBonferroni\n, \nStepDownSidak\n, \nStepUp\n, \nQValue\n, \nQValue41\n). The \nmultiplicity\n adjustment will calculate an \nAdjusted p-value\n column in the result report.\n\n\n\n\n\n\nFC Transformation\n specifies how the Fold Change is calculated based on estimate.     Fold change is defined as the unlogged estimate. By default, it is Exp2: sign(estimate)*2^abs(estimate). User also has the options of Exp, Exp10 and Ratio.\n\n\n\n\n\n\nThe \nAlpha level\n, or p-value cutoff, is used in the automatic generation of \nLists\n for each contrast. If a \nmultiplicity\n adjustment is set to anything other than \nNone\n, these lists will be generated for probesets that have an adjusted p-value less than this value (by default 0.05).\n\n\n\n\n\n\nReport F-Test Pvalues\n will report the p-values for the F-tests (i.e. one p-value each for time, treatment, and treatment*time). Leave this box unchecked as we are more interested in specific estimates.\n\n\n\n\n\n\nGenerate LSMean data\n will generate a new \nData\n object, where each observation is the LSMean of the interaction of \nFactor 1\n and \nFactor 2\n group (i.e. in this case, the LSMean     \ndata\n would have 8 observations, one for each \ntime*treatment\n group). For this tutorial, leave this box unchecked.\n\n\n\n\n\n\nIf \nGenerate LSMean data\n is checked, \nAppend LSMeans to the inference report\n becomes available. This will append the \nLSMeans data\n, for each interaction group, to the inference report. This can be used to see the adjusted mean intensity levels of each group for any potential differentially expressed probesets (i.e. some users prefer to ignore lower-expressing probesets, and this provides the user with a way to filter by these values).\n\n\n\n\n\n\nGenerate estimate data\n will generate a \nData\n object containing one observation per contrast. So, in the case of this tutorial, the new \nEstimate data\n would contain four observations, one for each of the four comparisons being generated. For the purposes of this tutorial, leave this box unchecked.\n\n\n\n\n\n\nSplit the significant list by change direction\n will split each generated significant list (based on the alpha level value) by direction of change.\n\n\n\n\n\n\nFor users familiar with SAS Code, clicking the \nShow SAS Code\n button will generate the equivalent SAS code in a text file (the SAS code can only be used to run one probeset at a time).\n\n\nTo run the differential expression, click the \nSubmit\n button.\n\n\nThe VolcanoPlotView and Inference Report\n\u00b6\n\n\nAfter running the \nTwo-way ANOVA\n (the computing time should be 1-3 seconds), a \nTable\n is generated under the \nInference\n folder of the Solution Explorer, \nMicroArray Data.Tests\n (expand the Inference folder to see this). This table contains the information generated by the \nTwo-way ANOVA\n. As can be observed in the \nSolution Explorer\n, this table contains 15923 rows (for the 15923 probesets) and 51 columns (35 from the original \nAnnotation\n and 16 new columns).\n\n\nAlso notice that a number of new \nLists\n have been automatically generated by the \nTwo-way ANOVA\n. These \nLists\n can be used for purposes of filtering, and also in the next section, for generating a \nVenn Diagram\n. These lists were generated using an adjusted p-value cutoff of 0.05 (this was set in the previous dialog menu). If the user preferred to automatically generate lists using raw p-value, then no multiplicity adjustment test should have been specified.\n\n\n\n\nBy default, a \nVolcanoPlotView\n will be generated for the \nInference Table\n. It should be the view visible in the main view window. If not, double-click on it in the \nSolution Explorer\n or switch to the view in the main \nData View\n window.\n\n\n\n\nAfter opening the \nview VolcanoPlot\n, notice that four \nvolcano plots\n have been created in this view, one for each comparison generated by the \nTwo-Way ANOVA\n window.\n\n\n\n\nTo change all graphs to the same scale, click \nUse Uniform Scale\n icon on the toolbar (as shown below).\n\n\n\n\nThe graph should be updated instantly.\n\n\n\n\nLooking in the \ntoolbar\n, the user should recognize many of the icons from previous views.\n\n\n\n\n \nOpen Current view as picture\n: will open current visible view in the default picture viewer\n\n\n\n\nOpen Current view in Excel:\n will open current visible view in Microsoft Excel\n\n\nOpen All Charts in Excel:\n will open all opened views in Microsoft Excel\n\n\nOpen Current view in Excel (Editable)\n: will open current visible view in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above)\n\n\nOpen All Charts in Excel (Editable)\n: will open all opened views in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above)\n\n\n\n\nOpen Current view in PowerPoint\n: will open current visible view in Microsoft PowerPoint\n\n\nOpen All Charts in PowerPoint\n: will open all opened views in Microsoft PowerPoint\n\n\nOpen Current view in PowerPoint (Editable)\n : will open current visible viewin Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above)\n\n\nOpen All Charts in PowerPoint (Editable)\n: will open current visible view in Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above)\n\n\n \nCopy Current View\n: will copy current view to the clipboard\n\n\n \nSave Current View\n: will save the current visible view as an image file (default is pdf but other formats include png, emf, gif, jpg, tif, bmp)\n\n\n \nPrint Current View\n: will print the current view\n\n\nPrint All Charts\n: will print charts that are currently opened\n\n\n \nSelect\n: allow the user to lasso multiple selections\n\n\n \nZoom in\n: will zoom in the table using lasso\n\n\n \nFull Screen\n: will open the view in full screen mode\n\n\n \nRefresh Chart and Undo all Zooms/Pans\n: Returns view to the original format\n\n\n\n\nSpecify Layout\n \n(rows*columns)\n: To specify layout by rows and columns. For instance, if the user was only interested in seeing one column per view in order to see a particular view in greater detail, this would be set to 3*1 (3 rows*1 column). Each column represents a view.\n\n\n \nUse Uniform Scale\n: when selected, will use the same scale (x and y-axis) for all graphs.\n\n\nThe \nVolcanoPlotView\n shows the * Log10* \nP-value\n on the y-axis and the \nEstimate\n (\nEstimate\n is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the most positive or negative genes can be found at the extremes of the x-axis. Similar to all views in Array Studio, the \nVolcanoPlotView\n is fully interactive. Selecting a particular point or points on the plot brings up the details of that probeset (based on its annotation) in the \nDetails\n window at the bottom of the screen.\n\n\nThe \nView Controller | Task\n under \nVolcanoPlotView\n mode gives the user options to \nChange Chart Properties\n (which includes renaming the title of the chart as well as the x and y-axis titles, and many other options), \nChange Symbol Properties\n, and \nChange To Quality-First Mode\n. The VolcanoPlot will often default to what is known as a \"Speed-First Mode\", where it is updated quickly when any changes are applied to the view (i.e. layout, specify columns). This mode is particularly useful when dealing with large numbers of variables. Users can toggle between this mode and \nQuality-First\n mode by clicking the option in the \nView Controller\n:\n\n\n\n\nSwitch to \nQuality-First\n mode now and select \nChange Symbol Properties\n. To enlarge the data points in the volcano plot and allow for better visualization, users can slide the button in Size. Users can also add labels to all data points, or only those selected. In this example, choose selected and use the drop-down menu to label by Probe Set ID:\n\n\n\n\nNow, move the mouse around the volcano plot named \n1 DBP vs. Control\n. Notice that a red square encompasses each individual point on the graph. This can be used to select an individual probeset from the graph, and retrieve information in the \nDetails Window\n. Now, click on the data point that is in the upper most right corner of this plot. The point should now turn red, as it has been selected and labeled.\n\n\n\n\nMake sure that the \nDetails Window\n is visible down below. If it has been closed, go to \nView | Show Details Window\n. If necessary, drag the border between the main \nData View Window\n and the \nDetails Window\n to expand the size of the \nDetails Window\n. After selecting the upper right-hand data point, check the \nDetails Window\n. Notice that the \nDetails Window\n now contains the information of \nEstimates\n, \nFold Changes\n, \nRaw P-values\n, and \nAdjusted P-values\n for each comparison.\n\n\n\n\nScroll right in the \nDetails Window\n to see the rest of the annotation columns.\n\n\n\n\nBecause the test report is a type of \nTable\n, it also allows the user to use the \nView Controller | Column\n and \nRow\n tabs to filter the data by any column or row (includes the \nTwo-Way ANOVA\n generated columns, as well as the gene \nannotation\n columns).\n\n\nClick the \nOptions\n icon in the \nRow\n tab \n\n\n\n\nThis allows the user to group the filters by either mode (i.e. p-value, fold-change, estimate, etc.) or contrast (time point 1 DBP vs. control, time point 2 DBP vs. control, etc.). Try grouping the p-values by \nmode\n now, and notice the effect on the filters.\n\n\nNotice that the Estimates for each comparison are now grouped together, as are the FoldChange, RawPValue, and AdjustedPValue columns. This is especially helpful for organizing filters in studies where a large number of contrasts have been generated.\n\n\nAlso, note that the filter can be set to \nMatch All Column\n or \nMatch Any Columns\n . By default, the filter uses \nMatch All Columns\n , ensuring that all filters will be matched when set. However, choosing \nMatch Any Columns\n will allow the user to get results matching any of the filters.\n\n\nThe \nTable View\n for the inference report is also automatically generated by the \nTwo-way ANOVA\n, as a \nTableView\n named \nReport\n. Open this view now by double clicking in the \nSolution Explorer\n.\n\n\n\n\nA \nTableView\n is now shown in the main view window, containing the columns generated by the \nTwo-way ANOVA\n, as well as the \nannotation\n columns. For this particular dataset, there are 15923 rows of probesets, with 51 columns of \nannotation\n.\n\n\nNotice that this includes \nannotation\n columns for \nEstimate\n columns, \nFold Change\n columns, \nRaw p-value\n columns, and \nAdjusted p-value\n columns for each comparison made by the \nTwo-way ANOVA\n.\n\n\n\n\nClick \nSpecify Columns\n in the \nView Controller | Task\n tab.\n\n\n\n\nA \nChoose Columns\n window allows the user to specify the columns for view in the table. This can be useful, as the user may want to create different \nTable Views\n for the report, each containing different information. Columns can be removed, added, or the order of the columns can be changed.\n\n\n\n\nClick \nOK\n to return to the \nTableView\n of the report.\n\n\nThe \nView Controller | Row\n tab can be used, just as in the \nVolcanoPlotView,\n to filter the data. Expand the \nRawPValue\n filter section, then expand \n1 DBP vs. Control.RawPValue\n filter and enter \n<.05\n to filter all probesets to only include those that have a \nRawPValue\n of less than 0.05 for \n1 DBP vs. Control\n.\n\n\n\n\nDo the same for the filter of \n3 DBP vs. Control.RawPValue\n filter, \n6 DBP vs. control.RawPValue\n and \n18 DBP vs. Control.RawPValue\n, filter. This will show only those genes with \np-values\n less than 0.05 in four comparisons.\n\n\n\n\nLook at the top right of the table view to see the number of rows remaining after filtering (or just look at the top of the \nView Controller\n). In this case, 24 probesets have p-values less than 0.05 at all 4 time points.\n\n\n\n\nGo to the \nAdd Item\n drop-down button in the tool strip. Choose \nAdd List From Visible rows\n to add a new \nList\n containing only those rows visible from the filter.\n\n\n\n\nThe \nChoose List Source\n window opens. This allows the user to create a list using any of the different columns in the \nTable\n. The name of the list can be set as well as the organized folder location for the list.\n\n\nHere we use \nProbe Set ID\n to generate the list, notice that each line has a unique Probe set ID so the list would not contain any repeated probe set IDs. However, if you choose other IDs such as Gene Name to build the list, it may have repeated IDs since mulitple rows may share the same gene name. In this case, users can check the \nMake a unique list\n so that the repeat IDs would only show up once in the list.\n\n\nChoose \nProbe Set ID\n, name the list \nSignificant at All Timepoints\n, and click \nOK\n to continue.\n\n\n\n\nNotice that a new list has been created.\n\n\n\n\nThe Venn diagram view\n\u00b6\n\n\nArray Studio also has the ability to easily create a \nVenn Diagram\n. The \nVenn Diagram\n could utilize the \nLists\n, either created by the user or by \nArray Studio\n and the \nTwo Way ANOVA\n (or other statistical inference module), to segment the data points.\n\n\nTo add a \nVenn Diagram View\n, first go to the \nSolution Explorer\n and the \n-Omic Data\n section. Right click on \nMicroarrayData\n and select \nAdd View\n from the menu.\n\n\n\n\nSelect \nVennDiagramView\n from the list of choices. Notice that the \nPreview\n window automatically creates a simple \nVenn Diagram\n, using only the first \nList\n in the \nLists\n tab of the \nSolution Explorer\n. This will be changed in the following steps. Click \nOK\n to add the \nView\n.\n\n\n\n\nNotice that a new view, called \nVenn Diagram\n, is now visible in the \nSolution Explorer Window\n, as well as in the main view window.\n\n\n\n\nNow the \nVenn Diagram\n view only contains one list.\n\n\nThe user can add more lists by using the \nSpecify Data Source\n option in the \nTask\n tab of the \nView Controller\n. However, it is much easier to do this using drag-and-drop.\n\n\nNote: Array Studio can handle up to six lists. However, only 4 lists can be shown in one chart at a time. So, if the user enters more than 4 lists, \nArray Studio\n will create every combination of those lists, and one chart for each combination will be shown in the \nView\n.\n\n\nTo drag-and-drop to the Venn Diagram view, go to the \nList\n in \nSolution Explorer\n, and choose the lists of all four time points (use shift or control-click to choose multiple lists at the same time). Now, drag these lists into the main view window, which is then updated to include the four lists in the \nDiagram\n.\n\n\n\n\nLike every other view in Array Studio, the \nVenn Diagram\n view is also fully interactive. Click on the number 29 in the intersection of the 3 lists. First, note that parentheses now appears after the number 29 so that it looks like 29(29). This indicates that the user has selected the 29 genes found in that intersection.\n\n\n\n\nLook at the \nDetails Window\n and notice that 29 probesets are now listed in the \nDetails Window\n.\n\n\n\n\nSimilar to every other view, the \nVenn Diagram\n view can be exported to other programs using the toolbar.\n\n\n\n\nThe General Linear Model\n\u00b6\n\n\nIf users have a complicated design table (such as some large clinical experiment) involving many factors, they can use General linear model function to build some complicated statistical model.\n\n\nUsers can find the function of General linear model here:\n\n\n\n\nOr through windows here:\n\n\n\n\nTwo-Way ANOVA is a specific case of General model, here we can get the same results using General linear model:\n\n\n\n\nJust like in Two Way ANOVA, users can specify the observations by list to do the analysis based the 23 observations.\n\n\n\n\nAfter that, users can specify the model by selecting the time and treatment and clicking \nAdd\n. The interaction term \"time:treatment\" is made by selecting both classes and clicking the  Cross  button as shown below.\n\n\n\n\nNotice that array studio would automatically treat numeric variables such as time as continuous factor, so users have to check the \nClass\n box to convert time as categorical factor.\nAfter clicking \nOK\n, users can specify the Test. Here we choose the option \nSpecify Test\n:\n\n\n\n\nHere we want to compare control to case for each time point, so users can specify the test by first checking the option \nFor each\n and selecting \ntime\n from the drop-down menu. Under the \nCompare to\n drop-down menu, select \ncontrol\n. Once these options are entered, click the \nAdd\n button and the four comparisons will be populated as below:\n\n\n\n\nAfter clicking \nOK\n, and \nSubmit\n, users will get the same results with 2-way ANOVA.\n\n\nSummarize Inference Report\n\u00b6\n\n\nSometimes, a user wishes to count the number of variables, or probesets, corresponding to a set of criteria for each comparison in an analysis.  For instance, the user might want to see how many variables have a p-value <0.05/Fold change >2, p-value<0.05/Fold change >3, p-value<0.05/Fold change>4,  p-value<0.05/Fold change<-2, p-value<0.05/Fold change <-3, and p-value<0.05/Fold change <-4 for each of the four comparisons.\n\n\nThis can be done manually by creating filters for each of these different criteria and counting the number of genes fitting that criteria.\n\n\nAlternatively, and the faster approach, the user can use the \nSummarize Inference Report\n module, by switching from \nSolution Explorer\n to \nWorkflow\n and clicking on \nSummarize inference report\n, or by going to the \nOmicData Menu | Inference | Summarize Inference Report\n.\n\n\n\n\nThis opens the \nSummarize Inference Report\n window.\n\n\nIn this window, the user needs to first set the \nProject\n and \nInference test\n object, on which to run the module. Choose \nTutorialMicroArray\n and \nMicroArrayData.Tests\n. Ensure that \nAll rows\n is selected for \nRows\n, and that all 4 estimates are selected for \nEstimates\n.\n\n\nUnder \nOptions\n, the user just needs to add the conditions of interest. For example, in order to add a condition whereby the Raw Pvalue<0.05 and the Fold change>2, ensure that both of these boxes are checked, and that the \nFold change >\n box contains 2 while the \n<\n box is empty.\n\n\nClick the \nAdd button\n to add this to the \nConditions\n section. Double-click the name of the condition to rename it (FC>2).\n\n\nRepeat this process until conditions have been added, whereby all have Raw Pvalue<0.05, but with FC>2, FC>3, FC>4, FC<-2, FC<-3, and FC<-4.\n\n\nThere should be a total of 6 conditions in the \nConditions\n box.\n\n\nThe module will generate (interactive) counts of variables that meet these conditions for each of the 4 estimates/contrasts selected.\n\n\nOptionally, the user can select the \nGenerate lists based on conditions\n checkbox (under the \nAdvanced\n tab) to automatically generate one \nList\n for each condition/estimate. For this tutorial, leave this unchecked, as it will generate 19 \nLists\n.\n\n\n\n\nClick \nSubmit\n to run the module.\n\n\nA new \nTable\n will be generated in the \nSolution Explorer\n, called \nMicroArray Data.Tests.SummaryReport\n, as well as a \nTableView\n.\n\n\n\n\nThe generated \nTableView\n, as shown below, contains the count, for each estimate, of the 6 different criteria.\n\n\n\n\nThis \nTableView\n is fully interactive, as selecting one or multiple cells shows the associated variables in the \nDetails Window\n. In addition, \nArray Studio\n automatically updates the \nDetails Window\n to only show the results of the particular tests for the selected estimate(s). In other words, if the user selects a summary count for certain condition(s) for 1 DBP vs. Control, only 1 DBP vs. Control columns (and annotation) will be shown in the \nDetails Window\n. This is done so that the user can easily export the results for that particular comparison.",
            "title": "Differential Expression"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#differential-expression",
            "text": "Array Studio  contains a number of different modules for performing univariate analysis/differential expression, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others.",
            "title": "Differential Expression"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#two-way-anova",
            "text": "Two-Way ANOVA  can be used to research the effects of multiple factors on expression data. The design of the experiment in this tutorial is set-up so that the user will perform a  Two-Way ANOVA .  For this tutorial, we are interested in generating contrasts for each time point, in comparing the DBP (treatment) group to the control group. The first factor in the ANOVA is  time  while the second factor is  treatment . Thus, we should be able to generate four contrasts, and associating fold changes, p-values, estimates, etc.  While the  General Linear Model  could easily be used instead (and provide more customization of the results), it is a much more straightforward process for the novice user to use the  Two-way ANOVA  module.  To run the  Differential Expression-Two Way ANOVA  module, go to the  Statistical Inference  section of the workflow, and select  Two-Way ANOVA . Alternatively, the same module can be selected by going to the  OmicData Menu | Inference | Standard Tests | Two-way ANOVA .   This opens the  Two-way Analysis of Variance  window:   As with other analysis windows, the user must first set the  Project  and  Data  on which to run the analysis, in the  Input/Output  section.    Make sure  TutorialMicroArray  is chosen as the project and  MicroArrayData  is chosen as the input data.    For  Variables  , ensure that  All Variables  is selected.    For  Observations , choose  Customized observations  , then click the  Select  button to choose the list  MicroArrayData.Observation23 . This ensures that the statistical tests are only run on the 23 observations that passed the PCA quality control.     Array Studio  will attempt to automatically populate the  Factor 1  and  Factor 2  dropdown boxes, using the first two  Factor  type columns in the design table. For this tutorial, this should correctly populate  Factor 1  as  time  and  Factor 2  as  treatment .    For generating the comparisons, the  For each  box is used. The factor chosen for  Factor 1  will automatically be populated into the  For each  box, and cannot be changed, unless the user changes the  Factor 1  column.    To figure out what comparisons will be generated, read the  For each ,  Compare to  boxes together. So,  For each: time\u00b8 Compare to : control will generate a contrast comparing DBP to control at each time point.    Ensure that the  Compare to  dropdown box is set to  control .    The option to  Include interaction term  should be enabled, however if users wish to run a two-way ANOVA without the interaction, this is available here as well.    Comparison  specifies the multiple comparison procedure. Options include  Control ,  Dunnett  and  Tukey .    By  - Allows the user to select an additional categorical variable to subset the data set before running ANOVA.    Multiplicity  adjustments for the comparisons can be set as well, with the default adjustment being FDR_BH (options include  None ,  FDR_BH ,  FDR_BY ,  Bonferonni ,  Sidak ,  StepDownBonferroni ,  StepDownSidak ,  StepUp ,  QValue ,  QValue41 ). The  multiplicity  adjustment will calculate an  Adjusted p-value  column in the result report.    FC Transformation  specifies how the Fold Change is calculated based on estimate.     Fold change is defined as the unlogged estimate. By default, it is Exp2: sign(estimate)*2^abs(estimate). User also has the options of Exp, Exp10 and Ratio.    The  Alpha level , or p-value cutoff, is used in the automatic generation of  Lists  for each contrast. If a  multiplicity  adjustment is set to anything other than  None , these lists will be generated for probesets that have an adjusted p-value less than this value (by default 0.05).    Report F-Test Pvalues  will report the p-values for the F-tests (i.e. one p-value each for time, treatment, and treatment*time). Leave this box unchecked as we are more interested in specific estimates.    Generate LSMean data  will generate a new  Data  object, where each observation is the LSMean of the interaction of  Factor 1  and  Factor 2  group (i.e. in this case, the LSMean      data  would have 8 observations, one for each  time*treatment  group). For this tutorial, leave this box unchecked.    If  Generate LSMean data  is checked,  Append LSMeans to the inference report  becomes available. This will append the  LSMeans data , for each interaction group, to the inference report. This can be used to see the adjusted mean intensity levels of each group for any potential differentially expressed probesets (i.e. some users prefer to ignore lower-expressing probesets, and this provides the user with a way to filter by these values).    Generate estimate data  will generate a  Data  object containing one observation per contrast. So, in the case of this tutorial, the new  Estimate data  would contain four observations, one for each of the four comparisons being generated. For the purposes of this tutorial, leave this box unchecked.    Split the significant list by change direction  will split each generated significant list (based on the alpha level value) by direction of change.    For users familiar with SAS Code, clicking the  Show SAS Code  button will generate the equivalent SAS code in a text file (the SAS code can only be used to run one probeset at a time).  To run the differential expression, click the  Submit  button.",
            "title": "Two-Way ANOVA"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#the-volcanoplotview-and-inference-report",
            "text": "After running the  Two-way ANOVA  (the computing time should be 1-3 seconds), a  Table  is generated under the  Inference  folder of the Solution Explorer,  MicroArray Data.Tests  (expand the Inference folder to see this). This table contains the information generated by the  Two-way ANOVA . As can be observed in the  Solution Explorer , this table contains 15923 rows (for the 15923 probesets) and 51 columns (35 from the original  Annotation  and 16 new columns).  Also notice that a number of new  Lists  have been automatically generated by the  Two-way ANOVA . These  Lists  can be used for purposes of filtering, and also in the next section, for generating a  Venn Diagram . These lists were generated using an adjusted p-value cutoff of 0.05 (this was set in the previous dialog menu). If the user preferred to automatically generate lists using raw p-value, then no multiplicity adjustment test should have been specified.   By default, a  VolcanoPlotView  will be generated for the  Inference Table . It should be the view visible in the main view window. If not, double-click on it in the  Solution Explorer  or switch to the view in the main  Data View  window.   After opening the  view VolcanoPlot , notice that four  volcano plots  have been created in this view, one for each comparison generated by the  Two-Way ANOVA  window.   To change all graphs to the same scale, click  Use Uniform Scale  icon on the toolbar (as shown below).   The graph should be updated instantly.   Looking in the  toolbar , the user should recognize many of the icons from previous views.     Open Current view as picture : will open current visible view in the default picture viewer   Open Current view in Excel:  will open current visible view in Microsoft Excel  Open All Charts in Excel:  will open all opened views in Microsoft Excel  Open Current view in Excel (Editable) : will open current visible view in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above)  Open All Charts in Excel (Editable) : will open all opened views in Microsoft Excel and allow the user to edit the graphics (in Office 2003 and above)   Open Current view in PowerPoint : will open current visible view in Microsoft PowerPoint  Open All Charts in PowerPoint : will open all opened views in Microsoft PowerPoint  Open Current view in PowerPoint (Editable)  : will open current visible viewin Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above)  Open All Charts in PowerPoint (Editable) : will open current visible view in Microsoft PowerPoint and allow the user to edit the graphics (in Office 2003 and above)    Copy Current View : will copy current view to the clipboard    Save Current View : will save the current visible view as an image file (default is pdf but other formats include png, emf, gif, jpg, tif, bmp)    Print Current View : will print the current view  Print All Charts : will print charts that are currently opened    Select : allow the user to lasso multiple selections    Zoom in : will zoom in the table using lasso    Full Screen : will open the view in full screen mode    Refresh Chart and Undo all Zooms/Pans : Returns view to the original format   Specify Layout   (rows*columns) : To specify layout by rows and columns. For instance, if the user was only interested in seeing one column per view in order to see a particular view in greater detail, this would be set to 3*1 (3 rows*1 column). Each column represents a view.    Use Uniform Scale : when selected, will use the same scale (x and y-axis) for all graphs.  The  VolcanoPlotView  shows the * Log10*  P-value  on the y-axis and the  Estimate  ( Estimate  is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the most positive or negative genes can be found at the extremes of the x-axis. Similar to all views in Array Studio, the  VolcanoPlotView  is fully interactive. Selecting a particular point or points on the plot brings up the details of that probeset (based on its annotation) in the  Details  window at the bottom of the screen.  The  View Controller | Task  under  VolcanoPlotView  mode gives the user options to  Change Chart Properties  (which includes renaming the title of the chart as well as the x and y-axis titles, and many other options),  Change Symbol Properties , and  Change To Quality-First Mode . The VolcanoPlot will often default to what is known as a \"Speed-First Mode\", where it is updated quickly when any changes are applied to the view (i.e. layout, specify columns). This mode is particularly useful when dealing with large numbers of variables. Users can toggle between this mode and  Quality-First  mode by clicking the option in the  View Controller :   Switch to  Quality-First  mode now and select  Change Symbol Properties . To enlarge the data points in the volcano plot and allow for better visualization, users can slide the button in Size. Users can also add labels to all data points, or only those selected. In this example, choose selected and use the drop-down menu to label by Probe Set ID:   Now, move the mouse around the volcano plot named  1 DBP vs. Control . Notice that a red square encompasses each individual point on the graph. This can be used to select an individual probeset from the graph, and retrieve information in the  Details Window . Now, click on the data point that is in the upper most right corner of this plot. The point should now turn red, as it has been selected and labeled.   Make sure that the  Details Window  is visible down below. If it has been closed, go to  View | Show Details Window . If necessary, drag the border between the main  Data View Window  and the  Details Window  to expand the size of the  Details Window . After selecting the upper right-hand data point, check the  Details Window . Notice that the  Details Window  now contains the information of  Estimates ,  Fold Changes ,  Raw P-values , and  Adjusted P-values  for each comparison.   Scroll right in the  Details Window  to see the rest of the annotation columns.   Because the test report is a type of  Table , it also allows the user to use the  View Controller | Column  and  Row  tabs to filter the data by any column or row (includes the  Two-Way ANOVA  generated columns, as well as the gene  annotation  columns).  Click the  Options  icon in the  Row  tab    This allows the user to group the filters by either mode (i.e. p-value, fold-change, estimate, etc.) or contrast (time point 1 DBP vs. control, time point 2 DBP vs. control, etc.). Try grouping the p-values by  mode  now, and notice the effect on the filters.  Notice that the Estimates for each comparison are now grouped together, as are the FoldChange, RawPValue, and AdjustedPValue columns. This is especially helpful for organizing filters in studies where a large number of contrasts have been generated.  Also, note that the filter can be set to  Match All Column  or  Match Any Columns  . By default, the filter uses  Match All Columns  , ensuring that all filters will be matched when set. However, choosing  Match Any Columns  will allow the user to get results matching any of the filters.  The  Table View  for the inference report is also automatically generated by the  Two-way ANOVA , as a  TableView  named  Report . Open this view now by double clicking in the  Solution Explorer .   A  TableView  is now shown in the main view window, containing the columns generated by the  Two-way ANOVA , as well as the  annotation  columns. For this particular dataset, there are 15923 rows of probesets, with 51 columns of  annotation .  Notice that this includes  annotation  columns for  Estimate  columns,  Fold Change  columns,  Raw p-value  columns, and  Adjusted p-value  columns for each comparison made by the  Two-way ANOVA .   Click  Specify Columns  in the  View Controller | Task  tab.   A  Choose Columns  window allows the user to specify the columns for view in the table. This can be useful, as the user may want to create different  Table Views  for the report, each containing different information. Columns can be removed, added, or the order of the columns can be changed.   Click  OK  to return to the  TableView  of the report.  The  View Controller | Row  tab can be used, just as in the  VolcanoPlotView,  to filter the data. Expand the  RawPValue  filter section, then expand  1 DBP vs. Control.RawPValue  filter and enter  <.05  to filter all probesets to only include those that have a  RawPValue  of less than 0.05 for  1 DBP vs. Control .   Do the same for the filter of  3 DBP vs. Control.RawPValue  filter,  6 DBP vs. control.RawPValue  and  18 DBP vs. Control.RawPValue , filter. This will show only those genes with  p-values  less than 0.05 in four comparisons.   Look at the top right of the table view to see the number of rows remaining after filtering (or just look at the top of the  View Controller ). In this case, 24 probesets have p-values less than 0.05 at all 4 time points.   Go to the  Add Item  drop-down button in the tool strip. Choose  Add List From Visible rows  to add a new  List  containing only those rows visible from the filter.   The  Choose List Source  window opens. This allows the user to create a list using any of the different columns in the  Table . The name of the list can be set as well as the organized folder location for the list.  Here we use  Probe Set ID  to generate the list, notice that each line has a unique Probe set ID so the list would not contain any repeated probe set IDs. However, if you choose other IDs such as Gene Name to build the list, it may have repeated IDs since mulitple rows may share the same gene name. In this case, users can check the  Make a unique list  so that the repeat IDs would only show up once in the list.  Choose  Probe Set ID , name the list  Significant at All Timepoints , and click  OK  to continue.   Notice that a new list has been created.",
            "title": "The VolcanoPlotView and Inference Report"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#the-venn-diagram-view",
            "text": "Array Studio also has the ability to easily create a  Venn Diagram . The  Venn Diagram  could utilize the  Lists , either created by the user or by  Array Studio  and the  Two Way ANOVA  (or other statistical inference module), to segment the data points.  To add a  Venn Diagram View , first go to the  Solution Explorer  and the  -Omic Data  section. Right click on  MicroarrayData  and select  Add View  from the menu.   Select  VennDiagramView  from the list of choices. Notice that the  Preview  window automatically creates a simple  Venn Diagram , using only the first  List  in the  Lists  tab of the  Solution Explorer . This will be changed in the following steps. Click  OK  to add the  View .   Notice that a new view, called  Venn Diagram , is now visible in the  Solution Explorer Window , as well as in the main view window.   Now the  Venn Diagram  view only contains one list.  The user can add more lists by using the  Specify Data Source  option in the  Task  tab of the  View Controller . However, it is much easier to do this using drag-and-drop.  Note: Array Studio can handle up to six lists. However, only 4 lists can be shown in one chart at a time. So, if the user enters more than 4 lists,  Array Studio  will create every combination of those lists, and one chart for each combination will be shown in the  View .  To drag-and-drop to the Venn Diagram view, go to the  List  in  Solution Explorer , and choose the lists of all four time points (use shift or control-click to choose multiple lists at the same time). Now, drag these lists into the main view window, which is then updated to include the four lists in the  Diagram .   Like every other view in Array Studio, the  Venn Diagram  view is also fully interactive. Click on the number 29 in the intersection of the 3 lists. First, note that parentheses now appears after the number 29 so that it looks like 29(29). This indicates that the user has selected the 29 genes found in that intersection.   Look at the  Details Window  and notice that 29 probesets are now listed in the  Details Window .   Similar to every other view, the  Venn Diagram  view can be exported to other programs using the toolbar.",
            "title": "The Venn diagram view"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#the-general-linear-model",
            "text": "If users have a complicated design table (such as some large clinical experiment) involving many factors, they can use General linear model function to build some complicated statistical model.  Users can find the function of General linear model here:   Or through windows here:   Two-Way ANOVA is a specific case of General model, here we can get the same results using General linear model:   Just like in Two Way ANOVA, users can specify the observations by list to do the analysis based the 23 observations.   After that, users can specify the model by selecting the time and treatment and clicking  Add . The interaction term \"time:treatment\" is made by selecting both classes and clicking the  Cross  button as shown below.   Notice that array studio would automatically treat numeric variables such as time as continuous factor, so users have to check the  Class  box to convert time as categorical factor.\nAfter clicking  OK , users can specify the Test. Here we choose the option  Specify Test :   Here we want to compare control to case for each time point, so users can specify the test by first checking the option  For each  and selecting  time  from the drop-down menu. Under the  Compare to  drop-down menu, select  control . Once these options are entered, click the  Add  button and the four comparisons will be populated as below:   After clicking  OK , and  Submit , users will get the same results with 2-way ANOVA.",
            "title": "The General Linear Model"
        },
        {
            "location": "/tutorials/Microarray/Differential_Expression/#summarize-inference-report",
            "text": "Sometimes, a user wishes to count the number of variables, or probesets, corresponding to a set of criteria for each comparison in an analysis.  For instance, the user might want to see how many variables have a p-value <0.05/Fold change >2, p-value<0.05/Fold change >3, p-value<0.05/Fold change>4,  p-value<0.05/Fold change<-2, p-value<0.05/Fold change <-3, and p-value<0.05/Fold change <-4 for each of the four comparisons.  This can be done manually by creating filters for each of these different criteria and counting the number of genes fitting that criteria.  Alternatively, and the faster approach, the user can use the  Summarize Inference Report  module, by switching from  Solution Explorer  to  Workflow  and clicking on  Summarize inference report , or by going to the  OmicData Menu | Inference | Summarize Inference Report .   This opens the  Summarize Inference Report  window.  In this window, the user needs to first set the  Project  and  Inference test  object, on which to run the module. Choose  TutorialMicroArray  and  MicroArrayData.Tests . Ensure that  All rows  is selected for  Rows , and that all 4 estimates are selected for  Estimates .  Under  Options , the user just needs to add the conditions of interest. For example, in order to add a condition whereby the Raw Pvalue<0.05 and the Fold change>2, ensure that both of these boxes are checked, and that the  Fold change >  box contains 2 while the  <  box is empty.  Click the  Add button  to add this to the  Conditions  section. Double-click the name of the condition to rename it (FC>2).  Repeat this process until conditions have been added, whereby all have Raw Pvalue<0.05, but with FC>2, FC>3, FC>4, FC<-2, FC<-3, and FC<-4.  There should be a total of 6 conditions in the  Conditions  box.  The module will generate (interactive) counts of variables that meet these conditions for each of the 4 estimates/contrasts selected.  Optionally, the user can select the  Generate lists based on conditions  checkbox (under the  Advanced  tab) to automatically generate one  List  for each condition/estimate. For this tutorial, leave this unchecked, as it will generate 19  Lists .   Click  Submit  to run the module.  A new  Table  will be generated in the  Solution Explorer , called  MicroArray Data.Tests.SummaryReport , as well as a  TableView .   The generated  TableView , as shown below, contains the count, for each estimate, of the 6 different criteria.   This  TableView  is fully interactive, as selecting one or multiple cells shows the associated variables in the  Details Window . In addition,  Array Studio  automatically updates the  Details Window  to only show the results of the particular tests for the selected estimate(s). In other words, if the user selects a summary count for certain condition(s) for 1 DBP vs. Control, only 1 DBP vs. Control columns (and annotation) will be shown in the  Details Window . This is done so that the user can easily export the results for that particular comparison.",
            "title": "Summarize Inference Report"
        },
        {
            "location": "/tutorials/Microarray/Data_Exploration/",
            "text": "Data Exploration\n\u00b6\n\n\nArray Studio has the ability to perform further analysis on a list or lists of genes. It has the ability to upload pathways and lists to Ingenuity Pathway Analysis (IPA),  as well as to check gene ontologies and find out if any significant ontology exists. IPA requires the user to have an account so that it is not covered in this tutorial.\n\n\nHierarchical clustering\n\u00b6\n\n\nHierarchical clustering can provide an overview of the data, and can easily be performed in Array Studio. Go to the \nOmicData | Pattern\n menu. The \nOmicData | Pattern\n menu contains a number of different pattern detection techniques that can be used in Array Studio. This includes \nFind Neighbors, Correlate Covariate, Hierarchical Clustering, NMF Clustering, Cluster Variables, Cluster Observations\n, and \nGene Shaving\n. \nCluster Variable and Cluster Observations\n include PAM, CAST, K-means, and SOM for clustering algorithms.\n\n\n\n\nArray Studio\n can handle (with a regular computer) \nHierarchical Clustering\n up to 30,000 variables in a few minutes. In comparison, the popular gene clustering program from Eisen, Gene Cluster, can only cluster up to 9,999 variables.\n\n\nFor the purposes of this tutorial, we will cluster the already created List, \n18 -> DBP vs control.Sig296\n, as an example.\n\n\nIn the Microarray \nWorkflow\n, select \nHierarchical Clustering\n, or go to the \nOmicData | Pattern | Hierarchical Clustering\n to open \nHierarchical Clustering\n.\n\n\n   \n\n\nOnce the \nHierarchical Clustering window\n opens, ensure that \nMicroArrayData\n is selected under \nInput/Output | Data\n.\n\n\n\n\nNext, ensure that the \n18 -> DBP vs. Control.Sig\n 296 is selected so that only probesets in this list are used for clustering (\nCustomized Variables\n). Ensure that \nMicroArray Data.Observation23(23)\n is selected under \nCustomized Observations\n, excluding the outlier filtered out by PCA.\n\n\nUnder \nOptions\n , ensure that \nCompute Observation tree\n and \nCompute variable tree\n are both selected. Array Studio gives the option of only clustering the observations, variables, or both. Both the observation tree and the variable tree contain options for \nLink\n and \nDistance\n for the clustering. \nLink\n includes options of \nWard\n, \nSingle\n, \nComplete\n, \nAverage\n, \nMcquitty\n, \nMedian\n, and \nCentroid\n. \nDistance\n includes options of \nEuclidean\n, \nMaximum\n, \nManhattan\n, \nCanberra\n, \nBinary\n, \nPearson\n (uncentered correlation), and \nCorrelation\n.\n\n\nLink Options\n\n\n\n\nDistance Options\n\n\n\n\nGenerate classic dendrogram view\n will generate the dendrogram view in the old Array Studio 1.0 format. Uncheck this box as the new improved dendrogram viewer is preferred by most users.\n\n\n\n\nNote\n\n\nfor correlation distance, there is no need to normalize the data.\n\n\n\n\n\n\nClick \nSubmit\n to begin clustering. This process should take approximately 3 seconds.\n\n\nA new view will be generated in the \nSolution Explorer\n, called \nDendrogram\n.\n\n\n\n\nThere are two visible windows in this \nView\n. The left window contains the dendrogram, while the right window contains a zoomed-in view of the dendrogram.\n\n\n\n\nIf the entire cluster is not visible in the left window, there are two options. First, the window size can be adjusted by dragging in between the left window and the right window.\n\n\nMore conveniently, the pixel size can be automatically adjusted using the toolbar at the top of the left window\n\n\n\n\nUse either the pixel size dropdown box (x*y)\n\n\nor clicking the \nFit Dendrogram to Window\n \n button.\n\n\nThe \n button provides other options for viewing the dendrogram\n\n\n\n\nClick the \nFit Dendrogram to Window\n \n button now. Resize the left window and click the \n button again if the data looks too small or distorted. When finished, the left window should look similar to below.\n\n\n\n\nThe left window view (heatmap thumbnail with dendrogram) is linked to the right window view. Clicking on a branch of the dendrogram will bring those specific rows and observations up in the right window. Branches on both the Y-axis and X-axis can be clicked on, individually and together.\n\n\nClick on a small branch in the left window (Y-axis). Note that the branch, when selected, turns to blue color.\n\n\n\n\nNow notice the right hand window. The right hand window contains a \nHeatmapTableView\n of the rows (probesets) selected in the left hand dendrogram view.\n\n\n\n\nInitially, all the columns will not be visible in the view . If necessary, shrink the column widths so that all columns are visible by grabbing between two columns on the header row and shrinking the column.\n\n\nIt may also help to hide the left hand window by clicking the \nHide Thumbnail\n \n button on the toolbar.\n\n\n\n\nNotice that scrolling to the right shows the annotation for each probeset.\n\n\nTo change the annotation columns displayed, click the \nSpecify Annotation Columns\n button in \nView Controller | Task | Data\n.\n\n\n\n\n\n\nNext, use the \nChange ColorBars\n under \nView Controller | Task | Customize\n \n| Change ColorBars\n to open up a window for selecting columns for color bars.\n\n\nChoose \ntime\n, then \ntreatment\n to create color bars on that heatmap. Click \nOK\n to continue.\n\n\n\n\nNotice that the ColorBars appear over the heatmap to label different Time and Treatment groups.\n\n\n\n\nTo view the legend, switch the \nView Controller\n to the \nLegend\n tab. Notice that \nTime and Treatment\n are separated on the legend for each viewing. Click on \nwith border\n or \nwithout border\n to switch the status of copied legend (whether to have border). Click on \nCopy Legend\n to copy the legend.\n\n\nNote: Right-clicking on anything in the Legend colors will allow the user to change colors for the chart or the color bars.\n\n\n\n\nSometimes the user might want to find a particular probeset or gene in the dendrogram, in order to see other genes clustered around it. To do this, first re-expand the left window thumbnail view using the \nShow Thumbnail\n \n button. Expand the left-window so that it splits about half the screen with the right-hand heatmap window. If necessary, click the \nFit Dendrogram to Window\n \n button in order to see the entire dendrogram.\n\n\n\n\nUsing the \nSelect\n button on the main toolbar, type the gene name \nStar\n and change the dropdown box to the \nGene Symbol\n selection, and then press Enter.\n\n\n\n\nThis ensures that Array Studio will select \nStar\n in the column \nGene Symbol\n.\n\n\nClick select by clicking on the binoculars button \n .\n\n\nNotice that in the left-hand dendrogram thumbnail view, two lines have been selected towards the middle of the dendrogram (indicated by the blue selection lines)\n\n\nIn the right-hand heatmap view, only the probesets containing \nStar\n in \nGene Symbol\n are now shown.\n\n\n\n\nTo see those genes found around Star in the Dendrogram, click on a branch of the dendrogram near the blue selection line.\n\n\n\n\nOn the right panel, scroll until the \nStar\n probeset is found, and notice the genes that are similar in pattern to \nStar\n.\n\n\nIn particular, it appears that the genes \nScarb1, Cyp17a1, and Stc2\n cluster around \nStar\n, as well as others.\n\n\n\n\nAs the last step in hierarchical clustering, the user can choose to change the coloring scheme of the heatmaps. This is accomplished by clicking \nChange Color Properties\n in the \nView Controller | Task\n tab.\n\n\n\n\nClick on the \nMiddle value color\n and change it to white.\n\n\n\n\nClose the \nColor Properties\n dialog and notice the heatmaps are instantly updated.\n\n\n\n\nPattern Matching (Find Neighbors)\n\u00b6\n\n\nArray Studio includes a number of pattern detection modules and we will discuss one of them, \nFind Neighbors\n, which allows the user to find neighbors for a variable or an observation based on correlations. By default, the currently selected variable or observation (if multiple variables or observations are selected, the first one) will be used as the input for this module, and the user can easily change that input.\n\n\nThe \nFind Neighbors\n module can be run by clicking on the \nFind Neighbors\n in the \nMicroarray Workflow | Pattern recognition\n, or by going to the \nOmicData Menu | Pattern | Find Neighbors\n. Now click \nFind neighbors\n to open this module.\n\n\n\n\nThis opens the \nFind Neighbors\n dialog window:\n\n\n\n\n\n\n\n\nUnder the \nInput/Output\n section, the user has an option for \nProject\n and Data (Choose     \nTutorial MicroArray\n and \nMicroArray Data\n now).\n\n\n\n\n\n\nEnsure that all variables are selected under the \nVariables\n section.\n\n\n\n\n\n\nThe user can choose to \nFind Neighbors\n using the data in a specific list of samples. Choose the \nList MicroArray Data.Observation23\n to only run the \nFind Neighbors\n module on the 23 chips in the \nList\n (with outlier 22A removed).\n\n\n\n\n\n\nLeave the \nOutput name\n blank and allow Array Studio to assign the default name.\n\n\n\n\n\n\nFor the \nOptions\n section, type \n1368321_at\n into the \nFind neighbors for\n text box.     This is the probeset for \nEgr1\n, and had this probeset been selected in the view prior to opening this window, Array Studio would have selected it by default. Instead, the top probeset on the selected list was the default option.\n\n\n\n\n\n\nEnsure that \nVariable\n is selected (this module can work on observations as well).\n\n\n\n\n\n\nCorrelation method\n contains options for \nPearson\n, \nSpearman\n, and \nKendall\n correlations. Ensure that \nPearson\n is selected.\n\n\n\n\n\n\nCorrelation direction\n allows the closest neighbors to be found for Positive, Negative, or both directions. Positive is the default option.\n\n\n\n\n\n\nArray Studio includes the option to either search for a fixed number of neighbors or by a p value cutoff of the correlations. For this practice, ensure that \nFixed neighbor number\n is selected and type \n20\n into the box. If specified a cutoff for \nWith P-value <,\n     correlation test pvalues will be used to search the neighbors.\n\n\n\n\n\n\nArray Studio allows the user to either output a \nHeatmapView\n for the \nFind Neighbors\n or a \nProfileView\n, which can be specified in \nOutput view\n. Ensure that \nHeatmapView\n is selected now.\n\n\n\n\n\n\nClick \nSubmit\n to continue.\n\n\nIn the \nSolution Explorer\n, a new \nOmic data\n named \n1368321_at.Neighbors\n is created under the \nPattern\n folder. Two new views are created (\nNeighbors\n a \nHeatmapView\n and \nTable\n  a \nTableView\n).\n\n\n\n\nA \nHeatmapView\n entitled Neighbors is shown by default in the \nview window\n. If the window does not appear as below (no rows shown), ensure that no filters are set in the \nView Controller | Variables\n tab by clicking the \nClear All\n \nFilters\n \n button in \nView Controller\n.\n\n\n\n\nWhile interesting, the above view is not all that useful without color bars to indicate the classification of each chip. This can be accomplished using the \nChange X-Axis ColorBars\n item in \nView Controller | Task | Customize\n tab. Click \nChange X-Axis ColorBars\n now to open the \nChoose Columns\n window.\n\n\n\n\nMove \ntreatment and time\n to the right-hand \nListed columns\n section to create color bars for each column. Click \nOK\n to continue.\n\n\n\n\nThe heatmap is updated to include the color bars.\n\n\n\n\nIn order to get a better idea of the pattern, we need to order the heatmap columns in a reasonable way. Click \nSort Heatmap columns\n in \nView Controller | Task | Data\n.\n\n\n\n\nFirst sort by \ntime\n then sort by \ntreatment\n.\n\n\n\n\nNow the heatmap columns are sorted appropriately as can be seen from the color bars.\n\n\n\n\nChoose the \nLegend\n tab in the \nView Controller\n to view the legend for the chart.\n\n\n\n\nThe chart can be opened in PowerPoint at any time using the \nOpen Current View in PowerPoint\n or \nOpen All Charts in PowerPoint\n button.\n\n\n\n\nBesides just showing the \nProbeset ID\n, the chart can also show additional columns of annotation.\n\n\nClick \nChange Y-Axis Labels\n in \nView Controller | Task | Customize\n now to open the \nChoose Columns\n \nwindow\n.\n\n\n\n\nMove \nGene Symbol\n to the \nListed columns\n section and click \nOK\n to continue.\n\n\n\n\nThe chart is updated, now showing the \nGene Symbol\n instead of \nProbeset ID\n.\n\n\n\n\nGene ontology analysis\n\u00b6\n\n\nArray Studio provides an internal gene ontology analysis. The gene ontology analysis takes lists of probesets and, using online Gene Ontology annotation, reports back the number of probesets found in each of the classes with the given ontology. This can be used, for example, to figure out if a particular class within ontology is over-represented in a particular treatment.\n\n\nGene Ontology\n analysis can be found in the \nOmicData Menu | Annotation | Gene Ontology\n. This opens the \nGene Ontology Classification Window\n.\n\n\n\n\nThe \nGene Ontology Classification\n window contains a number of options.\n\n\n\n\n\n\n\n\nFirst, select the \nProject\n and \nData\n to be used for classification (choose \nTutorial MicroArray\n and \nMicroArray Data\n).\n\n\n\n\n\n\nNext, choose \nLists for classification\n. In this case, we are interested in comparing the four estimates (\n1 ->DBP vs control\n, \n3 -> DBP vs control\n, \n6-> DBP vs control\n, \n18 -> DBP vs control\n). Choose these lists now and click \nOK\n.\n\n\n\n\n\n\n\n\n\n\n\n\nChoose \nGO term columns\n: because the user may choose to import customized annotation, the possibility exists that the user may wish to specify the columns that contain gene ontology terms. By default, Array Studio imports 3 columns of annotation with gene ontology terms. Array Studio automatically recognizes that \nGene Ontology Biological Process\n, \nGene Ontology Cellular Component\n, and \nGene Ontology Molecular Function\n all contain GO terms. Ensure that all 3 columns are selected.\n\n\n\n\n\n\nSet the level of classification using the \nClassification level (0-6)\n box. The higher the level (6 being the highest), the more specific the GO classification. For instance, Level 0 is the least specific, and will have general categories of \nBiological Process\n, \nCellular Component\n, and \nMolecular Function\n. On the other hand, level 6 will be extremely specific, for instance: cyclooxygenase pathway and GTP cyclohydrolase activity. For this exercise, leave the \nClassification level\n set to 3. This is the default setting, and may prove to be the most interesting for most practices.\n\n\n\n\n\n\nBiological process\n, \nmolecular function\n, and \ncellular component\n checkboxes are provided if the user wishes to only specify a specific type of gene ontology. Many times customized annotations will include all three types in one column of annotation, and thus these checkboxes are provided for such cases. Leave all three checkboxes selected for this tutorial.\n\n\n\n\n\n\nGene ontology is constantly being updated. This box \nUpdate frequency (days)\n sets the frequency that Array Studio should check for new ontology information. By default, this is set to 30 days. When run, if Array Studio has downloaded new annotation in the past 30 days, it will skip the download step and immediately begin classifying the lists.\n\n\n\n\n\n\nIf users check the \nCalculate p-values (assumes variable independence)\n, the software     will calculate a p-value for each GO category. This is based on Fisher s Exact Test, and it     assumes variable independence. Check this box now.\n\n\n\n\n\n\nThe \nChoose Universal List\n dropdown box is active only when \nCalculate p-values\n is selected. It can be used to choose the \nUniversal List\n used for a Fisher's Exact Test.     For instance, the user may choose to use the entire chip (all) for calculating of p-values, or only look at a list of probesets of interests.\n\n\n\n\n\n\nThe \nMultiplicity\n dropdown box is active only when \nCalculate p-values\n is selected.     It can be used to set the multiplicity adjustment for the Fisher s Exact Test, and contains the standard multiplicity adjustment types found elsewhere in Array Studio.\n\n\n\n\n\n\nClick \nSubmit\n to continue.\n\n\nIf the gene ontology has not been updated or it has been more than 30 days old (true for all first-time users of Array Studio), the gene ontology will be updated first, and then the module will run.\n\n\nWhen finished, a new \nTable\n, titled \nMicroArrayData.GeneOntologyReport\n is created in the \nSolution Explorer\n under the \nOntology\n tab, and the \nTable\n view is opened in the center \nData View\n window.\n\n\n\n\nNote\n\n\nNote:\n Due to the constantly updating nature of the Gene Ontology database, the number of rows in the example shown below and the number of rows when the user runs the tutorial may differ. This is expected.\n\n\n\n\n\n\n\n\nThe \nTable\n contains 10 columns. The first column contains the category (the gene ontology), the second column contains the GOTerm, with the other columns containing the number of probesets, in each list or universal list [all], belonging to each category and the corresponding Fisher Exact test p-values.\n\n\n\n\nAs in all \nviews\n in Array Studio, details can be provided on demand and are fully interactive. Clicking on a particular cell, for instance, in \n3 -> DBP vs control\n, actin filament-based process, will provide inference report details about the probesets contained in that category in the \nDetails Window\n.\n\n\n\n\nDetails for multiple cells can be obtained by holding \"Shift\" or \"Ctrl\" buttons and selecting multiple cells.",
            "title": "Data Exploration"
        },
        {
            "location": "/tutorials/Microarray/Data_Exploration/#data-exploration",
            "text": "Array Studio has the ability to perform further analysis on a list or lists of genes. It has the ability to upload pathways and lists to Ingenuity Pathway Analysis (IPA),  as well as to check gene ontologies and find out if any significant ontology exists. IPA requires the user to have an account so that it is not covered in this tutorial.",
            "title": "Data Exploration"
        },
        {
            "location": "/tutorials/Microarray/Data_Exploration/#hierarchical-clustering",
            "text": "Hierarchical clustering can provide an overview of the data, and can easily be performed in Array Studio. Go to the  OmicData | Pattern  menu. The  OmicData | Pattern  menu contains a number of different pattern detection techniques that can be used in Array Studio. This includes  Find Neighbors, Correlate Covariate, Hierarchical Clustering, NMF Clustering, Cluster Variables, Cluster Observations , and  Gene Shaving .  Cluster Variable and Cluster Observations  include PAM, CAST, K-means, and SOM for clustering algorithms.   Array Studio  can handle (with a regular computer)  Hierarchical Clustering  up to 30,000 variables in a few minutes. In comparison, the popular gene clustering program from Eisen, Gene Cluster, can only cluster up to 9,999 variables.  For the purposes of this tutorial, we will cluster the already created List,  18 -> DBP vs control.Sig296 , as an example.  In the Microarray  Workflow , select  Hierarchical Clustering , or go to the  OmicData | Pattern | Hierarchical Clustering  to open  Hierarchical Clustering .       Once the  Hierarchical Clustering window  opens, ensure that  MicroArrayData  is selected under  Input/Output | Data .   Next, ensure that the  18 -> DBP vs. Control.Sig  296 is selected so that only probesets in this list are used for clustering ( Customized Variables ). Ensure that  MicroArray Data.Observation23(23)  is selected under  Customized Observations , excluding the outlier filtered out by PCA.  Under  Options  , ensure that  Compute Observation tree  and  Compute variable tree  are both selected. Array Studio gives the option of only clustering the observations, variables, or both. Both the observation tree and the variable tree contain options for  Link  and  Distance  for the clustering.  Link  includes options of  Ward ,  Single ,  Complete ,  Average ,  Mcquitty ,  Median , and  Centroid .  Distance  includes options of  Euclidean ,  Maximum ,  Manhattan ,  Canberra ,  Binary ,  Pearson  (uncentered correlation), and  Correlation .  Link Options   Distance Options   Generate classic dendrogram view  will generate the dendrogram view in the old Array Studio 1.0 format. Uncheck this box as the new improved dendrogram viewer is preferred by most users.   Note  for correlation distance, there is no need to normalize the data.    Click  Submit  to begin clustering. This process should take approximately 3 seconds.  A new view will be generated in the  Solution Explorer , called  Dendrogram .   There are two visible windows in this  View . The left window contains the dendrogram, while the right window contains a zoomed-in view of the dendrogram.   If the entire cluster is not visible in the left window, there are two options. First, the window size can be adjusted by dragging in between the left window and the right window.  More conveniently, the pixel size can be automatically adjusted using the toolbar at the top of the left window   Use either the pixel size dropdown box (x*y)  or clicking the  Fit Dendrogram to Window    button.  The   button provides other options for viewing the dendrogram   Click the  Fit Dendrogram to Window    button now. Resize the left window and click the   button again if the data looks too small or distorted. When finished, the left window should look similar to below.   The left window view (heatmap thumbnail with dendrogram) is linked to the right window view. Clicking on a branch of the dendrogram will bring those specific rows and observations up in the right window. Branches on both the Y-axis and X-axis can be clicked on, individually and together.  Click on a small branch in the left window (Y-axis). Note that the branch, when selected, turns to blue color.   Now notice the right hand window. The right hand window contains a  HeatmapTableView  of the rows (probesets) selected in the left hand dendrogram view.   Initially, all the columns will not be visible in the view . If necessary, shrink the column widths so that all columns are visible by grabbing between two columns on the header row and shrinking the column.  It may also help to hide the left hand window by clicking the  Hide Thumbnail    button on the toolbar.   Notice that scrolling to the right shows the annotation for each probeset.  To change the annotation columns displayed, click the  Specify Annotation Columns  button in  View Controller | Task | Data .    Next, use the  Change ColorBars  under  View Controller | Task | Customize   | Change ColorBars  to open up a window for selecting columns for color bars.  Choose  time , then  treatment  to create color bars on that heatmap. Click  OK  to continue.   Notice that the ColorBars appear over the heatmap to label different Time and Treatment groups.   To view the legend, switch the  View Controller  to the  Legend  tab. Notice that  Time and Treatment  are separated on the legend for each viewing. Click on  with border  or  without border  to switch the status of copied legend (whether to have border). Click on  Copy Legend  to copy the legend.  Note: Right-clicking on anything in the Legend colors will allow the user to change colors for the chart or the color bars.   Sometimes the user might want to find a particular probeset or gene in the dendrogram, in order to see other genes clustered around it. To do this, first re-expand the left window thumbnail view using the  Show Thumbnail    button. Expand the left-window so that it splits about half the screen with the right-hand heatmap window. If necessary, click the  Fit Dendrogram to Window    button in order to see the entire dendrogram.   Using the  Select  button on the main toolbar, type the gene name  Star  and change the dropdown box to the  Gene Symbol  selection, and then press Enter.   This ensures that Array Studio will select  Star  in the column  Gene Symbol .  Click select by clicking on the binoculars button   .  Notice that in the left-hand dendrogram thumbnail view, two lines have been selected towards the middle of the dendrogram (indicated by the blue selection lines)  In the right-hand heatmap view, only the probesets containing  Star  in  Gene Symbol  are now shown.   To see those genes found around Star in the Dendrogram, click on a branch of the dendrogram near the blue selection line.   On the right panel, scroll until the  Star  probeset is found, and notice the genes that are similar in pattern to  Star .  In particular, it appears that the genes  Scarb1, Cyp17a1, and Stc2  cluster around  Star , as well as others.   As the last step in hierarchical clustering, the user can choose to change the coloring scheme of the heatmaps. This is accomplished by clicking  Change Color Properties  in the  View Controller | Task  tab.   Click on the  Middle value color  and change it to white.   Close the  Color Properties  dialog and notice the heatmaps are instantly updated.",
            "title": "Hierarchical clustering"
        },
        {
            "location": "/tutorials/Microarray/Data_Exploration/#pattern-matching-find-neighbors",
            "text": "Array Studio includes a number of pattern detection modules and we will discuss one of them,  Find Neighbors , which allows the user to find neighbors for a variable or an observation based on correlations. By default, the currently selected variable or observation (if multiple variables or observations are selected, the first one) will be used as the input for this module, and the user can easily change that input.  The  Find Neighbors  module can be run by clicking on the  Find Neighbors  in the  Microarray Workflow | Pattern recognition , or by going to the  OmicData Menu | Pattern | Find Neighbors . Now click  Find neighbors  to open this module.   This opens the  Find Neighbors  dialog window:     Under the  Input/Output  section, the user has an option for  Project  and Data (Choose      Tutorial MicroArray  and  MicroArray Data  now).    Ensure that all variables are selected under the  Variables  section.    The user can choose to  Find Neighbors  using the data in a specific list of samples. Choose the  List MicroArray Data.Observation23  to only run the  Find Neighbors  module on the 23 chips in the  List  (with outlier 22A removed).    Leave the  Output name  blank and allow Array Studio to assign the default name.    For the  Options  section, type  1368321_at  into the  Find neighbors for  text box.     This is the probeset for  Egr1 , and had this probeset been selected in the view prior to opening this window, Array Studio would have selected it by default. Instead, the top probeset on the selected list was the default option.    Ensure that  Variable  is selected (this module can work on observations as well).    Correlation method  contains options for  Pearson ,  Spearman , and  Kendall  correlations. Ensure that  Pearson  is selected.    Correlation direction  allows the closest neighbors to be found for Positive, Negative, or both directions. Positive is the default option.    Array Studio includes the option to either search for a fixed number of neighbors or by a p value cutoff of the correlations. For this practice, ensure that  Fixed neighbor number  is selected and type  20  into the box. If specified a cutoff for  With P-value <,      correlation test pvalues will be used to search the neighbors.    Array Studio allows the user to either output a  HeatmapView  for the  Find Neighbors  or a  ProfileView , which can be specified in  Output view . Ensure that  HeatmapView  is selected now.    Click  Submit  to continue.  In the  Solution Explorer , a new  Omic data  named  1368321_at.Neighbors  is created under the  Pattern  folder. Two new views are created ( Neighbors  a  HeatmapView  and  Table   a  TableView ).   A  HeatmapView  entitled Neighbors is shown by default in the  view window . If the window does not appear as below (no rows shown), ensure that no filters are set in the  View Controller | Variables  tab by clicking the  Clear All   Filters    button in  View Controller .   While interesting, the above view is not all that useful without color bars to indicate the classification of each chip. This can be accomplished using the  Change X-Axis ColorBars  item in  View Controller | Task | Customize  tab. Click  Change X-Axis ColorBars  now to open the  Choose Columns  window.   Move  treatment and time  to the right-hand  Listed columns  section to create color bars for each column. Click  OK  to continue.   The heatmap is updated to include the color bars.   In order to get a better idea of the pattern, we need to order the heatmap columns in a reasonable way. Click  Sort Heatmap columns  in  View Controller | Task | Data .   First sort by  time  then sort by  treatment .   Now the heatmap columns are sorted appropriately as can be seen from the color bars.   Choose the  Legend  tab in the  View Controller  to view the legend for the chart.   The chart can be opened in PowerPoint at any time using the  Open Current View in PowerPoint  or  Open All Charts in PowerPoint  button.   Besides just showing the  Probeset ID , the chart can also show additional columns of annotation.  Click  Change Y-Axis Labels  in  View Controller | Task | Customize  now to open the  Choose Columns   window .   Move  Gene Symbol  to the  Listed columns  section and click  OK  to continue.   The chart is updated, now showing the  Gene Symbol  instead of  Probeset ID .",
            "title": "Pattern Matching (Find Neighbors)"
        },
        {
            "location": "/tutorials/Microarray/Data_Exploration/#gene-ontology-analysis",
            "text": "Array Studio provides an internal gene ontology analysis. The gene ontology analysis takes lists of probesets and, using online Gene Ontology annotation, reports back the number of probesets found in each of the classes with the given ontology. This can be used, for example, to figure out if a particular class within ontology is over-represented in a particular treatment.  Gene Ontology  analysis can be found in the  OmicData Menu | Annotation | Gene Ontology . This opens the  Gene Ontology Classification Window .   The  Gene Ontology Classification  window contains a number of options.     First, select the  Project  and  Data  to be used for classification (choose  Tutorial MicroArray  and  MicroArray Data ).    Next, choose  Lists for classification . In this case, we are interested in comparing the four estimates ( 1 ->DBP vs control ,  3 -> DBP vs control ,  6-> DBP vs control ,  18 -> DBP vs control ). Choose these lists now and click  OK .       Choose  GO term columns : because the user may choose to import customized annotation, the possibility exists that the user may wish to specify the columns that contain gene ontology terms. By default, Array Studio imports 3 columns of annotation with gene ontology terms. Array Studio automatically recognizes that  Gene Ontology Biological Process ,  Gene Ontology Cellular Component , and  Gene Ontology Molecular Function  all contain GO terms. Ensure that all 3 columns are selected.    Set the level of classification using the  Classification level (0-6)  box. The higher the level (6 being the highest), the more specific the GO classification. For instance, Level 0 is the least specific, and will have general categories of  Biological Process ,  Cellular Component , and  Molecular Function . On the other hand, level 6 will be extremely specific, for instance: cyclooxygenase pathway and GTP cyclohydrolase activity. For this exercise, leave the  Classification level  set to 3. This is the default setting, and may prove to be the most interesting for most practices.    Biological process ,  molecular function , and  cellular component  checkboxes are provided if the user wishes to only specify a specific type of gene ontology. Many times customized annotations will include all three types in one column of annotation, and thus these checkboxes are provided for such cases. Leave all three checkboxes selected for this tutorial.    Gene ontology is constantly being updated. This box  Update frequency (days)  sets the frequency that Array Studio should check for new ontology information. By default, this is set to 30 days. When run, if Array Studio has downloaded new annotation in the past 30 days, it will skip the download step and immediately begin classifying the lists.    If users check the  Calculate p-values (assumes variable independence) , the software     will calculate a p-value for each GO category. This is based on Fisher s Exact Test, and it     assumes variable independence. Check this box now.    The  Choose Universal List  dropdown box is active only when  Calculate p-values  is selected. It can be used to choose the  Universal List  used for a Fisher's Exact Test.     For instance, the user may choose to use the entire chip (all) for calculating of p-values, or only look at a list of probesets of interests.    The  Multiplicity  dropdown box is active only when  Calculate p-values  is selected.     It can be used to set the multiplicity adjustment for the Fisher s Exact Test, and contains the standard multiplicity adjustment types found elsewhere in Array Studio.    Click  Submit  to continue.  If the gene ontology has not been updated or it has been more than 30 days old (true for all first-time users of Array Studio), the gene ontology will be updated first, and then the module will run.  When finished, a new  Table , titled  MicroArrayData.GeneOntologyReport  is created in the  Solution Explorer  under the  Ontology  tab, and the  Table  view is opened in the center  Data View  window.   Note  Note:  Due to the constantly updating nature of the Gene Ontology database, the number of rows in the example shown below and the number of rows when the user runs the tutorial may differ. This is expected.     The  Table  contains 10 columns. The first column contains the category (the gene ontology), the second column contains the GOTerm, with the other columns containing the number of probesets, in each list or universal list [all], belonging to each category and the corresponding Fisher Exact test p-values.   As in all  views  in Array Studio, details can be provided on demand and are fully interactive. Clicking on a particular cell, for instance, in  3 -> DBP vs control , actin filament-based process, will provide inference report details about the probesets contained in that category in the  Details Window .   Details for multiple cells can be obtained by holding \"Shift\" or \"Ctrl\" buttons and selecting multiple cells.",
            "title": "Gene ontology analysis"
        },
        {
            "location": "/tutorials/Microarray/Audit_trail/",
            "text": "Audit trail\n\u00b6\n\n\nArray Studio\n tracks all analysis steps done in a project, using its \nAudit Trail\n feature. This is important for many company s data integrity needs, and can also be used by the individual users to see what types of changes and procedures were made to the project and to rerun the exact analysis ran previously. To see the audit trail for the MicroArray tutorial project, go to \nFile Menu | Audit Trail\n to open the \nAudit Trail\n window.\n\n\nThe \nAudit Trail\n can be accessed using the \nFile | Audit Trail\n option. Open the \nAudit Trail\n window now.\n\n\n\n\nThe \nAudit Trail\n window contains two tabs: \nList\n and \nAll Scripts\n.\n\n\n\n\nThe \nList\n tab shows a step-by-step list of everything that was performed. Clicking on an individual step shows the \nOmicScript\n for that step at the bottom. The \nOmicScript\n specifies input data and options that Array Studio needs to run the module. The \nList\n can be exported using the \nExport List\n button or the \nSave All scripts\n button.\n\n\nNotice that for each step, an optional \nDescription\n can be entered to describe what was done at that step and other comments.\n\n\nSelecting an item in the List will provide the details for the script and also activate the \nRun Script\n button at the bottom of the window to allow the user to quickly rerun any script in the Audit Trail.\n\n\nSwitch to the \nAll Scripts\n tab to view all the scripts of actions and changes made to your \nProject\n. It can also be exported at any time.\n\n\nNotice that in the \nScript\n below that first a new project was created, followed by importation of Affymetrix CEL files and MAS report generation, etc.\n\n\n\n\nClick \nSave\n button to save the current project. Close the \nArray Studio\n software by clicking on the red button on top right of the window or go to \nFile\n \nMenu\n \n| Close\n.\n\n\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.\n\n\nThank you for\n \nusing\n \nArray Studio.\n\n\nPlease contact Omicsoft Support (\n \nsupport@omicsoft.com\n  \n) or Omicsoft Sales (\n \nsales@omicsoft.com\n  \n) for sales-related questions.",
            "title": "Audit trail"
        },
        {
            "location": "/tutorials/Microarray/Audit_trail/#audit-trail",
            "text": "Array Studio  tracks all analysis steps done in a project, using its  Audit Trail  feature. This is important for many company s data integrity needs, and can also be used by the individual users to see what types of changes and procedures were made to the project and to rerun the exact analysis ran previously. To see the audit trail for the MicroArray tutorial project, go to  File Menu | Audit Trail  to open the  Audit Trail  window.  The  Audit Trail  can be accessed using the  File | Audit Trail  option. Open the  Audit Trail  window now.   The  Audit Trail  window contains two tabs:  List  and  All Scripts .   The  List  tab shows a step-by-step list of everything that was performed. Clicking on an individual step shows the  OmicScript  for that step at the bottom. The  OmicScript  specifies input data and options that Array Studio needs to run the module. The  List  can be exported using the  Export List  button or the  Save All scripts  button.  Notice that for each step, an optional  Description  can be entered to describe what was done at that step and other comments.  Selecting an item in the List will provide the details for the script and also activate the  Run Script  button at the bottom of the window to allow the user to quickly rerun any script in the Audit Trail.  Switch to the  All Scripts  tab to view all the scripts of actions and changes made to your  Project . It can also be exported at any time.  Notice that in the  Script  below that first a new project was created, followed by importation of Affymetrix CEL files and MAS report generation, etc.   Click  Save  button to save the current project. Close the  Array Studio  software by clicking on the red button on top right of the window or go to  File   Menu   | Close .   Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.  Thank you for   using   Array Studio.  Please contact Omicsoft Support (   support@omicsoft.com    ) or Omicsoft Sales (   sales@omicsoft.com    ) for sales-related questions.",
            "title": "Audit trail"
        },
        {
            "location": "/tutorials/Microarray/References/",
            "text": "References\n\u00b6\n\n\nMAS5\n\u00b6\n\n\nHubbell, E. et al. (2002) Robust estimation for expression analysis. Bioinformatics, 18, 1585-1592\n\nlink\n\n\nRMA\n\u00b6\n\n\nIrizarry, R. A. et al., (2003) Exploration, normalization, and summaries of high density oligonucleotide array probe level data. Biostatistics, 4, 249-264\n\nlink\n\n\nGCRMA\n\u00b6\n\n\nA Model-Based Background Adjustment for Oligonucleotide Expression Arrays\n\n\nZhijin Wu , Rafael A. Irizarry , Robert Gentleman , Francisco Martinez-Murillo , Forrest Spencer\n\n\nJournal of the American Statistical Association, 2004 vol 99 page 909\n\nlink\n\n\nGCRMA 2\n\u00b6\n\n\nGCRMA2 is newer implementation of GCRMA which fixes a bug in original GCRMA implementation that introduces artifacts that can lead to the overestimation of pair wise correlation\n\nlink\n\n\nModerated t-test (Limma Package in R)\n\u00b6\n\n\nThe moderated t-test is used to rank genes in order of evidence for differential expression. They use an empirical Bayes method to shrink the probe-wise sample variances towards a common value and to augment the degrees of freedom for the individual variances (Smyth, 2004).\nThe empirical Bayes moderated t-statistics test each individual contrast equal to zero. For each probe (row), the moderated F-statistic tests whether all the contrasts are zero. The F-statistic is an overall test computed from the set of t-statistics for that probe. This is exactly analogous to the relationship between t-tests and F-statistics in conventional anova, except that the residual mean squares and residual degrees of freedom have been moderated between probes.\n\nlink",
            "title": "References"
        },
        {
            "location": "/tutorials/Microarray/References/#references",
            "text": "",
            "title": "References"
        },
        {
            "location": "/tutorials/Microarray/References/#mas5",
            "text": "Hubbell, E. et al. (2002) Robust estimation for expression analysis. Bioinformatics, 18, 1585-1592 link",
            "title": "MAS5"
        },
        {
            "location": "/tutorials/Microarray/References/#rma",
            "text": "Irizarry, R. A. et al., (2003) Exploration, normalization, and summaries of high density oligonucleotide array probe level data. Biostatistics, 4, 249-264 link",
            "title": "RMA"
        },
        {
            "location": "/tutorials/Microarray/References/#gcrma",
            "text": "A Model-Based Background Adjustment for Oligonucleotide Expression Arrays  Zhijin Wu , Rafael A. Irizarry , Robert Gentleman , Francisco Martinez-Murillo , Forrest Spencer  Journal of the American Statistical Association, 2004 vol 99 page 909 link",
            "title": "GCRMA"
        },
        {
            "location": "/tutorials/Microarray/References/#gcrma-2",
            "text": "GCRMA2 is newer implementation of GCRMA which fixes a bug in original GCRMA implementation that introduces artifacts that can lead to the overestimation of pair wise correlation link",
            "title": "GCRMA 2"
        },
        {
            "location": "/tutorials/Microarray/References/#moderated-t-test-limma-package-in-r",
            "text": "The moderated t-test is used to rank genes in order of evidence for differential expression. They use an empirical Bayes method to shrink the probe-wise sample variances towards a common value and to augment the degrees of freedom for the individual variances (Smyth, 2004).\nThe empirical Bayes moderated t-statistics test each individual contrast equal to zero. For each probe (row), the moderated F-statistic tests whether all the contrasts are zero. The F-statistic is an overall test computed from the set of t-statistics for that probe. This is exactly analogous to the relationship between t-tests and F-statistics in conventional anova, except that the residual mean squares and residual degrees of freedom have been moderated between probes. link",
            "title": "Moderated t-test (Limma Package in R)"
        },
        {
            "location": "/tutorials/CNV/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray studio\n\u00b6\n\n\nArray Studio\n provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its \nSolution Explorer\n, which organizes each project into \nData, QC, Table, List, Cluster, Text, Attachments\n and other categories. Multiple projects can be opened simultaneously in the \nSolution Explorer\n, and data can be shared among projects. Each view is controlled by a \nView Controller\n, which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the \nDetails Window\n and \nWeb Details On-Demand\n.\n\n\nIt is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to basic usage, data structure and standard visualization in Array Studio.\n\n\nDownloading the Copy Number Sample Data\n\u00b6\n\n\nFor this tutorial, the following materials will be required: the 10 .CEL files and the CopyNumber.design.txt file. The Copy Number Sample Data is available at:\n\nlink\n\n\nThe Copy Number sample data contains 10 samples and 1,855,448 CNVs from the Affymetrix platform. The 10 observations include cases of UPD on chromosome 15, DMD-del Xp21.1, Williams Syndrome, Mosaic Trisomy, Turner Mosaic, Trisomy 13, Smith-Magenis, Angelman/Prader-Willi, and a normal sample. An additional file that includes covariate information, relating the chip name to the type of syndrome, as well as the source of the chip, has been included as well. While this tutorial only includes 10 observations, \nArray Studio\n is easily capable of handling experiments with thousands of observations and millions of rows.\n\n\nThe CopyNumber.Design.txt file contains the design information for the tutorial\u2019s study, including columns for \nID\n, \nAbnormality\n, and \nSource\n. A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed \nID\n, that contains the exact file names of the arrays used in the experiment, without the extension (e.g. .CEL). That is, the IDs have to match the names of the Affymetrix .CEL files, or the names listed in the Illumina text file, etc. Additional columns usually include \ndisease status\n, \nquantitative traits\n, \netc.\n (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because design factors can be added or edited after importing the design into \nArray Studio\n. An example design table is shown below.\n\n\n\n\nAfter downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).\n\n\nCreating a New Project\n\u00b6\n\n\nWhen Array Studio is first installed, it will look similar to below. If you have previously had projects opened in Array Studio, just click Cancel so as to not reopen those projects now.\n\n\nNotice at the top there will be multiple tabs: Analysis, Server, Land, and Browser. This tutorial will concentrate on the Local Analysis. A separate tutorial is available for accessing Omicsoft\u2019s Array Server, and that tutorial can be used for the Server Explorer tab.\n\n\n\n\nNote\n\n\nThis tutorial is done in \nLocal\n mode, but can just as easily be completed using \nServer\n mode if Array Server is installed. Array Server allows a user to perform analyses on a high performance computing cluster with job management capabilities, greatly accelerating the speed at which analysis, data visualization and file transfer can occur.\n\n\n\n\n\n\n\n\nTo create a new project, click the \nNew\n button on the toolbar, or go to \nFile\n Menu, then click \nNew Project\n.\n\n\n\n\nThis opens the \nNew Project\n window.\n\n\nArray Studio\n allows the user to create two different project types: A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects).\n\n\nWith a simple project, all data will be saved in a single file. In a distributed project, data will be saved in separate files, stored in a folder of the project\u2019s name, and also includes a small project file \n.osprj\n (used for re-opening of the project).\n\n\nChoose the \nCreate a distributed project\n option. Click the \nBrowse\n button to choose a location to save the project, and enter the project name. The Data folder information is automatically filled in based on the location of the Project file.\n\n\n\n\n\n\nClick \nOK\n to continue.\n\n\nThe \nSolution Explorer\n will now be empty, containing a \nTutorialCNV\n Project and slots for \nList, Cluster, Text, and Attachments\n.\n\n\n\n\nYou can right-click on \nList, Cluster\n, and \nText\n for additional options for each. For instance, right-clicking on \nList\n will bring up options to add a new List, add list from file, etc. A \nList\n can be used to filter the data, by either \nVariables\n (SNP data), or \nObservations\n (Chips or SNP arrays).\n\n\nIf you cannot see the \nSolution Explorer\n, switch to it now by clicking it on the bottom left of the screen, or going to the \nView Menu | Show Solution Explorer\n.\n\n\n\n\nIn the next section, we will import the downloaded CNV data into Array Studio.\n\n\nImporting CNV Data and Attaching Design Table\n\u00b6\n\n\nTo import our sample CNV data, click  \nAdd Data | Add Omic Data | Add CNV/CGH Data\n.\n\n\n\n\nThis opens the \nSpecify CNV Data Source\n window. In this window, the user can choose the \nCNV Data Source\n for input. Choices include:\n\n\n\n\nThe sample data for this tutorial is in \nAffymetrix .CEL\n file format. Choose \nAffymetrix .CEL files\n now. This brings up the \nExtract Affymetrix CEL Files\n window.\n\n\nThe first step for this window is to add the files to be extracted by clicking the \nAdd\n button. Navigate to the location of the downloaded 10 .CEL files, and then click \nOpen\n to continue.\n\n\n\n\nOptions include:\n\n\n\n\n\n\nImport sample information from .ARR files\n will automatically import sample/design table information if the user has previously generated .ARR files).\n\n\nNote: \nImport sample information from ARR files\n can be selected but will have no effect for this tutorial, as that information was not generated with the sample files ( \nArray Studio\n looks in the same directory of the CNCHP files for the .ARR sample information files).\n\n\n\n\n\n\nEstimate B-Allele Frequency\n, which should be selected.\n\n\n\n\n\n\nimport the CEL images into design\n, which should be left unchecked.\n\n\n\n\n\n\nClick \nSubmit\n to begin the extraction.\n\n\n\n\nThe extraction process may take up to 15 minutes (the first time a specific chip type is used, annotation is automatically downloaded from Omicsoft\u2019s web server, and this may increase the time it takes for extraction as well. However, a standard computer with 2 Gigabytes of memory should have no problem extracting a large number of CEL files (1000 files can be easily extracted).\n\n\n\n\nNote\n\n\nArray Studio uses an algorithm similar to the Birdseed/Birdsuite algorithms for the SNP 6.0 and 500K Mapping chips (Tests have shown a 99.98% concordance between Omicsoft\u2019s algorithm and Birdseed/Birdsuite). Array Studio achieves this by previously generating the model, based on the HapMap 270 dataset. For more questions on the exact details of the algorithm, please read the following white paper on our wiki page: \nlink\n\n\n\n\n\n\nUpon completion of import, Array Studio will prompt the user to attach a \nDesign\n table to the data. If the user wishes to attach a design table at a later time, this can be done as well (by right-clicking the \nDesign\n section of the dataset in the \nSolution Explorer\n), however, it is recommended to build and have your design table ready for use upon import of the data. Click \nYes\n to begin the Design import process.\n\n\n\n\nArray Studio will prompt the user to specify a table source. As the design table for the sample data is in a \nTab delimited file\n format, choose that option now, and click \nOK\n.\n\n\n\n\nWhen prompted, choose the \nCopyNumber .design.txt\n file that was unzipped earlier, and click \nOpen\n to attach the design table to the dataset. When the \"Specify Options\" window appears, just select \"OK\":\n\n\n\n\nOnce imported, Array Studio should look similar to the following screenshot. By default, a \nTableView\n is created for the imported dataset (Log2Ratio).\n\n\n\n\nAlso, note that a new item has been added under the \nOmic Data\n section of the \nSolution Explorer\n (on the left-hand side of the screen).\n\n\nThe \nSolution Explorer\n can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset, \nLog2Ratio\n, Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,855,448 variables and 10 observations in each of the datasets.\n\n\nThe \nSolution Explorer\n also provides the user with information on the different views that have been created. Notice that the Project, \nCNVTutorial\n, contains a dataset \nLog2Ratio\n. There is a \nTableView\n under the \nDesign\n section, as well as a \nTableView\n in the main section. This indicates that if the user was to double-click either of these views (named Table), these would open up in the main view window.\n\n\nExpand the nodes (they are collapsed by default) to see something similar to below.\n\n\n\n\nCongratulations! You have successfully imported your first CNV dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/CNV/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/CNV/Introduction/#array-studio",
            "text": "Array Studio  provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient for organizing and visualizing data with its  Solution Explorer , which organizes each project into  Data, QC, Table, List, Cluster, Text, Attachments  and other categories. Multiple projects can be opened simultaneously in the  Solution Explorer , and data can be shared among projects. Each view is controlled by a  View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the  Details Window  and  Web Details On-Demand .  It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to basic usage, data structure and standard visualization in Array Studio.",
            "title": "Array studio"
        },
        {
            "location": "/tutorials/CNV/Introduction/#downloading-the-copy-number-sample-data",
            "text": "For this tutorial, the following materials will be required: the 10 .CEL files and the CopyNumber.design.txt file. The Copy Number Sample Data is available at: link  The Copy Number sample data contains 10 samples and 1,855,448 CNVs from the Affymetrix platform. The 10 observations include cases of UPD on chromosome 15, DMD-del Xp21.1, Williams Syndrome, Mosaic Trisomy, Turner Mosaic, Trisomy 13, Smith-Magenis, Angelman/Prader-Willi, and a normal sample. An additional file that includes covariate information, relating the chip name to the type of syndrome, as well as the source of the chip, has been included as well. While this tutorial only includes 10 observations,  Array Studio  is easily capable of handling experiments with thousands of observations and millions of rows.  The CopyNumber.Design.txt file contains the design information for the tutorial\u2019s study, including columns for  ID ,  Abnormality , and  Source . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed  ID , that contains the exact file names of the arrays used in the experiment, without the extension (e.g. .CEL). That is, the IDs have to match the names of the Affymetrix .CEL files, or the names listed in the Illumina text file, etc. Additional columns usually include  disease status ,  quantitative traits ,  etc.  (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because design factors can be added or edited after importing the design into  Array Studio . An example design table is shown below.   After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).",
            "title": "Downloading the Copy Number Sample Data"
        },
        {
            "location": "/tutorials/CNV/Introduction/#creating-a-new-project",
            "text": "When Array Studio is first installed, it will look similar to below. If you have previously had projects opened in Array Studio, just click Cancel so as to not reopen those projects now.  Notice at the top there will be multiple tabs: Analysis, Server, Land, and Browser. This tutorial will concentrate on the Local Analysis. A separate tutorial is available for accessing Omicsoft\u2019s Array Server, and that tutorial can be used for the Server Explorer tab.   Note  This tutorial is done in  Local  mode, but can just as easily be completed using  Server  mode if Array Server is installed. Array Server allows a user to perform analyses on a high performance computing cluster with job management capabilities, greatly accelerating the speed at which analysis, data visualization and file transfer can occur.     To create a new project, click the  New  button on the toolbar, or go to  File  Menu, then click  New Project .   This opens the  New Project  window.  Array Studio  allows the user to create two different project types: A simple project, in which all the outputs are saved in a single file (recommended for microarray and RT-PCR projects), and a distributed project, where output are saved in separate files (recommended for exon array, CNV, genotyping and NGS projects).  With a simple project, all data will be saved in a single file. In a distributed project, data will be saved in separate files, stored in a folder of the project\u2019s name, and also includes a small project file  .osprj  (used for re-opening of the project).  Choose the  Create a distributed project  option. Click the  Browse  button to choose a location to save the project, and enter the project name. The Data folder information is automatically filled in based on the location of the Project file.    Click  OK  to continue.  The  Solution Explorer  will now be empty, containing a  TutorialCNV  Project and slots for  List, Cluster, Text, and Attachments .   You can right-click on  List, Cluster , and  Text  for additional options for each. For instance, right-clicking on  List  will bring up options to add a new List, add list from file, etc. A  List  can be used to filter the data, by either  Variables  (SNP data), or  Observations  (Chips or SNP arrays).  If you cannot see the  Solution Explorer , switch to it now by clicking it on the bottom left of the screen, or going to the  View Menu | Show Solution Explorer .   In the next section, we will import the downloaded CNV data into Array Studio.",
            "title": "Creating a New Project"
        },
        {
            "location": "/tutorials/CNV/Introduction/#importing-cnv-data-and-attaching-design-table",
            "text": "To import our sample CNV data, click   Add Data | Add Omic Data | Add CNV/CGH Data .   This opens the  Specify CNV Data Source  window. In this window, the user can choose the  CNV Data Source  for input. Choices include:   The sample data for this tutorial is in  Affymetrix .CEL  file format. Choose  Affymetrix .CEL files  now. This brings up the  Extract Affymetrix CEL Files  window.  The first step for this window is to add the files to be extracted by clicking the  Add  button. Navigate to the location of the downloaded 10 .CEL files, and then click  Open  to continue.   Options include:    Import sample information from .ARR files  will automatically import sample/design table information if the user has previously generated .ARR files).  Note:  Import sample information from ARR files  can be selected but will have no effect for this tutorial, as that information was not generated with the sample files (  Array Studio  looks in the same directory of the CNCHP files for the .ARR sample information files).    Estimate B-Allele Frequency , which should be selected.    import the CEL images into design , which should be left unchecked.    Click  Submit  to begin the extraction.   The extraction process may take up to 15 minutes (the first time a specific chip type is used, annotation is automatically downloaded from Omicsoft\u2019s web server, and this may increase the time it takes for extraction as well. However, a standard computer with 2 Gigabytes of memory should have no problem extracting a large number of CEL files (1000 files can be easily extracted).   Note  Array Studio uses an algorithm similar to the Birdseed/Birdsuite algorithms for the SNP 6.0 and 500K Mapping chips (Tests have shown a 99.98% concordance between Omicsoft\u2019s algorithm and Birdseed/Birdsuite). Array Studio achieves this by previously generating the model, based on the HapMap 270 dataset. For more questions on the exact details of the algorithm, please read the following white paper on our wiki page:  link    Upon completion of import, Array Studio will prompt the user to attach a  Design  table to the data. If the user wishes to attach a design table at a later time, this can be done as well (by right-clicking the  Design  section of the dataset in the  Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click  Yes  to begin the Design import process.   Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a  Tab delimited file  format, choose that option now, and click  OK .   When prompted, choose the  CopyNumber .design.txt  file that was unzipped earlier, and click  Open  to attach the design table to the dataset. When the \"Specify Options\" window appears, just select \"OK\":   Once imported, Array Studio should look similar to the following screenshot. By default, a  TableView  is created for the imported dataset (Log2Ratio).   Also, note that a new item has been added under the  Omic Data  section of the  Solution Explorer  (on the left-hand side of the screen).  The  Solution Explorer  can provide important information about the different datasets and tables that are created in Array Studio. For instance, note that next to the name of the dataset,  Log2Ratio , Array Studio lists the number of rows and columns (or variables and observations) in the dataset. In this case, there are 1,855,448 variables and 10 observations in each of the datasets.  The  Solution Explorer  also provides the user with information on the different views that have been created. Notice that the Project,  CNVTutorial , contains a dataset  Log2Ratio . There is a  TableView  under the  Design  section, as well as a  TableView  in the main section. This indicates that if the user was to double-click either of these views (named Table), these would open up in the main view window.  Expand the nodes (they are collapsed by default) to see something similar to below.   Congratulations! You have successfully imported your first CNV dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.",
            "title": "Importing CNV Data and Attaching Design Table"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/",
            "text": "Visualization of Data\n\u00b6\n\n\nThe TableView\n\u00b6\n\n\nUpon import, Array Studio will automatically generate a \nTableView\n for the CNV data.\n\n\nThe \nTableView\n in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each variable is a row. Copy Number information is shown in each cell. First, take a look at the Log2Ratio data. If you have not already done so, double-click the \nTable\n view for the \nLog2Ratio\n data from the \nSolution Explorer\n.\n\n\nScroll through the data now to see the speed that Array Studio can display data. Notice that this Tableview contains the Log2Ratio data, extracted from the CNCHP files, for each variable.\n\n\n\n\nPlease refer to Microarray Tutorial for different options and filters for table view.\n\n\nThe ObservationTableView\n\u00b6\n\n\nBesides the regular \nTableView\n, where each row represents a variable and each column represents an observation, Array Studio also offers the \nObservationTableView\n. In this view, each column represents a variable, while each row represents an observation. \nArray Studio\n can easily handle millions of columns in this view.\n\n\nTo add an \nObservationTableView\n to the imported dataset, click the \nAdd View\n \n button from the toolbar.\n\n\nAlternatively and usually preferred for quick opening of new views for different data or table objects, the user can right click on the dataset or table in the \nSolution Explorer\n for the relevant data or table object.\n\n\nFor instance, to open a new view for \nLog2Ratio\n data, the user could right-click on \nLog2Ratio\n and choose \nAdd View\n, as shown below. Note: for \nData\n object types, the user can also open new views for \nAnnotation\n or \nDesign\n as well (see figures below\u2014for information purpose only, not necessary for this tutorial).\n\n\n\n\nSimilarly, to add a view for the \nAnnotation Table\n under the \nLog2Ratio\n, right click on the \nAnnotation\n icon in the \nSolution Explorer\n and select \nAdd View\n.\n\n\n\n\nThe same can be done for adding a view for the \nDesign\n icon as shown below.\n\n\n\n\nIf you have not already done so, click the \nAdd View\n \n button from the toolbar to open the \nSelect Data\n window.\n\n\n\n\nSelect \nLog2Ratio\n and click \nOK\n.\n\n\nFor each different type of imported dataset in Array Studio, different views are available. Some of these different types of views will be discussed in the tutorial.\n\n\nFor Log2Ratio data, available views include \nB-AlleleFrequencyTableView\n, \nBoxPlotView\n, \nFullTableView\n, \nGenomeView\n, \nHeatmapView\n, \nObservationTableView\n, \nPairwiseScatterView\n, \nRBoxPlotView\n, \nRegionView\n, \nScatterView\n, \nSnpTableView\n, \nTableView\n, \nVariableTableView\n, and \nVariableView\n.\n\n\nNotice that the preview window shows the user a basic preview of that view as you scroll through each option. Choose \nObservationTableView\n now, and click \nOK\n to continue.\n\n\n\n\nAfter adding the view, a new view is called \"ObservationTable\" appears in the \nSolution Explorer\n, under the dataset that was selected above.\n\n\n\n\nIn addition, this new view is opened in the main view window. The user can switch between different opened views by using the tabs at the top of the screen. This provides a fast mechanism for switching between views.\n\n\n\n\nAs you can see, a new \nObservationTableView\n is now visible, where each column represents a variable, and each row represents an observation. The first several columns show the design information for each subject, as shown below.\n\n\n\n\nThe \nView Controller\n, found on the right-hand side of the screen in \nArray Studio\n, contains tabs that allow the user to customize each view, by changing options using the \nTask\n tab, or filtering the data (using the \nVariables\n or \nObservations\n tabs).\n\n\nThe \nTask\n tab for the \nObservationTableView\n is shown below.\n\n\n\n\nTo filter for a particular marker, or CNV, click the \nVariable\n tab to switch to the \nVariable\n filter.\n\n\nThe \nVariable\n filter will contain one filter for every column in the \nAnnotation Table\n. By default, Affymetrix .CEL imported files have annotation for \nID, Chromosome, Start, End\n.\n\n\nExpand the ID column, and enter the marker \nSNP_A-4216564\n.\n\n\n\n\nNotice that when filtered, the \nView Controller\n provides feedback as to how many variables passed filtering. Also, notice that the view has automatically been filtered to only show the variable \nSNP_A-4216564\n, as well as the attached covariate information. This table can easily be exported to Excel or a text file, using the buttons available on the toolbar.\n\n\n\n\nTo remove any current filters on the dataset, manually click the \n(no filter)\n button for each filter (in this case just ID) or click the \nReset All Filters\n button in the toolbar of the \nView Controller\n to show all variables.\n\n\nReset all filters now.\n\n\n\n\nBesides filtering for a specific marker, we can also filter by chromosome and base pair position. Expand the \nChromosome\n filter as well as the \nStart\n and \nEnd\n filters now.\n\n\nUnlike the \nID\n filter, the \nChromosome\n filter shows radio buttons by default (instead of a string filter). For columns that contain limited number of levels (i.e. chromosome), users will have the choice of using \nString Filter\n, \nRadio\n, or \nCheckBox\n. Right-clicking on \nChromosome\n will bring up a choice so the user can change the type of filter.\n\n\nNow right click on \nChromosome\n and click on \nCheck None\n, which make it easier to select a few chromosomes. Select Chromosome \n1\n. Alternatively, you can simply right-click on Chromosome \n1\n and select the option \nCheck This Only\n.\n\n\nFor the \nStart\n filter, enter \">150mbp\" now.\n\n\n\n\nNotice that the view is updated to show only the variables that correspond to this filter.\n\n\nSwitch back to the regular \nTableView\n for the \nLog2Ratio\n dataset to see that every view for that dataset has been updated for the filter. This is an important feature in Array Studio. \nFiltering one view of a dataset will also filter the other views of that same dataset. In other words, the Filtering is linked among views.\n\n\n\n\nReset any filters by clicking the \nReset All Filters\n \n button in \nView Controller\n now.\n\n\nThe Details Window\n\u00b6\n\n\nArray Studio\n includes a feature called \nDetails on Demand\n. In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the \nDetails Window\n (at the bottom of the screen).\n\n\nClick on a marker in the row header of the \nTableView\n, and notice that the variable name changes to green. This indicates that this row has been selected, and information is available in the \nDetails\n window.\n\n\n\n\nThe \nDetails Window\n should be visible at the bottom of the screen, but if it is not, switch to it by selecting \nShow Details Window\n from the \nView\n menu. Note that all of the annotation information for the selected row or rows is shown in the \nDetails Window\n.\n\n\nThe \nDetails Window\n can also be used to show information about a particular subject. Click the header row of one of the subjects now.\n\n\n\n\nNote that the \nDetails Window\n is automatically updated with the design information about that subject.\n\n\nSegmenting Data\n\u00b6\n\n\nBefore continuing the investigation of the \nGenomeView\n data, we are going to take a moment and generate segment data for our Log2Ratio ratio.\n\n\nTo begin segmentation, go to the \nCNV Menu | CNV Segmentation\n.\n\n\n\n\nThis brings up the \nSegmentation\n window. The user has the option of fine-tuning the segmentation algorithm, although Omicsoft recommends the set of parameters that have been tested to work effectively. Make sure that the \nProject\n is \nTutorial CNV\n and that the \nData\n is \nLog2Ratio\n.\n\n\n\n\nThe user can select from the following Options:\n\n\n\n\n\n\nHeuristic search p-value cutoff\n the initial search for segments\u2014decreasing this will decrease the number of\n    segments, while increasing this will increase the number of segments).\n\n\n\n\n\n\nAfter finding all possible boundaries, the segmentation algorithm will merge contiguous regions if the\n    difference between regions does not meet or exceed the \nSignificant segment p-value cutoff\n (decreasing this will decrease the number of segments, while increasing this will increase the number of segments).\n\n\n\n\n\n\nA new segment will be created only if the difference is larger than \nMinimal difference of log2Ratios\n.\n\n\n\n\n\n\nA new segment will be created only if the number of markers is larger than the threshold set by \nMinimal\n    marker number\n.\n\n\n\n\n\n\nThe user can choose to \nIdentify copy neutral LOH segments\n, and can set criteria:\n\n\n\n\n\n\nHomozygosity rate cutoff (%)\n\n\n\n\n\n\nMinimal marker number\n\n\n\n\n\n\nMinimal span (MB)\n\n\n\n\n\n\n\n\n\n\nThe user can optionally \nAppend design columns to the output table\n (useful for filtering or if exporting the\n    segment report).\n\n\n\n\n\n\nUser can decide whether to \nuse start position for segmentation end coordinates.\n The end coordinate of a\n    segment can either be the \nstart\n or the \nend\n position of the last marker.\n\n\n\n\n\n\nThe user can predict copy number based on one of the following three choices:\n\n\n\n\n\n\nEstimate based on \nLog2Ratio\n value: Copy Number = round(2^(Log2RatioMean + 1), example:\n\n\n\n\n\n\nWhen Log2RatioMean = 0, Copy Number =2\n\n\n\n\n\n\nWhen Log2RatioMean = -1, Copy Number = 1\n\n\n\n\n\n\nWhen Log2RatioMean = 0.32, Copy Number = 3 (rounded)\n\n\n\n\n\n\nWhen Log2RatioMean = 1, Copy Number = 4\n\n\n\n\n\n\n\n\n\n\nEstimate based on \nB-Allele Frequency\n. This option will only work well for Illumina data.\n\n\n\n\n\n\nCall \nLoss/Gain/Amplification/Deletion\n based on Log2Ratio values, see details here\n\n\n\n\n\n\n\n\n\n\nlink\n\n\nUnder the \nMore Options\n tab, the following window is presented:\n\n\n\n\nCalling Options include:\n\n\n\n\n\n\nIf the Log2Ratio is close to zero, then there is No Change? in copy number. User can set the cutoff for\n    positive Log2Ratio or negative Log2Ratio\n\n\n\n\n\n\nMinimal supporting marker# for BAF based calling\n\n\n\n\n\n\nMinimal supporting marker% for BAF based calling\n\n\n\n\n\n\nLog2Ratio Threshold to call amplification and deletion\n\n\n\n\n\n\nCalling options for B-Allele Frequency is only effective when a user chooses to estimate copy number based on\n    B-Allele Frequency\n\n\n\n\n\n\nClick \nSubmit\n to begin the segmentation. This should take approximately 10 seconds per sample (100 seconds).\n\n\nAfter the segmentation is complete, a new \nGenome\n view will be generated under \n-Omic Data\n section and new data will be generated under \nTable | Segment | Log2Ratio.Segment\n. Also, a \nScatterView\n will be created showing Log2Ratio.Mean vs. AlleleDifference.Mean, and this scatter view can be used to examine the segmentation patterns and calls.\n\n\n\n\nDouble-click the \nTable\n view for \nSegment\n data now to make it visible in the main view window.\n\n\nEach row of the table corresponds to a segment and includes detailed annotation information for each segment. This table will be used in other visualizations and analysis. It can also be edited to create new segments, using some of the visualizations and analysis in \nArray Studio\n.\n\n\n\n\nNext, click on the \nScatter\n view for \nLog2Ratio.Segment\n in the \nSolution Explorer\n to open the \nScatter View\n showing the \nLog2Ratio.Mean vs. BAlleleFrequencyDeviation.Mean\n. By default, this graph is trellised by observation, so there should initially be 10 charts shown, one for each observation in the experiment. The user can change the trellising by using the \nTask\n tab in the \nView Controller\n, and choosing \nTrellis by Row Covariate\n. Switching to the \nLegend\n in the \nView Controller\n will show a \nLegend\n for the different colors.\n\n\nIndividual segments can be selected, and the segment can be removed using the \nRemove Segment\n option under \nTask\n tab of the \nView Controller\n.\n\n\n\n\nNote: The user can easily change the colors of the points in the plot or the column properties by right clicking in the Legend.\n\n\n\n\nThe GenomeView and Loss of Heterozygosity\n\u00b6\n\n\nThe \nGenomeView\n can be used to interrogate regions for Loss of Heterozygosity, and the sample dataset provides a nice demonstration of these features.\n\n\nFirst, switch to the \nGenome\n view under the \nSolution Explorer | Omic data\n section.\n\n\n\n\nThe initial view shows the Log2Ratio data and the segment data, for the chip 080207_LC_F2_U141_BETA6 on chromosome 1, plotted against the chromosomal location of each data point on the X-axis. This view is completely interactive, so selecting an individual point on the graph will show information about that CNV in the \nDetails Window\n.\n\n\nNotice that there are 500 charts in this view. This is because the \nGenomeView\n includes both a Log2Ratio chart and a B-Allele Frequency chart for each of the 25 chromosomes and each of the 10 samples. A third chart, for visualizing LOH scores, is also available but not shown by default.\n\n\nNote: to have the B-Allele Frequency chart generated, the option to \"Estimate B-Allele Frequency\" must have been selected when initially uploading the data to the CNV module.\n\n\nUsing the \nView Controller\n and the \nVariable\n and \nObservation\n filters, we can filter for specific chips and chromosomes. We know from our design information that the chip UC_2_R2271, contains a Copy-Neutral LOH, or uniparental disomy (UPD), on chromosome 15. So, let\u2019s filter for this now.\n\n\nFirst, switch to the \nObservation\n tab in the \nView Controller\n. Expand the \nID\n filter, and type \nUC_2_R2271\n to filter the views to only include that chip.\n\n\n\n\nNext, go to the \nVariable\n filter. Set the \nChromosome\n filter to \nChromosome 15\n.\n\n\n\n\nBy default, our segmentation table has been automatically attached to our \nLog2Ratio\n data, and segments are indicated by different colors (use the \nLegend\n to see what each color represents. Right-click in the legend to change the coloring scheme). It is very clear that a large section of this chromosome has copy-neutral LOH, or UPD.\n\n\n\n\nAny view in Array Studio can be easily opened in \nPowerPoint\n or \nExcel\n using one click. Click the \nOpen Current View in PowerPoint\n button on the toolbar in the main view window to open the current chart in PowerPoint.\n\n\n\n\n\n\nGenomeView and Copy Number Gain\n\u00b6\n\n\nTo better visualize segments of copy number gain or loss, we will now take a look at sample \nBeta 2\n, and chromosome 13. Sample \nBeta 2\n is a patient with \nTrisomy 13\n, so it should show an increased Log2Ratio across chromosome 13. To do this, we will need to change our \nObservation\n and \nVariable\n filters to this sample and chromosome.\n\n\nFirst, switch to the \nVariable Filter\n in the \nView Controller\n to filter chromosome 13.\n\n\nNext, switch to the \nObservation Filter\n in the \nView Controller\n to filter sample \nBeta 2\n.\n\n\n\n\nThis immediately updates the main view window, as shown below.\n\n\n\n\nFirst, more than half of the chromosome is colored in a light red. Checking the legend, this indicates that there is a gain in copy number (Copy Number =3) for this segment. This makes sense since this patient has the disorder \nTrisomy 13\n.\n\n\nNotice that for each segment, there is a red line across the entire chromosome. This indicates the average \nLog2Ratio\n. It\u2019s clear in this example that the average \nLog2Ratio\n and \nB Allele Frequency\n are much higher than that in other samples.\n\n\nAs stated before, this view is completely interactive. Select all data points in a segment by just one clicking an empty portion of that segment:\n\n\n\n\nNotice that the \nDetails Window\n is updated with information about the selected segment.\n\n\n\n\nSummary information about the selected region can be shown on demand. In the \nTask\n tab of the \nView Controller\n, click the \nSummary On Demand\n option now.\n\n\n\n\nThis opens the \nCNV Summary On Demand\n window. This provides basic statistical information about the selected region. For this particular region, we can clearly see that the Log2 Ratio mean is 0.3573, which is well above the expected value of 0.\n\n\n\n\nArray Studio also supports editing of the segments using drag-and drop. Drag the side of a segment to expand or contract that segment. Merge multiple segments together by dragging across boundaries.\n\n\nChromosomeView For Segmentation Data\n\u00b6\n\n\nArray Studio\n also provides \nChromosome View\n for visualizing segment data.\n\n\nThis view is trellised by chip, by default. So, there are initially 10 charts visible. For each chart, it shows any chromosome that has a segment (gain/loss). The legend indicates whether the segment contains a gain or loss (by default, red indicates gain, green loss, and blue indicates LOH).\n\n\n\n\nScroll through the charts until the chart for \nBeta 2\n is visible, as shown below.\n\n\nOnce again, it is very clear that this patient has trisomy 13, as most of chromosome 13 shows a gain (CN 3).\n\n\n\n\nAs with all views in \nArray Studio\n, this view is interactive. Selecting a particular region of a chromosome will give additional information about that region. Now click on any region to select (highlighted in purple) and see the details in the Details window below.\n\n\nIn the example shown below, the segment from chromosome 13 was selected, and information about those segments is shown in the \nDetails Window\n.",
            "title": "Data Visulization"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#visualization-of-data",
            "text": "",
            "title": "Visualization of Data"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#the-tableview",
            "text": "Upon import, Array Studio will automatically generate a  TableView  for the CNV data.  The  TableView  in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each variable is a row. Copy Number information is shown in each cell. First, take a look at the Log2Ratio data. If you have not already done so, double-click the  Table  view for the  Log2Ratio  data from the  Solution Explorer .  Scroll through the data now to see the speed that Array Studio can display data. Notice that this Tableview contains the Log2Ratio data, extracted from the CNCHP files, for each variable.   Please refer to Microarray Tutorial for different options and filters for table view.",
            "title": "The TableView"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#the-observationtableview",
            "text": "Besides the regular  TableView , where each row represents a variable and each column represents an observation, Array Studio also offers the  ObservationTableView . In this view, each column represents a variable, while each row represents an observation.  Array Studio  can easily handle millions of columns in this view.  To add an  ObservationTableView  to the imported dataset, click the  Add View    button from the toolbar.  Alternatively and usually preferred for quick opening of new views for different data or table objects, the user can right click on the dataset or table in the  Solution Explorer  for the relevant data or table object.  For instance, to open a new view for  Log2Ratio  data, the user could right-click on  Log2Ratio  and choose  Add View , as shown below. Note: for  Data  object types, the user can also open new views for  Annotation  or  Design  as well (see figures below\u2014for information purpose only, not necessary for this tutorial).   Similarly, to add a view for the  Annotation Table  under the  Log2Ratio , right click on the  Annotation  icon in the  Solution Explorer  and select  Add View .   The same can be done for adding a view for the  Design  icon as shown below.   If you have not already done so, click the  Add View    button from the toolbar to open the  Select Data  window.   Select  Log2Ratio  and click  OK .  For each different type of imported dataset in Array Studio, different views are available. Some of these different types of views will be discussed in the tutorial.  For Log2Ratio data, available views include  B-AlleleFrequencyTableView ,  BoxPlotView ,  FullTableView ,  GenomeView ,  HeatmapView ,  ObservationTableView ,  PairwiseScatterView ,  RBoxPlotView ,  RegionView ,  ScatterView ,  SnpTableView ,  TableView ,  VariableTableView , and  VariableView .  Notice that the preview window shows the user a basic preview of that view as you scroll through each option. Choose  ObservationTableView  now, and click  OK  to continue.   After adding the view, a new view is called \"ObservationTable\" appears in the  Solution Explorer , under the dataset that was selected above.   In addition, this new view is opened in the main view window. The user can switch between different opened views by using the tabs at the top of the screen. This provides a fast mechanism for switching between views.   As you can see, a new  ObservationTableView  is now visible, where each column represents a variable, and each row represents an observation. The first several columns show the design information for each subject, as shown below.   The  View Controller , found on the right-hand side of the screen in  Array Studio , contains tabs that allow the user to customize each view, by changing options using the  Task  tab, or filtering the data (using the  Variables  or  Observations  tabs).  The  Task  tab for the  ObservationTableView  is shown below.   To filter for a particular marker, or CNV, click the  Variable  tab to switch to the  Variable  filter.  The  Variable  filter will contain one filter for every column in the  Annotation Table . By default, Affymetrix .CEL imported files have annotation for  ID, Chromosome, Start, End .  Expand the ID column, and enter the marker  SNP_A-4216564 .   Notice that when filtered, the  View Controller  provides feedback as to how many variables passed filtering. Also, notice that the view has automatically been filtered to only show the variable  SNP_A-4216564 , as well as the attached covariate information. This table can easily be exported to Excel or a text file, using the buttons available on the toolbar.   To remove any current filters on the dataset, manually click the  (no filter)  button for each filter (in this case just ID) or click the  Reset All Filters  button in the toolbar of the  View Controller  to show all variables.  Reset all filters now.   Besides filtering for a specific marker, we can also filter by chromosome and base pair position. Expand the  Chromosome  filter as well as the  Start  and  End  filters now.  Unlike the  ID  filter, the  Chromosome  filter shows radio buttons by default (instead of a string filter). For columns that contain limited number of levels (i.e. chromosome), users will have the choice of using  String Filter ,  Radio , or  CheckBox . Right-clicking on  Chromosome  will bring up a choice so the user can change the type of filter.  Now right click on  Chromosome  and click on  Check None , which make it easier to select a few chromosomes. Select Chromosome  1 . Alternatively, you can simply right-click on Chromosome  1  and select the option  Check This Only .  For the  Start  filter, enter \">150mbp\" now.   Notice that the view is updated to show only the variables that correspond to this filter.  Switch back to the regular  TableView  for the  Log2Ratio  dataset to see that every view for that dataset has been updated for the filter. This is an important feature in Array Studio.  Filtering one view of a dataset will also filter the other views of that same dataset. In other words, the Filtering is linked among views.   Reset any filters by clicking the  Reset All Filters    button in  View Controller  now.",
            "title": "The ObservationTableView"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#the-details-window",
            "text": "Array Studio  includes a feature called  Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the  Details Window  (at the bottom of the screen).  Click on a marker in the row header of the  TableView , and notice that the variable name changes to green. This indicates that this row has been selected, and information is available in the  Details  window.   The  Details Window  should be visible at the bottom of the screen, but if it is not, switch to it by selecting  Show Details Window  from the  View  menu. Note that all of the annotation information for the selected row or rows is shown in the  Details Window .  The  Details Window  can also be used to show information about a particular subject. Click the header row of one of the subjects now.   Note that the  Details Window  is automatically updated with the design information about that subject.",
            "title": "The Details Window"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#segmenting-data",
            "text": "Before continuing the investigation of the  GenomeView  data, we are going to take a moment and generate segment data for our Log2Ratio ratio.  To begin segmentation, go to the  CNV Menu | CNV Segmentation .   This brings up the  Segmentation  window. The user has the option of fine-tuning the segmentation algorithm, although Omicsoft recommends the set of parameters that have been tested to work effectively. Make sure that the  Project  is  Tutorial CNV  and that the  Data  is  Log2Ratio .   The user can select from the following Options:    Heuristic search p-value cutoff  the initial search for segments\u2014decreasing this will decrease the number of\n    segments, while increasing this will increase the number of segments).    After finding all possible boundaries, the segmentation algorithm will merge contiguous regions if the\n    difference between regions does not meet or exceed the  Significant segment p-value cutoff  (decreasing this will decrease the number of segments, while increasing this will increase the number of segments).    A new segment will be created only if the difference is larger than  Minimal difference of log2Ratios .    A new segment will be created only if the number of markers is larger than the threshold set by  Minimal\n    marker number .    The user can choose to  Identify copy neutral LOH segments , and can set criteria:    Homozygosity rate cutoff (%)    Minimal marker number    Minimal span (MB)      The user can optionally  Append design columns to the output table  (useful for filtering or if exporting the\n    segment report).    User can decide whether to  use start position for segmentation end coordinates.  The end coordinate of a\n    segment can either be the  start  or the  end  position of the last marker.    The user can predict copy number based on one of the following three choices:    Estimate based on  Log2Ratio  value: Copy Number = round(2^(Log2RatioMean + 1), example:    When Log2RatioMean = 0, Copy Number =2    When Log2RatioMean = -1, Copy Number = 1    When Log2RatioMean = 0.32, Copy Number = 3 (rounded)    When Log2RatioMean = 1, Copy Number = 4      Estimate based on  B-Allele Frequency . This option will only work well for Illumina data.    Call  Loss/Gain/Amplification/Deletion  based on Log2Ratio values, see details here      link  Under the  More Options  tab, the following window is presented:   Calling Options include:    If the Log2Ratio is close to zero, then there is No Change? in copy number. User can set the cutoff for\n    positive Log2Ratio or negative Log2Ratio    Minimal supporting marker# for BAF based calling    Minimal supporting marker% for BAF based calling    Log2Ratio Threshold to call amplification and deletion    Calling options for B-Allele Frequency is only effective when a user chooses to estimate copy number based on\n    B-Allele Frequency    Click  Submit  to begin the segmentation. This should take approximately 10 seconds per sample (100 seconds).  After the segmentation is complete, a new  Genome  view will be generated under  -Omic Data  section and new data will be generated under  Table | Segment | Log2Ratio.Segment . Also, a  ScatterView  will be created showing Log2Ratio.Mean vs. AlleleDifference.Mean, and this scatter view can be used to examine the segmentation patterns and calls.   Double-click the  Table  view for  Segment  data now to make it visible in the main view window.  Each row of the table corresponds to a segment and includes detailed annotation information for each segment. This table will be used in other visualizations and analysis. It can also be edited to create new segments, using some of the visualizations and analysis in  Array Studio .   Next, click on the  Scatter  view for  Log2Ratio.Segment  in the  Solution Explorer  to open the  Scatter View  showing the  Log2Ratio.Mean vs. BAlleleFrequencyDeviation.Mean . By default, this graph is trellised by observation, so there should initially be 10 charts shown, one for each observation in the experiment. The user can change the trellising by using the  Task  tab in the  View Controller , and choosing  Trellis by Row Covariate . Switching to the  Legend  in the  View Controller  will show a  Legend  for the different colors.  Individual segments can be selected, and the segment can be removed using the  Remove Segment  option under  Task  tab of the  View Controller .   Note: The user can easily change the colors of the points in the plot or the column properties by right clicking in the Legend.",
            "title": "Segmenting Data"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#the-genomeview-and-loss-of-heterozygosity",
            "text": "The  GenomeView  can be used to interrogate regions for Loss of Heterozygosity, and the sample dataset provides a nice demonstration of these features.  First, switch to the  Genome  view under the  Solution Explorer | Omic data  section.   The initial view shows the Log2Ratio data and the segment data, for the chip 080207_LC_F2_U141_BETA6 on chromosome 1, plotted against the chromosomal location of each data point on the X-axis. This view is completely interactive, so selecting an individual point on the graph will show information about that CNV in the  Details Window .  Notice that there are 500 charts in this view. This is because the  GenomeView  includes both a Log2Ratio chart and a B-Allele Frequency chart for each of the 25 chromosomes and each of the 10 samples. A third chart, for visualizing LOH scores, is also available but not shown by default.  Note: to have the B-Allele Frequency chart generated, the option to \"Estimate B-Allele Frequency\" must have been selected when initially uploading the data to the CNV module.  Using the  View Controller  and the  Variable  and  Observation  filters, we can filter for specific chips and chromosomes. We know from our design information that the chip UC_2_R2271, contains a Copy-Neutral LOH, or uniparental disomy (UPD), on chromosome 15. So, let\u2019s filter for this now.  First, switch to the  Observation  tab in the  View Controller . Expand the  ID  filter, and type  UC_2_R2271  to filter the views to only include that chip.   Next, go to the  Variable  filter. Set the  Chromosome  filter to  Chromosome 15 .   By default, our segmentation table has been automatically attached to our  Log2Ratio  data, and segments are indicated by different colors (use the  Legend  to see what each color represents. Right-click in the legend to change the coloring scheme). It is very clear that a large section of this chromosome has copy-neutral LOH, or UPD.   Any view in Array Studio can be easily opened in  PowerPoint  or  Excel  using one click. Click the  Open Current View in PowerPoint  button on the toolbar in the main view window to open the current chart in PowerPoint.",
            "title": "The GenomeView and Loss of Heterozygosity"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#genomeview-and-copy-number-gain",
            "text": "To better visualize segments of copy number gain or loss, we will now take a look at sample  Beta 2 , and chromosome 13. Sample  Beta 2  is a patient with  Trisomy 13 , so it should show an increased Log2Ratio across chromosome 13. To do this, we will need to change our  Observation  and  Variable  filters to this sample and chromosome.  First, switch to the  Variable Filter  in the  View Controller  to filter chromosome 13.  Next, switch to the  Observation Filter  in the  View Controller  to filter sample  Beta 2 .   This immediately updates the main view window, as shown below.   First, more than half of the chromosome is colored in a light red. Checking the legend, this indicates that there is a gain in copy number (Copy Number =3) for this segment. This makes sense since this patient has the disorder  Trisomy 13 .  Notice that for each segment, there is a red line across the entire chromosome. This indicates the average  Log2Ratio . It\u2019s clear in this example that the average  Log2Ratio  and  B Allele Frequency  are much higher than that in other samples.  As stated before, this view is completely interactive. Select all data points in a segment by just one clicking an empty portion of that segment:   Notice that the  Details Window  is updated with information about the selected segment.   Summary information about the selected region can be shown on demand. In the  Task  tab of the  View Controller , click the  Summary On Demand  option now.   This opens the  CNV Summary On Demand  window. This provides basic statistical information about the selected region. For this particular region, we can clearly see that the Log2 Ratio mean is 0.3573, which is well above the expected value of 0.   Array Studio also supports editing of the segments using drag-and drop. Drag the side of a segment to expand or contract that segment. Merge multiple segments together by dragging across boundaries.",
            "title": "GenomeView and Copy Number Gain"
        },
        {
            "location": "/tutorials/CNV/Visualization_of_Data/#chromosomeview-for-segmentation-data",
            "text": "Array Studio  also provides  Chromosome View  for visualizing segment data.  This view is trellised by chip, by default. So, there are initially 10 charts visible. For each chart, it shows any chromosome that has a segment (gain/loss). The legend indicates whether the segment contains a gain or loss (by default, red indicates gain, green loss, and blue indicates LOH).   Scroll through the charts until the chart for  Beta 2  is visible, as shown below.  Once again, it is very clear that this patient has trisomy 13, as most of chromosome 13 shows a gain (CN 3).   As with all views in  Array Studio , this view is interactive. Selecting a particular region of a chromosome will give additional information about that region. Now click on any region to select (highlighted in purple) and see the details in the Details window below.  In the example shown below, the segment from chromosome 13 was selected, and information about those segments is shown in the  Details Window .",
            "title": "ChromosomeView For Segmentation Data"
        },
        {
            "location": "/tutorials/CNV/Summarization_of_CNV_Data/",
            "text": "Summarization of CNV Data\n\u00b6\n\n\nSummary Statistics\n\u00b6\n\n\nArray Studio\n can also provide summary statistics on CNV data using the module, \nSummary Statistics\n. This module is available in the \nCNV Menu | Summary Statistics\n. Open it now.\n\n\n\n\nThis brings up the \nCNV Summary Statistics\n window. All module windows in \nArray Studio\n follow a similar pattern to this one.\n\n\n\n\n\n\n\n\nFirst, the user can select the \nProject\n and \nData\n to be analysed; in this case our \nProject\n is \nTutorial CNV\n and our \nData\n is \nLog2Ratio\n.\n\n\n\n\n\n\nNext, if the user has generated a list of variables/markers for analysis, this can be selected through\n    \nCustomized variables\n. The user can also manually choose particular chromosomes for analysis.     For demonstration purposes, let\u2019s only generate statistics on chromosome 13. To do this, check \nFiltered by chromosomes\n option and click the \nFilter\n button.\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nObservations\n section allows the user to choose a list of subjects to analyze. Leave this to \nAll observations (10)\n.\n\n\n\n\n\n\nUnder Options, the user has a number of choices. The user has the option to summarize either each \nObservation\n or each \nVariable\n. Here we choose \nObservation\n to summarize statistics across all markers on chromosome 13 for each sample.\n\n\n\n\n\n\nThe user can also choose to summarize by a specific annotation table (for observations) or design table (for variables) column as \nGroup\n. For example, if the user is interested in statistics for each Syndrome     group, they could choose that column here.\n\n\n\n\n\n\nFinally, the \nStatistics\n section contains a number of different statistics that can be calculated, including N, Mean, StdDev, Min, Max, MinAbs, MaxAbs, Range, NMissing, NMissingPercentage, NNotMissing, NNotMissingPercentage, Sum, Variance, StdErr, CV, Median, IQR, Skewness, Kurtosis, MAD, NPositive, NNegative, PositivePercentage, NegativePercentage, PositiveChangeSize, NegativeChangeSize, PositiveMean, NegativeMean and GenometricMean. Choose \nMean\n here to summarize the mean of Log2Ratio values of all variables for each observation.\n\n\n\n\n\n\nUser also has the option to \nAppend the summary statistics to the covariate table\n as new design column.\n\n\n\n\n\n\nIn addition to the table report, user can also choose to generate \nlog2-ratio box plots\n or \ndistribution plots\n in correspondence to the table. Leave these unchecked for this tutorial.\n\n\n\n\n\n\nA new \nTable\n is generated under the \nTable | Summary\n section of the \nSolution Explorer\n, called \nLog2Ratio.Summary\n.\n\n\n\n\nNote that we may still be filtering for the single chip, so we need to reset all filters in the \nFilter\n tab of the \nView Controller\n to see all the samples in the table.\n\n\n\n\nOnce unfiltered, the \nTableView\n should include 10 rows and 3 columns. It is clear that for sample Beta 2, which is the patient with Trisomy 13, the mean is 0.32545, significantly higher than for any of the other samples. This module can be used to perform similar analyses as desired, generating other types of statistics.",
            "title": "Data Summarization"
        },
        {
            "location": "/tutorials/CNV/Summarization_of_CNV_Data/#summarization-of-cnv-data",
            "text": "",
            "title": "Summarization of CNV Data"
        },
        {
            "location": "/tutorials/CNV/Summarization_of_CNV_Data/#summary-statistics",
            "text": "Array Studio  can also provide summary statistics on CNV data using the module,  Summary Statistics . This module is available in the  CNV Menu | Summary Statistics . Open it now.   This brings up the  CNV Summary Statistics  window. All module windows in  Array Studio  follow a similar pattern to this one.     First, the user can select the  Project  and  Data  to be analysed; in this case our  Project  is  Tutorial CNV  and our  Data  is  Log2Ratio .    Next, if the user has generated a list of variables/markers for analysis, this can be selected through\n     Customized variables . The user can also manually choose particular chromosomes for analysis.     For demonstration purposes, let\u2019s only generate statistics on chromosome 13. To do this, check  Filtered by chromosomes  option and click the  Filter  button.       The  Observations  section allows the user to choose a list of subjects to analyze. Leave this to  All observations (10) .    Under Options, the user has a number of choices. The user has the option to summarize either each  Observation  or each  Variable . Here we choose  Observation  to summarize statistics across all markers on chromosome 13 for each sample.    The user can also choose to summarize by a specific annotation table (for observations) or design table (for variables) column as  Group . For example, if the user is interested in statistics for each Syndrome     group, they could choose that column here.    Finally, the  Statistics  section contains a number of different statistics that can be calculated, including N, Mean, StdDev, Min, Max, MinAbs, MaxAbs, Range, NMissing, NMissingPercentage, NNotMissing, NNotMissingPercentage, Sum, Variance, StdErr, CV, Median, IQR, Skewness, Kurtosis, MAD, NPositive, NNegative, PositivePercentage, NegativePercentage, PositiveChangeSize, NegativeChangeSize, PositiveMean, NegativeMean and GenometricMean. Choose  Mean  here to summarize the mean of Log2Ratio values of all variables for each observation.    User also has the option to  Append the summary statistics to the covariate table  as new design column.    In addition to the table report, user can also choose to generate  log2-ratio box plots  or  distribution plots  in correspondence to the table. Leave these unchecked for this tutorial.    A new  Table  is generated under the  Table | Summary  section of the  Solution Explorer , called  Log2Ratio.Summary .   Note that we may still be filtering for the single chip, so we need to reset all filters in the  Filter  tab of the  View Controller  to see all the samples in the table.   Once unfiltered, the  TableView  should include 10 rows and 3 columns. It is clear that for sample Beta 2, which is the patient with Trisomy 13, the mean is 0.32545, significantly higher than for any of the other samples. This module can be used to perform similar analyses as desired, generating other types of statistics.",
            "title": "Summary Statistics"
        },
        {
            "location": "/tutorials/CNV/Advanced_Visualization/",
            "text": "Genome Browser Visualization\n\u00b6\n\n\nProcessed data from CNV analyses performed in this tutorial can also be viewed directly in the Genome Broswer tab. To access the browser, simply click the \nBrowser\n tab at the top of your screen:\n\n\n\n\nIf you have not already done so, create a New Genome Browser by clicking new. You will see the following prompt:\n\n\n\n\nChoose the default reference and gene models and select and output folder and name. Click \"OK\". Go to \nAdd Track | Add Track from Analysis\n:\n\n\n\n\nFirst, try choosing the option \nSegment track: segment data\n and click \"OK\".\n\n\n\n\nFind your open segment table from this tutorial and click \"OK\":\n\n\n\n\nChoose the default options and click \"OK\" again:\n\n\n\n\nYou will see two additional tracks appear in your \nGenome Browser\n: \nLog2RatioMean\n and \nCNStatus\n. Browse to chromosome 13 within the toolbar and notice that the \nBeta2\n sample we examined earlier has a \nlog2RatioMean\n of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome:\n\n\n\n\nUser can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding \nShift\n and left-clicking to highlight a region.\n\n\nIn addition to the segment tracks, one can upload additional CNV tracks. Go to \nAdd Track | Add Track from Analysis\n:\n\n\n\n\nThis time, choose the option \nNumeric track with multiple series: CNV data\n:\n\n\n\n\nFind your CNV analysis output and click \nOK\n. Select the data you want to visualize and click \nOK\n. Here, we choose all the data and set all other parameters to default:\n\n\n\n\nIn this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view:\n\n\n\n\nAs you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:",
            "title": "Advanced Visulization"
        },
        {
            "location": "/tutorials/CNV/Advanced_Visualization/#genome-browser-visualization",
            "text": "Processed data from CNV analyses performed in this tutorial can also be viewed directly in the Genome Broswer tab. To access the browser, simply click the  Browser  tab at the top of your screen:   If you have not already done so, create a New Genome Browser by clicking new. You will see the following prompt:   Choose the default reference and gene models and select and output folder and name. Click \"OK\". Go to  Add Track | Add Track from Analysis :   First, try choosing the option  Segment track: segment data  and click \"OK\".   Find your open segment table from this tutorial and click \"OK\":   Choose the default options and click \"OK\" again:   You will see two additional tracks appear in your  Genome Browser :  Log2RatioMean  and  CNStatus . Browse to chromosome 13 within the toolbar and notice that the  Beta2  sample we examined earlier has a  log2RatioMean  of ~0.35 and a corresponding copy number status of 3 for a large portion of the chromosome:   User can zoom in on regions of interest by using magnification tools in the upper right part of the browser, the click wheel of a mouse, or by simply holding  Shift  and left-clicking to highlight a region.  In addition to the segment tracks, one can upload additional CNV tracks. Go to  Add Track | Add Track from Analysis :   This time, choose the option  Numeric track with multiple series: CNV data :   Find your CNV analysis output and click  OK . Select the data you want to visualize and click  OK . Here, we choose all the data and set all other parameters to default:   In this view you can visualize the individual SNPs on the CNV chip and their position within the genome. This can also be achieved by going to the Table view of the CNV data, right-clicking on individual SNPs, and selecting the genome browser view:   As you can see with this SNP, our top sample, has an elevated log2 value relative to the other samples. Users are encouraged to explore display options to adjust track height, width of data points, and more:",
            "title": "Genome Browser Visualization"
        },
        {
            "location": "/tutorials/CNV/Analysis_Modules/",
            "text": "Analysis Modules\n\u00b6\n\n\nBesides visualization and summarization, Array Studio includes a number of different association analysis modules. However, for this tutorial, we will not use these modules, as the sample data does not fit with that type of analysis.\n\n\nArray Studio\n includes modules for analyzing CNV data association under the \nCNV Menu\n as shown below. These include \nGeneral Linear Model\n, \nQuantitative Trait\n, \nCategorical Trait\n, \nSurvival Trait\n, and \nRepeated Measure Trait\n analysis modules. If user has quantitative trait, categorical trait, survival trait or repeated measure trait in the experiment, they can use appropriate modules for the association analysis.\n\n\n\n\nFor more information on what type of analysis should be performed on your data, consult a statistician or feel free to contact the Omicsoft support staff. You can always get details about every module in \nArray Studio\n by opening that module and clicking on the \nHelp\n button on the bottom left of the window.\n\n\nCongratulations! You have finished learning about the capabilities for analysis that can be done for CNV data in \nArray Studio\n. Feel free to contact Omicsoft support for help with any particular module.",
            "title": "Analysis"
        },
        {
            "location": "/tutorials/CNV/Analysis_Modules/#analysis-modules",
            "text": "Besides visualization and summarization, Array Studio includes a number of different association analysis modules. However, for this tutorial, we will not use these modules, as the sample data does not fit with that type of analysis.  Array Studio  includes modules for analyzing CNV data association under the  CNV Menu  as shown below. These include  General Linear Model ,  Quantitative Trait ,  Categorical Trait ,  Survival Trait , and  Repeated Measure Trait  analysis modules. If user has quantitative trait, categorical trait, survival trait or repeated measure trait in the experiment, they can use appropriate modules for the association analysis.   For more information on what type of analysis should be performed on your data, consult a statistician or feel free to contact the Omicsoft support staff. You can always get details about every module in  Array Studio  by opening that module and clicking on the  Help  button on the bottom left of the window.  Congratulations! You have finished learning about the capabilities for analysis that can be done for CNV data in  Array Studio . Feel free to contact Omicsoft support for help with any particular module.",
            "title": "Analysis Modules"
        },
        {
            "location": "/tutorials/CNV/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results. Please refer to the MicroArray tutorial for more details on the \nAudit Trial\n, which records all the analysis steps in for form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of, with reference to Copy number analysis and visualization. Feel free to try different options in the Task tab or the CNV menu to get a feel for what Array Studio can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/CNV/Save_Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results. Please refer to the MicroArray tutorial for more details on the  Audit Trial , which records all the analysis steps in for form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of, with reference to Copy number analysis and visualization. Feel free to try different options in the Task tab or the CNV menu to get a feel for what Array Studio can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/ExonArray/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray studio\n\u00b6\n\n\nArray Studio\n provides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient for organizing and visualizing data with its \nSolution Explorer\n, which organizes each project into \nData, QC, Table, List, Cluster, Text, Attachments\n and other categories.\nMultiple projects can be opened simultaneously in the \nSolution Explorer\n, and data can be shared among projects.\nEach view is controlled by a \nView Controller\n, which performs view customization, applies filtering, and displays legends.\nFurthermore, its interactive visualization technique provides the details of data with the \nDetails Window\n and \nWeb Details On-Demand\n.\n\n\nIt is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial,\nwhich is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ExonArray/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ExonArray/Introduction/#array-studio",
            "text": "Array Studio  provides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient for organizing and visualizing data with its  Solution Explorer , which organizes each project into  Data, QC, Table, List, Cluster, Text, Attachments  and other categories.\nMultiple projects can be opened simultaneously in the  Solution Explorer , and data can be shared among projects.\nEach view is controlled by a  View Controller , which performs view customization, applies filtering, and displays legends.\nFurthermore, its interactive visualization technique provides the details of data with the  Details Window  and  Web Details On-Demand .  It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial,\nwhich is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.",
            "title": "Array studio"
        },
        {
            "location": "/tutorials/ExonArray/Importing_a_Dataset/",
            "text": "Importing a Dataset\n\u00b6\n\n\nDownloading the Exon Array Dataset\n\u00b6\n\n\nFor this tutorial, the following materials will be required: 20 .CEL files from Affymetrix HuEx-1_0-st-v2 exon array platform, as well as the included .ARR files, which is the design (sample) information for the 20 .CEL files.\n\n\nThe Exon data set contains information for 1425647 probe sets in a paired design (each patient has a tumor and normal sample). The experiment measures the intensity of exon expression level of 1425647 probe sets, with 10 samples of normal and 10 samples of tumor. The primary interest of this experiment is to find exons that are differentially expressed between tumor and normal, or to find alternative splicing between tumor and normal.\n\n\nThe \n.ARR\n files contain the design information for this study, including columns for \nchip, time, treatment, and group\n. By default, \n.ARR\n files will be imported automatically, upon .CEL file extraction.\n\n\nOptionally, if the user does not have \n.ARR\n files, a design table can be created at any time by the user, using Microsoft Excel or Array Studio.\nAs a rule, the design table must contain a first column, usually deemed \nChip\n for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the \n.CEL\n file extension. Additional columns usually include \ntreatment, time, etc.\n (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into \nArray Studio\n.\n\n\nThe ExonArray sample dataset (20 Affymetrix .CEL files and 20 \n.ARR\n files) is available at:\n\nlink\n\n\nAfter downloading the single .zip file, unzip the file to a folder to be used for this tutorial.\n\n\nCreating a New Project\n\u00b6\n\n\nWhen Array Studio is first installed, it will look similar to what is displayed below.\n\n\nIf you have previously opened projects in Array Studio, you will see the \nLast Opened Projects\n window. If so, just click cancel so that Array Studio looks similar to below.\n\n\n\n\nTo create a new project, click the \nNew Project\n button in the Workflow, or the \nNew\n button on the toolbar, or go to \nFile\n Menu, then click \nNew Project\n.\n\n\nThis opens the \nNew Project\n window.\n\n\n\n\nArray Studio\n allows the user to create two different project types:\n\n\n\n\n\n\nA simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects).\n\n\n\n\n\n\nA distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects).\n\n\n\n\n\n\nChoose the \nCreate a distributed project\n option. Click the \nBrowse\n button to choose a location and name for the project. Click \nOK\n to continue.\n\n\nSwitch to the \nSolution Explorer\n by clicking on the \nSolution Explorer\n tab, which should be found at the bottom of the \nWorkflow Window\n.\nIf the \nSolution Explorer\n tab is not visible, open to it by going to the \nView Menu | Show Solution Explorer\n.\n\n\n\n\nThe Solution Explorer will be empty except for data containers for List, Cluster, and Text files.\nYou can right-click on List, Cluster, and Text for their additional options.\nFor instance, right-clicking on List will bring up options to add a new List, add list from file, etc.\nA List can be used to filter the data, by either Variables (e.g. probe sets), or Observations (e.g. chips or samples).\n\n\nAdding Exon Data & Chip Normalization\n\u00b6\n\n\nAt this point, we are ready to add ExonArray data to the \nSolution Explorer\n.\nThis can be done in a variety of ways, but the easiest way is to first switch back to the \nWorkflow\n \nWindow\n, by selecting the \nWorkflow\n tab at the bottom of the \nSolution Explorer\n.\nAlternatively, go to \nView Menu | Show Workflow\n to show the \nWorkflow Window\n.\n\n\n\n\nNext, choose \nAdd ExonArray Data\n, from \nthe Manage Data\n section of the workflow.\nAlternatively, data can be added by going to the \nFile Menu | Add Data | Add ExonArray Data\n or by clicking the \nAdd\n button on the taskbar, and choosing \nAdd ExonArray Data\n.\n\n\n\n\nA dialog box will open asking the user to specify the source of data.\nTwo different sources of data are currently available in Array Studio and can be seen in the dialog window below.\nFor this tutorial, the 20 Affymetrix .CEL files downloaded earlier will be used.\nSelect \nAffymetrix .CEL files (Exon Arrays)\n and click \nOK\n.\n\n\n\n\nThe \nExtract Affymetrix Exon Array CEL file\n window appears.\n\n\n\n\nClick the \nAdd\n button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click \nOpen\n to continue.\n\n\n\n\nCheck that there are 20 .CEL files listed for extraction by looking in the upper left corner of the dialog box. When complete, the window should look similar to the following screenshot.\n\n\n\n\nUnder \nOptions\n, the \nChip type\n and \nArray type\n of the CEL files automatically recognized.\n\n\nIf the user is using \nAffymetrix Expression Console\n, the \nImport Sample Information from ARR files\n checkbox will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files.\n\n\nClick \nSubmit\n to start the CEL signal matrix extraction. Data extraction will begin and take approximately 10-20 minutes (about 60 seconds per .CEL file, but the first time an extraction is done annotation has to be downloaded, so the process may be slower).\n\n\nOnce data is imported, Array Studio should look similar to the following screenshot. By default, a \nTableView\n is created for the imported dataset.\n\n\n\n\nAlso, note that a new data object (\"ExonData\") has been added under the \n-Omic Data\n section of the \nSolution Explorer\n (on the left-hand side of the screen).\n\n\n\n\nThe \nSolution Explorer\n can provide important information about the different datasets and tables that are created in Array Studio.\nFor instance, note that next to the name of the dataset, \nExonData\n, Array Studio lists the number of rows and columns (or variables and observations) in the dataset.\nIn this case, there are 1,425,647 variables and 20 observations in each of the datasets.\n\n\nThe \nSolution Explorer\n also provides the user with information on the different views that have been created.\nNotice that there is a \nTableView\n for dataset \nExonData\n, as well as for \nAnnotation\n and \nDesign\n (Expand the nodes to see this).\nUser can double-click either of these views (named \nTable\n), and open them in the main view window.",
            "title": "Importing a Dataset"
        },
        {
            "location": "/tutorials/ExonArray/Importing_a_Dataset/#importing-a-dataset",
            "text": "",
            "title": "Importing a Dataset"
        },
        {
            "location": "/tutorials/ExonArray/Importing_a_Dataset/#downloading-the-exon-array-dataset",
            "text": "For this tutorial, the following materials will be required: 20 .CEL files from Affymetrix HuEx-1_0-st-v2 exon array platform, as well as the included .ARR files, which is the design (sample) information for the 20 .CEL files.  The Exon data set contains information for 1425647 probe sets in a paired design (each patient has a tumor and normal sample). The experiment measures the intensity of exon expression level of 1425647 probe sets, with 10 samples of normal and 10 samples of tumor. The primary interest of this experiment is to find exons that are differentially expressed between tumor and normal, or to find alternative splicing between tumor and normal.  The  .ARR  files contain the design information for this study, including columns for  chip, time, treatment, and group . By default,  .ARR  files will be imported automatically, upon .CEL file extraction.  Optionally, if the user does not have  .ARR  files, a design table can be created at any time by the user, using Microsoft Excel or Array Studio.\nAs a rule, the design table must contain a first column, usually deemed  Chip  for Affymetrix platforms, that contains the exact file names of the chips used in the experiment, without the  .CEL  file extension. Additional columns usually include  treatment, time, etc.  (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into  Array Studio .  The ExonArray sample dataset (20 Affymetrix .CEL files and 20  .ARR  files) is available at: link  After downloading the single .zip file, unzip the file to a folder to be used for this tutorial.",
            "title": "Downloading the Exon Array Dataset"
        },
        {
            "location": "/tutorials/ExonArray/Importing_a_Dataset/#creating-a-new-project",
            "text": "When Array Studio is first installed, it will look similar to what is displayed below.  If you have previously opened projects in Array Studio, you will see the  Last Opened Projects  window. If so, just click cancel so that Array Studio looks similar to below.   To create a new project, click the  New Project  button in the Workflow, or the  New  button on the toolbar, or go to  File  Menu, then click  New Project .  This opens the  New Project  window.   Array Studio  allows the user to create two different project types:    A simple project, in which all the project is saved in a single file (recommended for microarray and RT-PCR projects).    A distributed project, where data is saved in separate files (recommended for exon array, CNV, or genotyping projects).    Choose the  Create a distributed project  option. Click the  Browse  button to choose a location and name for the project. Click  OK  to continue.  Switch to the  Solution Explorer  by clicking on the  Solution Explorer  tab, which should be found at the bottom of the  Workflow Window .\nIf the  Solution Explorer  tab is not visible, open to it by going to the  View Menu | Show Solution Explorer .   The Solution Explorer will be empty except for data containers for List, Cluster, and Text files.\nYou can right-click on List, Cluster, and Text for their additional options.\nFor instance, right-clicking on List will bring up options to add a new List, add list from file, etc.\nA List can be used to filter the data, by either Variables (e.g. probe sets), or Observations (e.g. chips or samples).",
            "title": "Creating a New Project"
        },
        {
            "location": "/tutorials/ExonArray/Importing_a_Dataset/#adding-exon-data-chip-normalization",
            "text": "At this point, we are ready to add ExonArray data to the  Solution Explorer .\nThis can be done in a variety of ways, but the easiest way is to first switch back to the  Workflow   Window , by selecting the  Workflow  tab at the bottom of the  Solution Explorer .\nAlternatively, go to  View Menu | Show Workflow  to show the  Workflow Window .   Next, choose  Add ExonArray Data , from  the Manage Data  section of the workflow.\nAlternatively, data can be added by going to the  File Menu | Add Data | Add ExonArray Data  or by clicking the  Add  button on the taskbar, and choosing  Add ExonArray Data .   A dialog box will open asking the user to specify the source of data.\nTwo different sources of data are currently available in Array Studio and can be seen in the dialog window below.\nFor this tutorial, the 20 Affymetrix .CEL files downloaded earlier will be used.\nSelect  Affymetrix .CEL files (Exon Arrays)  and click  OK .   The  Extract Affymetrix Exon Array CEL file  window appears.   Click the  Add  button to select the CEL files for extraction. Navigate to the location of the CEL files, and then click  Open  to continue.   Check that there are 20 .CEL files listed for extraction by looking in the upper left corner of the dialog box. When complete, the window should look similar to the following screenshot.   Under  Options , the  Chip type  and  Array type  of the CEL files automatically recognized.  If the user is using  Affymetrix Expression Console , the  Import Sample Information from ARR files  checkbox will automatically import sample information (design table) from any ARR files found in the same directory as the selected CEL files.  Click  Submit  to start the CEL signal matrix extraction. Data extraction will begin and take approximately 10-20 minutes (about 60 seconds per .CEL file, but the first time an extraction is done annotation has to be downloaded, so the process may be slower).  Once data is imported, Array Studio should look similar to the following screenshot. By default, a  TableView  is created for the imported dataset.   Also, note that a new data object (\"ExonData\") has been added under the  -Omic Data  section of the  Solution Explorer  (on the left-hand side of the screen).   The  Solution Explorer  can provide important information about the different datasets and tables that are created in Array Studio.\nFor instance, note that next to the name of the dataset,  ExonData , Array Studio lists the number of rows and columns (or variables and observations) in the dataset.\nIn this case, there are 1,425,647 variables and 20 observations in each of the datasets.  The  Solution Explorer  also provides the user with information on the different views that have been created.\nNotice that there is a  TableView  for dataset  ExonData , as well as for  Annotation  and  Design  (Expand the nodes to see this).\nUser can double-click either of these views (named  Table ), and open them in the main view window.",
            "title": "Adding Exon Data &amp; Chip Normalization"
        },
        {
            "location": "/tutorials/ExonArray/Visualization_of_Data/",
            "text": "Visualization of Data\n\u00b6\n\n\nThe TableView\n\u00b6\n\n\nAt this point, the screen should look similar to below. On the left, the \nSolution Explorer\n should be visible. In the center of the screen, a table view called \nTable\n should be visible.\n\n\nScroll through the dataset to see how quickly \nArray Studio\n is able to scroll. \nArray Studio\n is able to easily handle millions of rows and columns in the \nTableView\n.\n\n\n\n\nPlease refer to Microarray Tutorial for different options and filters for TableView.\n\n\nDetails Window/Web Details\n\u00b6\n\n\nThe \nTableView\n, and all other views in \nArray Studio\n, are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the \nDetails Window\n.\n\n\nIn the \nTableView\n, click the column header cell for \n1_1T\n and \n2_1N\n. Notice that the sample information for these 2 selected sample IDs are shown in the \nDetails\n window.\n\n\n\n\nIf the \nDetails Window\n is not shown at the bottom of the screen, go to \nView Menu | Show Details Window\n now to show it.\n\n\nThe user can also click on the row header cell to show annotation for any variable. Do this now, and notice that the \nDetails Window\n updates with the annotation for that particular probeset.",
            "title": "Visualization of Data"
        },
        {
            "location": "/tutorials/ExonArray/Visualization_of_Data/#visualization-of-data",
            "text": "",
            "title": "Visualization of Data"
        },
        {
            "location": "/tutorials/ExonArray/Visualization_of_Data/#the-tableview",
            "text": "At this point, the screen should look similar to below. On the left, the  Solution Explorer  should be visible. In the center of the screen, a table view called  Table  should be visible.  Scroll through the dataset to see how quickly  Array Studio  is able to scroll.  Array Studio  is able to easily handle millions of rows and columns in the  TableView .   Please refer to Microarray Tutorial for different options and filters for TableView.",
            "title": "The TableView"
        },
        {
            "location": "/tutorials/ExonArray/Visualization_of_Data/#details-windowweb-details",
            "text": "The  TableView , and all other views in  Array Studio , are fully interactive. Clicking on particular column headers or row headers will bring up details about those observations or variables in the  Details Window .  In the  TableView , click the column header cell for  1_1T  and  2_1N . Notice that the sample information for these 2 selected sample IDs are shown in the  Details  window.   If the  Details Window  is not shown at the bottom of the screen, go to  View Menu | Show Details Window  now to show it.  The user can also click on the row header cell to show annotation for any variable. Do this now, and notice that the  Details Window  updates with the annotation for that particular probeset.",
            "title": "Details Window/Web Details"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/",
            "text": "Data Visualization and Quality Control\n\u00b6\n\n\nArray Studio\n contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.\n\n\nThe VariableView\n\u00b6\n\n\nOnce a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular probeset or probesets.\nThis can be accomplished in a number of different ways in \nArray Studio\n, but the most unique way is the \nVariableView\n.\n\n\nThe \nVariableView\n allows the user to visualize one chart for each of the variables in the dataset. So, for this dataset, there will be 1425647 charts available for visualization.\n\n\nTo add a \nVariableView\n, go to the \nSolution Explorer\n. For the \nExonArray\n dataset, right-click on ExonData and select \nAdd View\n from the dropdown box.\n\n\n\n\nThis opens the \nAdd View\n window, which lists all the different types of views available for a \nData\n object.\n\n\nChoose \nVariableView\n from the \nChoose View Type\n box. Notice that a preview of the view is shown in the \nPreview\n box. Click \nOK\n to add the view.\n\n\n\n\nAfter adding it, a new View will appear in the main View window. In addition, this new View will appear in the \nSolution Explorer\n, as shown below.\nAnytime the \nVariableView\n needs to be opened, user can double click on the \nVariable\n item in the \nSolution Explorer\n, and the view will show up in the main window.\n\n\n\n\nScroll through all 1425647 charts in the \nVariableView\n to see that \nArray Studio\n can easily handle showing the visualizations for all the variables in the dataset.\nNote: if you don't have 1425647 charts, it is likely that a previously generated filter is still applied.\n\n\nOn the X-Axis, each of the 20 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed).\nEach point on the chart represents the intensity value of that chip for that variable (probeset).\n\n\nHowever, the power of the \nVariableView\n lies in its ability to be customized.\n\n\nThe \nTask\n tab in the \nView Controller\n of the \nVariableView\n (below), will be used to customize this view.\nThe first step in customizing the view is to start from the top of the \nTask\n tab and work down, completing the customization.\nIn the \nData\n section of the \nTask\n tab of the \nView Controller\n, click \nSpecify Title Columns\n now.\n\n\n\n\nThis opens the \nSpecify Title Columns\n window.\nThis window allows the user to specify which columns from the attached \nAnnotation table\n (downloaded automatically for Affymetrix datasets) should be used to identify each chart.\nScroll through the \nAvailable columns to add\n, and select \nGene Symbol\n.\nMove it to the \nListed columns\n box, so that \nProbe Set ID\n and \nGene Symbol\n are all listed. Click \nOK\n to continue.\n\n\n\n\nNotice that the charts have been updated to reflect the additional title information, from the \nGene Symbol\n columns.\n\n\n\n\nFor the purposes of this tutorial, go to the \nVariable\n tab of the \nView Controller\n, and once again filter \nGene Symbol\n, using **^EGR1\n\\(** as the filter, as shown below.\n\"^\" and \"\\)\n\" are RegEx symbols to require that EGR1 is matched \nexactly\n, instead of as part of a longer string (\ne.g. FEGR12\n).\nNote: All of the customizations performed on this view apply to all variables; however we will concentrate on visualizing \nEGR1\n for demonstration purposes.\n\n\n\n\nNotice that the view is now updated to reflect the filter, and shows 16 charts.\n\n\n\n\nNow go back to the \nTask\n tab of the \nView Controller\n.\n\n\nThe next step is to \nSpecify Profile Column\n.\nThis allows the user to group the data points by a particular column of the \nDesign Table\n.\nRemember, the \nDesign Table\n contained columns for a number of different items, including \ntissue\n \ntype\n.\nChoose \ntissue_type\n and click \nOK\n.\n\n\n\n\nThe chart is updated so that data points are grouped by \ntissue_type\n.\n\n\n\n\nThe user could use \nSpecify Split Column\n from the \nTask\n tab of the \nView Controller\n to further split each \nProfile Column\n.\nWe will not do so in this tutorial.\nPlease refer to the McroArray Tutorial for more options on customizing a view using \nView Controller\n.\n\n\nBefore continuing, make sure to \nClear all filters\n in the \nVariable\n tab of the \nView Controller\n.\n\n\nVisualization of Transcripts\n\u00b6\n\n\nArray Studio includes two specialized views for exon data at the transcript level (rather than the probeset level). These views are the \nTranscriptProfileView\n and \nTranscriptHeatmapView\n.\n\n\nTo add a \nTranscriptProfileView\n, right-click on \nExonData\n, click \nAdd View\n and select \nTranscriptProfileView\n. Click \nOK\n to continue.\n\n\nThis view shows one chart for each transcript on the chip. Notice that there are 311971 charts, one for each transcript according to the Transcript ID in annotation.\n\n\nThe x-axis represents each probeset belong to this transcript, while the y-axis represents the expression level (on a log2 scale).\n\n\nEach line represents one sample.\n\n\n\n\nTo make the view more interesting, it is possible to either color or group the samples by a design column. Click \nSpecify Grouping\n from the \nTask\n tab of the \nView Controller\n. Choose \ntissue_type\n from the window.\n\n\n\n\nThis groups the view by each tissue type (in this case normal and tumor).\n\n\n\n\nThe user can further color the two groups by choosing \nChange Line Properties\n, then changing the \nColor By\n to \nCategorical\n and selecting \ntissue_type\n.\n\n\n\n\nThis updates the view colors each line by either tumor or normal.\n\n\n\n\nThis shows the each probeset in the transcript, and can help to differentiate between transcripts (or genes) that have differential expression.\n\n\nFor purposes of alternative splicing, the user would want to remove the gene effect from the view (i.e. subtract the average of the probesets for that gene). This can easily be done by clicking \nRemove gene effect\n in the \nTask\n tab of the \nView Controller\n.\n\n\n\n\nThis effectively normalizes the data around 0, but helps indicate if there is any differential expression. This gene, in the example shown, clearly does not have any differential expression.\n\n\n\n\nTo see the known transcripts for a particular gene, click \nShow Ensembl Entries\n in the \nTask\n tab of the \nView Controller.\n\n\n\n\nThis shows each known transcript (from Ensembl) for a particular gene. The user can use this to visualize whether there is any known alternative transcription occurring. If there are multiple probesets for an exon, they will be separated by a space in the view, as shown below.\n\n\n\n\nSimilarly, to add a \nTranscriptHeatmapView\n, right-click on \nExon\n \nData\n, click \nAdd View\n and select \nTranscriptHeatmapView\n. Click \nOK\n to continue.\n\n\n\n\nThis shows the intensity of each probeset in a transcript. User can order samples by \ntissue_type\n to see whether there is a different pattern in normal and tumor tissue types.\nClick on \nSort Heatmap Rows\n in the \nTask\n tab in \nView Controller\n and select \ntissue_type\n to sort.\n\n\n\n\nThe user can add tissue_type in the Y-axis label, by clicking on \nChange Y-Axis Labels\n.\n\n\n\n\n\n\nAfter customization, user can easily visualize whether there is any difference between tissue types.\nAgain, this gene clearly does not have any differential expression in any of the probesets.\n\n\nPrincipal Component Analysis of RMA Signals\n\u00b6\n\n\nFor quality control purposes, the user may be interested in running a \nPrincipal Component Analysis\n.\n\n\nPrincipal component analysis can be used to detect outliers in a dataset. To run a principal component analysis on an ExonArray dataset, go to the \nExonArray Workflow\n, and select \nPrincipal component analysis\n from the \nQuality control\n section of the \nWorkflow\n.\nAlternatively, go to \nMicroArray | ExonArray | Principal Component Analysis\n to open the \nPrincipal Component Analysis\n window.\n\n\n\n\nThe \nPrincipal Component Analysis\n window, like most analysis windows in \nArray Studio\n , contains an \nInput/Output\n section.\nIn this section, the user picks the \nProject\n and \nData\n on which to run the analysis, as well as the \nVariables\n and \nObservations\n on which to run the analysis.\nThis allows the user to specify if the analysis should be run on all, selected, visible, or particular \nCustomized Lists\n of \nVariables\n or \nObservations\n.\n\n\n\n\nEnsure that \nTutorial\n \nExonArray\n is selected under the \nInput/Output Project\n drop-down box and \nExonData\n is selected under \nData\n drop-down box.\nEnsure that \nAll variables\n is selected for \nVariables\n.\nEnsure that \nAll observations\n is selected for \nObservations\n.\nLeave \nOutput Name\n blank, as by default the outputted plots will be called \n(DataName).PcaScores\n.\n\n\nUnder options, change the \nGroup\n to \ntissue_type\n.\nEnsure that \nScale variables\n, \nOutput scores\n, and \nCalculate Hotelling T2\n are selected, with an \nAlpha level\n of \n0.05\n. Click \nSubmit\n.\n\n\nA dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 minutes.\n\n\nWhen complete, a new view will have been created, as well as a new \nTable\n object in the \nQC\n tab of the \nSolution Explorer\n with associated views.\n\n\n\n\nSwitch to the view \nExonData.PcaScores | PcaScores\n to look at the score plot.\nFirst, notice that on the X and Y axis, the percentage of variance each component can explain (equivalent of R 2 value). Component 1 (x-axis) explains 13.00 % of the variance in the data, while Component 2 represents an additional 7.47% of the variance in the data. At first glance, it is clear that there is one outlier in the chart.\n\n\nSampleID for each data point on the plot can be displayed by customizing the symbol properties. Click on the \nChange Symbol Properties\n in the task tab. Change the \nLabels\n section to \nAll\n, then the \nBy\n drop-down box to \nID\n. Then close the dialog box.\n\n\n\n\nThe SampleID of the outlier (8_4N) shows up once the plot is updated.\n\n\n\n\nArray Studio\n includes the unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, select sample 8_4N by selecting it on the chart (either click directly on the data point, or left-click and drag, or right-click and use the \nLasso\n to drag around the sample). When selected, the point will turn red.\n\n\n\n\nIn the \nView Controller\n, select the \nTask\n tab. Then, under the \nUpdate\n tab, select \nExclude Selection\n.\nThe principal component analysis will re-run on the remaining samples, with a newly generated \nPCAScores\n object in the \nSolution Explorer\n.\n\n\n\n\nArray Studio\n has also added a new \nList\n, called \nExon Data.Observation19\n. This is a list of the remaining 19 chips (after the outlier, 8_4N, has been removed).\nThis \nList\n can be used for all further downstream analysis, to automatically exclude chip 8_4N.\n\n\n\n\nFiltering Data\n\u00b6\n\n\nFor ExonArray data, it is important to filter the data, as many of the probesets have low intensities. Array Studio allows the user to create a filtered \nList\n of probeset IDs that can be used for further downstream analysis.\n\n\nThis module can be opened by selecting \nFilter variables/observations\n from the \nPreprocess\n tab of the \nWorkflow\n window. Alternatively, user can open it by going to the \nMicro Array Menu | Preprocess | Filter\n.\n\n\n\n\nThere are many ways to filter in \nArray Studio\n.\nFor instance, one may want a list of all probesets where the Max intensity of that probeset is greater than 4.\nThis, in effect, would only return probesets that had at least one chip over the log2 intensity of 4 (16 on a linear scale).\n\n\nArray Studio also allows filtering using the detection p-values generated in the importation of the .CEL files, which is the recommended way to filter. The user would want to create a list of probesets where at least one sample had a detection p-value of less than 0.05. To do this, set the \nCriterion\n to \nMin < 0.05\n, and click \nAdd criterion\n.\n\n\nMake sure to select the \nFilter by detection\n checkbox.\n\n\n\n\nAn example of this setting is shown above.\nClick \nTest\n to find out how many probesets fit this criterion.\nIf acceptable, click \nSubmit\n to run the module and generate a list.\n\n\n\n\nWhen completed, a \nList\n is generated in the \nList\n section of the \nSolution Explorer\n, containing the 1,159,411 probesets that fit this criterion. This list will be used for further downstream analysis.",
            "title": "Data Visualization and Quality Control"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/#data-visualization-and-quality-control",
            "text": "Array Studio  contains a large collection of visualizations and Quality Control (QC) modules for MicroArray Data. Two commonly used visualizations and one quality control method are described in this chapter.",
            "title": "Data Visualization and Quality Control"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/#the-variableview",
            "text": "Once a dataset has been imported, one of the first tasks for a user might be to visualize the results of a particular probeset or probesets.\nThis can be accomplished in a number of different ways in  Array Studio , but the most unique way is the  VariableView .  The  VariableView  allows the user to visualize one chart for each of the variables in the dataset. So, for this dataset, there will be 1425647 charts available for visualization.  To add a  VariableView , go to the  Solution Explorer . For the  ExonArray  dataset, right-click on ExonData and select  Add View  from the dropdown box.   This opens the  Add View  window, which lists all the different types of views available for a  Data  object.  Choose  VariableView  from the  Choose View Type  box. Notice that a preview of the view is shown in the  Preview  box. Click  OK  to add the view.   After adding it, a new View will appear in the main View window. In addition, this new View will appear in the  Solution Explorer , as shown below.\nAnytime the  VariableView  needs to be opened, user can double click on the  Variable  item in the  Solution Explorer , and the view will show up in the main window.   Scroll through all 1425647 charts in the  VariableView  to see that  Array Studio  can easily handle showing the visualizations for all the variables in the dataset.\nNote: if you don't have 1425647 charts, it is likely that a previously generated filter is still applied.  On the X-Axis, each of the 20 chips are shown, while the Y-Axis represents the intensity values (values are log2 transformed).\nEach point on the chart represents the intensity value of that chip for that variable (probeset).  However, the power of the  VariableView  lies in its ability to be customized.  The  Task  tab in the  View Controller  of the  VariableView  (below), will be used to customize this view.\nThe first step in customizing the view is to start from the top of the  Task  tab and work down, completing the customization.\nIn the  Data  section of the  Task  tab of the  View Controller , click  Specify Title Columns  now.   This opens the  Specify Title Columns  window.\nThis window allows the user to specify which columns from the attached  Annotation table  (downloaded automatically for Affymetrix datasets) should be used to identify each chart.\nScroll through the  Available columns to add , and select  Gene Symbol .\nMove it to the  Listed columns  box, so that  Probe Set ID  and  Gene Symbol  are all listed. Click  OK  to continue.   Notice that the charts have been updated to reflect the additional title information, from the  Gene Symbol  columns.   For the purposes of this tutorial, go to the  Variable  tab of the  View Controller , and once again filter  Gene Symbol , using **^EGR1 \\(** as the filter, as shown below.\n\"^\" and \"\\) \" are RegEx symbols to require that EGR1 is matched  exactly , instead of as part of a longer string ( e.g. FEGR12 ).\nNote: All of the customizations performed on this view apply to all variables; however we will concentrate on visualizing  EGR1  for demonstration purposes.   Notice that the view is now updated to reflect the filter, and shows 16 charts.   Now go back to the  Task  tab of the  View Controller .  The next step is to  Specify Profile Column .\nThis allows the user to group the data points by a particular column of the  Design Table .\nRemember, the  Design Table  contained columns for a number of different items, including  tissue   type .\nChoose  tissue_type  and click  OK .   The chart is updated so that data points are grouped by  tissue_type .   The user could use  Specify Split Column  from the  Task  tab of the  View Controller  to further split each  Profile Column .\nWe will not do so in this tutorial.\nPlease refer to the McroArray Tutorial for more options on customizing a view using  View Controller .  Before continuing, make sure to  Clear all filters  in the  Variable  tab of the  View Controller .",
            "title": "The VariableView"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/#visualization-of-transcripts",
            "text": "Array Studio includes two specialized views for exon data at the transcript level (rather than the probeset level). These views are the  TranscriptProfileView  and  TranscriptHeatmapView .  To add a  TranscriptProfileView , right-click on  ExonData , click  Add View  and select  TranscriptProfileView . Click  OK  to continue.  This view shows one chart for each transcript on the chip. Notice that there are 311971 charts, one for each transcript according to the Transcript ID in annotation.  The x-axis represents each probeset belong to this transcript, while the y-axis represents the expression level (on a log2 scale).  Each line represents one sample.   To make the view more interesting, it is possible to either color or group the samples by a design column. Click  Specify Grouping  from the  Task  tab of the  View Controller . Choose  tissue_type  from the window.   This groups the view by each tissue type (in this case normal and tumor).   The user can further color the two groups by choosing  Change Line Properties , then changing the  Color By  to  Categorical  and selecting  tissue_type .   This updates the view colors each line by either tumor or normal.   This shows the each probeset in the transcript, and can help to differentiate between transcripts (or genes) that have differential expression.  For purposes of alternative splicing, the user would want to remove the gene effect from the view (i.e. subtract the average of the probesets for that gene). This can easily be done by clicking  Remove gene effect  in the  Task  tab of the  View Controller .   This effectively normalizes the data around 0, but helps indicate if there is any differential expression. This gene, in the example shown, clearly does not have any differential expression.   To see the known transcripts for a particular gene, click  Show Ensembl Entries  in the  Task  tab of the  View Controller.   This shows each known transcript (from Ensembl) for a particular gene. The user can use this to visualize whether there is any known alternative transcription occurring. If there are multiple probesets for an exon, they will be separated by a space in the view, as shown below.   Similarly, to add a  TranscriptHeatmapView , right-click on  Exon   Data , click  Add View  and select  TranscriptHeatmapView . Click  OK  to continue.   This shows the intensity of each probeset in a transcript. User can order samples by  tissue_type  to see whether there is a different pattern in normal and tumor tissue types.\nClick on  Sort Heatmap Rows  in the  Task  tab in  View Controller  and select  tissue_type  to sort.   The user can add tissue_type in the Y-axis label, by clicking on  Change Y-Axis Labels .    After customization, user can easily visualize whether there is any difference between tissue types.\nAgain, this gene clearly does not have any differential expression in any of the probesets.",
            "title": "Visualization of Transcripts"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/#principal-component-analysis-of-rma-signals",
            "text": "For quality control purposes, the user may be interested in running a  Principal Component Analysis .  Principal component analysis can be used to detect outliers in a dataset. To run a principal component analysis on an ExonArray dataset, go to the  ExonArray Workflow , and select  Principal component analysis  from the  Quality control  section of the  Workflow .\nAlternatively, go to  MicroArray | ExonArray | Principal Component Analysis  to open the  Principal Component Analysis  window.   The  Principal Component Analysis  window, like most analysis windows in  Array Studio  , contains an  Input/Output  section.\nIn this section, the user picks the  Project  and  Data  on which to run the analysis, as well as the  Variables  and  Observations  on which to run the analysis.\nThis allows the user to specify if the analysis should be run on all, selected, visible, or particular  Customized Lists  of  Variables  or  Observations .   Ensure that  Tutorial   ExonArray  is selected under the  Input/Output Project  drop-down box and  ExonData  is selected under  Data  drop-down box.\nEnsure that  All variables  is selected for  Variables .\nEnsure that  All observations  is selected for  Observations .\nLeave  Output Name  blank, as by default the outputted plots will be called  (DataName).PcaScores .  Under options, change the  Group  to  tissue_type .\nEnsure that  Scale variables ,  Output scores , and  Calculate Hotelling T2  are selected, with an  Alpha level  of  0.05 . Click  Submit .  A dialog box will open showing the progress of the PCA. This should take approximately 1 or 2 minutes.  When complete, a new view will have been created, as well as a new  Table  object in the  QC  tab of the  Solution Explorer  with associated views.   Switch to the view  ExonData.PcaScores | PcaScores  to look at the score plot.\nFirst, notice that on the X and Y axis, the percentage of variance each component can explain (equivalent of R 2 value). Component 1 (x-axis) explains 13.00 % of the variance in the data, while Component 2 represents an additional 7.47% of the variance in the data. At first glance, it is clear that there is one outlier in the chart.  SampleID for each data point on the plot can be displayed by customizing the symbol properties. Click on the  Change Symbol Properties  in the task tab. Change the  Labels  section to  All , then the  By  drop-down box to  ID . Then close the dialog box.   The SampleID of the outlier (8_4N) shows up once the plot is updated.   Array Studio  includes the unique feature to quickly and easily re-run a principal component analysis with selected outliers removed. First, select sample 8_4N by selecting it on the chart (either click directly on the data point, or left-click and drag, or right-click and use the  Lasso  to drag around the sample). When selected, the point will turn red.   In the  View Controller , select the  Task  tab. Then, under the  Update  tab, select  Exclude Selection .\nThe principal component analysis will re-run on the remaining samples, with a newly generated  PCAScores  object in the  Solution Explorer .   Array Studio  has also added a new  List , called  Exon Data.Observation19 . This is a list of the remaining 19 chips (after the outlier, 8_4N, has been removed).\nThis  List  can be used for all further downstream analysis, to automatically exclude chip 8_4N.",
            "title": "Principal Component Analysis of RMA Signals"
        },
        {
            "location": "/tutorials/ExonArray/Data_Visualization_and_Quality_Control/#filtering-data",
            "text": "For ExonArray data, it is important to filter the data, as many of the probesets have low intensities. Array Studio allows the user to create a filtered  List  of probeset IDs that can be used for further downstream analysis.  This module can be opened by selecting  Filter variables/observations  from the  Preprocess  tab of the  Workflow  window. Alternatively, user can open it by going to the  Micro Array Menu | Preprocess | Filter .   There are many ways to filter in  Array Studio .\nFor instance, one may want a list of all probesets where the Max intensity of that probeset is greater than 4.\nThis, in effect, would only return probesets that had at least one chip over the log2 intensity of 4 (16 on a linear scale).  Array Studio also allows filtering using the detection p-values generated in the importation of the .CEL files, which is the recommended way to filter. The user would want to create a list of probesets where at least one sample had a detection p-value of less than 0.05. To do this, set the  Criterion  to  Min < 0.05 , and click  Add criterion .  Make sure to select the  Filter by detection  checkbox.   An example of this setting is shown above.\nClick  Test  to find out how many probesets fit this criterion.\nIf acceptable, click  Submit  to run the module and generate a list.   When completed, a  List  is generated in the  List  section of the  Solution Explorer , containing the 1,159,411 probesets that fit this criterion. This list will be used for further downstream analysis.",
            "title": "Filtering Data"
        },
        {
            "location": "/tutorials/ExonArray/Differential_Expression__Probeset_Level_/",
            "text": "Differential Expression (Probeset Level)\n\u00b6\n\n\nArray Studio\n contains a number of different modules for performing univariate analysis/differential expression on the probeset level, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others. For probeset level, the differential expression analysis is similar to that discussed in MicroArray Tutorial. We will only provide an example of \nGeneral Linear Model\n in this tutorial.\n\n\nProbeset Level Linear Model\n\u00b6\n\n\nThe design of the experiment in this tutorial is set-up so that the user should perform a \nProbeset Level\n \nLinear Model\n. The first factor in the ANOVA is \ntissue_type\n while the second factor is \npatient_id\n. For each patient, there is a tumor and a normal sample, and we are interested in the difference between the two.\n\n\nTo run the \nProbeset Level Linear Module\n, go to the \nStatistical Inference\n section of the \nworkflow\n, and select \nProbeset Level Linear model\n. Alternatively, the same module can be selected by going to the \nMicroArray Menu | Inference | General Linear Model\n.\n\n\n\n\nThis opens the \nGeneral Linear Model\n window.\n\n\n\n\nAs with other analysis windows, the user must first set the \nProject\n and \nData\n on which to run the analysis, in the \nInput/Output\n section. Make sure \nTutorial ExonArray\n is chosen as the project and \nExon Data\n is chosen as the input data.\n\n\nFor \nVariables\n, choose \nCustomized variables\n and click \nSelect\n. Choose the list that was generated earlier by the \nFilter\n command.\n\n\n\n\nFor \nObservations\n, choose \nCustomized Observations\n, and then click the \nSelect\n button to choose the list \nExonData.Observation19\n.\nThis ensures that the statistical tests are only run on the  good  19 observations, ignoring the one outlier chip.\n\n\n\n\nGo to \nStep 1: Specify Model\n.\n\n\nThe two factors in this model are \ntissue_type\n and \npatient number\n. Use ctrl + click to select both of them and click the \nAdd\n button.\n\n\n\n\nPatient\n is random effect, so click the \nRandom\n checkbox for \npatient number\n.\nClick \nOK\n to return to the \nGeneral Linear Model\n window.\nNotice that the information of the specified model is displayed in the box under step 1.\n\n\n\n\nNext, click \nSpecify Test\n for comparisons.\n\n\nThis opens the \nSpecify Test\n window, which allows the user to manually or automatically specify the tests (or comparisons). In this case, the user is interested in the difference between tumor samples and normal.\n\n\n\n\nThe easiest way to specify the comparison is to ensure that the \nTerm\n box is set to \ntissue_type\n, click the \nFor each\n box to set to \n(none)\n, and set \nCompare to\n as \nNormal\n.\nIn effect, this says that for every level of \ntissue_type\n, compare it to normal.\nSince there are only two levels (tumor and normal), there will be one comparison.\n\n\nMake sure that \nEstimate\n, \nFold Change\n, \nRaw p-values\n and \nAdjusted p-values\n are checked, and then click \nAdd\n to add the test. Add test will be displayed in the \nTTests\n box.\n\n\nClick OK to return to the original \nGeneral Linear Model\n window.\n\n\n\n\nStep 3\n is optional, and includes a number of options that can be set for the \nGeneral Linear Model\n. Please refer to MicroArray Tutorial for more details on the options.\n\n\nThe \nLinear Model\n option is now complete.\nIf the user is familiar with SAS code, clicking \nShow SAS Code\n will show the equivalent SAS code.\n\n\nClick \nSubmit\n to run the module.\n\n\nThis module should take approximately 6 minutes (Note: the length of time is dependent on the number of variables in this case over 1 million, as well as the type of model).\n\n\nThe Volcano Plot View and Inference Report\n\u00b6\n\n\nAfter running the \nGeneral Linear Model\n (the computing time should be a few minutes), a \nTable\n is generated under the \nInference\n tab of the \nSolution Explorer\n, named \nExonData.Tests\n.\n This table contains the statistics report generated by the General Linear Model, together with a \nVolcanoPlot\n visualizing the pvalues vs. estimate.\n\n\n\n\nAlso notice that a new \nList\n has been automatically generated by the \nGeneral Linear Model\n. This \nList\n can be used for purposes of filtering, and any other downstream analysis. However, for this experiment, there are actually no probesets that pass the adjusted p-value criteria of 0.05, so this list contains 0 probesets.\n\n\n\n\nDouble click on \nVolcanoPlot\n to open it. Notice that one \nvolcano plot\n has been created in this view, for the comparison \nTumor vs. Normal\n.\n\n\n\n\nThe \nVolcanoPlotView\n shows the \n-Log10 (Raw P-value)\n on the y-axis and the \nEstimate\n (\nEstimate\n is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the mostly differentially expressed probesets can be found at the extremes of the x-axis. Similar to all views in Array Studio, the \nVolcanoPlotView\n is fully interactive. Please refer to MicroArray Tutorial for more details on these options.",
            "title": "Differential Expression Probeset Level"
        },
        {
            "location": "/tutorials/ExonArray/Differential_Expression__Probeset_Level_/#differential-expression-probeset-level",
            "text": "Array Studio  contains a number of different modules for performing univariate analysis/differential expression on the probeset level, including One-Way ANOVA, Two-Way ANOVA, and the more advanced General Linear Model, as well as a few others. For probeset level, the differential expression analysis is similar to that discussed in MicroArray Tutorial. We will only provide an example of  General Linear Model  in this tutorial.",
            "title": "Differential Expression (Probeset Level)"
        },
        {
            "location": "/tutorials/ExonArray/Differential_Expression__Probeset_Level_/#probeset-level-linear-model",
            "text": "The design of the experiment in this tutorial is set-up so that the user should perform a  Probeset Level   Linear Model . The first factor in the ANOVA is  tissue_type  while the second factor is  patient_id . For each patient, there is a tumor and a normal sample, and we are interested in the difference between the two.  To run the  Probeset Level Linear Module , go to the  Statistical Inference  section of the  workflow , and select  Probeset Level Linear model . Alternatively, the same module can be selected by going to the  MicroArray Menu | Inference | General Linear Model .   This opens the  General Linear Model  window.   As with other analysis windows, the user must first set the  Project  and  Data  on which to run the analysis, in the  Input/Output  section. Make sure  Tutorial ExonArray  is chosen as the project and  Exon Data  is chosen as the input data.  For  Variables , choose  Customized variables  and click  Select . Choose the list that was generated earlier by the  Filter  command.   For  Observations , choose  Customized Observations , and then click the  Select  button to choose the list  ExonData.Observation19 .\nThis ensures that the statistical tests are only run on the  good  19 observations, ignoring the one outlier chip.   Go to  Step 1: Specify Model .  The two factors in this model are  tissue_type  and  patient number . Use ctrl + click to select both of them and click the  Add  button.   Patient  is random effect, so click the  Random  checkbox for  patient number .\nClick  OK  to return to the  General Linear Model  window.\nNotice that the information of the specified model is displayed in the box under step 1.   Next, click  Specify Test  for comparisons.  This opens the  Specify Test  window, which allows the user to manually or automatically specify the tests (or comparisons). In this case, the user is interested in the difference between tumor samples and normal.   The easiest way to specify the comparison is to ensure that the  Term  box is set to  tissue_type , click the  For each  box to set to  (none) , and set  Compare to  as  Normal .\nIn effect, this says that for every level of  tissue_type , compare it to normal.\nSince there are only two levels (tumor and normal), there will be one comparison.  Make sure that  Estimate ,  Fold Change ,  Raw p-values  and  Adjusted p-values  are checked, and then click  Add  to add the test. Add test will be displayed in the  TTests  box.  Click OK to return to the original  General Linear Model  window.   Step 3  is optional, and includes a number of options that can be set for the  General Linear Model . Please refer to MicroArray Tutorial for more details on the options.  The  Linear Model  option is now complete.\nIf the user is familiar with SAS code, clicking  Show SAS Code  will show the equivalent SAS code.  Click  Submit  to run the module.  This module should take approximately 6 minutes (Note: the length of time is dependent on the number of variables in this case over 1 million, as well as the type of model).",
            "title": "Probeset Level Linear Model"
        },
        {
            "location": "/tutorials/ExonArray/Differential_Expression__Probeset_Level_/#the-volcano-plot-view-and-inference-report",
            "text": "After running the  General Linear Model  (the computing time should be a few minutes), a  Table  is generated under the  Inference  tab of the  Solution Explorer , named  ExonData.Tests .\n This table contains the statistics report generated by the General Linear Model, together with a  VolcanoPlot  visualizing the pvalues vs. estimate.   Also notice that a new  List  has been automatically generated by the  General Linear Model . This  List  can be used for purposes of filtering, and any other downstream analysis. However, for this experiment, there are actually no probesets that pass the adjusted p-value criteria of 0.05, so this list contains 0 probesets.   Double click on  VolcanoPlot  to open it. Notice that one  volcano plot  has been created in this view, for the comparison  Tumor vs. Normal .   The  VolcanoPlotView  shows the  -Log10 (Raw P-value)  on the y-axis and the  Estimate  ( Estimate  is defined as the statistically adjusted difference between the means of the two groups being compared) on the x-axis. Thus, the most significant probesets are higher on the y-axis, while the mostly differentially expressed probesets can be found at the extremes of the x-axis. Similar to all views in Array Studio, the  VolcanoPlotView  is fully interactive. Please refer to MicroArray Tutorial for more details on these options.",
            "title": "The Volcano Plot View and Inference Report"
        },
        {
            "location": "/tutorials/ExonArray/Exon_Level_ANOVA_ExonDiffertialExpression_/",
            "text": "Exon Level General Linear Model (Exon Differential Expression)\n\u00b6\n\n\nArray Studio includes the ability to find differential expression at the exon level, rather than the probeset level.\nThis can help for finding differentially expressed exons, or alternatively expressed exons.\nTo open the \nExon Level Linear Model\n, user can click on the \nExon Level Linear Model\n in \nAlternative Splicing\n section of the \nWorkflow\n window.\nAlternatively, user can go to \nMicroArray | ExonArray | Exon Level Linear Model\n.\n\n\n\n\nThis opens the \nGeneral Linear Model (Exon Level)\n window.\n\n\n\n\nThe first step is to select the \nCustomized variables\n and \nCustomized observations\n using the lists created with the \nPrincipal Component Analysis\n and \nFilter\n module.\n\n\nClick \nSpecify Model\n to begin \nStep 1\n.\n\n\nAs with the probeset level linear model, the two factors are \ntissue_type\n and \npatient number\n. Use ctrl + click to select both of them and click the \nAdd\n button.\n\n\n\n\nPatient\n is random effect, so click the \nRandom\n checkbox for \npatient number\n. Click \nOK\n to return to the \nGeneral Linear Model\n window. Notice that the information of the specified model is displayed in the box under step 1.\n\n\nClick \nSpecify Test\n to start \nStep 2\n.\n\n\nOnce again, choose \ntissue_type\n as the \nTerm\n, click the \nFor each\n checkbox, set it to \n(none)\n, and set \nCompare to\n as \nNormal\n. Click \nAdd\n to add the test. Click \nOK\n to continue.\n\n\n\n\nFor step 3, \nChange Options\n, we will leave all the options as the default.\n\n\nFor this module, the user has the option to choose how the summarization of the exons will be calculated ( \nMean\n, \nMedian\n, or \nMedian Polish\n). In addition, the \nRemove gene effect\n option allows the user to remove the gene effect (i.e. subtract the average of the probesets for that gene) from the data when running the ANOVA. This is useful for detection of exons involved in alternative splicing.\n\n\nLeave the \nWork on core probesets only (level=core)\n checkbox on to only run the ANOVA on the core probesets (recommended for the tutorial).\n\n\n\n\nClick \nSubmit\n to run the linear model, which should take 2-3 minutes for over 1 million variables.\n\n\nThis module, in effect, summarizes the probesets into the exon level, then looks for differentially expressed exons.\n\n\nThis returns \nExonData.Tests_2\n under the \nInference\n tab of the \nSolution Explorer\n. Both a \nReport\n and \nVolcanoPlot\n are generated. Double-click \nReport\n to take a look at the results.\n\n\n\n\nThis time, p-values and fold changes are generated at the exon level. This data can be sorted by p-value. Right-click on the raw p-value column now and choose \nSort Ascending\n. This sorts the table by p-value, from most significant to least significant.\n\n\nNotice \nABCG1\n is one of the top transcripts at the top of the list.\n\n\n\n\nSwitch back to the \nTranscriptProfileView\n and filter for this gene.\n\n\n\n\nMake sure that the \nRemove gene effect\n button has been clicked.\n\n\n\n\nYou can now look for those exons in this gene that may have alternative splicing using this filtered TranscriptProfile View. The top Exon has ID 993113 and probeset ID 3922532.",
            "title": "Exon Level Differtial Expression"
        },
        {
            "location": "/tutorials/ExonArray/Exon_Level_ANOVA_ExonDiffertialExpression_/#exon-level-general-linear-model-exon-differential-expression",
            "text": "Array Studio includes the ability to find differential expression at the exon level, rather than the probeset level.\nThis can help for finding differentially expressed exons, or alternatively expressed exons.\nTo open the  Exon Level Linear Model , user can click on the  Exon Level Linear Model  in  Alternative Splicing  section of the  Workflow  window.\nAlternatively, user can go to  MicroArray | ExonArray | Exon Level Linear Model .   This opens the  General Linear Model (Exon Level)  window.   The first step is to select the  Customized variables  and  Customized observations  using the lists created with the  Principal Component Analysis  and  Filter  module.  Click  Specify Model  to begin  Step 1 .  As with the probeset level linear model, the two factors are  tissue_type  and  patient number . Use ctrl + click to select both of them and click the  Add  button.   Patient  is random effect, so click the  Random  checkbox for  patient number . Click  OK  to return to the  General Linear Model  window. Notice that the information of the specified model is displayed in the box under step 1.  Click  Specify Test  to start  Step 2 .  Once again, choose  tissue_type  as the  Term , click the  For each  checkbox, set it to  (none) , and set  Compare to  as  Normal . Click  Add  to add the test. Click  OK  to continue.   For step 3,  Change Options , we will leave all the options as the default.  For this module, the user has the option to choose how the summarization of the exons will be calculated (  Mean ,  Median , or  Median Polish ). In addition, the  Remove gene effect  option allows the user to remove the gene effect (i.e. subtract the average of the probesets for that gene) from the data when running the ANOVA. This is useful for detection of exons involved in alternative splicing.  Leave the  Work on core probesets only (level=core)  checkbox on to only run the ANOVA on the core probesets (recommended for the tutorial).   Click  Submit  to run the linear model, which should take 2-3 minutes for over 1 million variables.  This module, in effect, summarizes the probesets into the exon level, then looks for differentially expressed exons.  This returns  ExonData.Tests_2  under the  Inference  tab of the  Solution Explorer . Both a  Report  and  VolcanoPlot  are generated. Double-click  Report  to take a look at the results.   This time, p-values and fold changes are generated at the exon level. This data can be sorted by p-value. Right-click on the raw p-value column now and choose  Sort Ascending . This sorts the table by p-value, from most significant to least significant.  Notice  ABCG1  is one of the top transcripts at the top of the list.   Switch back to the  TranscriptProfileView  and filter for this gene.   Make sure that the  Remove gene effect  button has been clicked.   You can now look for those exons in this gene that may have alternative splicing using this filtered TranscriptProfile View. The top Exon has ID 993113 and probeset ID 3922532.",
            "title": "Exon Level General Linear Model (Exon Differential Expression)"
        },
        {
            "location": "/tutorials/ExonArray/Alternative_Splicing_ANOVA/",
            "text": "Alternative Splicing ANOVA\n\u00b6\n\n\nArray Studio includes an \nAlternative Splicing ANOVA\n module that detects at the transcript level the transcripts that are alternatively spliced.\n\n\nThe model for this ANOVA is slightly different from the previous tests. Instead of tissue_type + patient number, this model is Probeset*tissue_type+patient number + Probeset+tissue_type. Also, the chip effect will be automatically added (random effect nested in tissue_type and patient number). So, when generating the model, we will have to adapt our usual procedure for this. In general, the user is most interested in the interaction between probeset and a factor (factors) of interest.\n\n\nTo run the \nAlternative Splicing ANOVA\n, click \nAlternative Splicing ANOVA\n from the \nAlternative Splicing\n section of \nWorkflow\n or go to the \nMicroArray Menu | ExonArray | Alternative Splicing ANOVA\n.\n\n\n\n\nThis opens the \nAlternative Splicing ANOVA\n window. As usual, set the \nCustomized Variables\n and \nCustomized Observations\n to the lists we created earlier.\n\n\n\n\nClick \nSpecify Model\n to proceed to \nStep 1\n of the analysis.\n\n\nBy default, probeset is already added to the model. To add the interaction between probeset and \ntissue_type\n, click \ntissue_type\n in the \nColumns\n box and \nProbeSet\n in the \nConstruct Model\n box, then click the \nCross\n button. The interaction is displayed as \nProbeset:tissue_type\n.\n\n\n\n\nNext, add both \ntissue_type\n and \npatient number\n to the model, by selecting both, and clicking \nAdd\n. Set \npatient number\n as \nRandom\n, and click \nOK\n to continue.\n\n\n\n\nNext, click \nSpecify Test\n to proceed to step 2.\n\n\nThis opens the \nSpecify Test\n window.\nUnlike the other ANOVAs performed earlier, there are no estimates (contrasts) to be completed for this module.\nInstead, the only test is \nFTest\n.\nThe user needs to pick the \nTerms\n for which to generate p-values.\nThe important term is the interaction between \nProbeSet\n and \ntissue_type\n.\nClick on \nProbeset:tissue_type\n and click \nAdd\n, then click \nOK\n to continue.\n\n\n\n\nNext, click \nChange Options\n to proceed to Step 3.\n\n\nThis module contains some of the options as the previous tests, however the point of interest is that by default, the module only runs on transcripts with \nprobeset#<100\n, and probesets \nwith max(intensity)<4\n will be excluded.\nFor transcripts with more than 100 probesets, there are too many degree of the freedom for the modeling.\nIf a probeset is consistently not expressed (all samples < 4), it will decrease the power of the mixed model.\nLeave these options as default and click on \nOK\n to continue.\n\n\n\n\nOnce again, leave the \nWork on core probesets only (level=core)\n checkbox checked to only run the ANOVA on the core level probesets. Click \nSubmit\n to continue.\n\n\n\n\nThis generates an \nAlternativeSplicingArray.Tests\n table in the \nSolution Explorer\n, as well as a \nReport Tableview\n (double-click this to open it, then sort by the first column ascending).\n\n\n\n\nNotice now that the table is generated on the transcript level, rather than the probeset or exon level (as in the previous test results).\n\n\n\n\nWe can filter this table by p values.",
            "title": "Alternative Splicing ANOVA"
        },
        {
            "location": "/tutorials/ExonArray/Alternative_Splicing_ANOVA/#alternative-splicing-anova",
            "text": "Array Studio includes an  Alternative Splicing ANOVA  module that detects at the transcript level the transcripts that are alternatively spliced.  The model for this ANOVA is slightly different from the previous tests. Instead of tissue_type + patient number, this model is Probeset*tissue_type+patient number + Probeset+tissue_type. Also, the chip effect will be automatically added (random effect nested in tissue_type and patient number). So, when generating the model, we will have to adapt our usual procedure for this. In general, the user is most interested in the interaction between probeset and a factor (factors) of interest.  To run the  Alternative Splicing ANOVA , click  Alternative Splicing ANOVA  from the  Alternative Splicing  section of  Workflow  or go to the  MicroArray Menu | ExonArray | Alternative Splicing ANOVA .   This opens the  Alternative Splicing ANOVA  window. As usual, set the  Customized Variables  and  Customized Observations  to the lists we created earlier.   Click  Specify Model  to proceed to  Step 1  of the analysis.  By default, probeset is already added to the model. To add the interaction between probeset and  tissue_type , click  tissue_type  in the  Columns  box and  ProbeSet  in the  Construct Model  box, then click the  Cross  button. The interaction is displayed as  Probeset:tissue_type .   Next, add both  tissue_type  and  patient number  to the model, by selecting both, and clicking  Add . Set  patient number  as  Random , and click  OK  to continue.   Next, click  Specify Test  to proceed to step 2.  This opens the  Specify Test  window.\nUnlike the other ANOVAs performed earlier, there are no estimates (contrasts) to be completed for this module.\nInstead, the only test is  FTest .\nThe user needs to pick the  Terms  for which to generate p-values.\nThe important term is the interaction between  ProbeSet  and  tissue_type .\nClick on  Probeset:tissue_type  and click  Add , then click  OK  to continue.   Next, click  Change Options  to proceed to Step 3.  This module contains some of the options as the previous tests, however the point of interest is that by default, the module only runs on transcripts with  probeset#<100 , and probesets  with max(intensity)<4  will be excluded.\nFor transcripts with more than 100 probesets, there are too many degree of the freedom for the modeling.\nIf a probeset is consistently not expressed (all samples < 4), it will decrease the power of the mixed model.\nLeave these options as default and click on  OK  to continue.   Once again, leave the  Work on core probesets only (level=core)  checkbox checked to only run the ANOVA on the core level probesets. Click  Submit  to continue.   This generates an  AlternativeSplicingArray.Tests  table in the  Solution Explorer , as well as a  Report Tableview  (double-click this to open it, then sort by the first column ascending).   Notice now that the table is generated on the transcript level, rather than the probeset or exon level (as in the previous test results).   We can filter this table by p values.",
            "title": "Alternative Splicing ANOVA"
        },
        {
            "location": "/tutorials/ExonArray/Generate_Transcript_Level_Data/",
            "text": "Generate Transcript Level Data\n\u00b6\n\n\nFor users interested in obtaining transcript-level data from the exon array, \nArray Studio\n includes the capability to \nGenerate Transcript Level Data\n by summarizing the probesets from exons level data.\n\n\nFrom there, any of the standard microarray modules (see the Microarray Tutorial for more information) can be run on this data to differentiate the gene expression (i.e. Genera Linear Model, ontology analysis, clustering, etc.).\n\n\nTo run this module, go to \nGenerate Transcript Level Data\n in the \nPreprocess\n section of the \nworkflow\n.\n\n\n\n\nAlternatively, user can open this module by going to the \nMicroArray menu | ExonArray | Generate Transcript Level Data\n.\n\n\nThis opens the \nSelect Data\n window. Select the \nExon Data\n and click \nOK\n.\n\n\n\n\nThe \nGenerate Transcript Level Data\n dialog box appears next.\n\n\n\n\nThe user can choose the \nExon level\n (\ncore\n, \ncore + entended\n, \ncore + entended + full\n and \nall\n).\nThe user can choose customized variables and observations (just leave this as default), then choose a \nSummary method\n (\nMean\n, \nMedian\n, and \nMedianPolish\n), then click \nOK\n to continue.\n\n\nThis will create a new \nMicroArray\n dataset under the \n-Omic Data\n section in the \nSolution Explorer\n, \nExonData.Transcript\n.\nThe data is based on transcript level.\nAny of the \nMicroarray\n modules should work on this data (including running the General Linear Model to find differentially expressed transcripts).",
            "title": "Generate Transcript Level Data"
        },
        {
            "location": "/tutorials/ExonArray/Generate_Transcript_Level_Data/#generate-transcript-level-data",
            "text": "For users interested in obtaining transcript-level data from the exon array,  Array Studio  includes the capability to  Generate Transcript Level Data  by summarizing the probesets from exons level data.  From there, any of the standard microarray modules (see the Microarray Tutorial for more information) can be run on this data to differentiate the gene expression (i.e. Genera Linear Model, ontology analysis, clustering, etc.).  To run this module, go to  Generate Transcript Level Data  in the  Preprocess  section of the  workflow .   Alternatively, user can open this module by going to the  MicroArray menu | ExonArray | Generate Transcript Level Data .  This opens the  Select Data  window. Select the  Exon Data  and click  OK .   The  Generate Transcript Level Data  dialog box appears next.   The user can choose the  Exon level  ( core ,  core + entended ,  core + entended + full  and  all ).\nThe user can choose customized variables and observations (just leave this as default), then choose a  Summary method  ( Mean ,  Median , and  MedianPolish ), then click  OK  to continue.  This will create a new  MicroArray  dataset under the  -Omic Data  section in the  Solution Explorer ,  ExonData.Transcript .\nThe data is based on transcript level.\nAny of the  Microarray  modules should work on this data (including running the General Linear Model to find differentially expressed transcripts).",
            "title": "Generate Transcript Level Data"
        },
        {
            "location": "/tutorials/ExonArray/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results. Please refer to the MicroArray tutorial for more details on the \nAudit Trial\n, which records all the analysis steps in for form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of, with reference to Exon array analysis and visualization. Feel free to try different options in the Task tab or the \nMicroArray|ExonArray\n menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft's support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/ExonArray/Save_Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results. Please refer to the MicroArray tutorial for more details on the  Audit Trial , which records all the analysis steps in for form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of, with reference to Exon array analysis and visualization. Feel free to try different options in the Task tab or the  MicroArray|ExonArray  menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft's support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/RTPCR/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray Studio\n\nprovides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient in organizing and visualizing data with its \nSolution Explorer\n, which organizes each project into \nData, QC, Table, List, Cluster, Text, Attachments\n and other categories. Multiple projects can be opened simultaneously in the \nSolution Explorer\n, and data can be shared among projects.\nEach view is controlled by a \nView Controller\n, which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the \nDetails Window\n and \nWeb Details On-Demand\n.\n\n\nIt is highly recommended that users complete the prerequisite for this tutorial: \nMicroArray Tutorial\n, which is a good introduction to\ninstallation, basic usage, data structure and standard visualization in Array Studio.\n\n\nDownloading the SDS21 dataset\n\u00b6\n\n\nFor this tutorial, the following materials will be required:\n\n\n\n\n\n\nThe SDS21 text file containing the RT-PCR data\n\n\n\n\n\n\nThe SDS21.design.txt file containing the RT-PCR data design information\n\n\n\n\n\n\nIn this dataset, there are 24 observations (6 treatments * 4 samples) and 24 variables. Each variable (AssayID) has 2 technical replicates in each observation. These files are available in a zipped resource file located on the Omicsoft web srver at the following URL:\n\nlink\n\n\nAfter downloading the single .zip file, unzip the file to a folder to be used for this tutorial.\n\n\nWith the downloaded sample data, this tutorial will cover the steps involved in:\n\n\n\n\n\n\nImporting data directly from \nABI\n result text files\n\n\n\n\n\n\nNormalizing data using a number of statistical methods\n\n\n\n\n\n\nViewing results using the same visualization tools employed elsewhere in Array Studio\n\n\n\n\n\n\nThe Workflow Window/ The Solution Explorer\n\u00b6\n\n\nWhen Array Studio is first installed, it will look similar to what is displayed below.\n\n\nIf you have previously opened projects in Array Studio, you will see the \nLast Opened Projects\n window. If so, just click cancel so that Array Studio looks similar to below.\n\n\n\n\nThe \"Workflow\" window should be visible on the left side of the screen. If the window is not visible, go to the \nView\n Menu and select \nShow Workflow\n. Click the \nWorkflow\n tab (next to \nSolution Explorer\n) and the \nWorkflow\n window should appear similar to the screenshot below.\n\n\n\n\nThis window provides users, especially new users, with a  guide  to running different types of analysis. Click the Workflow dropdown box now and select \nRT-PCR\n.\n\n\nNotice that the RT-PCR Workflow is separated into different categories, including \nGetting started\n, \nManage data\n, \nPreprocess\n, \nQuality control\n, \nStatistical inference\n, and\n\nPattern recognition\n. While it is possible to access all of these functions via the menu commands in Array Studio, the workflows are designed to make it easier for the new users to work through their data.\n\n\nThe first section of the RT-PCR Workflow is the \nGetting Started\n section. In this section, it is suggested that the user either create a new project or open a previously created project.\n\n\nTo create a new project, click the \nNew Project\n button in the Workflow, or the \nNew\n button on the toolbar, or go to the \nFile\n Menu, then click \nNew Local Project\n. This opens the \nNew Project\n window. \nNote\n: For the purposes of this tutorial, we will do the analysis under \nLocal Project\n. However, this module can also be performed under \nServer\n mode, by simply clicking \nFile | New Server Project\n or \nNew | New Server Project\n\n\n\n\nArray Studio\n allows the user to create two different project types:\n\n\n\n\n\n\nA simple project, in which all the project is saved in a single file (recommended for microarray and\n    RT-PCR projects).\n\n\n\n\n\n\nA distributed project, where data is saved in separate files (recommended for exon array, CNV,\n    or genotyping projects).\n\n\n\n\n\n\nSince this project involves an RT-PCR project, choose \nCreate a simple project\n now. Then, click the \nBrowse\n button to select a location and name for the project. Once this is complete, click \nOK\n to continue.\n\n\nSwitch to the \nSolution Explorer\n by clicking on the \nSolution Explorer\n tab, which should be found at the bottom of the \nWorkflow Window\n. If the \nSolution Explorer\n tab is not visible, open it by going to the \nView Menu | Show Solution Explorer\n.\n\n\n\n\nThe Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/RTPCR/Introduction/#introduction",
            "text": "Array Studio \nprovides an integrated environment for analyzing and visualizing high dimensional data.\nIt is convenient in organizing and visualizing data with its  Solution Explorer , which organizes each project into  Data, QC, Table, List, Cluster, Text, Attachments  and other categories. Multiple projects can be opened simultaneously in the  Solution Explorer , and data can be shared among projects.\nEach view is controlled by a  View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the  Details Window  and  Web Details On-Demand .  It is highly recommended that users complete the prerequisite for this tutorial:  MicroArray Tutorial , which is a good introduction to\ninstallation, basic usage, data structure and standard visualization in Array Studio.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/RTPCR/Introduction/#downloading-the-sds21-dataset",
            "text": "For this tutorial, the following materials will be required:    The SDS21 text file containing the RT-PCR data    The SDS21.design.txt file containing the RT-PCR data design information    In this dataset, there are 24 observations (6 treatments * 4 samples) and 24 variables. Each variable (AssayID) has 2 technical replicates in each observation. These files are available in a zipped resource file located on the Omicsoft web srver at the following URL: link  After downloading the single .zip file, unzip the file to a folder to be used for this tutorial.  With the downloaded sample data, this tutorial will cover the steps involved in:    Importing data directly from  ABI  result text files    Normalizing data using a number of statistical methods    Viewing results using the same visualization tools employed elsewhere in Array Studio",
            "title": "Downloading the SDS21 dataset"
        },
        {
            "location": "/tutorials/RTPCR/Introduction/#the-workflow-window-the-solution-explorer",
            "text": "When Array Studio is first installed, it will look similar to what is displayed below.  If you have previously opened projects in Array Studio, you will see the  Last Opened Projects  window. If so, just click cancel so that Array Studio looks similar to below.   The \"Workflow\" window should be visible on the left side of the screen. If the window is not visible, go to the  View  Menu and select  Show Workflow . Click the  Workflow  tab (next to  Solution Explorer ) and the  Workflow  window should appear similar to the screenshot below.   This window provides users, especially new users, with a  guide  to running different types of analysis. Click the Workflow dropdown box now and select  RT-PCR .  Notice that the RT-PCR Workflow is separated into different categories, including  Getting started ,  Manage data ,  Preprocess ,  Quality control ,  Statistical inference , and Pattern recognition . While it is possible to access all of these functions via the menu commands in Array Studio, the workflows are designed to make it easier for the new users to work through their data.  The first section of the RT-PCR Workflow is the  Getting Started  section. In this section, it is suggested that the user either create a new project or open a previously created project.  To create a new project, click the  New Project  button in the Workflow, or the  New  button on the toolbar, or go to the  File  Menu, then click  New Local Project . This opens the  New Project  window.  Note : For the purposes of this tutorial, we will do the analysis under  Local Project . However, this module can also be performed under  Server  mode, by simply clicking  File | New Server Project  or  New | New Server Project   Array Studio  allows the user to create two different project types:    A simple project, in which all the project is saved in a single file (recommended for microarray and\n    RT-PCR projects).    A distributed project, where data is saved in separate files (recommended for exon array, CNV,\n    or genotyping projects).    Since this project involves an RT-PCR project, choose  Create a simple project  now. Then, click the  Browse  button to select a location and name for the project. Once this is complete, click  OK  to continue.  Switch to the  Solution Explorer  by clicking on the  Solution Explorer  tab, which should be found at the bottom of the  Workflow Window . If the  Solution Explorer  tab is not visible, open it by going to the  View Menu | Show Solution Explorer .   The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).",
            "title": "The Workflow Window/ The Solution Explorer"
        },
        {
            "location": "/tutorials/RTPCR/Manage_RT-PCR_Raw_Data/",
            "text": "Manage RT-PCR Raw Data\n\u00b6\n\n\nAt this point, we are ready to add RT-PCR data to the \nSolution Explorer\n. This can be done in a variety of ways, but the easiest way is to first switch back to the \nWorkflow\n \nWindow\n, by selecting the \nWorkflow\n tab at the bottom of the \nSolution Explorer\n. Alternatively, go to \nView Menu | Show Workflow\n to show the \nWorkflow Window\n.\n\n\nRT-PCR data can be imported directly from \"ABI SDS 2.x\", \"Roche LC480\" and  BioMark  exported text files. The module \nManage RT-PCR raw data\n can take any number of these text files and convert them to a format suitable for the \nImport RT-PCR Wizard\n (for normalizing and importing RT-PCR data into Array Studio).\n\n\n\n\nWhen selected, this opens the Manage RT-PCR Raw Data window, as shown below:\n\n\n\n\nInitially, this will show a blank main window, as well as a section for organizing the plates (initially will just show an \"All plates\" folder with nothing in it). Go to the \nFile\n menu and select \nAdd Plate File(s)\n to begin the process of importing RT-PCR data.\n\n\n\n\nThis will open the \nImport RT-PCR Plates\n window\n\n\n\n\nThe first priority for this screen is to add plate files. This can be accomplished by selecting the \nPlate type\n to \nABI SDS 2x\n and clicking the \nAdd\n button.\n\n\nThis opens a window to select your plate file. Choose the \"sds21.txt\" file you downloaded earlier in this tutorial.\n\n\n\n\nOnce the files have been added to the \nFile name(s)\n section, information in the files is automatically extracted. Clicking on an individual plate file shows a preview of that file in the \nPreview\n box. This allows the user to see if the correct plate files were imported, and also helps to set the \nOptions\n section.\n\n\n\n\nIn general, you should pay particular attention to the options on the right, including \nPlateID column\n, \nWell column\n, \nSampleID column\n, \nAssayID column\n, \nCt/Cp column\n and \nAbundance column\n.\nSince there is no abundance information in this file, the abundance column indicates \n(none)\n, while other information is extracted automatically from the file. By default, undetermined values are set to 40, but users can \nSet undetermined value to\n 35, 40 or missing. When finished, click the \nOK\n button to return to the \nManage RT-PCR Raw Data\n window to proceed to the next step.\n\n\nOnce plates have been added to the \nManage RT-PCR Raw Data\n window, they will be organized in the left-most box. Notice in the example below that there are three plate files.\n\n\n\n\nIf data needs to be edited at this point (i.e. editing Sample Names, AssayID, etc.) this can be done at this step. To exclude a particular data point, change the \nInclude\n column from \nY\n to \nN\n. Once finished, select from the menu \nFile | Save Raw Data\n to save the data.\n\n\n\n\nThe imported raw data will be saved as an Omicsoft RT-PCR raw data (.taqman) file, which can be uploaded anytime in the future through \nImport RT-PCR Wizard\n.\n\n\n\n\nNow that the raw data has been successfully saved, we can proceed to the \nImport RT-PCR Wizard\n to finish the normalization and importing of the data as a regular Array Studio dataset.",
            "title": "Manage RT-PCR Raw Data"
        },
        {
            "location": "/tutorials/RTPCR/Manage_RT-PCR_Raw_Data/#manage-rt-pcr-raw-data",
            "text": "At this point, we are ready to add RT-PCR data to the  Solution Explorer . This can be done in a variety of ways, but the easiest way is to first switch back to the  Workflow   Window , by selecting the  Workflow  tab at the bottom of the  Solution Explorer . Alternatively, go to  View Menu | Show Workflow  to show the  Workflow Window .  RT-PCR data can be imported directly from \"ABI SDS 2.x\", \"Roche LC480\" and  BioMark  exported text files. The module  Manage RT-PCR raw data  can take any number of these text files and convert them to a format suitable for the  Import RT-PCR Wizard  (for normalizing and importing RT-PCR data into Array Studio).   When selected, this opens the Manage RT-PCR Raw Data window, as shown below:   Initially, this will show a blank main window, as well as a section for organizing the plates (initially will just show an \"All plates\" folder with nothing in it). Go to the  File  menu and select  Add Plate File(s)  to begin the process of importing RT-PCR data.   This will open the  Import RT-PCR Plates  window   The first priority for this screen is to add plate files. This can be accomplished by selecting the  Plate type  to  ABI SDS 2x  and clicking the  Add  button.  This opens a window to select your plate file. Choose the \"sds21.txt\" file you downloaded earlier in this tutorial.   Once the files have been added to the  File name(s)  section, information in the files is automatically extracted. Clicking on an individual plate file shows a preview of that file in the  Preview  box. This allows the user to see if the correct plate files were imported, and also helps to set the  Options  section.   In general, you should pay particular attention to the options on the right, including  PlateID column ,  Well column ,  SampleID column ,  AssayID column ,  Ct/Cp column  and  Abundance column .\nSince there is no abundance information in this file, the abundance column indicates  (none) , while other information is extracted automatically from the file. By default, undetermined values are set to 40, but users can  Set undetermined value to  35, 40 or missing. When finished, click the  OK  button to return to the  Manage RT-PCR Raw Data  window to proceed to the next step.  Once plates have been added to the  Manage RT-PCR Raw Data  window, they will be organized in the left-most box. Notice in the example below that there are three plate files.   If data needs to be edited at this point (i.e. editing Sample Names, AssayID, etc.) this can be done at this step. To exclude a particular data point, change the  Include  column from  Y  to  N . Once finished, select from the menu  File | Save Raw Data  to save the data.   The imported raw data will be saved as an Omicsoft RT-PCR raw data (.taqman) file, which can be uploaded anytime in the future through  Import RT-PCR Wizard .   Now that the raw data has been successfully saved, we can proceed to the  Import RT-PCR Wizard  to finish the normalization and importing of the data as a regular Array Studio dataset.",
            "title": "Manage RT-PCR Raw Data"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/",
            "text": "Import RT-PCR Wizard\n\u00b6\n\n\nThe \nImport RT-PCR Wizard\n can be used to walk the user through the process of importing and normalizing data. It can be opened via the \nAdd RT-PCR Data\n menu item, or through the \nManage RT-PCR Raw Data\n menu (after adding plate files).\n\n\nClick the \nFile | Import RT-PCR Wizard\n to continue:\n\n\n\n\nAt this point, the user is asked to choose an RT-PCR Value source. Options include\nusing the \nCt/Cp values\n, using the \nabundance values\n, or using \nany available abundance values and converting Ct/Cp to abundance where abundance is not available\n. In this tutorial, since the imported plate file did not contain abundances, choose the first option and click \nOK\n now:\n\n\n\n\nThe \nImport RT-PCR Wizard\n is now displayed and contains two main sections. On the left is the workflow section. The Workflow section shows the user on which step of the \nImport RT-PCR Wizard\n the user is working. Initially, this will be the \nImport data\n step, as shown below but will be updated throughout the completion of the wizard. Also, clicking the \nWorkflow\n button will allow the user to save the workflow to return at another time.\n\n\n\n\nArray Studio supports importing data from the following formats:\n\n\n\n\n\n\nStandard format (one data point per row)-For this format, Data should be a table containing exactly 7 columns, including a row header column. This table should include the following columns #, PlateID, Well, AssayID, SampleID, Value, and Include. This is the format used in Tools | Data | Manage Taqman Raw Data.\n\n\n\n\n\n\nTall skinny data (one data point per row)- For this format, data should be in a table where each row contains the information for a well, and may also include other descriptive information for the sample and assay.\n\n\n\n\n\n\nTable data (one sample per row)- For this format, data should be in a table where each row contains the information for all the assays and may include other descriptive information for the sample.\n\n\n\n\n\n\nTable data (one gene per row) - For this format, data should be in a table where each row contains the information for all the genes and may include other descriptive information for the assay.\n\n\n\n\n\n\nBecause the data was imported using the \nManage RT-PCR Raw Data\n module, most of the options on this screen will be filled in by detecting the file automatically.\n\n\nThe only option that could possibly be in need of changing at this stage is the \nRemove assays with no data points\n and \nRemove samples with no data points\n options.\n\n\nThe user also has the option to import the original CT data into the project. This is unselected by default.\n\n\nUses can also import QuantStudio RT-PCR data.\n\n\nBelow is an example QuantStudio file\n\n\n\n\nAs one row is for one data point, the data can be imported as Tall Skinny Data format.\n\n\n\n\n\n\nThen specify each column\n\n\n\n\nUses can also import TaqMan hPSC Scorecard data, formatted as below:\n\n\n\n\nThe data can be imported as Table format\n\n\n\n\n\n\nSelect the \nNext\n button at the bottom of the window\n\n\nPreview Data\n\u00b6\n\n\nThe\n\nWorkflow\n frame of the \nImport RT-PCR Wizard\n window now shows that we have advanced to the \nPreview data\n step.\n\n\n\n\nThe right side frame contains statistics for the data being imported, as well as visualizations (Heatmap Table tab) of the data. Samples can be removed in this screen by clicking on sample IDs on the column header and clicking on \nRemove selected samples\n option. Notice that number of sample selected will be updated to reflect how many you have selected.\n\n\nIndividual genes can also be deleted by first clicking on the gene ID (header of the row) and clicking on \nRemove selected assays\n.\n\n\n\n\nClick the \nHeatmapTable\n tab to see the heatmap view of the data.\n\n\n\n\nThis shows a Heatmap view of the gene abundance in different samples. Any missing data points will be a yellow color. The table and heatmap views are fully customizable by selecting the \nCustomize View\n option.\n\n\n\n\nThis will return the \nCustomize View\n window which contains multiple tabs (\nTask\n, \nVariable\n, and \nObservation\n) for customization - these are similar to the options available under \nView Controller\n in the Microarray tutorial. These can be used to format the display options of the table and heatmap views, as well as filter for specific samples or assays.\n\n\n\n\nThrough the preview step, now we have made sure that the imported data is correct. Click the \nNext\n button to advance to the next step.\n\n\nAttach Design and Annotation\n\u00b6\n\n\nThis brings up the \nAttach design/annotation\n step as indicated in the \nWorkflow\n section. Your design table will have been created in advance, and should contain each sample in your dataset in a row with the different design annotations in each column. For this particular dataset, a file has already been created that contains the name of each sample, and a treatment column containing the treatment each sample belongs to.\n\n\nClick the \nImport\n button to open the already saved design table:\n\n\n\n\nDesign tables can be imported using a number of different formats. Choose \ntab delimited file\n now and click \nOK\n.\n\n\n\n\nThe design table was saved as \nsds21.design.txt\n in the same directory as the data file. Select this file now:\n\n\n\n\nOnce the design file is imported, the design information will be automatically extracted into the biological grouping box.\n\n\n\n\nThe user should select the column that represents the biological grouping of their design. For the purpose of this tutorial, select \nTreatment\n.\n\n\nClick on the \nNext\n button to advance to the next step.\n\n\nCombine Technical Replicates\n\u00b6\n\n\nThe \nCombine technical replicates\n is the next step in the \nWorkflow\n frame.\n\n\n\n\nOn the right side frame, the user can visualize the technical replicates, auto-filter out \"bad\" replicates as well as manually filter the replicates. Finally, the user can specify the combination method for the replicates (Mean, Geometric Mean, or Median).\n\n\nClick the \nAuto filter\n option at the top of the frame. This will return the \nAuto filter\n window:\n\n\n\n\nThe \nAuto Filter\n allows the user to automatically filter the technical replicates based on these\ncriteria:\n\n\n\n\n\n\nExclude data point if value is greater than the specified value.\n\n\n\n\n\n\nExclude data points if value is less than the specified value.\n\n\n\n\n\n\nExclude the entire cell if the range of the cell is greater than the specified value. For abundance data, range is defined as log2(max/min). For Ct/Cp data, range is defined as max-min.\n\n\n\n\n\n\nExclude outlier data points based on Grubb's test - Can be used for filtering based on technical replicates (minimum of 3 replicates required). See\n    \nlink\n\n    for more details.\n\n\n\n\n\n\nExclude the whole cell if mean is greater than the specified value. For abundance data, mean is defined as mean(log2(value). For Ct/Cp data, range is defined as mean(value).\n\n\n\n\n\n\nExclude the whole cell if SEM (Standard error of the mean) is greater than the specified value.\n\n\n\n\n\n\nKeep the default settings and click on \nOK\n. This will generate a new tab Replicate.Summary Table, which summarizes the 2 technical replicates for each variable (AssayID) by range, mean, SEM (Standard error of the mean). Individual points can be selected for exclusion in this table as well.\n\n\n\n\nThe scatter view will highlight data points that are set as missing by the auto filter. Switch to the \nScatter\n tab now. Each chart shows the 24 points (24 observations) for one variable. There are 24 variables (genes) in total, so there are 24 charts. Users can scroll up and down to visualize each chart. Additional charts can be displayed in the same window by choosing the window size option on the toolbar. Each data point on the chart is the average of the 2 replicates of this gene in each observation.\n\n\n\n\nReplicates that have either been selected by the \nAuto Filter\n or manually selected will be highlighted (red). Notice that one particular gene (Control Ribosomal 18s) appears to have a large number of data points that are highlighted. This is due to the \nAuto Filter\n attempting to exclude data points with a Ct value less than 10.\n\n\nTo see which 45 points were selected in the text file, click the option labeled \n45 selected and set as missing\n. This will open up a text file showing the 45 excluded data points:\n\n\n\n\nThe last step in combining technical replicates is choosing the combination method (bottom of window). The available methods include taking the \nMean\n, \nGeometric mean\n or \nMedian\n of the technical replicates. For the purpose of this demonstration, we will use the mean which is the default option.\n\n\n\n\nClick on \nNext\n will advance to the next step: \nHandle missing data\n.\n\n\nHandle Missing Data\n\u00b6\n\n\nThe \nHandle missing Data\n step provides the user with two views to visualize the missing data. In addition, selected missing data points can be replaced with a value of the user's choosing (35 by default).\n\n\n\n\nProceed to the next step by clicking on \nNext\n.\n\n\nData Transformation\n\u00b6\n\n\nThe \nData transformation\n provides user several options for the data transformation.\n\n\n\n\nIf the data imported contains CT values, these values must be converted to abundance values. An editable formula is given for the conversion of these values as indicated above. The user has the options (enabled by default) to perform a log2 transformation on the data and to calculate relative abundance or relative quantification (RQ). For this demonstration, please choose the first option.\n\n\n\n\nClick on Next to proceed to the next step \nData Normalization\n.\n\n\nData Normalization\n\u00b6\n\n\n\n\nThere are multiple methods available for normalizing theRT-PCR data:\n\n\n\n\n\n\nBy using \nAnalysis of Covariance (the default option)\n, you\n    can use one or more housekeeping genes to compute a robust score and use this score as a covariate to adjust other genes. This method is statistically sound and the user has the best control on the process.\n\n\n\n\n\n\nBy using\n    \nSimple housekeeper normalization\n, you can compute a robust score for all of the housekeepers as the normalizer. Missing data will be excluded from the calculation\n    if simple summarization (e.g. mean) is used.\n\n\n\n\n\n\nBy using\n    \nGlobal normalization\n, you can compute\n    the median of all the assays as the normalizer. Missing data will be excluded from the median calculation.\n\n\n\n\n\n\nOptions to calculate the normalizer:\n\n\n\n\n\n\nChoose the Summarization method for normalizer calculation.\n\n\n\n\n\n\nPCA\n    -First, a PCA analysis is done based on the housekeeper matrix (housekeepers were centered and scaled). Then the first component is extracted and used to approximate the data matrix. Next, for each sample, the fitted values were averaged to get a single value (normalizer) for each sample.\n\n\n\n\n\n\nMean\n\n\n\n\n\n\nMedian\n\n\n\n\n\n\n\n\n\n\nChoose \nI prefer to use the full model\n if you just need the software to calculate the\n    normalizer for you (not normalizing the data). This option, when selected, will not normalize the data. It provides the normalizer value for the user but does not go through the normalization process.\n\n\n\n\n\n\nChoose \nI would like to perform a separate normalization for each group (e.g. tissue type)\n\n    if you want to specify a group by which to perform separate normalizations. For example, if the user had an experiment with different tissues types, they may want to normalize\n    within each tissue type separately. If this box is selected, the user would have to\n    choose the \nSample group column\n from the columns in design table and perform the remaining normalization steps on each group.\n\n\n\n\n\n\nFor this demonstration, please choose the first option.\n\n\n\n\nClicking on \nNext\n will proceed to the \nChoose Housekeepers\n section of the \nData Normalization\n step. If you choose \nGlobal normalization\n method, the \nChoose Housekeepers\n step will be skipped.\n\n\nHousekeeping Gene Selection\n\u00b6\n\n\nThe \nChoose housekeeper(s)\n step allows the user to specifically select the housekeeping genes that will be used for normalization:\n\n\n\n\nClicking on the \nSelect housekeepers\n button will present the \nSelect Rows\n window:\n\n\n\n\nThis brings up a list of available genes. The user can scroll to their specific housekeeper genes and use Ctrl + click to select multiple genes. Finally use the arrow button, move them to the right panel.\n\n\n\n\nFor this tutorial, select \nControl-ACTB\n, \nControl-GAPDH\n and \nControl-PPIA\n. Once the housekeepers are selected and moved to the right \nListed rows\n panel, click on \nOK\n button to proceed.\n\n\n\n\nArray Studio creates a number of different views. The first view is a summary table containing information for each of the housekeepers, including \nMissing samples, mean, range of values, standard deviation of values, FtestPvalue (based on biological group), Min, Max and Max/Min\n.\n\n\n\n\nNotice that the Control-GAPDH row is colored red to warn the user that the one-way ANOVA test Pvalue falls below 0.1 (housekeeper gene has significant different intensity in the 24 treatment groups. The user could choose to remove this housekeeper and recalculate but for the purpose of this tutorial, leave this as is.\n\n\nSwitch to the \nVariable\n tab.\n\n\nThe \nVariableView\n allows the user to see a Scatter View of each housekeeper gene for each of the biological groups (from \nAttach design\n step). There are actually 4 data points for each biological group, but they have similar abundance and group close to one other. Click on \nCustomize View\n, choose \nChange Symbol Properties\n and use the \nJitter\n option to get a better visualization of the 4 points. This can be used to manually eliminate \"suspect\" data points from the normalization calculations, by clicking directly on the blue data points and checking the \nMark selected points as missing\n option on top right.\n\n\n\n\nSwitch to \nData\n tab, the next view for visualization of the housekeepers. This table lists values for all the data points in \nVariable\n view.\n\n\n\n\nSwitch to \nProfile\n tab now to see the \nProfile view\n, which show the values from \nData\n table.\n\n\n\n\nWith the visualization and selection of housekeepers complete, click \nNext\n now to continue. This will bring up the \nShow Normalizer\n step.\n\n\nShow Normalizer\n\u00b6\n\n\nThe \nShow Normalizer\n includes several views of the normalizer, the first being a table, listing the 24 normalizers calculated for each of the 24 observations.\n\n\n\n\nClick the \nProfile\n tab now to see the profile view for the normalizers  values in 24 observations. The Normalizer is shown in blue at the bottom, while the 3 housekeepers are shown in different colors at the top. User can check the legend by clicking on \nCustomize view\n on top right and clicking on \nLegend\n tab.\n\n\n\n\nClick the \nVariable\n tab now to see the variable view. Like the \nVariable\n view in previous step, data points are organized by biological group. On every chart there are 4 data points for each group, and using \nJitter\n can separate them on the chart.\n\n\n\n\nClick on \nNext\n to continue to the next section of the \nData normalization\n step.\n\n\nAnalysis of Covariance\n\u00b6\n\n\nIn \nAnalysis of Covariance\n step the user needs to set the model to be used for the normalization. By default, the previously calculated normalizer is included in the model:\n\n\n\n\nClick the option \nSpecify full model\n now to specify the model. This opens up the \nSpecify Linear Model\n window. This is the same window used in the \nGeneral Linear Model\n analysis module. More details on how to use this window can be found in the \nMicroarray Tutorial\n.\nFor the purpose of this tutorial, our model will consist of the normalizer and treatment. Select \nTreatment\n from the left side of the window and then click \nAdd\n to add it as one of the terms in the model. Notice that for categorical factors, user should make sure that its \nClass\n box is checked.\n\n\n\n\nClick \nOK\n button to finish specifying model and return to the \nAnalysis of Covariance\n window.\n\n\nAt this point, the model is ready and we just need to run it. Notice that the model now shows \nNormalizer + Treatment\n. Advanced options for this section include a special outlier filtering option that is enabled by default. Click \nRun Model\n now to run the model.\n\n\n\n\nResults are returned in the window above, which is empty before running the model.\nThe summary note indicates that there are 20 out of 21 assays (21 genes without counting the 3 housekeepers) that have improved \nCEFR\n (Covariate Efficiency Factor Residual). These 20 genes showed smaller RMSE (Root mean square error) in model with normalizer than that without normalizer. The CEFR is calculated by the following formula:\n\n\n\n\nThe summary note also indicates that there are 3 outliers detected and marked as missing. This summary table shows the number of outliers removed (outlier filtration can be\nspecified in the advanced options), as well as a coefficient for each gene and PValue indicating whether the gene was improved due to normalization. This is used in conjunction with the calculated \nCEFR\n value to give the user an idea of how well the normalization went. This table can be opened in Excel or as a text file and saved for later use if interested. After looking at the results of the normalization, click the \nNext\n button to continue to the next section of \nData normalization\n.\n\n\nShow Residuals\n\u00b6\n\n\nThe \nShow Residuals\n section provides more detailed statistical views of the results of the normalization.\n\n\nFor each assay (gene), there are \nObserved vs. Fitted\n plot, \nObserved\n plot, \nFitted\n plot, \nStudentized\n plot, \nJackknife\n plot. The first 3 views plot observed and fitted values and the last 2 plot Studentized residuals and Jackknife residuals.\n\n\nObserved vs. Fitted\n plot:\n\n\n\n\nSwitch the tab to see \nObserved\n plot:\n\n\n\n\nSwitch to the \nFitted\n plot:\n\n\n\n\nSwitch to the \nStudentized\n plot:\n\n\n\n\nSwitch to the \nJackknife\n plot:\n\n\n\n\nClick on \nNext\n to go to the \nPreview data\n step.\n\n\nPreview Data\n\u00b6\n\n\nThe \nPreview Data\n displays a preview of the data to be imported.\nMissing values are indicated by dots\n\n\n.\n\n\n.\n\n\n\n\nClick \nNext\n to go to the final section of the \nImport RT-PCR Wizard\n.\n\n\nFinish\n\u00b6\n\n\n\n\nClick on \nFinish\n at the bottom right of the window. This will complete the Import RT-PCR Wizard and will import the data shown in \nPreview Data\n step into Array Studio.\n\n\nThe data has now been completely imported into Array Studio as \nRT-PCR\n data listed under \nOmic Data\n folder of the \nSolution Explorer\n.\n\n\n\n\nLike the \nMicroarray\n data in Microarray tutorial, this data has design table and annotation table.\nThe 24 normalizer values are listed in the design table for each of the 24 observations.",
            "title": "Import RT-PCR Wizard"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#import-rt-pcr-wizard",
            "text": "The  Import RT-PCR Wizard  can be used to walk the user through the process of importing and normalizing data. It can be opened via the  Add RT-PCR Data  menu item, or through the  Manage RT-PCR Raw Data  menu (after adding plate files).  Click the  File | Import RT-PCR Wizard  to continue:   At this point, the user is asked to choose an RT-PCR Value source. Options include\nusing the  Ct/Cp values , using the  abundance values , or using  any available abundance values and converting Ct/Cp to abundance where abundance is not available . In this tutorial, since the imported plate file did not contain abundances, choose the first option and click  OK  now:   The  Import RT-PCR Wizard  is now displayed and contains two main sections. On the left is the workflow section. The Workflow section shows the user on which step of the  Import RT-PCR Wizard  the user is working. Initially, this will be the  Import data  step, as shown below but will be updated throughout the completion of the wizard. Also, clicking the  Workflow  button will allow the user to save the workflow to return at another time.   Array Studio supports importing data from the following formats:    Standard format (one data point per row)-For this format, Data should be a table containing exactly 7 columns, including a row header column. This table should include the following columns #, PlateID, Well, AssayID, SampleID, Value, and Include. This is the format used in Tools | Data | Manage Taqman Raw Data.    Tall skinny data (one data point per row)- For this format, data should be in a table where each row contains the information for a well, and may also include other descriptive information for the sample and assay.    Table data (one sample per row)- For this format, data should be in a table where each row contains the information for all the assays and may include other descriptive information for the sample.    Table data (one gene per row) - For this format, data should be in a table where each row contains the information for all the genes and may include other descriptive information for the assay.    Because the data was imported using the  Manage RT-PCR Raw Data  module, most of the options on this screen will be filled in by detecting the file automatically.  The only option that could possibly be in need of changing at this stage is the  Remove assays with no data points  and  Remove samples with no data points  options.  The user also has the option to import the original CT data into the project. This is unselected by default.  Uses can also import QuantStudio RT-PCR data.  Below is an example QuantStudio file   As one row is for one data point, the data can be imported as Tall Skinny Data format.    Then specify each column   Uses can also import TaqMan hPSC Scorecard data, formatted as below:   The data can be imported as Table format    Select the  Next  button at the bottom of the window",
            "title": "Import RT-PCR Wizard"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#preview-data",
            "text": "The Workflow  frame of the  Import RT-PCR Wizard  window now shows that we have advanced to the  Preview data  step.   The right side frame contains statistics for the data being imported, as well as visualizations (Heatmap Table tab) of the data. Samples can be removed in this screen by clicking on sample IDs on the column header and clicking on  Remove selected samples  option. Notice that number of sample selected will be updated to reflect how many you have selected.  Individual genes can also be deleted by first clicking on the gene ID (header of the row) and clicking on  Remove selected assays .   Click the  HeatmapTable  tab to see the heatmap view of the data.   This shows a Heatmap view of the gene abundance in different samples. Any missing data points will be a yellow color. The table and heatmap views are fully customizable by selecting the  Customize View  option.   This will return the  Customize View  window which contains multiple tabs ( Task ,  Variable , and  Observation ) for customization - these are similar to the options available under  View Controller  in the Microarray tutorial. These can be used to format the display options of the table and heatmap views, as well as filter for specific samples or assays.   Through the preview step, now we have made sure that the imported data is correct. Click the  Next  button to advance to the next step.",
            "title": "Preview Data"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#attach-design-and-annotation",
            "text": "This brings up the  Attach design/annotation  step as indicated in the  Workflow  section. Your design table will have been created in advance, and should contain each sample in your dataset in a row with the different design annotations in each column. For this particular dataset, a file has already been created that contains the name of each sample, and a treatment column containing the treatment each sample belongs to.  Click the  Import  button to open the already saved design table:   Design tables can be imported using a number of different formats. Choose  tab delimited file  now and click  OK .   The design table was saved as  sds21.design.txt  in the same directory as the data file. Select this file now:   Once the design file is imported, the design information will be automatically extracted into the biological grouping box.   The user should select the column that represents the biological grouping of their design. For the purpose of this tutorial, select  Treatment .  Click on the  Next  button to advance to the next step.",
            "title": "Attach Design and Annotation"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#combine-technical-replicates",
            "text": "The  Combine technical replicates  is the next step in the  Workflow  frame.   On the right side frame, the user can visualize the technical replicates, auto-filter out \"bad\" replicates as well as manually filter the replicates. Finally, the user can specify the combination method for the replicates (Mean, Geometric Mean, or Median).  Click the  Auto filter  option at the top of the frame. This will return the  Auto filter  window:   The  Auto Filter  allows the user to automatically filter the technical replicates based on these\ncriteria:    Exclude data point if value is greater than the specified value.    Exclude data points if value is less than the specified value.    Exclude the entire cell if the range of the cell is greater than the specified value. For abundance data, range is defined as log2(max/min). For Ct/Cp data, range is defined as max-min.    Exclude outlier data points based on Grubb's test - Can be used for filtering based on technical replicates (minimum of 3 replicates required). See\n     link \n    for more details.    Exclude the whole cell if mean is greater than the specified value. For abundance data, mean is defined as mean(log2(value). For Ct/Cp data, range is defined as mean(value).    Exclude the whole cell if SEM (Standard error of the mean) is greater than the specified value.    Keep the default settings and click on  OK . This will generate a new tab Replicate.Summary Table, which summarizes the 2 technical replicates for each variable (AssayID) by range, mean, SEM (Standard error of the mean). Individual points can be selected for exclusion in this table as well.   The scatter view will highlight data points that are set as missing by the auto filter. Switch to the  Scatter  tab now. Each chart shows the 24 points (24 observations) for one variable. There are 24 variables (genes) in total, so there are 24 charts. Users can scroll up and down to visualize each chart. Additional charts can be displayed in the same window by choosing the window size option on the toolbar. Each data point on the chart is the average of the 2 replicates of this gene in each observation.   Replicates that have either been selected by the  Auto Filter  or manually selected will be highlighted (red). Notice that one particular gene (Control Ribosomal 18s) appears to have a large number of data points that are highlighted. This is due to the  Auto Filter  attempting to exclude data points with a Ct value less than 10.  To see which 45 points were selected in the text file, click the option labeled  45 selected and set as missing . This will open up a text file showing the 45 excluded data points:   The last step in combining technical replicates is choosing the combination method (bottom of window). The available methods include taking the  Mean ,  Geometric mean  or  Median  of the technical replicates. For the purpose of this demonstration, we will use the mean which is the default option.   Click on  Next  will advance to the next step:  Handle missing data .",
            "title": "Combine Technical Replicates"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#handle-missing-data",
            "text": "The  Handle missing Data  step provides the user with two views to visualize the missing data. In addition, selected missing data points can be replaced with a value of the user's choosing (35 by default).   Proceed to the next step by clicking on  Next .",
            "title": "Handle Missing Data"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#data-transformation",
            "text": "The  Data transformation  provides user several options for the data transformation.   If the data imported contains CT values, these values must be converted to abundance values. An editable formula is given for the conversion of these values as indicated above. The user has the options (enabled by default) to perform a log2 transformation on the data and to calculate relative abundance or relative quantification (RQ). For this demonstration, please choose the first option.   Click on Next to proceed to the next step  Data Normalization .",
            "title": "Data Transformation"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#data-normalization",
            "text": "There are multiple methods available for normalizing theRT-PCR data:    By using  Analysis of Covariance (the default option) , you\n    can use one or more housekeeping genes to compute a robust score and use this score as a covariate to adjust other genes. This method is statistically sound and the user has the best control on the process.    By using\n     Simple housekeeper normalization , you can compute a robust score for all of the housekeepers as the normalizer. Missing data will be excluded from the calculation\n    if simple summarization (e.g. mean) is used.    By using\n     Global normalization , you can compute\n    the median of all the assays as the normalizer. Missing data will be excluded from the median calculation.    Options to calculate the normalizer:    Choose the Summarization method for normalizer calculation.    PCA\n    -First, a PCA analysis is done based on the housekeeper matrix (housekeepers were centered and scaled). Then the first component is extracted and used to approximate the data matrix. Next, for each sample, the fitted values were averaged to get a single value (normalizer) for each sample.    Mean    Median      Choose  I prefer to use the full model  if you just need the software to calculate the\n    normalizer for you (not normalizing the data). This option, when selected, will not normalize the data. It provides the normalizer value for the user but does not go through the normalization process.    Choose  I would like to perform a separate normalization for each group (e.g. tissue type) \n    if you want to specify a group by which to perform separate normalizations. For example, if the user had an experiment with different tissues types, they may want to normalize\n    within each tissue type separately. If this box is selected, the user would have to\n    choose the  Sample group column  from the columns in design table and perform the remaining normalization steps on each group.    For this demonstration, please choose the first option.   Clicking on  Next  will proceed to the  Choose Housekeepers  section of the  Data Normalization  step. If you choose  Global normalization  method, the  Choose Housekeepers  step will be skipped.",
            "title": "Data Normalization"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#housekeeping-gene-selection",
            "text": "The  Choose housekeeper(s)  step allows the user to specifically select the housekeeping genes that will be used for normalization:   Clicking on the  Select housekeepers  button will present the  Select Rows  window:   This brings up a list of available genes. The user can scroll to their specific housekeeper genes and use Ctrl + click to select multiple genes. Finally use the arrow button, move them to the right panel.   For this tutorial, select  Control-ACTB ,  Control-GAPDH  and  Control-PPIA . Once the housekeepers are selected and moved to the right  Listed rows  panel, click on  OK  button to proceed.   Array Studio creates a number of different views. The first view is a summary table containing information for each of the housekeepers, including  Missing samples, mean, range of values, standard deviation of values, FtestPvalue (based on biological group), Min, Max and Max/Min .   Notice that the Control-GAPDH row is colored red to warn the user that the one-way ANOVA test Pvalue falls below 0.1 (housekeeper gene has significant different intensity in the 24 treatment groups. The user could choose to remove this housekeeper and recalculate but for the purpose of this tutorial, leave this as is.  Switch to the  Variable  tab.  The  VariableView  allows the user to see a Scatter View of each housekeeper gene for each of the biological groups (from  Attach design  step). There are actually 4 data points for each biological group, but they have similar abundance and group close to one other. Click on  Customize View , choose  Change Symbol Properties  and use the  Jitter  option to get a better visualization of the 4 points. This can be used to manually eliminate \"suspect\" data points from the normalization calculations, by clicking directly on the blue data points and checking the  Mark selected points as missing  option on top right.   Switch to  Data  tab, the next view for visualization of the housekeepers. This table lists values for all the data points in  Variable  view.   Switch to  Profile  tab now to see the  Profile view , which show the values from  Data  table.   With the visualization and selection of housekeepers complete, click  Next  now to continue. This will bring up the  Show Normalizer  step.",
            "title": "Housekeeping Gene Selection"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#show-normalizer",
            "text": "The  Show Normalizer  includes several views of the normalizer, the first being a table, listing the 24 normalizers calculated for each of the 24 observations.   Click the  Profile  tab now to see the profile view for the normalizers  values in 24 observations. The Normalizer is shown in blue at the bottom, while the 3 housekeepers are shown in different colors at the top. User can check the legend by clicking on  Customize view  on top right and clicking on  Legend  tab.   Click the  Variable  tab now to see the variable view. Like the  Variable  view in previous step, data points are organized by biological group. On every chart there are 4 data points for each group, and using  Jitter  can separate them on the chart.   Click on  Next  to continue to the next section of the  Data normalization  step.",
            "title": "Show Normalizer"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#analysis-of-covariance",
            "text": "In  Analysis of Covariance  step the user needs to set the model to be used for the normalization. By default, the previously calculated normalizer is included in the model:   Click the option  Specify full model  now to specify the model. This opens up the  Specify Linear Model  window. This is the same window used in the  General Linear Model  analysis module. More details on how to use this window can be found in the  Microarray Tutorial .\nFor the purpose of this tutorial, our model will consist of the normalizer and treatment. Select  Treatment  from the left side of the window and then click  Add  to add it as one of the terms in the model. Notice that for categorical factors, user should make sure that its  Class  box is checked.   Click  OK  button to finish specifying model and return to the  Analysis of Covariance  window.  At this point, the model is ready and we just need to run it. Notice that the model now shows  Normalizer + Treatment . Advanced options for this section include a special outlier filtering option that is enabled by default. Click  Run Model  now to run the model.   Results are returned in the window above, which is empty before running the model.\nThe summary note indicates that there are 20 out of 21 assays (21 genes without counting the 3 housekeepers) that have improved  CEFR  (Covariate Efficiency Factor Residual). These 20 genes showed smaller RMSE (Root mean square error) in model with normalizer than that without normalizer. The CEFR is calculated by the following formula:   The summary note also indicates that there are 3 outliers detected and marked as missing. This summary table shows the number of outliers removed (outlier filtration can be\nspecified in the advanced options), as well as a coefficient for each gene and PValue indicating whether the gene was improved due to normalization. This is used in conjunction with the calculated  CEFR  value to give the user an idea of how well the normalization went. This table can be opened in Excel or as a text file and saved for later use if interested. After looking at the results of the normalization, click the  Next  button to continue to the next section of  Data normalization .",
            "title": "Analysis of Covariance"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#show-residuals",
            "text": "The  Show Residuals  section provides more detailed statistical views of the results of the normalization.  For each assay (gene), there are  Observed vs. Fitted  plot,  Observed  plot,  Fitted  plot,  Studentized  plot,  Jackknife  plot. The first 3 views plot observed and fitted values and the last 2 plot Studentized residuals and Jackknife residuals.  Observed vs. Fitted  plot:   Switch the tab to see  Observed  plot:   Switch to the  Fitted  plot:   Switch to the  Studentized  plot:   Switch to the  Jackknife  plot:   Click on  Next  to go to the  Preview data  step.",
            "title": "Show Residuals"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#preview-data_1",
            "text": "The  Preview Data  displays a preview of the data to be imported.\nMissing values are indicated by dots  .  .   Click  Next  to go to the final section of the  Import RT-PCR Wizard .",
            "title": "Preview Data"
        },
        {
            "location": "/tutorials/RTPCR/Import_RT-PCR_Wizard/#finish",
            "text": "Click on  Finish  at the bottom right of the window. This will complete the Import RT-PCR Wizard and will import the data shown in  Preview Data  step into Array Studio.  The data has now been completely imported into Array Studio as  RT-PCR  data listed under  Omic Data  folder of the  Solution Explorer .   Like the  Microarray  data in Microarray tutorial, this data has design table and annotation table.\nThe 24 normalizer values are listed in the design table for each of the 24 observations.",
            "title": "Finish"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/",
            "text": "Downstream Analysis of RT-PCR data\n\u00b6\n\n\nBased on this \nRT-PCR\n data, downstream analysis can be applied in the same way as \nMicroarray\n data.\n\n\nHere we will introduce QC wizard, principal component analysis, general linear model, and hierarchical clustering. For more details on other downstream statistical methods, please refer to Microarray tutorial.\n\n\n\n\nTo better annotate the samples to do the downstream analysis, please first follow the below steps to parse the ID in design table to Treatment and Sample.\n\n\nFirst choose \nParse Column\n in \nAnalysis | Table\n, then select the design table\n\n\n\n\nAs treatment and sample are combined with \"-\" sign. We use \"-\" to split the columns\n\n\n\n\nThen design table will add two more columns. Double click the column name of the last column, then change it to \"Sample\"\n\n\n\n\nQC wizard\n\u00b6\n\n\nQC wizard is a quick and easy way to run multiple QC commands simultaneously. Available options are Pairwise correlation, Correlation based QC, Principal component analysis and Kernel density. From the \nWorkflow\n tab, select QC Wizard. This menu item can also be found under \nOmicdata | QC | QCWizard\n\n\n\n\nCheck \"Kernel density\" and keep all other options as default then click \"Submit\".\n\n\nThe results will show in Table and Summary folder.\n\n\nA Density plot will show in the window. It shows the RT-PCR value distribution for each sample.\n\n\n\n\nCorrelation based QC calculates Median Absolute Deviation (MAD) scores for each group. By default, the cutoff for MAD score is -5.\n\n\n\n\nFrom the scatter plot, we see that there are two blue (FAIL) points that can be considered outliers. Users have the option to remove these outlier points and under \nView Controller\n, select \"Exclude Selection\" under the \nTask\n tab. To keep the analysis simple for this tutorial we will leave these potential outliers alone, but users are encouraged to explore the results of selecting the \"Exclude Selectin\" option after the completion of this tutorial to see how it affects these analyses.\n\n\n\n\n\n\nNote\n\n\nWhen user does choose \"Exclude Selection\" option in this module, QC Analysis will be repeated on remaining samples, which can lead to additional samples failing MADScore filter.\n\n\n\n\n\n\nPcaScores will show a 2-D plot on the first and the second principal components. A Hotelling T2 ellipse with alpha level of 0.05 is also shown. From this plot, there is no outlier sample.\n\n\n\n\nThere is also a summary table that shows the average correlation in each group. As group was not selected in QC wizard, the correlation will be based on all samples. \nNote\n: \nAs outliers are excluded based on failing MADScore or PCA analyses, this correlation value will creep closer to 1 (100%)\n.\n\n\n\n\nIf user-defined options instead of default options are needed for QC analysis, users can perform each QC step, rather than QC wizard.\n\n\n\n\nPrincipal Component Analysis\n\u00b6\n\n\nAs mentioned previously, QC wizard is used to perform QC analysis with default parameters.\n\n\nHere principal component analysis has more options to change. For example, we want a 3-D plot for PCA.\n\n\n\n\nThen a 3-D plot for the first three principal components will be shown. Users can drag the plot and rotate the plot to get a better view.\n\n\nUsers can change the symbol properties to make the points color by Treatment, and make it show label ID when selected.\n\n\n\n\n\n\nThe plot shows samples do not cluster with Treatment in this data. But in some other cases the data will be clustered in some specific groups.\n\n\nIf there are obvious outlier samples, users can select the samples and choose \"Exclude Selection\". From the PCA plot, there is no outlier sample, so keep all of them.\n\n\nGeneral Linear Model\n\u00b6\n\n\nGeneral linear model is an important command to run statistical analysis on data. It allows the user to model the data on a variable-by-variable vasis. The user can specify a fixed, mixed or random model. Estimates, fold change, p-value, significant lists can be generated using this model. Using general linear model can generate more complicated statistical models than one-way ANOVA or two-way ANOVA.\n\n\nIn the next example, a general linear model on Treatment with Sample as random factor will be generated. The purpose is to find out the differentially expressed genes in treatment samples compared with DMSO control samples.\n\n\nGo to \nOmicData | Inference | General Linear Model\n or in the Workflow tab, select \nStatistical inference | General linear model\n:\n\n\n\n\nThe first step in this process will be to \"Specify Model\":\n\n\n\n\nChoose Treatment and Sample on the left (these two columns are in categorical types, so \"Class\" is checked). Then Click \"Add\" to add in the model. Check \"Random\" before Sample as we want sample as a random factor. Then click \"OK\" to finish setting up the model.\n\n\n\n\nNow the model has been set. The next step is to \"Specify Test\" (T-test and/or F-test):\n\n\n\n\nWe want to compare each treatment with DMSO. So check \"For each\" (Treatment), then compare to \"DMSO\". Then we check all the options to generate estimates, fold changes, P-values, and significant lists. Then click \"Add\"\n\n\n\n\nFor this example, F-test is not needed so we leave it as blank. In future studies, users can use \"FTest (ANOVA)\" tab to specify F-test options.\n\n\nThen click \"OK\". Now the model has been generated.\n\n\n\n\nThe next step is to change the options for the model, for example changing the cutoff of alpha-value or generating LSMean data. For this example, we just leave it as it is.\n\n\n\n\nThen click \"Submit\" to run the model.\n\n\nThe results include a report and volcano plots in \"Inference\" folder, and significant gene lists in \"List\" folder of the \nSolution Explorer\n.\n\n\nWe can change the number of plots shown in one window, and also unify the scale.\n\n\nWhen a point is selected in one plot, the corresponding point will also highlight in other plots. Details about the selected point will be in \"Detail\" window.\n\n\n\n\nAdditional view options are available in the \nView Controller\n on the right side of the user interface. For example, users can specify the X and Y-axes columns by \"Specify Columns\". Users can also specify p-value and estimate/fold change cutoff lines to better visualize and select the significant genes.\n\n\n\n\nHierarchical Clustering\n\u00b6\n\n\nThe Hierarchical Clustering command performs hierarchical clustering on data object observations and/or variables.\n\n\nFor example, we would like to see how the significant genes in the general linear model step (expressed differently in other treatments compared to DMSO) and how the samples cluster. Then in the Hierarchical clustering, we choose the significant gene list and all samples, and compute both observation and variable trees. Users can access this option by choosing in the \nWorkflow\n tab \nPattern Recognition | Hierarchical Clustering\n or the menu option \nOmicData | Pattern | Hierarchical Clustering\n:\n\n\n\n\nWe choose the significant gene lists by selecting the \"GLM LinearModel Sig10\" under the \"Customized\" Variables option. Choose the \"Compute variable tree\" and assign an Output name that will allow you recognize this customized clustering report:\n\n\n\n\nAfter clicking \"Submit\", the dendrogram will appear in the main view. Users can change the clustering normalization method by \"Specify Normalization\" in the \nView Controller | Task | Data\n.\n\n\n\n\nThere are additional customization options under the \nTask\n tab in the \nView Controller\n window. For example, we see that X-axis labels are not showing in full. We can rotate the labels for better visualization by choosing \nView Controller | Task | Properties | Change Chart Properties\n:\n\n\n\n\nWe can also add color bars for observations and variables to better see the clustering feature by selecting \nView Controller | Task | Customize | Change X-axis or Change Y-axis ColorBars\n:\n\n\n\n\n\n\nOur view has chanegd to reflect these changes. The \nColor Legend\n is in the top view of \nView Controller\n. Colors can be changed by simply right-clicking within this legend.\n\n\n\n\nFrom the dendrogram, we can see how the observations and variables cluster. However, there is not a specific pattern in this example dataset. In some other cases, you may find the samples cluster by specific factors such as gender, age, treatment, etc.\n\n\nUsers also have the option of choosing specific branches within the dendrogram to see which genes or samples cluster. Simply click on the dendrogram in the dendrogram view and only those selected branches will appear in the heat map. Additional annotations (i.e. color bars) can also be added as described above.\n\n\n\n\n|\n\n\nCongratulations! You are done with the analysis. Feel free to browse other options in the workflow to examine other features of this module. As mentioned above, users are encouraged to examine the consequences of filtering out samples (i.e. ones that did not pass MADScore filters) on subsequent steps (QC, GLM, and hierarchical clustering). Click \"Save\" to save this project. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of, with reference to RT-PCR preprocessing and analysis. Feel free to try different options along the \nImport RT-PCR Wizard\n to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.\n\n\nPlease contact Omicsoft Support (\n \nsupport@omicsoft.com\n \n) or Omicsoft Sales (\n \nsales@omicsoft.com\n \n) for sales-related questions.",
            "title": "Downstream Analysis of RT-PCR data"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#downstream-analysis-of-rt-pcr-data",
            "text": "Based on this  RT-PCR  data, downstream analysis can be applied in the same way as  Microarray  data.  Here we will introduce QC wizard, principal component analysis, general linear model, and hierarchical clustering. For more details on other downstream statistical methods, please refer to Microarray tutorial.   To better annotate the samples to do the downstream analysis, please first follow the below steps to parse the ID in design table to Treatment and Sample.  First choose  Parse Column  in  Analysis | Table , then select the design table   As treatment and sample are combined with \"-\" sign. We use \"-\" to split the columns   Then design table will add two more columns. Double click the column name of the last column, then change it to \"Sample\"",
            "title": "Downstream Analysis of RT-PCR data"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#qc-wizard",
            "text": "QC wizard is a quick and easy way to run multiple QC commands simultaneously. Available options are Pairwise correlation, Correlation based QC, Principal component analysis and Kernel density. From the  Workflow  tab, select QC Wizard. This menu item can also be found under  Omicdata | QC | QCWizard   Check \"Kernel density\" and keep all other options as default then click \"Submit\".  The results will show in Table and Summary folder.  A Density plot will show in the window. It shows the RT-PCR value distribution for each sample.   Correlation based QC calculates Median Absolute Deviation (MAD) scores for each group. By default, the cutoff for MAD score is -5.   From the scatter plot, we see that there are two blue (FAIL) points that can be considered outliers. Users have the option to remove these outlier points and under  View Controller , select \"Exclude Selection\" under the  Task  tab. To keep the analysis simple for this tutorial we will leave these potential outliers alone, but users are encouraged to explore the results of selecting the \"Exclude Selectin\" option after the completion of this tutorial to see how it affects these analyses.    Note  When user does choose \"Exclude Selection\" option in this module, QC Analysis will be repeated on remaining samples, which can lead to additional samples failing MADScore filter.    PcaScores will show a 2-D plot on the first and the second principal components. A Hotelling T2 ellipse with alpha level of 0.05 is also shown. From this plot, there is no outlier sample.   There is also a summary table that shows the average correlation in each group. As group was not selected in QC wizard, the correlation will be based on all samples.  Note :  As outliers are excluded based on failing MADScore or PCA analyses, this correlation value will creep closer to 1 (100%) .   If user-defined options instead of default options are needed for QC analysis, users can perform each QC step, rather than QC wizard.",
            "title": "QC wizard"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#principal-component-analysis",
            "text": "As mentioned previously, QC wizard is used to perform QC analysis with default parameters.  Here principal component analysis has more options to change. For example, we want a 3-D plot for PCA.   Then a 3-D plot for the first three principal components will be shown. Users can drag the plot and rotate the plot to get a better view.  Users can change the symbol properties to make the points color by Treatment, and make it show label ID when selected.    The plot shows samples do not cluster with Treatment in this data. But in some other cases the data will be clustered in some specific groups.  If there are obvious outlier samples, users can select the samples and choose \"Exclude Selection\". From the PCA plot, there is no outlier sample, so keep all of them.",
            "title": "Principal Component Analysis"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#general-linear-model",
            "text": "General linear model is an important command to run statistical analysis on data. It allows the user to model the data on a variable-by-variable vasis. The user can specify a fixed, mixed or random model. Estimates, fold change, p-value, significant lists can be generated using this model. Using general linear model can generate more complicated statistical models than one-way ANOVA or two-way ANOVA.  In the next example, a general linear model on Treatment with Sample as random factor will be generated. The purpose is to find out the differentially expressed genes in treatment samples compared with DMSO control samples.  Go to  OmicData | Inference | General Linear Model  or in the Workflow tab, select  Statistical inference | General linear model :   The first step in this process will be to \"Specify Model\":   Choose Treatment and Sample on the left (these two columns are in categorical types, so \"Class\" is checked). Then Click \"Add\" to add in the model. Check \"Random\" before Sample as we want sample as a random factor. Then click \"OK\" to finish setting up the model.   Now the model has been set. The next step is to \"Specify Test\" (T-test and/or F-test):   We want to compare each treatment with DMSO. So check \"For each\" (Treatment), then compare to \"DMSO\". Then we check all the options to generate estimates, fold changes, P-values, and significant lists. Then click \"Add\"   For this example, F-test is not needed so we leave it as blank. In future studies, users can use \"FTest (ANOVA)\" tab to specify F-test options.  Then click \"OK\". Now the model has been generated.   The next step is to change the options for the model, for example changing the cutoff of alpha-value or generating LSMean data. For this example, we just leave it as it is.   Then click \"Submit\" to run the model.  The results include a report and volcano plots in \"Inference\" folder, and significant gene lists in \"List\" folder of the  Solution Explorer .  We can change the number of plots shown in one window, and also unify the scale.  When a point is selected in one plot, the corresponding point will also highlight in other plots. Details about the selected point will be in \"Detail\" window.   Additional view options are available in the  View Controller  on the right side of the user interface. For example, users can specify the X and Y-axes columns by \"Specify Columns\". Users can also specify p-value and estimate/fold change cutoff lines to better visualize and select the significant genes.",
            "title": "General Linear Model"
        },
        {
            "location": "/tutorials/RTPCR/Downstream_Analysis_of_RT-PCR_data/#hierarchical-clustering",
            "text": "The Hierarchical Clustering command performs hierarchical clustering on data object observations and/or variables.  For example, we would like to see how the significant genes in the general linear model step (expressed differently in other treatments compared to DMSO) and how the samples cluster. Then in the Hierarchical clustering, we choose the significant gene list and all samples, and compute both observation and variable trees. Users can access this option by choosing in the  Workflow  tab  Pattern Recognition | Hierarchical Clustering  or the menu option  OmicData | Pattern | Hierarchical Clustering :   We choose the significant gene lists by selecting the \"GLM LinearModel Sig10\" under the \"Customized\" Variables option. Choose the \"Compute variable tree\" and assign an Output name that will allow you recognize this customized clustering report:   After clicking \"Submit\", the dendrogram will appear in the main view. Users can change the clustering normalization method by \"Specify Normalization\" in the  View Controller | Task | Data .   There are additional customization options under the  Task  tab in the  View Controller  window. For example, we see that X-axis labels are not showing in full. We can rotate the labels for better visualization by choosing  View Controller | Task | Properties | Change Chart Properties :   We can also add color bars for observations and variables to better see the clustering feature by selecting  View Controller | Task | Customize | Change X-axis or Change Y-axis ColorBars :    Our view has chanegd to reflect these changes. The  Color Legend  is in the top view of  View Controller . Colors can be changed by simply right-clicking within this legend.   From the dendrogram, we can see how the observations and variables cluster. However, there is not a specific pattern in this example dataset. In some other cases, you may find the samples cluster by specific factors such as gender, age, treatment, etc.  Users also have the option of choosing specific branches within the dendrogram to see which genes or samples cluster. Simply click on the dendrogram in the dendrogram view and only those selected branches will appear in the heat map. Additional annotations (i.e. color bars) can also be added as described above.   |  Congratulations! You are done with the analysis. Feel free to browse other options in the workflow to examine other features of this module. As mentioned above, users are encouraged to examine the consequences of filtering out samples (i.e. ones that did not pass MADScore filters) on subsequent steps (QC, GLM, and hierarchical clustering). Click \"Save\" to save this project. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of, with reference to RT-PCR preprocessing and analysis. Feel free to try different options along the  Import RT-PCR Wizard  to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ).  Thank you for using Array Studio.  Please contact Omicsoft Support (   support@omicsoft.com   ) or Omicsoft Sales (   sales@omicsoft.com   ) for sales-related questions.",
            "title": "Hierarchical Clustering"
        },
        {
            "location": "/tutorials/SNP/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray studio\n\u00b6\n\n\nArray Studio\n provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its \nSolution Explorer\n, which organizes each project into \nData, QC, Table, List, Cluster, Text, Attachments\n and other categories. Multiple projects can be opened simultaneously in the \nSolution Explorer\n, and data can be shared among projects. Each view is controlled by a \nView Controller\n, which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the \nDetails Window\n and \nWeb Details On-Demand\n.\n\n\nIt is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.\n\n\nDownloading the SNP Sample Data\n\u00b6\n\n\nThis chapter will cover the import of the .MAP and .PED file sample dataset, as well as the attachment of the pedigree and phenotype covariate information to the dataset (the \nDesign Table\n).\n\n\nFor this tutorial, the following files will be required:\n\n\n\n\n\n\nThe GenotypeData.ped file\n\n\n\n\n\n\nThe GenotypeData.map file\n\n\n\n\n\n\nThe SNP.design.txt file, derived from the simulated sample covariate information for this study.\n\n\n\n\n\n\nThese files are available in a zipped resource file located on the Omicsoft web server at the following URL:\n\nlink\n\n\nThe SNP sample data contains 90 samples and 45,930 SNPs. The 90 observations are split into their two sources, Japanese and Chinese (JPT and CHN). Additional covariate information includes a simulated Group column (for an example of case/control association analysis), a simulated Group2 column (for an example of categorical trait association analysis), a simulated Qtrait column (for an example of quantitative trait association analysis), and simulated Survival Time and Status columns (for an example of survival trait association analysis). The size of the original dataset has been reduced because of the large size of the imported data files, but \nArray Studio\n can handle millions of SNPs and many thousands of observations.\n\n\nThe SNP.Design.txt file contains the design information for the tutorial s study, including columns for \nSource, Sex, Group, Group2, Qtrait, Covariate 1, Covariate 2, Survival Time, and Status\n. A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed \nID\n, that contains the exact file names of the SNP arrays used in the experiment (it has to match the names of the Affymetrix .CHP files, or the names listed in the Illumina text file, etc.). Additional columns usually include \ndisease status, quantitative traits, etc.\n (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into \nArray Studio\n. An example design table is shown below.\n\n\n\n\nAfter downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).\n\n\nCreating a New Project\n\u00b6\n\n\nWhen Array Studio is first installed, it will look similar to what is displayed below.\n\n\nIf you have previously opened projects in Array Studio, you will see the \nLast Opened Projects\n window. If so, just click cancel so that Array Studio looks similar to below.\n\n\n\n\nThe \nWorkflow\n window should be visible on the left side of the screen. If the window is not visible, go to the \nView Menu | Show Workflow\n. The \nWorkflow\n window should appear similar to the screenshot below.\n\n\n\n\nThis window provides users, especially new users, with a  guide  to running different types of analysis. Click the Workflow dropdown box now and select \nGenotype\n.\n\n\nTo create a new project, click the \nNew Project\n button in the Workflow, or the \nNew\n button on the toolbar, or go to \nFile\n Menu, then click \nNew Project\n.\n\n\nThis opens the \nNew Project\n window.\n\n\n\n\nArray Studio\n allows the user to create two different project types:\n\n\n\n\n\n\nA simple project, in which the project is saved in a single file (recommended for microarray and RT-PCR projects).\n\n\n\n\n\n\nA distributed project, where data are saved in separate files (recommended for exon array, CNV, or genotyping projects).\n\n\n\n\n\n\nChoose the \nCreate a distributed project\n option. Click the \nBrowse\n button to choose a location and name for the project. Click \nOK\n to continue.\n\n\nSwitch to the \nSolution Explorer\n by clicking on the \nSolution Explorer\n tab, which should be found at the bottom of the \nWorkflow Window\n. If the \nSolution Explorer\n tab is not visible, open to it by going to the menu bar and choosing \nView | Show Solution Explorer\n.\n\n\n\n\nThe Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).\n\n\nImporting SNP Data and Attaching Design Table\n\u00b6\n\n\nTo import our sample SNP data, click \nAdd genotype data\n in the Workflow Window, or click the \nAdd Data |Add -Omic Data\n button in the toolbar, and then choose \nAdd Genotype Data\n.\n\n\n\n\nThis opens the \nSpecify Genotype Data Source\n window. In this window, the user can choose the \nGenotype Data Source\n for input. Choices include using the import \nWizard\n, \nSNP Data: PED file + Map file\n, \nSNP Data: Transposed PED file + Family file\n, \nSNP Data: PLINK binary file (.bed)\n, \nSNP Data: Affymetrix CEL files\n, \nSNP Data: Affymetrix .CHP files\n, \nSNP Data: Illumina genotype final report (standard)\n, \nGenotype data: PED file + Map file\n, \nGenotype data: Transposed PED file +Family file\n, \nSNP Dose data: output from MACH(.mldose)\n, and \nSNP Probability data:\n \noutput from MACH(.mlprob)\n.\n\n\nIn Array Studio, with SNP data, all markers are assumed to be biallelic, with support for millions of SNPs and thousands of samples.\nWith Genotype data, all markers are not assumed to be biallelic, with support in Array Studio of up to 100K markers and hundreds of samples.\n\n\nThe sample data is stored in the \nSNP Data: PED file + Map file\n format, so choose that option now, and click OK to continue.\n\n\n\n\nThis brings up the \nImport PED File\n window. The first step in this window is to click the \nBrowse\n button, and navigate to the \nGenotypeData.ped\n file downloaded earlier. Once the \nPED\n file is selected, the \nMAP file\n will be automatically selected as well. Array Studio assumes that the \nMAP\n file is located in the same directory as the \nPED\n file, so if this is not the case, the user can change the location of the \nMAP\n file.\n\n\n\n\nOnce a file name has been selected, the user should verify any other information in the \nMAP\n and \nPED\n files, and set the checkboxes accordingly (\ni.e. Family ID, Father ID, etc.\n). Once all the information is confirmed click \nOK\n to continue.\n\n\nThe import process should take approximately 10 seconds.\n\n\nUpon completion of importing, Array Studio will prompt the user to attach a \nDesign\n to the data. If the user wishes to attach a design at a later time, this can be done as well (by right-clicking the \nDesign\n folder of the dataset in the \nSolution Explorer\n), however, it is recommended to build and have your design table ready for use upon import of the data. Click \nYes\n to begin the Design import process.\n\n\n\n\nArray Studio will prompt the user to specify a table source. As the design table for the sample data is in a \ntab delimited file\n format, choose that option now, and click \nOK\n.\n\n\n\n\nWhen prompted, choose the \nSNP.design.txt\n file that was unzipped earlier, and click \nOpen\n to attach the design table to the dataset.\n\n\n\n\nOnce the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to \nAppend to the existing covariate table\n (if one exists) and to \nUse the name order in the new covariate table\n. Leave these options as default.\n\n\n\n\nAfter choosing a design file, the user is prompted with a \nSet Columns\n window. In this window, the user can inform Array Studio if any of the imported design columns pertains to \nFamilyID\n, \nIndividualID\n, \nFatherID\n, \nMotherID\n, \nSex\n, or \nPhenotype\n. Some of this information is used in different modules for analysis. By default, these columns should be set correctly, since this data was included in the \n.PED\n and \n.MAP\n files.\n\n\nIf the user chooses not to set the columns at this time, they can later reopen the design table, and later use the \nTable Menu | Columns | Column Properties\n to set the column mode. For this tutorial, these columns need not be set and can you can just select the \"OK\" button.\n\n\n\n\nOnce imported, Array Studio should look similar to the following screenshot. By default, a \nTableView\n is created for the imported dataset.\n\n\n\n\nAlso, note that a new data object has been added under the \nOmic Data\n section of the \nSolution Explorer\n (on the left-hand side of the screen).\n\n\nThe \nSolution Explorer\n can provide important information about the different datasets and tables that are created in Array Studio.\nFor instance, note that next to the name of the dataset, \nGenotypeData\n, Array Studio lists the number of rows and columns (or markers and observations) in the dataset. In this case, there are 45,930 markers and 90 observations.\n\n\nThe \nSolution Explorer\n also provides the user with information on the different views that have been created. Notice that there is a \nTableView\n for dataset \nGenotypeData\n, as well as for \nAnnotation\n and \nDesign\n (Expand the nodes to see this). User can double-click either of these views (named \nTable\n), and open them in the main view window.\n\n\n\n\nCongratulations! You have successfully imported your first SNP dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/SNP/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/SNP/Introduction/#array-studio",
            "text": "Array Studio  provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its  Solution Explorer , which organizes each project into  Data, QC, Table, List, Cluster, Text, Attachments  and other categories. Multiple projects can be opened simultaneously in the  Solution Explorer , and data can be shared among projects. Each view is controlled by a  View Controller , which performs view customization, applies filtering, and displays legends. Furthermore, its interactive visualization technique provides the details of data with the  Details Window  and  Web Details On-Demand .  It is highly recommended that the user complete the prerequisite for this tutorial: MicroArray Tutorial, which is a good introduction to installation, basic usage, data structure and standard visualization in Array Studio.",
            "title": "Array studio"
        },
        {
            "location": "/tutorials/SNP/Introduction/#downloading-the-snp-sample-data",
            "text": "This chapter will cover the import of the .MAP and .PED file sample dataset, as well as the attachment of the pedigree and phenotype covariate information to the dataset (the  Design Table ).  For this tutorial, the following files will be required:    The GenotypeData.ped file    The GenotypeData.map file    The SNP.design.txt file, derived from the simulated sample covariate information for this study.    These files are available in a zipped resource file located on the Omicsoft web server at the following URL: link  The SNP sample data contains 90 samples and 45,930 SNPs. The 90 observations are split into their two sources, Japanese and Chinese (JPT and CHN). Additional covariate information includes a simulated Group column (for an example of case/control association analysis), a simulated Group2 column (for an example of categorical trait association analysis), a simulated Qtrait column (for an example of quantitative trait association analysis), and simulated Survival Time and Status columns (for an example of survival trait association analysis). The size of the original dataset has been reduced because of the large size of the imported data files, but  Array Studio  can handle millions of SNPs and many thousands of observations.  The SNP.Design.txt file contains the design information for the tutorial s study, including columns for  Source, Sex, Group, Group2, Qtrait, Covariate 1, Covariate 2, Survival Time, and Status . A design table can be created at any time by a user, using Microsoft Excel or Array Studio. As a rule, the design table must contain a first column, usually deemed  ID , that contains the exact file names of the SNP arrays used in the experiment (it has to match the names of the Affymetrix .CHP files, or the names listed in the Illumina text file, etc.). Additional columns usually include  disease status, quantitative traits, etc.  (anything pertinent to the experiment). If you forget to include a particular column at the time of the creation of the design table, it is not a problem, because any design factors can be added or edited after importing the design into  Array Studio . An example design table is shown below.   After downloading the single .zip file, unzip the file to a folder of your choice (to be used in the remainder of this tutorial).",
            "title": "Downloading the SNP Sample Data"
        },
        {
            "location": "/tutorials/SNP/Introduction/#creating-a-new-project",
            "text": "When Array Studio is first installed, it will look similar to what is displayed below.  If you have previously opened projects in Array Studio, you will see the  Last Opened Projects  window. If so, just click cancel so that Array Studio looks similar to below.   The  Workflow  window should be visible on the left side of the screen. If the window is not visible, go to the  View Menu | Show Workflow . The  Workflow  window should appear similar to the screenshot below.   This window provides users, especially new users, with a  guide  to running different types of analysis. Click the Workflow dropdown box now and select  Genotype .  To create a new project, click the  New Project  button in the Workflow, or the  New  button on the toolbar, or go to  File  Menu, then click  New Project .  This opens the  New Project  window.   Array Studio  allows the user to create two different project types:    A simple project, in which the project is saved in a single file (recommended for microarray and RT-PCR projects).    A distributed project, where data are saved in separate files (recommended for exon array, CNV, or genotyping projects).    Choose the  Create a distributed project  option. Click the  Browse  button to choose a location and name for the project. Click  OK  to continue.  Switch to the  Solution Explorer  by clicking on the  Solution Explorer  tab, which should be found at the bottom of the  Workflow Window . If the  Solution Explorer  tab is not visible, open to it by going to the menu bar and choosing  View | Show Solution Explorer .   The Solution Explorer will be empty except for data containers for List, Cluster, and Text files. You can right-click on List, Cluster, and Text for their additional options. For instance, right-clicking on List will bring up options to add a new List, add list from file, etc. A List can be used to filter the data, by either Variables (e.g. probesets), or Observations (e.g. chips or samples).",
            "title": "Creating a New Project"
        },
        {
            "location": "/tutorials/SNP/Introduction/#importing-snp-data-and-attaching-design-table",
            "text": "To import our sample SNP data, click  Add genotype data  in the Workflow Window, or click the  Add Data |Add -Omic Data  button in the toolbar, and then choose  Add Genotype Data .   This opens the  Specify Genotype Data Source  window. In this window, the user can choose the  Genotype Data Source  for input. Choices include using the import  Wizard ,  SNP Data: PED file + Map file ,  SNP Data: Transposed PED file + Family file ,  SNP Data: PLINK binary file (.bed) ,  SNP Data: Affymetrix CEL files ,  SNP Data: Affymetrix .CHP files ,  SNP Data: Illumina genotype final report (standard) ,  Genotype data: PED file + Map file ,  Genotype data: Transposed PED file +Family file ,  SNP Dose data: output from MACH(.mldose) , and  SNP Probability data:   output from MACH(.mlprob) .  In Array Studio, with SNP data, all markers are assumed to be biallelic, with support for millions of SNPs and thousands of samples.\nWith Genotype data, all markers are not assumed to be biallelic, with support in Array Studio of up to 100K markers and hundreds of samples.  The sample data is stored in the  SNP Data: PED file + Map file  format, so choose that option now, and click OK to continue.   This brings up the  Import PED File  window. The first step in this window is to click the  Browse  button, and navigate to the  GenotypeData.ped  file downloaded earlier. Once the  PED  file is selected, the  MAP file  will be automatically selected as well. Array Studio assumes that the  MAP  file is located in the same directory as the  PED  file, so if this is not the case, the user can change the location of the  MAP  file.   Once a file name has been selected, the user should verify any other information in the  MAP  and  PED  files, and set the checkboxes accordingly ( i.e. Family ID, Father ID, etc. ). Once all the information is confirmed click  OK  to continue.  The import process should take approximately 10 seconds.  Upon completion of importing, Array Studio will prompt the user to attach a  Design  to the data. If the user wishes to attach a design at a later time, this can be done as well (by right-clicking the  Design  folder of the dataset in the  Solution Explorer ), however, it is recommended to build and have your design table ready for use upon import of the data. Click  Yes  to begin the Design import process.   Array Studio will prompt the user to specify a table source. As the design table for the sample data is in a  tab delimited file  format, choose that option now, and click  OK .   When prompted, choose the  SNP.design.txt  file that was unzipped earlier, and click  Open  to attach the design table to the dataset.   Once the design table is imported, a \"Specify Options\" window will appear. Here the user can select the options to  Append to the existing covariate table  (if one exists) and to  Use the name order in the new covariate table . Leave these options as default.   After choosing a design file, the user is prompted with a  Set Columns  window. In this window, the user can inform Array Studio if any of the imported design columns pertains to  FamilyID ,  IndividualID ,  FatherID ,  MotherID ,  Sex , or  Phenotype . Some of this information is used in different modules for analysis. By default, these columns should be set correctly, since this data was included in the  .PED  and  .MAP  files.  If the user chooses not to set the columns at this time, they can later reopen the design table, and later use the  Table Menu | Columns | Column Properties  to set the column mode. For this tutorial, these columns need not be set and can you can just select the \"OK\" button.   Once imported, Array Studio should look similar to the following screenshot. By default, a  TableView  is created for the imported dataset.   Also, note that a new data object has been added under the  Omic Data  section of the  Solution Explorer  (on the left-hand side of the screen).  The  Solution Explorer  can provide important information about the different datasets and tables that are created in Array Studio.\nFor instance, note that next to the name of the dataset,  GenotypeData , Array Studio lists the number of rows and columns (or markers and observations) in the dataset. In this case, there are 45,930 markers and 90 observations.  The  Solution Explorer  also provides the user with information on the different views that have been created. Notice that there is a  TableView  for dataset  GenotypeData , as well as for  Annotation  and  Design  (Expand the nodes to see this). User can double-click either of these views (named  Table ), and open them in the main view window.   Congratulations! You have successfully imported your first SNP dataset into Array Studio. In the next chapter, we will explore some of the different visualizations and views available in Array Studio.",
            "title": "Importing SNP Data and Attaching Design Table"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/",
            "text": "Visualization of Data\n\u00b6\n\n\nThe TableView\n\u00b6\n\n\nUpon import, Array Studio will automatically generate a \nTableView\n for the genotyping or SNP data.\n\n\nThe \nTableView\n in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each marker is a row. Genotype information is shown in each cell (in this case, A_A, C_C, C_T, etc.).\n\n\nScroll through the data now to see the speed that Array Studio can display data.\n\n\n\n\nPlease refer to Microarray Tutorial for different options and filters for table view.\n\n\nThe Details Window and Web Details\n\u00b6\n\n\nArray Studio\n includes a feature called \nDetails on Demand\n. In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the \nDetails\n \nWindow\n (at the bottom of the screen).\n\n\nClick on a marker in the row header of the \nTableView\n, and notice that the marker name changes to green. This indicates that this row has been selected, and information is available in the \nDetails\n \nWindow\n.\n\n\n\n\nIf the \nDetails Window\n is not currently visible at the bottom of the screen, switch to it by selecting \nView Menu | Show Details Window\n. Note that all of the annotation information for the selected row or rows is shown in the \nDetails Window\n.\n\n\nThe \nDetails Window\n can also be used to show information about a particular observation (subject in this tutorial). Click the header row of one of the subjects now.\n\n\n\n\nArray Studio\n also includes a feature called \nWeb Details on Demand\n, supported by default for Illumina and Affymetrix chips. This allows the user to find out detailed information on particular marker from a few public databases/websites (available websites depend on the user s choice and the chip type).\n\n\nTo access \nWeb Details\n, right click on any marker row header column, in either the \nTableView\n or \nDetails Window\n. Available \nWeb Details\n for this particular marker and chip are Hapmap, NCBI, and UCSC. Select any one of the three options. This will open a new Internet Explorer browser window.\n\n\n\n\nAn example Hapmap \nWeb Details\n window is shown below (if the link does not work, open HapMap homepage first and then try again).\n\n\n\n\nNow clear all row and column selections for next step: visualization in \nHistogramView\n and \nAlleleSignalView\n.\n\n\n\n\nHistogramView and AlleleSignalView\n\u00b6\n\n\nWhile the speed and flexibility of the \nTableView\n are nice, it is the other views in \nArray Studio\n that really allow it to stand out over other programs when it comes to visualizations. The \nHistogramView\n, along with the \nAlleleSignalView\n (only available for Illumina imported and Affymetrix imported data), will allow the user to further investigate individual markers in the dataset.\n\n\nTo add a \nHistogramView\n, right-click on \nGenotypeData\n, and click \nAdd View\n.\n\n\n\n\nThis brings up the now familiar \nAdd View\n window. Choose \nHistogramView\n and click \nOK\n.\n\n\n\n\nArray Studio\n should now display a \nHistogramView\n. This view shows one chart for each marker, split by the three genotypes. Scroll through the charts, and notice that you are scrolling through almost 46,000 charts.\n\n\nAt this point, let s filter by the marker \nrs2235523\n. The view should now look similar to below.\n\n\n\n\nNotice that all three genotypes are represented in the data. We can use any of our covariate design information to make this view more informative.\n\n\nFor most of the rest of the tutorial, we are going to work with only the JPT population from this study. The reason for this is that we only have simulated covariate information for the JPT population. So, to filter to only see the JPT population, switch to the \nObservation\n tab in the \nView Controller\n and expand the \nSource\n filter and choose JPT. The chart will update to show only the JPT population.\n\n\n\n\nGo back to the \nTask\n tab in the \nView Controller\n and click \nSpecify Split Column\n. This allows the user to split each genotype, by a specified column in the \nDesign Table\n.\n\n\n\n\nChoose \nPhenotype\n from the \nChoose Split Column\n window and click OK.\n\n\n\n\nThe view is updated so that each genotype is now split by \nStatus\n (Death and Censored). It is clear from looking at the chart that there is a difference between the two groups for some of the genotypes.\n\n\n\n\nChange to the \nLegend\n tab of the \nView Controller\n to see the Legend for the chart.\n\n\n\n\n\n\nNote\n\n\nThe colors of the Legend can be changed by right-clicking on the different options in the Legend (alternatively, the colors can be changed using the options in the Task tab of the \nView Controller\n. The user can also change the Column properties for the selected field which links back to the design table.\n\n\n\n\n\n\nArray Studio\n can show on-the-fly p-value information (using a Fisher Exact test) for any marker in the \nHistogram View\n. Click the \nShow Summary Information\n button in the \nCustomize\n section of the \nTask\n tab in the \nView Controller\n.\n\n\n\n\nAnother view, called the \nAlleleSignalView\n , is available for data that include allele signal file (this view is not available for this tutorial as the allele signal information is not contained in the data imported via \nPED/MAP\n files). An example \nAlleleSignalView\n is shown below, along with the Silhouette values (in practice, the closer to 1 each silhouette value is, the better the genotype call. If you would like to get some recommendations for the empirical cutoff  values, contact the Omicsoft support team). This view is not available for data imported via \nPED/MAP\n files, as the allele signal information is not contained in those files.\n\n\n\n\nThe VariableView\n\u00b6\n\n\nThe \nVariableView\n is another useful view, as it can show numeric values for each marker. If the user has a quantitative trait (i.e., cholesterol level, systolic blood pressure, etc.), they can visualize individual markers for each genotype based on that trait.\n\n\nAdd a \nVariableView\n now by right-clicking the -Omic data object and choosing \nAdd View\n. When complete, the new view should look similar to below.\n\n\n\n\nBy default, \nArray Studio\n has chosen a column to the response variable (using a numeric column). To verify that the response column is set as we want it to be (to the column Qtrait), go to the \nTask\n tab of the \nView Controller\n, and click the \nSpecify Response Column\n button now.\n\n\n\n\nAs we have a quantitative trait in our design table under the column Qtrait, ensure that it is chosen in the \nChoose Response Column\n window and click \nOK\n.\n\n\n\n\nSince the correct column was already chosen, the view is not changed. As we have the view filtered for the one specific marker, there is only one chart available. However, if we removed the filter, we\\'d be able to scroll through all 46000+ markers in the dataset, and look at the response by genotype.\n\n\nThe \nVariableView\n can be further customized, using the \nSpecify Split Column\n button in the \nTask\n tab of the \nView Controller\n. The split column will split each genotype by whatever categorical design column we choose, and automatically distinguish different groups by color.\n\n\nClick \nSpecify Split Column\n now.\n\n\n\n\nFor demonstration purposes, choose \nPhenotype\n from the \nChoose Split Column\n window now.\n\n\n\n\nThe view is once again updated, with the two statuses now colored differently. Again, these views can be opened in PowerPoint, or the legend can be viewed by going to the \nLegend\n tab of the \nView Controller\n.\n\n\n\n\nThe next customization is to  jitter  the data points so that they don t overlap to each other by using the \nChange Symbol Properties\n button in the \nTask\n tab of the \nView Controller\n (found in the \nProperties\n section). Choose this now.\n\n\n\n\nThe \nSymbol Properties\n window allows the user to configure a number of different options. Notice that the \nColor By\n section has already been set to \nStatus\n. Other options include changing the size of the symbols, rotation, shape, labels, and opacity.\n\n\nFor demonstration purposes, let s increase the \nJitter\n about \u2155 of the way to max. Then close this window to see the updated view.\n\n\n\n\nThe view is updated, with each group now  jittered so that the user can now see all the data points.\n\n\n\n\nThe SurvivalView\n\u00b6\n\n\nIn SNP-related experiments from clinical trials, usually there is survival information available. \nArray Studio\n includes a special \nSurvivalView\n, for visualizing the time to event data. Let s add that now, in the usual way. When completed, it should look similar to the following.\n\n\nArray Studio\n is informing the user that the time column has not yet been specified. Click \nOK\n to continue and then specify the \nTime\n column in \nTask\n tab of \nView Controller\n.\n\n\n\n\nIn the \nTask\n tab of the \nView Controller\n, click the \nSpecify Time Column\n button.\n\n\n\n\nChoose \nSurvivalTime\n in the \nChoose Time Column\n window. The \nSurvivalTime\n column in our design table contains the information on time, needed for this view.\n\n\n\n\nArray Studio\n now informs the user that the \nStatus\n column has not yet been specified.\n\n\n\n\nClick the \nSpecify Status Column\n button in the \nTask\n tab of the \nView Controller\n, and then choose Status in the \nChoose Status Column\n window.\n\n\n\n\nArray Studio\n now informs the user to specify an \nEvent\n.\n\n\n\n\nClick the \nSpecify Event\n button in the \nTask\n tab of the \nView Controller\n.\n\n\nArray Studio\n now lists all the levels of events in the status column. For this study, available choices include \nDeath\n or \nCensored\n. Choose \nDeath\n and click \nOK\n.\n\n\n\n\nThe \nSurvivalView\n is finally configured. Censored events are marked with a vertical line. The user can use this view to investigate different markers, based on survival time. It is clear in this case that there is a difference between the three genotypes, when it comes to survival time.\n\n\n\n\nNote: If you see the following message: \nMissing/negative data found in Y\n.\n\n\nAssure that that under the Observation tab in the View Controller has the source selected as below:\n\n\n\n\nAt this point, it is recommended that the user save the project (\nFile Menu | Save)\n. If interested, the user can stop at this time. All filters, views, tables, etc., that have been generated in \nArray Studio\n are saved with the project, so the user could conceivably close the project, then reopen it, and continue right where they left off.\n\n\nCongratulations! You\\'ve now used many of the important views in \nArray Studio\n for analyzing SNP data. In the next chapter, we will investigate Marker Statistics, Data Filtering, and Population Structure.",
            "title": "Visualization of Data"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#visualization-of-data",
            "text": "",
            "title": "Visualization of Data"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#the-tableview",
            "text": "Upon import, Array Studio will automatically generate a  TableView  for the genotyping or SNP data.  The  TableView  in Array Studio can easily display millions of rows or columns. In this view, each observation is in a column, while each marker is a row. Genotype information is shown in each cell (in this case, A_A, C_C, C_T, etc.).  Scroll through the data now to see the speed that Array Studio can display data.   Please refer to Microarray Tutorial for different options and filters for table view.",
            "title": "The TableView"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#the-details-window-and-web-details",
            "text": "Array Studio  includes a feature called  Details on Demand . In most views, selecting objects in the view will show details about that object (i.e. row, column, data point), in the  Details   Window  (at the bottom of the screen).  Click on a marker in the row header of the  TableView , and notice that the marker name changes to green. This indicates that this row has been selected, and information is available in the  Details   Window .   If the  Details Window  is not currently visible at the bottom of the screen, switch to it by selecting  View Menu | Show Details Window . Note that all of the annotation information for the selected row or rows is shown in the  Details Window .  The  Details Window  can also be used to show information about a particular observation (subject in this tutorial). Click the header row of one of the subjects now.   Array Studio  also includes a feature called  Web Details on Demand , supported by default for Illumina and Affymetrix chips. This allows the user to find out detailed information on particular marker from a few public databases/websites (available websites depend on the user s choice and the chip type).  To access  Web Details , right click on any marker row header column, in either the  TableView  or  Details Window . Available  Web Details  for this particular marker and chip are Hapmap, NCBI, and UCSC. Select any one of the three options. This will open a new Internet Explorer browser window.   An example Hapmap  Web Details  window is shown below (if the link does not work, open HapMap homepage first and then try again).   Now clear all row and column selections for next step: visualization in  HistogramView  and  AlleleSignalView .",
            "title": "The Details Window and Web Details"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#histogramview-and-allelesignalview",
            "text": "While the speed and flexibility of the  TableView  are nice, it is the other views in  Array Studio  that really allow it to stand out over other programs when it comes to visualizations. The  HistogramView , along with the  AlleleSignalView  (only available for Illumina imported and Affymetrix imported data), will allow the user to further investigate individual markers in the dataset.  To add a  HistogramView , right-click on  GenotypeData , and click  Add View .   This brings up the now familiar  Add View  window. Choose  HistogramView  and click  OK .   Array Studio  should now display a  HistogramView . This view shows one chart for each marker, split by the three genotypes. Scroll through the charts, and notice that you are scrolling through almost 46,000 charts.  At this point, let s filter by the marker  rs2235523 . The view should now look similar to below.   Notice that all three genotypes are represented in the data. We can use any of our covariate design information to make this view more informative.  For most of the rest of the tutorial, we are going to work with only the JPT population from this study. The reason for this is that we only have simulated covariate information for the JPT population. So, to filter to only see the JPT population, switch to the  Observation  tab in the  View Controller  and expand the  Source  filter and choose JPT. The chart will update to show only the JPT population.   Go back to the  Task  tab in the  View Controller  and click  Specify Split Column . This allows the user to split each genotype, by a specified column in the  Design Table .   Choose  Phenotype  from the  Choose Split Column  window and click OK.   The view is updated so that each genotype is now split by  Status  (Death and Censored). It is clear from looking at the chart that there is a difference between the two groups for some of the genotypes.   Change to the  Legend  tab of the  View Controller  to see the Legend for the chart.    Note  The colors of the Legend can be changed by right-clicking on the different options in the Legend (alternatively, the colors can be changed using the options in the Task tab of the  View Controller . The user can also change the Column properties for the selected field which links back to the design table.    Array Studio  can show on-the-fly p-value information (using a Fisher Exact test) for any marker in the  Histogram View . Click the  Show Summary Information  button in the  Customize  section of the  Task  tab in the  View Controller .   Another view, called the  AlleleSignalView  , is available for data that include allele signal file (this view is not available for this tutorial as the allele signal information is not contained in the data imported via  PED/MAP  files). An example  AlleleSignalView  is shown below, along with the Silhouette values (in practice, the closer to 1 each silhouette value is, the better the genotype call. If you would like to get some recommendations for the empirical cutoff  values, contact the Omicsoft support team). This view is not available for data imported via  PED/MAP  files, as the allele signal information is not contained in those files.",
            "title": "HistogramView and AlleleSignalView"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#the-variableview",
            "text": "The  VariableView  is another useful view, as it can show numeric values for each marker. If the user has a quantitative trait (i.e., cholesterol level, systolic blood pressure, etc.), they can visualize individual markers for each genotype based on that trait.  Add a  VariableView  now by right-clicking the -Omic data object and choosing  Add View . When complete, the new view should look similar to below.   By default,  Array Studio  has chosen a column to the response variable (using a numeric column). To verify that the response column is set as we want it to be (to the column Qtrait), go to the  Task  tab of the  View Controller , and click the  Specify Response Column  button now.   As we have a quantitative trait in our design table under the column Qtrait, ensure that it is chosen in the  Choose Response Column  window and click  OK .   Since the correct column was already chosen, the view is not changed. As we have the view filtered for the one specific marker, there is only one chart available. However, if we removed the filter, we\\'d be able to scroll through all 46000+ markers in the dataset, and look at the response by genotype.  The  VariableView  can be further customized, using the  Specify Split Column  button in the  Task  tab of the  View Controller . The split column will split each genotype by whatever categorical design column we choose, and automatically distinguish different groups by color.  Click  Specify Split Column  now.   For demonstration purposes, choose  Phenotype  from the  Choose Split Column  window now.   The view is once again updated, with the two statuses now colored differently. Again, these views can be opened in PowerPoint, or the legend can be viewed by going to the  Legend  tab of the  View Controller .   The next customization is to  jitter  the data points so that they don t overlap to each other by using the  Change Symbol Properties  button in the  Task  tab of the  View Controller  (found in the  Properties  section). Choose this now.   The  Symbol Properties  window allows the user to configure a number of different options. Notice that the  Color By  section has already been set to  Status . Other options include changing the size of the symbols, rotation, shape, labels, and opacity.  For demonstration purposes, let s increase the  Jitter  about \u2155 of the way to max. Then close this window to see the updated view.   The view is updated, with each group now  jittered so that the user can now see all the data points.",
            "title": "The VariableView"
        },
        {
            "location": "/tutorials/SNP/Visualization_of_Data/#the-survivalview",
            "text": "In SNP-related experiments from clinical trials, usually there is survival information available.  Array Studio  includes a special  SurvivalView , for visualizing the time to event data. Let s add that now, in the usual way. When completed, it should look similar to the following.  Array Studio  is informing the user that the time column has not yet been specified. Click  OK  to continue and then specify the  Time  column in  Task  tab of  View Controller .   In the  Task  tab of the  View Controller , click the  Specify Time Column  button.   Choose  SurvivalTime  in the  Choose Time Column  window. The  SurvivalTime  column in our design table contains the information on time, needed for this view.   Array Studio  now informs the user that the  Status  column has not yet been specified.   Click the  Specify Status Column  button in the  Task  tab of the  View Controller , and then choose Status in the  Choose Status Column  window.   Array Studio  now informs the user to specify an  Event .   Click the  Specify Event  button in the  Task  tab of the  View Controller .  Array Studio  now lists all the levels of events in the status column. For this study, available choices include  Death  or  Censored . Choose  Death  and click  OK .   The  SurvivalView  is finally configured. Censored events are marked with a vertical line. The user can use this view to investigate different markers, based on survival time. It is clear in this case that there is a difference between the three genotypes, when it comes to survival time.   Note: If you see the following message:  Missing/negative data found in Y .  Assure that that under the Observation tab in the View Controller has the source selected as below:   At this point, it is recommended that the user save the project ( File Menu | Save) . If interested, the user can stop at this time. All filters, views, tables, etc., that have been generated in  Array Studio  are saved with the project, so the user could conceivably close the project, then reopen it, and continue right where they left off.  Congratulations! You\\'ve now used many of the important views in  Array Studio  for analyzing SNP data. In the next chapter, we will investigate Marker Statistics, Data Filtering, and Population Structure.",
            "title": "The SurvivalView"
        },
        {
            "location": "/tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/",
            "text": "Marker Statistics, Data Filtering, and Population Structure\n\u00b6\n\n\nMarker Statistics\n\u00b6\n\n\nIn \nArray Studio\n, the user can generate a number of different summary and QC statistics. In particular, the user can generate \nMarker Statistics\n or \nSubject Statistics\n. In this tutorial, we will just generate marker statistics, but the generation of subject statistics is very similar, and can be done by the user on their own.\n\n\nGo to \nGenotyping | Summarize/QC | Marker Statistics\n now.\n\n\n\n\nThis brings up the \nMarker Statistics\n window.\n\n\n\n\nAll module windows in \nArray Studio\n follow a similar pattern to this one. First, the user can select the \nProject\n and \nData\n to be analyzed; in this case the only project opened is \nTutorial SNP\n and our only \nData\n is \nGenotype Data\n.\nNext, if the user has generated a list of variables/markers (subset) for analysis, this can be selected. The user can also manually choose particular chromosomes for analysis.\n\n\nAs we are really only interested in marker statistics for the Japanese population, and since\nthese samples are currently filtered and are visible, choose \nVisible Observations (45)\n now, to ensure that only the visible subjects (i.e. the Japanese subjects) will be analyzed.\n\n\n\n\n\n\nFirst, a \nGroup\n may be specified, and the marker statistics will be calculated separately for each group.\n\n\n\n\n\n\nNext, the user can choose to report a number of statistics, including\n\n\n\n\n\n\nAllele frequencies\n\n\n\n\n\n\nMinor allele frequency\n\n\n\n\n\n\nMissing genotype count\n\n\n\n\n\n\nEffective genotype count\n\n\n\n\n\n\nMissing genotype proportion\n\n\n\n\n\n\nGenotype frequencies\n\n\n\n\n\n\nObserved heterozygosity\n\n\n\n\n\n\nGene Diversity\n\n\n\n\n\n\nHWE chi square p-value\n\n\n\n\n\n\nHWE exact p-value\n\n\n\n\n\n\nInbreeding coefficient\n\n\n\n\n\n\nSilhouettes width\n (requires SNP intensity data, i.e. Affymetrix or Illumina).\n\n\n\n\n\n\n\n\n\n\nLeave the other settings as default, and click \nSubmit\n to run the module.\n\n\nA new \nTable\n is generated under the \nTable | Summary\n folder of the \nSolution Explorer\n, called \nGenotypeData.MarkerSummary\n. It s evident from the solution explorer that this data contains 45930 rows (or markers) and 9 columns of information.\n\n\n\n\nMake sure that all variable filters are cleared.\n\n\n\n\nOnce unfiltered, the \nTableView\n should look as follows. It contains a column for the minor allele frequency (Maf), missing genotype count and percentage, as well as the covariate information (AlleleA, AlleleB, Chromosome, and BasePairPosition). This table, like any other table views, can be filtered, sorted and customized using \nView Controller\n.\n\n\n\n\nData Filtering\n\u00b6\n\n\nPrior to SNP analysis, it is a good idea to filter the markers and subjects, to exclude markers and subjects with high missing data percentage, as well as exclude markers where the minor allele frequency (MAF) is below a certain cutoff. Other options include removing markers due to an extremely significant Hardy Weinberg Equilibrium (HWE) p-value.\n\n\nTo filter genotype or SNP data in \nArray Studio\n, go to the \nGenotyping Menu | Summarize/QC | Filter\n to open the \nFilter\n window, as shown below.\n\n\n\n\nIn this window, make sure that the \nProject\n is set to \nTutorial\n, \nData\n is set to \nGenotypeData\n, \nVariables\n to \nAll Variables\n, and \nObservations\n are set to \nVisible Observations (45)\n so that we filter only on the \nJPT\n subjects.\n\n\n\n\nFor the options,\n\n\n\n\n\n\nFirst, a \nGroup\n may be specified, and the marker statistics will be calculated separately for each group.\n\n\n\n\n\n\nBy default the filter will \nexclude subjects with a missing percentage\n > 10%\n\n\n\n\n\n\nExclude markers with a missing percentage\n > 10%.\n\n\n\n\n\n\nChange  \nExclude markers with MAF<\n to 0.05 (from default of 0.01).\n    This is done because of the small number of subjects we have. This is a subjective criterion and the user can change.\n\n\n\n\n\n\nIf we were interested, it is also possible to \nexclude markers with a HWE p-value\n < a cutoff.\n\n\nAlso, note the \nOutput type\n is \nVariable and Observation list\n for this module.\nThis means that \ntwo Lists\n will be generated in the \nSolution Explorer\n as a result of filtering, a \nList\n of markers that passed the criteria, and a \nList\n of observations that passed the criteria. Optionally, the user can name the list as well.\n\n\nClick \nSubmit\n to run the filtering.\n\n\nAs can be seen below, two new \nLists\n were generated by the module. All 45 JPN subjects passed the filter, as did 31008 markers. These \nLists\n will be used for all further analysis.\n\n\n\n\nPopulation Structure - Principal Component Analysis\n\u00b6\n\n\nPrinciple Component Analysis\n\ncan be used with SNP and Genotyping data to get an idea of population structure. The components generated from this data can then be used as covariates when running the analysis model.\n\n\nIn this tutorial, we will demonstrate how to run \nPrinciple Component Analysis\n (on the CHN and JPN subjects), but we will not use the generated component information for our modeling, because in our modeling we are not interested in CHN subjects. However, this can be easily accomplished with other experiment designs, if the necessary design information is available.\n\n\nTo run \nPrinciple Component Analysis (PCA)\n, go to the \nGenotyping Menu | Pattern | Principle Component Analysis\n to open the \nPrinciple Component Analysis\n window.\n\n\n\n\nAs always, ensure that the \nProject\n is set to \nTutorial\n and \nGenotypeData\n is set as the \nData\n. To choose the markers that passed the filters from our last step, choose the \nSelect\n button next to \nCustomized variables\n to open the \nSelect List\n window.\n\n\n\n\nThis allows the user to choose any variable list, including those from any open project in the \nSolution Explorer\n (as we only have one open project, the only lists shown are from the \nTutorial SNP\n project). Choose the variable list31008 and click on OK to continue. Notice the \nVariables\n section in \nPrincipal Component Analysis\n window is updated.\n\n\n\n\nObservations should be left as the default \nAll observations\n.\n\n\n\n\n\n\nComponent number\n can be set to the user s choice number of components, but is set at 10 by default.\n\n\n\n\n\n\nChange the \nGroup\n drop-down menu to \nSource\n. This does not affect the generation of the data; rather it provides automatic coloring using a group of the user s choosing. \nSource\n is chosen, so we distinguish between the CHN subjects and the JPT subjects to better visualize the population difference.\n\n\n\n\n\n\nFor \nCoding\n, choose \nEigenstrat\n which is a publicly recognized method for Principle Component Analysis, and probably most familiar to users. A  classical genotypic  method is also available.\n\n\n\n\n\n\nEnsure that \nScale Markers\n and \nOutput Scores\n are selected, as well as \nCalculate Hotelling T2\n with alpha level of 0.05.\n\n\n\n\n\n\nClick \nSubmit\n to run the \nPrinciple Component Analysis.\n\n\nInitially, the output only showing one group because our filter of JPT subjects has been carried over to every view.\n\n\n\n\nNow, choose \nCHN\n population or reset all filters using the button \nClear All Filters\n.\n\n\n\n\nBy default, \nArray Studio\n shows the first two components of the PCA, but this can be changed by using the \nSpecify X Column\n and \nSpecify Y Column\n options in the \nTask\n tab of the \nView Controller\n.\n\n\nNote:\n\n\nThe  outliers  from the PCA analysis is a result of the default EigenStrat coding. Using the classical coding (genotypic) will remove this effect from the output. In practice, we recommend classical coding (using dummy variables to represent genotypes), although EigenStrat has been very popular in academia. Please contact Omicsoft to learn more details.\n\n\nThe PCA has also generated a new \nPcaScore Table\n in the \nTable | Pattern\n section of the \nSolution Explorer\n.\n\n\n\n\nAs stated earlier, all of the generated components can be used as covariates in the model.\nThis will not be done in this tutorial, but to visualize all 10 components in a \nTableView\n, open up the view PcaScores by double clicking on it.\n\n\nThis TableView could, in other circumstances, be incorporated into the design table of your SNP data, so that it could be used as covariates in further analysis.\n\n\n\n\nCongratulations! You have learned about \nMarker Analysis\n, \nData Filtering\n, and \nPrincipal Component Analysis\n.\n\n\nIn the next chapter, we will focus on different types of association analysis.",
            "title": "Marker Statistics Data Filtering and Population Structure"
        },
        {
            "location": "/tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#marker-statistics-data-filtering-and-population-structure",
            "text": "",
            "title": "Marker Statistics, Data Filtering, and Population Structure"
        },
        {
            "location": "/tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#marker-statistics",
            "text": "In  Array Studio , the user can generate a number of different summary and QC statistics. In particular, the user can generate  Marker Statistics  or  Subject Statistics . In this tutorial, we will just generate marker statistics, but the generation of subject statistics is very similar, and can be done by the user on their own.  Go to  Genotyping | Summarize/QC | Marker Statistics  now.   This brings up the  Marker Statistics  window.   All module windows in  Array Studio  follow a similar pattern to this one. First, the user can select the  Project  and  Data  to be analyzed; in this case the only project opened is  Tutorial SNP  and our only  Data  is  Genotype Data .\nNext, if the user has generated a list of variables/markers (subset) for analysis, this can be selected. The user can also manually choose particular chromosomes for analysis.  As we are really only interested in marker statistics for the Japanese population, and since\nthese samples are currently filtered and are visible, choose  Visible Observations (45)  now, to ensure that only the visible subjects (i.e. the Japanese subjects) will be analyzed.    First, a  Group  may be specified, and the marker statistics will be calculated separately for each group.    Next, the user can choose to report a number of statistics, including    Allele frequencies    Minor allele frequency    Missing genotype count    Effective genotype count    Missing genotype proportion    Genotype frequencies    Observed heterozygosity    Gene Diversity    HWE chi square p-value    HWE exact p-value    Inbreeding coefficient    Silhouettes width  (requires SNP intensity data, i.e. Affymetrix or Illumina).      Leave the other settings as default, and click  Submit  to run the module.  A new  Table  is generated under the  Table | Summary  folder of the  Solution Explorer , called  GenotypeData.MarkerSummary . It s evident from the solution explorer that this data contains 45930 rows (or markers) and 9 columns of information.   Make sure that all variable filters are cleared.   Once unfiltered, the  TableView  should look as follows. It contains a column for the minor allele frequency (Maf), missing genotype count and percentage, as well as the covariate information (AlleleA, AlleleB, Chromosome, and BasePairPosition). This table, like any other table views, can be filtered, sorted and customized using  View Controller .",
            "title": "Marker Statistics"
        },
        {
            "location": "/tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#data-filtering",
            "text": "Prior to SNP analysis, it is a good idea to filter the markers and subjects, to exclude markers and subjects with high missing data percentage, as well as exclude markers where the minor allele frequency (MAF) is below a certain cutoff. Other options include removing markers due to an extremely significant Hardy Weinberg Equilibrium (HWE) p-value.  To filter genotype or SNP data in  Array Studio , go to the  Genotyping Menu | Summarize/QC | Filter  to open the  Filter  window, as shown below.   In this window, make sure that the  Project  is set to  Tutorial ,  Data  is set to  GenotypeData ,  Variables  to  All Variables , and  Observations  are set to  Visible Observations (45)  so that we filter only on the  JPT  subjects.   For the options,    First, a  Group  may be specified, and the marker statistics will be calculated separately for each group.    By default the filter will  exclude subjects with a missing percentage  > 10%    Exclude markers with a missing percentage  > 10%.    Change   Exclude markers with MAF<  to 0.05 (from default of 0.01).\n    This is done because of the small number of subjects we have. This is a subjective criterion and the user can change.    If we were interested, it is also possible to  exclude markers with a HWE p-value  < a cutoff.  Also, note the  Output type  is  Variable and Observation list  for this module.\nThis means that  two Lists  will be generated in the  Solution Explorer  as a result of filtering, a  List  of markers that passed the criteria, and a  List  of observations that passed the criteria. Optionally, the user can name the list as well.  Click  Submit  to run the filtering.  As can be seen below, two new  Lists  were generated by the module. All 45 JPN subjects passed the filter, as did 31008 markers. These  Lists  will be used for all further analysis.",
            "title": "Data Filtering"
        },
        {
            "location": "/tutorials/SNP/Marker_Statistics__Data_Filtering__and_Population_Structure/#population-structure-principal-component-analysis",
            "text": "Principle Component Analysis \ncan be used with SNP and Genotyping data to get an idea of population structure. The components generated from this data can then be used as covariates when running the analysis model.  In this tutorial, we will demonstrate how to run  Principle Component Analysis  (on the CHN and JPN subjects), but we will not use the generated component information for our modeling, because in our modeling we are not interested in CHN subjects. However, this can be easily accomplished with other experiment designs, if the necessary design information is available.  To run  Principle Component Analysis (PCA) , go to the  Genotyping Menu | Pattern | Principle Component Analysis  to open the  Principle Component Analysis  window.   As always, ensure that the  Project  is set to  Tutorial  and  GenotypeData  is set as the  Data . To choose the markers that passed the filters from our last step, choose the  Select  button next to  Customized variables  to open the  Select List  window.   This allows the user to choose any variable list, including those from any open project in the  Solution Explorer  (as we only have one open project, the only lists shown are from the  Tutorial SNP  project). Choose the variable list31008 and click on OK to continue. Notice the  Variables  section in  Principal Component Analysis  window is updated.   Observations should be left as the default  All observations .    Component number  can be set to the user s choice number of components, but is set at 10 by default.    Change the  Group  drop-down menu to  Source . This does not affect the generation of the data; rather it provides automatic coloring using a group of the user s choosing.  Source  is chosen, so we distinguish between the CHN subjects and the JPT subjects to better visualize the population difference.    For  Coding , choose  Eigenstrat  which is a publicly recognized method for Principle Component Analysis, and probably most familiar to users. A  classical genotypic  method is also available.    Ensure that  Scale Markers  and  Output Scores  are selected, as well as  Calculate Hotelling T2  with alpha level of 0.05.    Click  Submit  to run the  Principle Component Analysis.  Initially, the output only showing one group because our filter of JPT subjects has been carried over to every view.   Now, choose  CHN  population or reset all filters using the button  Clear All Filters .   By default,  Array Studio  shows the first two components of the PCA, but this can be changed by using the  Specify X Column  and  Specify Y Column  options in the  Task  tab of the  View Controller .  Note:  The  outliers  from the PCA analysis is a result of the default EigenStrat coding. Using the classical coding (genotypic) will remove this effect from the output. In practice, we recommend classical coding (using dummy variables to represent genotypes), although EigenStrat has been very popular in academia. Please contact Omicsoft to learn more details.  The PCA has also generated a new  PcaScore Table  in the  Table | Pattern  section of the  Solution Explorer .   As stated earlier, all of the generated components can be used as covariates in the model.\nThis will not be done in this tutorial, but to visualize all 10 components in a  TableView , open up the view PcaScores by double clicking on it.  This TableView could, in other circumstances, be incorporated into the design table of your SNP data, so that it could be used as covariates in further analysis.   Congratulations! You have learned about  Marker Analysis ,  Data Filtering , and  Principal Component Analysis .  In the next chapter, we will focus on different types of association analysis.",
            "title": "Population Structure - Principal Component Analysis"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/",
            "text": "Association Analysis\n\u00b6\n\n\nBesides visualization, summarization, and QC data, \nArray Studio\n contains a powerful set of tools for SNP association analysis. Users can analyze data using \nSingle-Marker Association\n tests or \nTwo-Marker Association\n tests. Available tests include \nBasic Association\n, \nStratified Association\n (single marker only),  \nQuantitative Trait\n, \nCategorical Trait\n, \nSurvival Trait\n, \nRepeated Measure Trait\n, as well as \nDose Data\n and \nProbability Data Association\n tests (also CNV analysis modules are available).\n\n\nIn this tutorial, we will cover basic association, categorical trait, quantitative trait, and survival trait analysis.\n\n\nBasic Association Single Marker\n\u00b6\n\n\nSingle marker-basic association analysis is based on Fisher s Exact test to test the allele frequency difference between Case/Control traits. To start a single marker-basic association analysis, go to \nGenotyping Menu | Single Marker Association | Basic Association\n to open the \nBasic Association\n window.\n\n\n\n\nAs usual, ensure that the \nProject\n is \nTutorial\n and \nData\n is \nGenotypeData\n and the \nVariables\n are set to customized variables using the list \nGenotypeData.Variable31008\n. For all of our association analyses, we only have design information for the \nJPT\n group, so use the \nObservation\n list \nGenotypeData.Observation45\n that was created in the last chapter during the \nFilter\n step (use customized observation list).\n\n\n\n\nUnder \nOptions\n,\n\n\n\n\n\n\nWe need to set the design column containing the \nTrait\n we wish to analyze, in this case \nPhenotype\n (Note: By default, \nArray Studio\n should have chosen this as the \nTrait\n, due to the selection of \nGroup\n as the \nPhenotype\n column when importing the \nDesign Table\n).\n\n\n\n\n\n\nNext, we need to set the \nCase\n level. As the levels of \nGroup\n are named case and control, we should choose \nCase\n as our \nCase\n level.\n\n\n\n\n\n\nUser can use following options to decide which statistics to include in the result:\n\n\n\n\n\n\nGenerate the \nMinor allele\n (make sure it s checked)\n\n\n\n\n\n\nMinor allele count\n\n\n\n\n\n\nAllelic test p-value and odds ratio\n (make sure it s checked)\n\n\n\n\n\n\nGenotypic test p-value\n (uncheck this box)\n\n\n\n\n\n\nDominant test p-value\n\n\n\n\n\n\nRecessive test p-value\n\n\n\n\n\n\nAdditive test p-value\n\n\n\n\n\n\n\n\nNote\n\n\nWhile it is possible to run this analysis and test for a genotypic p-value, dominant test p-value, recessive test p-value, additive test p-value, and use Fisher Exact test instead of Chi-square test, for the purposes of this tutorial we will only investigate the allelic test Chi-square p-value and asymptotic odds ratio (Fisher Exact test will give exact odds ratio).\n\n\n\n\n\n\nWe can set the Multiplicity adjustment for the test (leave as is with \nFDR_BH\n, an Alpha level of \n0.05\n, and a Confidence interval of \n0.95\n).\n\n\nFinally, change the \nOutput name\n to \nBasic Association\n and click \nSubmit\n to run the basic association test.\n\n\nA new \nTable\n will be created in the \nSolution Explorer\n under the \nInference\n section. All association analyses in \nArray Studio\n will generate \nInference Reports\n. Notice the name of the report, \nBasic Association.Tests\n (as this is the name we specified above), and the type the report \nInferenceReport Data\n.\n\n\n\n\nA \nTableView\n called \nReport\n will be generated by default and immediately visible in the main view window (make sure filters are cleared to see all variables). All of the requested information is now available for each marker, including the MinorAllele, Allelic.RawPvalue, Allelic.AdjustedPValue, and Allelic.OddsRatio. The Odds Ratio also includes the confidence interval. The last 5 columns are the appended annotation table.\n\n\n\n\nRight click in the header of the \nAllelic.RawPvalue\n column and select \nSort Ascending\n.\n\n\n\n\nThe \nTableView\n is sorted, showing the most significant markers based on this analysis.\n\n\nWe can also choose to filter this view, and we can do so using any of the generated columns (p-value, adjusted p-value etc.) or any of the annotation columns. As we are going to run three more similar analyses (categorical, quantitative and survival traits), we will do some filtering by p-value in later chapters.\n\n\nCategorical Trait Single Marker\n\u00b6\n\n\nTo run a single marker-categorical trait analysis, go to the \nGenotyping Menu | Single Marker Analysis | Categorical Trait\n.\n\n\n\n\nAs always, ensure that \nTutorial\n is chosen for \nProject, GenotypeData\n is chosen for \nData\n, \nGenotypeData.Variable31008\n is chosen for \nCustomized Variables\n. As we only have categorical trait information on the JPT subjects, make sure that our subject list, \nGenotypeData.Observation45\n, is chosen for \nCustomized Observations\n.\n\n\n\n\nClick the \nSpecify Model\n button to open the \nSpecify Model\n window:\n\n\n\n\nSet the \nTrait\n to \nGroup2\n.\nNotice that the type of trait is now recognized as a \nCategorical Trait\n, and lists the three categories. Note: for categorical traits, the user can specify whether the data is ordered. If it is ordered, it should be analyzed differently (using cumulative odds logistic regression instead of generalized logistic regression), and the \nLevels are ordered\n checkbox should be checked when running the model for this dataset. Check the \nLevels are ordered\n checkbox now (Array Studio has the ability to deal with nominal traits or ordinal traits).\n\n\nAdditional covariates could be added to the model at this point, including potential principal component analysis components. However, for this tutorial, leave the model as is (\nCategorical Trait\n is \nGroup2\n, \nordered\n, model only includes \nGenotype\n).\n\n\nClick \nOK\n to return to the \nCategorical Trait\n window.\n\n\nAt this point, the updated model should be reflected in the window.\n\n\n\n\nEnsure that \nGenerate odds ratio data\n and \nGenerate odds data\n is selected. Ensure that \nGenotypic\n is chosen for the \nDisease model\n. Other available diseases models include \nAdditive\n, \nDominant\n, and \nRecessive\n.\n\n\nMultiplicity\n should be set to \nFDR_BH\n, with an \nAlpha level\n of 0.05 and a \nConfidence interval\n of 0.95.\n\n\nSet the \nAnova type\n to Type3, and set the \nTest type\n to \nWaldTest\n (the other option is \nLikelihoodRatio\n test).\n\n\nFinally, set \nOutput name\n to \nCategorical Trait\n.\n\n\nIf the user is interested, the equivalent SAS code can be generated after all options are set, by clicking the \nShow SAS code\n button.\n\n\nClick \nSubmit\n to run the Categorical Trait association analysis.\n\n\nThree new \nTables\n will be generated under the \nInference\n section of the \nSolution Explorer\n: the standard \nTests\n table, as well as the requested Odds and OddsRatio \nTables\n.\n\n\n\n\nDouble click on the \nCategorical Trait.Tests Report\n to display the \nTableView\n in the main view window. If this data is filtered, reset all filters to see all variables.\n\n\n\n\nNotice that the \nCategorical Trait.OddsRatio\n table contains two views: an \nOddsRatio\n view and a \nTable\n view. Switch to the \nOddsRatio\n view now by double-clicking it.\n\n\nThe \nOddsRatio\n table will only be generated for significant genotypes. Remove any filters on this view, and notice that there are 3 charts that were generated. To view all 3 charts in the same time, change to \n2*2\n in the drop down list.\n\n\n\n\nThe user can also see the \nTableView\n information for the \nOddsRatio\n by double-clicking the generated table view.\n\n\nIn this \nTableView\n, each row contains the marker ID, the group that is being compared, and the p-value, as well as the odds ratio and confidence intervals. Annotation information is also included.\n\n\n\n\nFinally, a Table has been created for viewing the Odds. This includes a visualization of the \nOdds\n, as well as a \nTableView\n. Double-click on the \nOdds\n view now to open it in the main view window.\n\n\n\n\nDouble-click on the \nTableView\n of \nOdds\n now to see the generated Odds for each group.\n\n\n\n\nQuantitative Trait Single Marker(General)\n\u00b6\n\n\nTo run a single marker-quantitative trait, go to \nGenotyping | Single Marker Analysis | Quantitative Trait (General)\n, which opens the \nQuantitative Trait\n window.\n\n\n\n\nAs always, ensure that \nTutorial\n is chosen for \nProject\n, \nGenotypeData\n is chosen for \nData\n, and \nGenotypeData.Variable31008\n is chosen for \nCustomized Variables\n. As we only have categorical trait information on the JPT subjects, make sure that our subject list, \nGenotypeData.Observation45\n, is chosen for*Customized Observations.*\n\n\n\n\nClick the \nSpecify Model\n button to open the \nSpecify Model\n window:\n\n\n\n\nThe first step in this window is to select the quantitative trait to be used for analysis. For \nTrait\n, choose the column \nQtrait\n, as this contains our quantitative trait information. If the correct column is selected, the box to the right will indicate that the type of trait is indeed a quantitative trait.\n\n\nNext, we can add any covariates to our model. Normally, this may include generated components from a principal component analysis.\n\n\nFor this tutorial, we will just add the columns labeled \nCovariate 1\n and \nCovariate 2\n. They can be added by selecting both of these columns (under \nColumns\n), and clicking the \nAdd\n button to add them to the model.\nNotice that \nQtrait\n, \nCovariate 1\n and \nCovariate 2\n are set to \nClass\n, uncheck the box for them.\n\n\nClick \nOK\n to return to the \nQuantitative Trait\n window. At this point, the updated model should be reflected in the window.\n\n\n\n\nUnder \nOptions\n, ensure that \nGenerate LSMeans data\n is selected, as well as \nGenerate contrast data\n, and that \nGenotypic\n is chosen for the \nDisease model\n. Other available diseases models include \nAdditive\n, \nDominant\n, and \nRecessive\n.\n\n\nMultiplicity\n should be set to \nFDR_BH\n, with an \nAlpha level\n of 0.05 and a \nConfidence interval\n of 0.95.\n\n\nSet the \nAnova type\n to Type3, and set the \nTest type\n to \nWaldTest\n (the other option is \nLikelihoodRatio\n test).\n\n\nFinally, set \nOutput name\n to \nCategorical Trait\n.\n\n\nClick \nSubmit\n to run the Quantitative Trait association analysis.\n\n\nThree new \nTables\n will be generated under the \nInference\n tab of the \nSolution Explorer\n: an \nLSMeans\n (least square mean) \nTable,\n a \nContrasts Table\n and a \nTests\n table. The \nTests\n table is similar to the \nTable\n encountered with the \nBasic Association\n analysis and with the categorical association analysis.\n\n\n\n\nEnsure that the \nReport TableView\n for \nQuantitative Trait.Tests\n is showing in the main view window. Reset any filters if need.\n\n\nNext, let s filter the table, to only show us markers where the \nGENOTYPE.FDR_BH\n (adjusted p-value) is less than \n0.05\n (enter \"<0.05\" into the \nGENOTYPE.FDR_BH\n filter).\n\n\n\n\nThis should show a \nTableView\n containing 12 rows. Let s further sort these rows by the adjusted p-value column, so that the most significant markers are shown first, as shown below.\n\n\n\n\nSelect the top three markers now, by clicking on the header row names in the ID column.\n\n\n\n\nNow, let s generate a \nChromosomeView\n for this data. To add a \nChromosomeView\n, right click \nQuantitative Trait.Tests\n, click on \nAdd View\n and then choose \nChromosomeView\n. When added, it should look similar to the following screenshot.\n\n\nOnly two chromosomes are shown, because the data was previously filtered. We will un-filter this data in one minute, but first, let s check to see whether the three selected markers (with the same p-values) are in linkage disequilibrium.\n\n\n\n\nTo generate Linkage Disequilibrium results on demand, click the \nLD On Demand\n button in the \nTask\n tab of the \nView Controller\n.\n\n\n\n\nThis generates a correlation heatmap of our selected rows, with a red color indicating higher correlation. The coloring scheme can be changed by clicking the \nCustomize View\n window in this window\n\n\n\n\nIf the Correlation Heatmap does not look similar to the screen shot above, click the \nCustomize View\n button and remove any \nVariable\n filters.\n\n\nIt is clear from the perfect correlation values (=1), that these three markers are in complete linkage disequilibrium.\n\n\nClose the window and return to the \nChromosomeView\n.\n\n\nNow, remove the previously set p-value filter. Your \nChromosomeView\n should now look similar to below. In this view, you can see all of the Chromosomes in your experiment, and then each chromosome has lines colored, based on a certain criteria.\n\n\n\n\nClick the \nSpecify Data Source\n option in the \nTask\n tab of the \nView Controller\n. Note that the \nGenotype.RawPValue\n option is chosen. This means that the color is based on this column. Click \nOK\n to return to the view.\n\n\n\n\nNow click the \nChange Color Properties\n option in the \nTask\n tab of the \nView Controller\n. This dialog box shows you how the chart is colored. In this case, high p-values are colored as a clear color, while low p-values are colored as blue. The user can also specify what counts as a high and low p-value.\n\n\nFeel free to change the colors, and/or the high and low p-values, and reflect the changes on the chart.\n\n\n\n\nThe user also has the option of looking at each individual chromosome in its own chart. This can be accomplished by clicking the \nTrellis by Chromosome\n option in the \nTask\n tab of the \nView Controller\n. Click this option now and the view should reflect the screenshot below.\n\n\n\n\nScroll through the charts, to see all of the chromosomes. Notice that the Y-axis of the chart represents the  log10 (p-value). This is a fully interactive view as well, so individual data points can be selected and viewed in the \nDetails Window\n. When selected, points turn a red color.\n\n\nArray Studio\n also generated \nLSMeans\n table and charts for the quantitative data.\n\n\nSwitch to the \nLSMeans\n view for the Table \nQuantitative Trait.LSMeans\n. By default, LSMeans data was generated for each significant marker (as we noted earlier, there are 12 significant markers, with an adjusted p-value<0.05). Scroll through the charts and take a look at the data (unfilter the data if necessary). It is clear that for each significant marker, the different genotypes have different least square mean values for the quantitative trait.\n\n\n\n\nA Table view of the \nLSMeans\n data was also generated and can be opened and viewed at any time.\n\n\nFinally, a \nContrasts Table\n was generated, with a \nContrasts\n view, as well as a Table view. Double-click the \nContrasts\n view now.\n\n\n\n\nOn the X-axis is each contrast (i.e. A_T vs. A_A, T_T vs. A_A), with the Y-axis the value of the estimate.\n\n\n\n\nA Table view was created for the \nContrasts\n dataset. This can be opened and viewed at any time.\n\n\nSurvival Trait Single Marker\n\u00b6\n\n\nSurvival Trait analysis could be an important component of any SNP study from clinical trials. As we noted earlier, it is possible to generate a \nSurvivalView\n in \nArray Studio\n. However, we can also perform single-marker and two-marker survival trait association analysis.\n\n\nSingle-Marker Survival Trait analysis will be demonstrated in this tutorial. To perform this analysis, go to the menu \nGenotyping | Single Marker Association | Survival Trait\n.\n\n\n\n\n\n\nAs always, ensure that \nTutorial\n is chosen for \nProject\n, \nGenotypeData\n is chosen for \nData\n, \nGenotypeData.Variable31008\n is chosen for \nCustomized Variables\n. As we only have categorical trait information on the JPT subjects, make sure that our subject list, \nGenotypeData.Observation45\n, is chosen for \nCustomized Observations.\n\n\nClick the \nSpecify Model\n button to open the \nSpecify Model\n window:\n\n\n\n\nFor Survival Analysis, the user needs to have design columns containing at least three pieces of information. First, the \nTime\n column must be set (in this case, use the \nSurvivalTime\n column). Second, the \nStatus\n column must be set (in this case, use the column \nStatus\n). Finally, the \nEvent\n must be set (using \nDeath\n from the \nStatus\n column).\n\n\nStrata\n and other covariate factors can also be added to the model at this stage as well. However, for this tutorial, just leave \nGenotype\n in the model.\n\n\nClick \nOK\n to return to the \nQuantitative Trait\n window. At this point, the updated model should be reflected in the window.\n\n\n\n\nUnder \nOptions\n, ensure that the \nGenerate hazard ratio data\n is selected, and that \nGenotypic\n is chosen for the \nDisease model\n. Other available diseases models include \nAdditive\n, \nDominant\n, and \nRecessive\n.\n\n\nMultiplicity\n should be set to \nFDR_BH\n, with an \nAlpha level\n of 0.05 and a \nConfidence interval\n of 0.95.\n\n\nSet the \nAnova type\n to Type3, and set the \nTest type\n to \nWaldTest\n (the other option is \nLikelihoodRatio\n test).\n\n\nFinally, set \nOutput name\n to \nSurvival Trait\n.\n\n\nClick \nSubmit\n to run the Quantitative Trait association analysis.\n\n\nTwo tables will be generated in the \nInference\n section of the \nSolution Explorer\n, \nSurvival Trait.HazrdRatios\n and \nSurvival Trait.Tests data\n.\n\n\n\n\n\n\nFinally, notice in the \nLists\n section of the \nSolution Explorer\n, that each of our analyses has generated lists of significant genes, based on our criteria of an FDR-BH adjusted p-value of 0.05.\n\n\n\n\nLet s use our survival analysis \nList\n with the previously generated \nSurvivalView\n in the GenotypeData dataset to see what these markers look like.\n\n\nFirst, reopen the \nSurvivalView\n of the \nGenotypeData\n dataset by double-clicking it in the \nSolution Explorer\n.\n\n\n\n\nNext, once the \nSurvivalView\n is opened, go to the \nVariables\n filter in the \nView Controller\n.\n\n\nSelect the \nID\n column of the filter, and expand it.\n\n\n\n\nNote\n\n\nIf the main view window shows an error message, stating that there is missing or negative information in Y, you will need to re-filter the \nObservations\n to ONLY include the \nJPT\n subjects as the remaining subjects do not include survival time information, and this filter had been previously removed.\n\n\n\n\n\n\nTo add a filter based on a list, right click on ID and choose \nAdd List Filter\n. Select the \nSurvival Trait.Association.Sig6\n which contains the six significant markers in the survival trait analysis, and then click \nOK\n.\n\n\n\n\nThe main view window is updated to only show the 6 charts from the significant markers.\n\n\n\n\nCongratulations! You have completed four different association analyses in \nArray Studio\n. Save your project file, in case you want to go back to it in the future. In the next chapter, we will look at further visualizations that can be used on the analysis results.",
            "title": "Association Analysis"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/#association-analysis",
            "text": "Besides visualization, summarization, and QC data,  Array Studio  contains a powerful set of tools for SNP association analysis. Users can analyze data using  Single-Marker Association  tests or  Two-Marker Association  tests. Available tests include  Basic Association ,  Stratified Association  (single marker only),   Quantitative Trait ,  Categorical Trait ,  Survival Trait ,  Repeated Measure Trait , as well as  Dose Data  and  Probability Data Association  tests (also CNV analysis modules are available).  In this tutorial, we will cover basic association, categorical trait, quantitative trait, and survival trait analysis.",
            "title": "Association Analysis"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/#basic-association-single-marker",
            "text": "Single marker-basic association analysis is based on Fisher s Exact test to test the allele frequency difference between Case/Control traits. To start a single marker-basic association analysis, go to  Genotyping Menu | Single Marker Association | Basic Association  to open the  Basic Association  window.   As usual, ensure that the  Project  is  Tutorial  and  Data  is  GenotypeData  and the  Variables  are set to customized variables using the list  GenotypeData.Variable31008 . For all of our association analyses, we only have design information for the  JPT  group, so use the  Observation  list  GenotypeData.Observation45  that was created in the last chapter during the  Filter  step (use customized observation list).   Under  Options ,    We need to set the design column containing the  Trait  we wish to analyze, in this case  Phenotype  (Note: By default,  Array Studio  should have chosen this as the  Trait , due to the selection of  Group  as the  Phenotype  column when importing the  Design Table ).    Next, we need to set the  Case  level. As the levels of  Group  are named case and control, we should choose  Case  as our  Case  level.    User can use following options to decide which statistics to include in the result:    Generate the  Minor allele  (make sure it s checked)    Minor allele count    Allelic test p-value and odds ratio  (make sure it s checked)    Genotypic test p-value  (uncheck this box)    Dominant test p-value    Recessive test p-value    Additive test p-value     Note  While it is possible to run this analysis and test for a genotypic p-value, dominant test p-value, recessive test p-value, additive test p-value, and use Fisher Exact test instead of Chi-square test, for the purposes of this tutorial we will only investigate the allelic test Chi-square p-value and asymptotic odds ratio (Fisher Exact test will give exact odds ratio).    We can set the Multiplicity adjustment for the test (leave as is with  FDR_BH , an Alpha level of  0.05 , and a Confidence interval of  0.95 ).  Finally, change the  Output name  to  Basic Association  and click  Submit  to run the basic association test.  A new  Table  will be created in the  Solution Explorer  under the  Inference  section. All association analyses in  Array Studio  will generate  Inference Reports . Notice the name of the report,  Basic Association.Tests  (as this is the name we specified above), and the type the report  InferenceReport Data .   A  TableView  called  Report  will be generated by default and immediately visible in the main view window (make sure filters are cleared to see all variables). All of the requested information is now available for each marker, including the MinorAllele, Allelic.RawPvalue, Allelic.AdjustedPValue, and Allelic.OddsRatio. The Odds Ratio also includes the confidence interval. The last 5 columns are the appended annotation table.   Right click in the header of the  Allelic.RawPvalue  column and select  Sort Ascending .   The  TableView  is sorted, showing the most significant markers based on this analysis.  We can also choose to filter this view, and we can do so using any of the generated columns (p-value, adjusted p-value etc.) or any of the annotation columns. As we are going to run three more similar analyses (categorical, quantitative and survival traits), we will do some filtering by p-value in later chapters.",
            "title": "Basic Association Single Marker"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/#categorical-trait-single-marker",
            "text": "To run a single marker-categorical trait analysis, go to the  Genotyping Menu | Single Marker Analysis | Categorical Trait .   As always, ensure that  Tutorial  is chosen for  Project, GenotypeData  is chosen for  Data ,  GenotypeData.Variable31008  is chosen for  Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list,  GenotypeData.Observation45 , is chosen for  Customized Observations .   Click the  Specify Model  button to open the  Specify Model  window:   Set the  Trait  to  Group2 .\nNotice that the type of trait is now recognized as a  Categorical Trait , and lists the three categories. Note: for categorical traits, the user can specify whether the data is ordered. If it is ordered, it should be analyzed differently (using cumulative odds logistic regression instead of generalized logistic regression), and the  Levels are ordered  checkbox should be checked when running the model for this dataset. Check the  Levels are ordered  checkbox now (Array Studio has the ability to deal with nominal traits or ordinal traits).  Additional covariates could be added to the model at this point, including potential principal component analysis components. However, for this tutorial, leave the model as is ( Categorical Trait  is  Group2 ,  ordered , model only includes  Genotype ).  Click  OK  to return to the  Categorical Trait  window.  At this point, the updated model should be reflected in the window.   Ensure that  Generate odds ratio data  and  Generate odds data  is selected. Ensure that  Genotypic  is chosen for the  Disease model . Other available diseases models include  Additive ,  Dominant , and  Recessive .  Multiplicity  should be set to  FDR_BH , with an  Alpha level  of 0.05 and a  Confidence interval  of 0.95.  Set the  Anova type  to Type3, and set the  Test type  to  WaldTest  (the other option is  LikelihoodRatio  test).  Finally, set  Output name  to  Categorical Trait .  If the user is interested, the equivalent SAS code can be generated after all options are set, by clicking the  Show SAS code  button.  Click  Submit  to run the Categorical Trait association analysis.  Three new  Tables  will be generated under the  Inference  section of the  Solution Explorer : the standard  Tests  table, as well as the requested Odds and OddsRatio  Tables .   Double click on the  Categorical Trait.Tests Report  to display the  TableView  in the main view window. If this data is filtered, reset all filters to see all variables.   Notice that the  Categorical Trait.OddsRatio  table contains two views: an  OddsRatio  view and a  Table  view. Switch to the  OddsRatio  view now by double-clicking it.  The  OddsRatio  table will only be generated for significant genotypes. Remove any filters on this view, and notice that there are 3 charts that were generated. To view all 3 charts in the same time, change to  2*2  in the drop down list.   The user can also see the  TableView  information for the  OddsRatio  by double-clicking the generated table view.  In this  TableView , each row contains the marker ID, the group that is being compared, and the p-value, as well as the odds ratio and confidence intervals. Annotation information is also included.   Finally, a Table has been created for viewing the Odds. This includes a visualization of the  Odds , as well as a  TableView . Double-click on the  Odds  view now to open it in the main view window.   Double-click on the  TableView  of  Odds  now to see the generated Odds for each group.",
            "title": "Categorical Trait Single Marker"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/#quantitative-trait-single-markergeneral",
            "text": "To run a single marker-quantitative trait, go to  Genotyping | Single Marker Analysis | Quantitative Trait (General) , which opens the  Quantitative Trait  window.   As always, ensure that  Tutorial  is chosen for  Project ,  GenotypeData  is chosen for  Data , and  GenotypeData.Variable31008  is chosen for  Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list,  GenotypeData.Observation45 , is chosen for*Customized Observations.*   Click the  Specify Model  button to open the  Specify Model  window:   The first step in this window is to select the quantitative trait to be used for analysis. For  Trait , choose the column  Qtrait , as this contains our quantitative trait information. If the correct column is selected, the box to the right will indicate that the type of trait is indeed a quantitative trait.  Next, we can add any covariates to our model. Normally, this may include generated components from a principal component analysis.  For this tutorial, we will just add the columns labeled  Covariate 1  and  Covariate 2 . They can be added by selecting both of these columns (under  Columns ), and clicking the  Add  button to add them to the model.\nNotice that  Qtrait ,  Covariate 1  and  Covariate 2  are set to  Class , uncheck the box for them.  Click  OK  to return to the  Quantitative Trait  window. At this point, the updated model should be reflected in the window.   Under  Options , ensure that  Generate LSMeans data  is selected, as well as  Generate contrast data , and that  Genotypic  is chosen for the  Disease model . Other available diseases models include  Additive ,  Dominant , and  Recessive .  Multiplicity  should be set to  FDR_BH , with an  Alpha level  of 0.05 and a  Confidence interval  of 0.95.  Set the  Anova type  to Type3, and set the  Test type  to  WaldTest  (the other option is  LikelihoodRatio  test).  Finally, set  Output name  to  Categorical Trait .  Click  Submit  to run the Quantitative Trait association analysis.  Three new  Tables  will be generated under the  Inference  tab of the  Solution Explorer : an  LSMeans  (least square mean)  Table,  a  Contrasts Table  and a  Tests  table. The  Tests  table is similar to the  Table  encountered with the  Basic Association  analysis and with the categorical association analysis.   Ensure that the  Report TableView  for  Quantitative Trait.Tests  is showing in the main view window. Reset any filters if need.  Next, let s filter the table, to only show us markers where the  GENOTYPE.FDR_BH  (adjusted p-value) is less than  0.05  (enter \"<0.05\" into the  GENOTYPE.FDR_BH  filter).   This should show a  TableView  containing 12 rows. Let s further sort these rows by the adjusted p-value column, so that the most significant markers are shown first, as shown below.   Select the top three markers now, by clicking on the header row names in the ID column.   Now, let s generate a  ChromosomeView  for this data. To add a  ChromosomeView , right click  Quantitative Trait.Tests , click on  Add View  and then choose  ChromosomeView . When added, it should look similar to the following screenshot.  Only two chromosomes are shown, because the data was previously filtered. We will un-filter this data in one minute, but first, let s check to see whether the three selected markers (with the same p-values) are in linkage disequilibrium.   To generate Linkage Disequilibrium results on demand, click the  LD On Demand  button in the  Task  tab of the  View Controller .   This generates a correlation heatmap of our selected rows, with a red color indicating higher correlation. The coloring scheme can be changed by clicking the  Customize View  window in this window   If the Correlation Heatmap does not look similar to the screen shot above, click the  Customize View  button and remove any  Variable  filters.  It is clear from the perfect correlation values (=1), that these three markers are in complete linkage disequilibrium.  Close the window and return to the  ChromosomeView .  Now, remove the previously set p-value filter. Your  ChromosomeView  should now look similar to below. In this view, you can see all of the Chromosomes in your experiment, and then each chromosome has lines colored, based on a certain criteria.   Click the  Specify Data Source  option in the  Task  tab of the  View Controller . Note that the  Genotype.RawPValue  option is chosen. This means that the color is based on this column. Click  OK  to return to the view.   Now click the  Change Color Properties  option in the  Task  tab of the  View Controller . This dialog box shows you how the chart is colored. In this case, high p-values are colored as a clear color, while low p-values are colored as blue. The user can also specify what counts as a high and low p-value.  Feel free to change the colors, and/or the high and low p-values, and reflect the changes on the chart.   The user also has the option of looking at each individual chromosome in its own chart. This can be accomplished by clicking the  Trellis by Chromosome  option in the  Task  tab of the  View Controller . Click this option now and the view should reflect the screenshot below.   Scroll through the charts, to see all of the chromosomes. Notice that the Y-axis of the chart represents the  log10 (p-value). This is a fully interactive view as well, so individual data points can be selected and viewed in the  Details Window . When selected, points turn a red color.  Array Studio  also generated  LSMeans  table and charts for the quantitative data.  Switch to the  LSMeans  view for the Table  Quantitative Trait.LSMeans . By default, LSMeans data was generated for each significant marker (as we noted earlier, there are 12 significant markers, with an adjusted p-value<0.05). Scroll through the charts and take a look at the data (unfilter the data if necessary). It is clear that for each significant marker, the different genotypes have different least square mean values for the quantitative trait.   A Table view of the  LSMeans  data was also generated and can be opened and viewed at any time.  Finally, a  Contrasts Table  was generated, with a  Contrasts  view, as well as a Table view. Double-click the  Contrasts  view now.   On the X-axis is each contrast (i.e. A_T vs. A_A, T_T vs. A_A), with the Y-axis the value of the estimate.   A Table view was created for the  Contrasts  dataset. This can be opened and viewed at any time.",
            "title": "Quantitative Trait Single Marker(General)"
        },
        {
            "location": "/tutorials/SNP/Association_Analysis/#survival-trait-single-marker",
            "text": "Survival Trait analysis could be an important component of any SNP study from clinical trials. As we noted earlier, it is possible to generate a  SurvivalView  in  Array Studio . However, we can also perform single-marker and two-marker survival trait association analysis.  Single-Marker Survival Trait analysis will be demonstrated in this tutorial. To perform this analysis, go to the menu  Genotyping | Single Marker Association | Survival Trait .    As always, ensure that  Tutorial  is chosen for  Project ,  GenotypeData  is chosen for  Data ,  GenotypeData.Variable31008  is chosen for  Customized Variables . As we only have categorical trait information on the JPT subjects, make sure that our subject list,  GenotypeData.Observation45 , is chosen for  Customized Observations.  Click the  Specify Model  button to open the  Specify Model  window:   For Survival Analysis, the user needs to have design columns containing at least three pieces of information. First, the  Time  column must be set (in this case, use the  SurvivalTime  column). Second, the  Status  column must be set (in this case, use the column  Status ). Finally, the  Event  must be set (using  Death  from the  Status  column).  Strata  and other covariate factors can also be added to the model at this stage as well. However, for this tutorial, just leave  Genotype  in the model.  Click  OK  to return to the  Quantitative Trait  window. At this point, the updated model should be reflected in the window.   Under  Options , ensure that the  Generate hazard ratio data  is selected, and that  Genotypic  is chosen for the  Disease model . Other available diseases models include  Additive ,  Dominant , and  Recessive .  Multiplicity  should be set to  FDR_BH , with an  Alpha level  of 0.05 and a  Confidence interval  of 0.95.  Set the  Anova type  to Type3, and set the  Test type  to  WaldTest  (the other option is  LikelihoodRatio  test).  Finally, set  Output name  to  Survival Trait .  Click  Submit  to run the Quantitative Trait association analysis.  Two tables will be generated in the  Inference  section of the  Solution Explorer ,  Survival Trait.HazrdRatios  and  Survival Trait.Tests data .    Finally, notice in the  Lists  section of the  Solution Explorer , that each of our analyses has generated lists of significant genes, based on our criteria of an FDR-BH adjusted p-value of 0.05.   Let s use our survival analysis  List  with the previously generated  SurvivalView  in the GenotypeData dataset to see what these markers look like.  First, reopen the  SurvivalView  of the  GenotypeData  dataset by double-clicking it in the  Solution Explorer .   Next, once the  SurvivalView  is opened, go to the  Variables  filter in the  View Controller .  Select the  ID  column of the filter, and expand it.   Note  If the main view window shows an error message, stating that there is missing or negative information in Y, you will need to re-filter the  Observations  to ONLY include the  JPT  subjects as the remaining subjects do not include survival time information, and this filter had been previously removed.    To add a filter based on a list, right click on ID and choose  Add List Filter . Select the  Survival Trait.Association.Sig6  which contains the six significant markers in the survival trait analysis, and then click  OK .   The main view window is updated to only show the 6 charts from the significant markers.   Congratulations! You have completed four different association analyses in  Array Studio . Save your project file, in case you want to go back to it in the future. In the next chapter, we will look at further visualizations that can be used on the analysis results.",
            "title": "Survival Trait Single Marker"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/",
            "text": "Visualization of P-Values\n\u00b6\n\n\nArray Studio\n also includes a number of other views, specifically for visualizing p-values after running an analysis. For this tutorial, we will investigate the p-values generated by the quantitative trait analysis in the previous chapter. Specifically, this includes \nChromosomeView\n, \nHistogramView\n, \nPvaluePlotView\n, \nGenomeView\n, and \nRegionView\n. As we already discussed the \nChromosomeView\n in the previous chapter, it will not be discussed again here. But, feel free to investigate the \nChromosomeView\n again on your own.\n\n\nHistogramView\n\u00b6\n\n\nAdd a \nHistogramView\n to the \nQuantitative Trait.Tests\n table in the \nInference\n section of the \nSolution Explorer\n. Right click on \nQuantitative Trait.Tests\n, and choose \nAdd View\n. Choose \nHistogramView\n from the list.\n\n\n\n\nOnce the view is open, it will look similar to the following.\n\n\n\n\nOn the x-axis is the p-value, while the y-axis is the count of each p-value.\n\n\nTo change the column used for the p-value, use the \nSpecify Histogram Columns\n option in the \nTask\n tab of the \nView Controller\n.\n\n\n\n\nThis opens the \nChoose Columns\n window. Add \nGENOTYPE.FDR_BH\n to the \nListed columns\n and click \nOK\n to return to the view.\n\n\nNotice now that there are 2 charts in the view. Scroll to the chart to see the initial \nHistogramView\n for the adjusted p-values.\n\n\n\n\nFiltering on p-values can reveal more significant ones in this view. Try this now, by filtering the \nGENOTYPE.FDR_BH\n to those markers less than 0.05 (enter \"<0.05\" into the \nGENOTYPE.FDR_BH\n filter).\n\n\n\n\nClick on any bar in the \nHistogramView\n to see the details of variables in that bar. Selected bars are highlighted in red. Notice that the \nDetails\n window is updated to show the selected variables.\n\n\nPValuePlotView (PValueQQPlot now)\n\u00b6\n\n\nBesides the \nHistogramView\n, \nArray Studio\n provides a \nPValuePlotView\n for looking at analyzed data. Add this view to the \nQuantitative Trait.Tests\n table by adding it in the usual manner. Once added, it should look similar to the screenshot below. If you have an active filter (e.g. raw-pvalue < 0.05), reset the filter now.\n\n\nThe \nPvaluePlotView\n plot the expected p-value versus the observed p-value and can be used for examining the distribution of the p-value results.\n\n\nIn this view, the x-axis shows the  Log10 of the expected PValue, while the y-axis shows the  Log10 of the observed PValue.\n\n\n\n\nThe expected p-value line can be drawn by clicking the \nShow Line\n option in the \nCustomize\n section of the \nTask\n tab of the \nSolution Explorer\n.\n\n\n\n\nThe view is updated with the expected p-value line in red and the 95% confidence interval values in green. It appears from this graph the observed p-values do deviate from the expected distribution.\n\n\n\n\nOther options in the \nTask\n tab of the \nView Controller\n include removing the  Log10 transformation from the graph, and specifying which columns to be used as p-value columns. Like all the other views in Array Studio, PValuePlot view is also fully interactive.\n\n\nGenomeView\n\u00b6\n\n\nAnother view that can be added is the \nGenomeView\n. In this view, the x-axis represents the whole genome, while the y-axis represents the p-value. The user can set a specific p-value cutoff for visualization (by default 0.01).\n\n\nAdd a new \nGenomeView\n to the \nQuantitative Trait.Tests\n table now. When added, it should look similar to the screenshot below. Points shown by default have p-value < 0.01.\n\n\n\n\nTo change the P-value cutoff, click the \nSpecify PValue Cutoff\n in the \nTask\n tab of the \nView Controller\n.\n\n\n\n\nThis opens the \nSpecify PValue Cutoff\n window. The user can either choose one of the preset p-values, or enter the value in the box. Change the \nPValue cutoff\n to \n1\n in order to display all data points. Click \nOK\n to continue.\n\n\n\n\nThe graph is updated. Note that by default the symbols are colored by chromosome. This works well, as the user can easily distinguish between the data points on each chromosome.\n\n\n\n\nFinally, the user can also trellis the chart by chromosome, so that each chart represents one chromosome. Do this by selecting the \nTrellis By Row Covariate\n option in the \nTask\n tab of the \nSolution Explorer\n.\n\n\n\n\nThis opens the \nChoose Columns\n window. Add \nChromosome\n to the \nListed Columns\n and click \nOK\n to trellis the chart by chromosome.\n\n\n\n\nThe view is updated so that there is one chart per chromosome. In total, there are 32 charts.\n\n\nThe chart of chromosome 16 is shown below.\n\n\n\n\nRegion View\n\u00b6\n\n\nAnother view that can be added is the \nRegionView\n. In this view, the user can use the latest Ensembl build to visualize their results across the chromosomes. In addition, they can easily find particular genes of interest and automatically zoom to that region.\n\n\nClear all filters on the \nQuantitative Trait.Tests\n report now.\n\n\nAdd a new \nRegionView\n to the \nQuantitative Trait.Tests\n table now. When added, it should look similar to the screenshot below.\n\n\nNote:\n\nThe first time a RegionView is added, it may take a few minutes to download the Ensembl and Hapmap information.\n\n\n\n\nThe \nRegionView\n contains multiple parts. Each part is fully interactive, and contains options that can be accessed by right-clicking.\n\n\nThe first section is the Overview of the chromosome. The chromosome in view can be set, either by manually setting the Start and End points or by using the zoom in and zoom out.\n\n\nFor the Overview section, the user can right-click to switch between panning and zoom modes. Selecting particular sections of the chromosome will zoom in the main view.\n\n\nThe next section contains the cytoband for that chromosome.\n\n\n\n\nThe next visible section is the transcript view. This will show the names of the transcripts for the currently visible region. It becomes very useful as you zoom in. Again, right-clicking allows a number of options.\n\n\nRight click on that region and choose \nFind Gene\n from the dropdown box.\n\n\n\n\nThis opens the \nAutofill\n window where the user can search for their gene of interest. Type \nPrdm2\n and move it over to the right-hand side, and then choose the region. Click \nOK\n to continue.\n\n\n\n\nThe transcript view is now zoomed to the region of PRDM2, where the user can visualize all the p-values associated with this region. The current chromosome region we are viewing is highlighted in red on the cytoband.\n\n\nAgain, all of these sections can be further customized by using right-click, and switching between modes.\n\n\n\n\nBy default, the main view will contain 1 chart of p-values. The x-axis is the position of the chromosome, while the y-axis shows the  Log10 Pvalue. Use the \nSpecify Value Columns\n from the \nTask\n tab of \nView Controller\n to display more numerical columns.\n\n\n\n\nAdd \nGENOTYPE.FDR_BH\n from the left panel to the right \nListed columns\n panel. The main view is updated to have 2 parallel plots.\n\n\n\n\nCongratulations! You have now explored your results of your analysis, using a number of different visualizations.",
            "title": "Visualizationof pValues"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/#visualization-of-p-values",
            "text": "Array Studio  also includes a number of other views, specifically for visualizing p-values after running an analysis. For this tutorial, we will investigate the p-values generated by the quantitative trait analysis in the previous chapter. Specifically, this includes  ChromosomeView ,  HistogramView ,  PvaluePlotView ,  GenomeView , and  RegionView . As we already discussed the  ChromosomeView  in the previous chapter, it will not be discussed again here. But, feel free to investigate the  ChromosomeView  again on your own.",
            "title": "Visualization of P-Values"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/#histogramview",
            "text": "Add a  HistogramView  to the  Quantitative Trait.Tests  table in the  Inference  section of the  Solution Explorer . Right click on  Quantitative Trait.Tests , and choose  Add View . Choose  HistogramView  from the list.   Once the view is open, it will look similar to the following.   On the x-axis is the p-value, while the y-axis is the count of each p-value.  To change the column used for the p-value, use the  Specify Histogram Columns  option in the  Task  tab of the  View Controller .   This opens the  Choose Columns  window. Add  GENOTYPE.FDR_BH  to the  Listed columns  and click  OK  to return to the view.  Notice now that there are 2 charts in the view. Scroll to the chart to see the initial  HistogramView  for the adjusted p-values.   Filtering on p-values can reveal more significant ones in this view. Try this now, by filtering the  GENOTYPE.FDR_BH  to those markers less than 0.05 (enter \"<0.05\" into the  GENOTYPE.FDR_BH  filter).   Click on any bar in the  HistogramView  to see the details of variables in that bar. Selected bars are highlighted in red. Notice that the  Details  window is updated to show the selected variables.",
            "title": "HistogramView"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/#pvalueplotview-pvalueqqplot-now",
            "text": "Besides the  HistogramView ,  Array Studio  provides a  PValuePlotView  for looking at analyzed data. Add this view to the  Quantitative Trait.Tests  table by adding it in the usual manner. Once added, it should look similar to the screenshot below. If you have an active filter (e.g. raw-pvalue < 0.05), reset the filter now.  The  PvaluePlotView  plot the expected p-value versus the observed p-value and can be used for examining the distribution of the p-value results.  In this view, the x-axis shows the  Log10 of the expected PValue, while the y-axis shows the  Log10 of the observed PValue.   The expected p-value line can be drawn by clicking the  Show Line  option in the  Customize  section of the  Task  tab of the  Solution Explorer .   The view is updated with the expected p-value line in red and the 95% confidence interval values in green. It appears from this graph the observed p-values do deviate from the expected distribution.   Other options in the  Task  tab of the  View Controller  include removing the  Log10 transformation from the graph, and specifying which columns to be used as p-value columns. Like all the other views in Array Studio, PValuePlot view is also fully interactive.",
            "title": "PValuePlotView (PValueQQPlot now)"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/#genomeview",
            "text": "Another view that can be added is the  GenomeView . In this view, the x-axis represents the whole genome, while the y-axis represents the p-value. The user can set a specific p-value cutoff for visualization (by default 0.01).  Add a new  GenomeView  to the  Quantitative Trait.Tests  table now. When added, it should look similar to the screenshot below. Points shown by default have p-value < 0.01.   To change the P-value cutoff, click the  Specify PValue Cutoff  in the  Task  tab of the  View Controller .   This opens the  Specify PValue Cutoff  window. The user can either choose one of the preset p-values, or enter the value in the box. Change the  PValue cutoff  to  1  in order to display all data points. Click  OK  to continue.   The graph is updated. Note that by default the symbols are colored by chromosome. This works well, as the user can easily distinguish between the data points on each chromosome.   Finally, the user can also trellis the chart by chromosome, so that each chart represents one chromosome. Do this by selecting the  Trellis By Row Covariate  option in the  Task  tab of the  Solution Explorer .   This opens the  Choose Columns  window. Add  Chromosome  to the  Listed Columns  and click  OK  to trellis the chart by chromosome.   The view is updated so that there is one chart per chromosome. In total, there are 32 charts.  The chart of chromosome 16 is shown below.",
            "title": "GenomeView"
        },
        {
            "location": "/tutorials/SNP/Visualizationof_pValues/#region-view",
            "text": "Another view that can be added is the  RegionView . In this view, the user can use the latest Ensembl build to visualize their results across the chromosomes. In addition, they can easily find particular genes of interest and automatically zoom to that region.  Clear all filters on the  Quantitative Trait.Tests  report now.  Add a new  RegionView  to the  Quantitative Trait.Tests  table now. When added, it should look similar to the screenshot below.  Note: \nThe first time a RegionView is added, it may take a few minutes to download the Ensembl and Hapmap information.   The  RegionView  contains multiple parts. Each part is fully interactive, and contains options that can be accessed by right-clicking.  The first section is the Overview of the chromosome. The chromosome in view can be set, either by manually setting the Start and End points or by using the zoom in and zoom out.  For the Overview section, the user can right-click to switch between panning and zoom modes. Selecting particular sections of the chromosome will zoom in the main view.  The next section contains the cytoband for that chromosome.   The next visible section is the transcript view. This will show the names of the transcripts for the currently visible region. It becomes very useful as you zoom in. Again, right-clicking allows a number of options.  Right click on that region and choose  Find Gene  from the dropdown box.   This opens the  Autofill  window where the user can search for their gene of interest. Type  Prdm2  and move it over to the right-hand side, and then choose the region. Click  OK  to continue.   The transcript view is now zoomed to the region of PRDM2, where the user can visualize all the p-values associated with this region. The current chromosome region we are viewing is highlighted in red on the cytoband.  Again, all of these sections can be further customized by using right-click, and switching between modes.   By default, the main view will contain 1 chart of p-values. The x-axis is the position of the chromosome, while the y-axis shows the  Log10 Pvalue. Use the  Specify Value Columns  from the  Task  tab of  View Controller  to display more numerical columns.   Add  GENOTYPE.FDR_BH  from the left panel to the right  Listed columns  panel. The main view is updated to have 2 parallel plots.   Congratulations! You have now explored your results of your analysis, using a number of different visualizations.",
            "title": "Region View"
        },
        {
            "location": "/tutorials/SNP/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results. Please refer to the MicroArray tutorial for more details on the \nAudit Trial\n, which records all the analysis steps in for form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of, with reference to Genotyping analysis and visualization.\nFeel free to try different options in the Task tab or the Genotyping menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft's support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.\n\n\nPlease contact Omicsoft Support (\n \nsupport@omicsoft.com\n \n) or Omicsoft Sales (\n \nsales@omicsoft.com\n \n) for sales-related questions.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/SNP/Save_Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results. Please refer to the MicroArray tutorial for more details on the  Audit Trial , which records all the analysis steps in for form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of, with reference to Genotyping analysis and visualization.\nFeel free to try different options in the Task tab or the Genotyping menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ).  Thank you for using Array Studio.  Please contact Omicsoft Support (   support@omicsoft.com   ) or Omicsoft Sales (   sales@omicsoft.com   ) for sales-related questions.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/RNASeq/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArrayStudio\n\u00b6\n\n\nArray Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The tutorial is based on a server-based NGS analysis using a Windows Workstation with\n3.4GHz Intel\u00ae Core TM i7-3770 Processor (# of cores: 4; # of threads: 8) with 16GB RAM.\n\n\nIt is highly recommend that the user complete the prerequisite for this tutorial:\n\nthe Microarray tutorial\n, as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software.\nAs many of the downstream data types from next generation sequencing are \"Microarray\" data sets, the Microarray tutorial is an invaluable starting tool.\n\n\nTest Dataset\n\u00b6\n\n\nThis RNA-Seq tutorial will utilize a public dataset that will be imported into Array Studio. This dataset was run on the Illumina Genome Analyzer platform, and each read is 76bp long. We have selected six SRR run .fastq paired-end files for use in this analysis. The full dataset is available on the SRA archive:\n\n\nSRR521461-521463 from GSM958729:\n\nlink\n\n\nSRR521522-521524 from\nGSM958745:\n\nlink\n\n\nThere are two groups of samples in this dataset from the files we have selected (cell line K562 and MCF7). Within ArrayStudio, SRA archives can be downloaded directly by choosing in the menu bar \nTools | Data | Download SRA Data (NGS)\n:\n\n\n\n\nEnter in all the SRR run IDs and specify a folder for the download as the \"Output Folder\". Be sure to enable Aspera to optimize efficient and accurate downloads:\n\n\n\n\nThe whole dataset is ~35GB. For convenience, if you prefer to work with a smaller dataset for this training (i.e. to run a local project - see Chapter 2), we also provide a subset (5% of reads) of the dataset for download:\n\nlink\n\n\nNote:\nThis download also contains a design table, \"Design.txt\" that will be required and discussed for further analyses during this tutorial.  Also, since this tutorial is based on the full dataset, users analyzing the smaller subset of data will obtain results that are different than what is shown in this tutorial.\n\n\nRNA-Seq Analysis Workflow\n\u00b6\n\n\nIn this tutorial, we will introduce the RNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for RNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, quantification at gene, transcript, exon and exon junction levels, and detection of fusions and mutations, as shown the scheme below:",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/RNASeq/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/RNASeq/Introduction/#arraystudio",
            "text": "Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The tutorial is based on a server-based NGS analysis using a Windows Workstation with\n3.4GHz Intel\u00ae Core TM i7-3770 Processor (# of cores: 4; # of threads: 8) with 16GB RAM.  It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software.\nAs many of the downstream data types from next generation sequencing are \"Microarray\" data sets, the Microarray tutorial is an invaluable starting tool.",
            "title": "ArrayStudio"
        },
        {
            "location": "/tutorials/RNASeq/Introduction/#test-dataset",
            "text": "This RNA-Seq tutorial will utilize a public dataset that will be imported into Array Studio. This dataset was run on the Illumina Genome Analyzer platform, and each read is 76bp long. We have selected six SRR run .fastq paired-end files for use in this analysis. The full dataset is available on the SRA archive:  SRR521461-521463 from GSM958729: link  SRR521522-521524 from\nGSM958745: link  There are two groups of samples in this dataset from the files we have selected (cell line K562 and MCF7). Within ArrayStudio, SRA archives can be downloaded directly by choosing in the menu bar  Tools | Data | Download SRA Data (NGS) :   Enter in all the SRR run IDs and specify a folder for the download as the \"Output Folder\". Be sure to enable Aspera to optimize efficient and accurate downloads:   The whole dataset is ~35GB. For convenience, if you prefer to work with a smaller dataset for this training (i.e. to run a local project - see Chapter 2), we also provide a subset (5% of reads) of the dataset for download: link  Note:\nThis download also contains a design table, \"Design.txt\" that will be required and discussed for further analyses during this tutorial.  Also, since this tutorial is based on the full dataset, users analyzing the smaller subset of data will obtain results that are different than what is shown in this tutorial.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/RNASeq/Introduction/#rna-seq-analysis-workflow",
            "text": "In this tutorial, we will introduce the RNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for RNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, quantification at gene, transcript, exon and exon junction levels, and detection of fusions and mutations, as shown the scheme below:",
            "title": "RNA-Seq Analysis Workflow"
        },
        {
            "location": "/tutorials/RNASeq/CreateArray_Studio_Project/",
            "text": "Create Array Studio Project\n\u00b6\n\n\nArray Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data.\n\n\nIn this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project and analysis steps are almost the same as described in this tutorial.\n\n\nOnce Array Studio has been opened, under the \nServer\n tab at the top of the screen, log in to the server where Array Server is running. Click \nFile | New Server Project\n from the File Menu (also can be accessed via the \nNew\n button on the toolbar).\n\n\n\n\nNote to \"Local\" mode users:\n If you are using this tutorial in \nLocal\n mode for any Next Generation Sequencing datasets, choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. It is required that the user has approximately 100GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using \nTools Menu | Preferences | Advanced\n.\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location.\n\n\nClick \nCreate\n to store the project and you will see your empty project in the \nSolution Explorer\n:",
            "title": "Create ArrayStudio Project"
        },
        {
            "location": "/tutorials/RNASeq/CreateArray_Studio_Project/#create-array-studio-project",
            "text": "Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data.  In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project and analysis steps are almost the same as described in this tutorial.  Once Array Studio has been opened, under the  Server  tab at the top of the screen, log in to the server where Array Server is running. Click  File | New Server Project  from the File Menu (also can be accessed via the  New  button on the toolbar).   Note to \"Local\" mode users:  If you are using this tutorial in  Local  mode for any Next Generation Sequencing datasets, choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset. It is required that the user has approximately 100GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using  Tools Menu | Preferences | Advanced .\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location.  Click  Create  to store the project and you will see your empty project in the  Solution Explorer :",
            "title": "Create Array Studio Project"
        },
        {
            "location": "/tutorials/RNASeq/Add From RNA-Seq Pipeline/",
            "text": "Add From RNA-Seq Pipeline\n\u00b6\n\n\nUsers have two options to perform RNA-Seq analysis -- one is to run through RNA-Seq pipeline, the other is to run step by step.\n\n\nAdd From RNA-Seq Pipeline\n, as dicussed in this chapter, allows users to finish the whole RNA-Seq analysis in a single click. Based on a user's selections, Array Studio will run the following pipeline:\n\n\n\n\nTo perform RNA-Seq pipeline analysis, choose \nAdd NGS Data - Add From Pipeline - RNA-Seq Pipeline\n\n\n\n\nFor each step in the RNA-Seq pipeline, the user can choose the default parameters found in Array Studio or customize settings such as genome version, gene model, alignment stringency and reporting options. To ease in the sharing of data after processing, it is recommended that the user choose the \nReporting\n option to \nGenerate land ALV files\n.\n\n\nIf users want to add more user-defined options in each step, users can perform RNA-Seq analysis step by step starting with raw data QC and alignment. The step-by-step methods will be discussed in the next chapters.\n\n\n\n\nIf the input files are in FASTQ, FASTA, or QSEQ format, then the data will be aligned in the same way as by \nAdd RNA-Seq Data - Map Reads To Genome (Illumina)\n which will be discussed in the Chapter 5, with the default parameters. For this module, select the default options, and check \"Reads are paired\" as these reads are paired. These files will be automatically paired during the pipeline analysis. Depending on your server options, adjust the number of threads. Job number will determine how many parallel jobs (such as alignments) will be performed at once. This number should not exceed the number of samples. Click Send to Queue and the analysis will begin.\n\n\nThis could take hours, depending on the number of threads/jobs or type of computer (64-bit/32-bit), etc.\n\n\nAfter alignment, it will load BAM files once and finish all selected downstream analyses.\n\n\nIf user is using BAM files as input, the module will use AddGenomeMappedRnaSeqReads to add alignment file as NgsData directly for all downstream analysis. The pipeline has been tested briefly for external BAM files generated by other aligners (outside of Omicsoft). We are recommending users starting from raw (fastq/fasta) files. If you have BAM files and would like to use the Array Studio RNA-Seq Pipeline, you can covert these files back to fastq.gz files by using \nNGS | Tools | Convert Files\n.\n\n\nThe pipeline module is particularly better than individual modules when enabling cloud based analysis with less file transfers and saving EC2 machine setup time.",
            "title": "Add From RNA-Seq Pipeline"
        },
        {
            "location": "/tutorials/RNASeq/Add From RNA-Seq Pipeline/#add-from-rna-seq-pipeline",
            "text": "Users have two options to perform RNA-Seq analysis -- one is to run through RNA-Seq pipeline, the other is to run step by step.  Add From RNA-Seq Pipeline , as dicussed in this chapter, allows users to finish the whole RNA-Seq analysis in a single click. Based on a user's selections, Array Studio will run the following pipeline:   To perform RNA-Seq pipeline analysis, choose  Add NGS Data - Add From Pipeline - RNA-Seq Pipeline   For each step in the RNA-Seq pipeline, the user can choose the default parameters found in Array Studio or customize settings such as genome version, gene model, alignment stringency and reporting options. To ease in the sharing of data after processing, it is recommended that the user choose the  Reporting  option to  Generate land ALV files .  If users want to add more user-defined options in each step, users can perform RNA-Seq analysis step by step starting with raw data QC and alignment. The step-by-step methods will be discussed in the next chapters.   If the input files are in FASTQ, FASTA, or QSEQ format, then the data will be aligned in the same way as by  Add RNA-Seq Data - Map Reads To Genome (Illumina)  which will be discussed in the Chapter 5, with the default parameters. For this module, select the default options, and check \"Reads are paired\" as these reads are paired. These files will be automatically paired during the pipeline analysis. Depending on your server options, adjust the number of threads. Job number will determine how many parallel jobs (such as alignments) will be performed at once. This number should not exceed the number of samples. Click Send to Queue and the analysis will begin.  This could take hours, depending on the number of threads/jobs or type of computer (64-bit/32-bit), etc.  After alignment, it will load BAM files once and finish all selected downstream analyses.  If user is using BAM files as input, the module will use AddGenomeMappedRnaSeqReads to add alignment file as NgsData directly for all downstream analysis. The pipeline has been tested briefly for external BAM files generated by other aligners (outside of Omicsoft). We are recommending users starting from raw (fastq/fasta) files. If you have BAM files and would like to use the Array Studio RNA-Seq Pipeline, you can covert these files back to fastq.gz files by using  NGS | Tools | Convert Files .  The pipeline module is particularly better than individual modules when enabling cloud based analysis with less file transfers and saving EC2 machine setup time.",
            "title": "Add From RNA-Seq Pipeline"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/",
            "text": "QC of RawData Files\n\u00b6\n\n\nIf users want to run RNA-Seq analysis with more custom options, other than running RNA-Seq pipeline, users can run the whole process step by step. The first step will be raw data QC.\n\n\nArray Studio contains a few modules for QC of raw data files. The easiest way is to run \nRaw Data QC Wizard\n which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position.\n\n\n\n\nClick \nAdd\n to find all 12 files for the six samples, check QC metric to run. Optionally, for a quicker analysis, the user can choose \nPreview mode\n to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave \nQuality encoding\n as \nAutomatic\n to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify \nJob Number\n as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.\n\n\nClick \nSend to Queue\n to begin the analysis.\n\n\n\n\nThe raw data QC returns multiple raw data QC results/reports in \nRaw Data QC\n folder which are described in the following subsections.\n\n\n\n\nThe corresponding output files can be found in the output directory specified as shown below. Please refer to \nlink\n for the meaning of specific file extensions in Omicsoft.\n\n\n\n\nBasic Statistics\n\u00b6\n\n\nThe basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.\n\n\nBase distribution QC results are located in the \nSolution Explorer | Raw Data QC\n folder with name \nBasicStats\n. Double click the table view to open if you do not see basic statistics table in the middle window:\n\n\n\n\nBase Distribution\n\u00b6\n\n\nBase distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes this can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the \nRaw Data QC\n folder with name \nBaseDistribution\n.\nBy default, the BaseDistribution \nProfileView\n should be shown, but if not, open it by double-clicking the \nProfile\n view from the \nSolution Explorer\n.\n\n\n\n\nIn the \nView Controller\n window of the right hand side of the screen, the \nLegend\n section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot.\n\n\nNotice that there are a total of 12 charts (scroll through them to look at each sample), one for each file that was QC d.\n\n\nSelecting points on the chart will also show additional details in the \nDetails\n window, as shown below.\n\n\n\n\nOne can also switch to line plot view by going to \nView Controller | Task | Customize | Change To Line Type\n.\n\n\n\n\nRead Quality QC\n\u00b6\n\n\nThe QC results include a \nPerSequenceQuality\n (view and table), a \nQualityBoxPlot\n (view and table) and a \nOverallQualityReport\n (view and table) in the \nSolution Explorer\n.\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.\n\n\n\n\nIn \nQuality BoxPlot\n, all reads in a file are overlaid and box plot for each base pair position is shown.\nThis gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. This can be done easily by changing the view option in the tool strip as in the image below (arrow).\n\n\n\n\nFrom the \nQualityBoxPlot\n view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR521461. Scroll through each of the 12 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the \nDetails Window\n below the plot.\n\n\nThe \nOverall Quality Report\n summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.\n\n\n\n\nK-Mer analysis\n\u00b6\n\n\nThe \nK-Mer Analysis\n module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of K-Mer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.\n\n\n\n\nIn the \nKMerAnalysis\n profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each K-Mer. There is no significant (all less than 1%) enrichment of K-Mer in this tutorial dataset.",
            "title": "QC of RawData Files"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/#qc-of-rawdata-files",
            "text": "If users want to run RNA-Seq analysis with more custom options, other than running RNA-Seq pipeline, users can run the whole process step by step. The first step will be raw data QC.  Array Studio contains a few modules for QC of raw data files. The easiest way is to run  Raw Data QC Wizard  which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position.   Click  Add  to find all 12 files for the six samples, check QC metric to run. Optionally, for a quicker analysis, the user can choose  Preview mode  to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave  Quality encoding  as  Automatic  to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify  Job Number  as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.  Click  Send to Queue  to begin the analysis.   The raw data QC returns multiple raw data QC results/reports in  Raw Data QC  folder which are described in the following subsections.   The corresponding output files can be found in the output directory specified as shown below. Please refer to  link  for the meaning of specific file extensions in Omicsoft.",
            "title": "QC of RawData Files"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/#basic-statistics",
            "text": "The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.  Base distribution QC results are located in the  Solution Explorer | Raw Data QC  folder with name  BasicStats . Double click the table view to open if you do not see basic statistics table in the middle window:",
            "title": "Basic Statistics"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/#base-distribution",
            "text": "Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes this can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the  Raw Data QC  folder with name  BaseDistribution .\nBy default, the BaseDistribution  ProfileView  should be shown, but if not, open it by double-clicking the  Profile  view from the  Solution Explorer .   In the  View Controller  window of the right hand side of the screen, the  Legend  section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot.  Notice that there are a total of 12 charts (scroll through them to look at each sample), one for each file that was QC d.  Selecting points on the chart will also show additional details in the  Details  window, as shown below.   One can also switch to line plot view by going to  View Controller | Task | Customize | Change To Line Type .",
            "title": "Base Distribution"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/#read-quality-qc",
            "text": "The QC results include a  PerSequenceQuality  (view and table), a  QualityBoxPlot  (view and table) and a  OverallQualityReport  (view and table) in the  Solution Explorer .\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.   In  Quality BoxPlot , all reads in a file are overlaid and box plot for each base pair position is shown.\nThis gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples. This can be done easily by changing the view option in the tool strip as in the image below (arrow).   From the  QualityBoxPlot  view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR521461. Scroll through each of the 12 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the  Details Window  below the plot.  The  Overall Quality Report  summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.",
            "title": "Read Quality QC"
        },
        {
            "location": "/tutorials/RNASeq/QC_ofRawData_Files/#k-mer-analysis",
            "text": "The  K-Mer Analysis  module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of K-Mer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.   In the  KMerAnalysis  profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each K-Mer. There is no significant (all less than 1%) enrichment of K-Mer in this tutorial dataset.",
            "title": "K-Mer analysis"
        },
        {
            "location": "/tutorials/RNASeq/Alignment_to_the_Genome/",
            "text": "Alignment to the Genome\n\u00b6\n\n\nThe second step in the analysis of most RNA-Seq data is the alignment of the reads to the genome. Alternatively, if the data has already been aligned, the alignment files (BAM/SAM) can be imported using \nAdd NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads\n.\n\n\nFor this experiment, we will align the data using Array Studio.\nPlease go to the \nAdd Data\n dropdown menu on the toolbar, then choose \nAdd NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina)\n.\n\n\n\n\nAt this point, the Map RNA-Seq Reads to Genome module appears. The first step is to click the \nAdd\n button to specify the location of the files. Choose the 12 files that were downloaded from SRA or the subset of the dataset downloaded from the OmicSoft website.\n\n\nNote that these files are in the .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files.\n\n\n\n\nSince this is a paired experiment, click the \nReads are paired\n checkbox.\nThis will ensure that the pairing information is used in the alignment and counting process.\n\n\nChoose the \nGenome\n for the experiment. In this analysis, we used \nHuman.B37.3\n.\nOmicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the \nGene Model\n to be used for alignment. Here we use an Omicsoft gene model built on 07/23/2013, but the user can also choose from various Ensembl, UCSC or RefGene builds, or build their own gene model. Options to build genome and gene models can be found in the menu under \nNGS | Build | Build Reference Library\n and \nNGS | Build | Build Gene Model\n.  \n\n\nLeave the \nquality encoding\n set to automatic. The files used in this tutorial were encoded using the Sanger quality scoring system.\n\nTotal penalty\n should be left as automatic - alignment parameters are described completely in Omicsoft's white paper on alignment \nlink\n.\n\n\nThread number\n indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes).\n\n\nNon-unique mapping\n indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together.\n\n\nOnly BAM files will be output. If users also want SAM files, there is a tool (\nNGS | Tools | Convert Files\n) in ArrayStudio to generate SAM files from BAM files.\n\n\nOutput folder\n is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step (for fusion detection).\n\n\nThere are a few options in the \nAdvanced\n Tab (e.g. Indel detection). In general the default values have been tuned and should work well in most cases.\n\n\nLeave the \nExclude unmapped reads\n \nunchecked\n, so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input for the single-end fusion detection algorithm (see the fusion chapter in this tutorial).\n\n\n\n\nClick \nSend to Queue\n to submit the analysis.\n\n\nThis analysis could take hours to complete, depending on the number of threads, type of computer (64-bit/32-bit), etc. As an additional option, in the parameters for mapping the reads, there is an additional \nPreview\n tab, which allows the user to specify a percentage of the reads to sample for alignment and QC. This option may be attractive to a user who wishes to test the quality of the data before performing a large-scale analysis on new RNA-seq datasets.\n\n\nAfter the alignment, you will see a NgsData object and an alignment report table in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder:\n\n\n\n\n\n\nAdd the design table, \"Design.txt\", which can be found in the .zip folder containing the subset of RNA-Seq data downloaded in Chapter 1 of this tutorial. Right click on \nDesign\n. Select \nImport | Tab delimited file\n\n\n\n\nThere will be two options to specify:\n\n\nAppend to the existing covariate table\n: checking this option will append the selected design file contents to the existing design table.\n\n\nUse the name order in the new covariate table\n: checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table.\n\n\n\n\nThese two options should be left unchecked for this tutorial (as this is a new design table to import).\n\n\nThe study includes 3 K562 cellline samples and 3 MCF7 cellline samples.",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/RNASeq/Alignment_to_the_Genome/#alignment-to-the-genome",
            "text": "The second step in the analysis of most RNA-Seq data is the alignment of the reads to the genome. Alternatively, if the data has already been aligned, the alignment files (BAM/SAM) can be imported using  Add NGS Data | Add RNA-Seq Data | Add Genome Mapped Reads .  For this experiment, we will align the data using Array Studio.\nPlease go to the  Add Data  dropdown menu on the toolbar, then choose  Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) .   At this point, the Map RNA-Seq Reads to Genome module appears. The first step is to click the  Add  button to specify the location of the files. Choose the 12 files that were downloaded from SRA or the subset of the dataset downloaded from the OmicSoft website.  Note that these files are in the .gz format. The alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files.   Since this is a paired experiment, click the  Reads are paired  checkbox.\nThis will ensure that the pairing information is used in the alignment and counting process.  Choose the  Genome  for the experiment. In this analysis, we used  Human.B37.3 .\nOmicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the  Gene Model  to be used for alignment. Here we use an Omicsoft gene model built on 07/23/2013, but the user can also choose from various Ensembl, UCSC or RefGene builds, or build their own gene model. Options to build genome and gene models can be found in the menu under  NGS | Build | Build Reference Library  and  NGS | Build | Build Gene Model .    Leave the  quality encoding  set to automatic. The files used in this tutorial were encoded using the Sanger quality scoring system. Total penalty  should be left as automatic - alignment parameters are described completely in Omicsoft's white paper on alignment  link .  Thread number  indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes).  Non-unique mapping  indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together.  Only BAM files will be output. If users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files.  Output folder  is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step (for fusion detection).  There are a few options in the  Advanced  Tab (e.g. Indel detection). In general the default values have been tuned and should work well in most cases.  Leave the  Exclude unmapped reads   unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input for the single-end fusion detection algorithm (see the fusion chapter in this tutorial).   Click  Send to Queue  to submit the analysis.  This analysis could take hours to complete, depending on the number of threads, type of computer (64-bit/32-bit), etc. As an additional option, in the parameters for mapping the reads, there is an additional  Preview  tab, which allows the user to specify a percentage of the reads to sample for alignment and QC. This option may be attractive to a user who wishes to test the quality of the data before performing a large-scale analysis on new RNA-seq datasets.  After the alignment, you will see a NgsData object and an alignment report table in the solution explorer, and BAM files as well as alignment report summary files in the specified output folder:    Add the design table, \"Design.txt\", which can be found in the .zip folder containing the subset of RNA-Seq data downloaded in Chapter 1 of this tutorial. Right click on  Design . Select  Import | Tab delimited file   There will be two options to specify:  Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table.  Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table.   These two options should be left unchecked for this tutorial (as this is a new design table to import).  The study includes 3 K562 cellline samples and 3 MCF7 cellline samples.",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/",
            "text": "QC of Aligned Data\n\u00b6\n\n\nAlignment Report\n\u00b6\n\n\nBy default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the \nAlignmentReport\n table.\n\n\nThis will show, for each pair (or single file if the user did not do a paired alignment), some statistics regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired). \nNote:\n Omicsoft is constantly updating algorithms and data to make sure that users have the most accurate results. You may have slightly different results when you compare your results with the tutorial.\n\n\n\n\nRNA-Seq Aligned QC\n\u00b6\n\n\nThis module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a \nProfileView\n showing a chart for each metric.\n\n\nHere we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to \nAdd Data | Add NGS Data | Add RNA-Seq Data | Add Genome-Mapped Reads\n. To run the RNA-Seq QC module, go to \nNGS | Aligned Data QC | RNA-Seq QC Metrics\n now.\n\n\n\n\nYou will see the following menu item:\n\n\n\n\nChoose the NGS data and leave all other settings as their defaults and click \nSend to Queue\n to run the module. \nSource\n metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723.\n\n\nThe analysis returns \nTable\n and \nProfile\n Views of QC metrics in the \nAligned Data QC\n folder:\n\n\n\n\nIn the \nTable\n view, as you scroll from top to bottom on the table, you will find the following sections:\n\n\nAlignment Metrics\n\u00b6\n\n\nThese metrics can be used to give an overall idea of the quality of the alignment for your samples.\n\n\n\n\nCoverage Metrics\n\u00b6\n\n\nThe coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.\n\n\n\n\nDuplication Metrics\n\u00b6\n\n\nThe duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an RNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.\n\n\n\n\nFeature Metrics\n\u00b6\n\n\nFeature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.\n\n\n\n\nFlag Metrics\n\u00b6\n\n\nFlag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.\n\n\n\n\nInsert Size Metrics\n\u00b6\n\n\nInsert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values.\n\n\n\n\nProfile Metrics\n\u00b6\n\n\nProfile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.\n\n\n\n\nSource Metrics\n\u00b6\n\n\nThese metrics can be used to get a sense of the overall types of transcripts that are being aligned. For instance, in this experiment shown below, most reads are mapped to hg19 known genes and a small fraction is mapped to mitochondria.\n\n\n\n\nStrand Metrics\n\u00b6\n\n\nThe strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.\n\n\n\n\nSequencing (Positional) Trend\n\u00b6\n\n\nThis module is specifically designed to investigate the sequencing positional biases by summarizing the overall coverage along the transcripts. In practice, we find that the module is particularly useful to assess the quality of RNA-Seq data from low input protocols , where we observed severe positional bias due to library preparation steps.\nYou can find the function in \nNGS | Aligned Data QC | RNA-Seq 5->3 Trend\n.\n\n\n\n\nChoose the NGS data and leave all other settings as their defaults and click \nSend to Queue\n to run the module.\n\n\n\n\nThe analysis returns a QC table in the \nAligned Data QC\n folder with name \nTrend53\n:\n\n\n\n\nDouble click the \nProfile\n View if it is not opened:\n\n\n\n\nBy Default, all transcripts are classified into seven length groups (0-499bp, 500-999bp, 1000-1999bp, 2000-2999bp, 3000-3999bp, 4000-4999bp, 5000+bp). Coverage values in each length group are linearly scaled to have the maximum to be 1, so that they are comparable among different length groups. Bins 1-100 are from transcript 5' to 3'. The view above shows very minor positional bias toward 5' (little higher coverage on 5' end).\n\n\nOther Aligned Data QC\n\u00b6\n\n\nRNA-Seq QC Metrics\n provides comprehensive assessment of the alignment data. We also provide metrics such as \nFlag Summary Statistics\n, \nMapping Summary Statistics\n, \nPaired End Insert Size\n, \nRNA-Seq Mapping Profile\n as separate functions, where users can specify more analysis options.",
            "title": "QC of AlignedData"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#qc-of-aligned-data",
            "text": "",
            "title": "QC of Aligned Data"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#alignment-report",
            "text": "By default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the  AlignmentReport  table.  This will show, for each pair (or single file if the user did not do a paired alignment), some statistics regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired).  Note:  Omicsoft is constantly updating algorithms and data to make sure that users have the most accurate results. You may have slightly different results when you compare your results with the tutorial.",
            "title": "Alignment Report"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#rna-seq-aligned-qc",
            "text": "This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. It also generates a  ProfileView  showing a chart for each metric.  Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to  Add Data | Add NGS Data | Add RNA-Seq Data | Add Genome-Mapped Reads . To run the RNA-Seq QC module, go to  NGS | Aligned Data QC | RNA-Seq QC Metrics  now.   You will see the following menu item:   Choose the NGS data and leave all other settings as their defaults and click  Send to Queue  to run the module.  Source  metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723.  The analysis returns  Table  and  Profile  Views of QC metrics in the  Aligned Data QC  folder:   In the  Table  view, as you scroll from top to bottom on the table, you will find the following sections:",
            "title": "RNA-Seq Aligned QC"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#alignment-metrics",
            "text": "These metrics can be used to give an overall idea of the quality of the alignment for your samples.",
            "title": "Alignment Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#coverage-metrics",
            "text": "The coverage metrics give you an overall idea of the mean coverage of your experiment. For RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model). It also gives metrics on the number and percentage of genes with coverage. Finally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.",
            "title": "Coverage Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#duplication-metrics",
            "text": "The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an RNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.",
            "title": "Duplication Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#feature-metrics",
            "text": "Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.",
            "title": "Feature Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#flag-metrics",
            "text": "Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.",
            "title": "Flag Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#insert-size-metrics",
            "text": "Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values.",
            "title": "Insert Size Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#profile-metrics",
            "text": "Profile Metrics provide important overall statistics based on the provided gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.",
            "title": "Profile Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#source-metrics",
            "text": "These metrics can be used to get a sense of the overall types of transcripts that are being aligned. For instance, in this experiment shown below, most reads are mapped to hg19 known genes and a small fraction is mapped to mitochondria.",
            "title": "Source Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#strand-metrics",
            "text": "The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.",
            "title": "Strand Metrics"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#sequencing-positional-trend",
            "text": "This module is specifically designed to investigate the sequencing positional biases by summarizing the overall coverage along the transcripts. In practice, we find that the module is particularly useful to assess the quality of RNA-Seq data from low input protocols , where we observed severe positional bias due to library preparation steps.\nYou can find the function in  NGS | Aligned Data QC | RNA-Seq 5->3 Trend .   Choose the NGS data and leave all other settings as their defaults and click  Send to Queue  to run the module.   The analysis returns a QC table in the  Aligned Data QC  folder with name  Trend53 :   Double click the  Profile  View if it is not opened:   By Default, all transcripts are classified into seven length groups (0-499bp, 500-999bp, 1000-1999bp, 2000-2999bp, 3000-3999bp, 4000-4999bp, 5000+bp). Coverage values in each length group are linearly scaled to have the maximum to be 1, so that they are comparable among different length groups. Bins 1-100 are from transcript 5' to 3'. The view above shows very minor positional bias toward 5' (little higher coverage on 5' end).",
            "title": "Sequencing (Positional) Trend"
        },
        {
            "location": "/tutorials/RNASeq/QC_of_AlignedData/#other-aligned-data-qc",
            "text": "RNA-Seq QC Metrics  provides comprehensive assessment of the alignment data. We also provide metrics such as  Flag Summary Statistics ,  Mapping Summary Statistics ,  Paired End Insert Size ,  RNA-Seq Mapping Profile  as separate functions, where users can specify more analysis options.",
            "title": "Other Aligned Data QC"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/",
            "text": "RNA-Seq Quantification\n\u00b6\n\n\nArrayStudio provides a number of modules and options for RNA-Seq quantification at gene, transcript, exon and exon junction levels.\n\n\nReport Gene/Transcript Counts\n\u00b6\n\n\nGiven the alignment, one can summarize the gene expression at both gene and transcript levels, using the Quantification module in \nNGS | Quantification | Report Gene/Transcript Counts\n.\n\n\n\n\nBoth RPKM and Count tables can be generated. In this tutorial we summarize the gene level expression values with both the RPKM and Counts in one step. User can also choose to quantify at transcript level by selecting it in the \nSummary Level\n option. By default, option \nCount fragments instead of reads\n is selected to use paired reads only (thus FPKM is calculated). Options to count reads based on strands are designed for datasets from strand-specific protocols. In this tutorial, the six samples are not strand-specific as shown in the strand metrics from aligned QC table. Both stranded counting options are checked, and ArrayStudio will quantify expression values based on all mapping data.\n\n\n\n\nChoose the NGS data and leave all other settings as their defaults and click \nSubmit\n to run the module.\nThe output includes two Omic datasets, Counts and FPKM.\n\n\n\n\nBoth Omic datasets have gene and transcript annotation attached which were pre-built when building gene model. The design table attached to Ngsdata previously is automatically attached to these new data. They are treated as \nOmicData Data\n and all microarray data analysis functions, such as \nOmicData | Pattern | Hierarchical Clustering\n, \nOmicData | QC | Principal Component Analysis\n, \nOmicData | Inference | General Linear Model\n and other modules can be used for downstream data analyses.\nPlease read the Microarray tutorial to get detailed analysis information.\n\n\nCounts can be used to look for changes between groups of samples through DESeq analysis in \nNGS | Inference | DESeq (V2) One Way Test\n or \nDESeq (V2) General Linear Model\n.\n\n\nBelow shows an example of DESeq One Way Test. DESeq One Way Test offers a statistical method to test whether a gene/transcript is differentially expressed between two or more groups of samples. Choose the newly generated Count table from the Quantification step and specify the analyses you would like performed. Here, we use the default parameters of DESeq, in which we compare the two tissue types (Bone marrow and breast, as specified in our design table). Output options can be customized to include separate lists for enrichment in one sample versus another, and to obtain additional analyses. This step can also be performed locally or on the server (check box if this is preferred). Click \nSubmit\n to perform the analysis.\n\n\n\n\nThe results include an Inference Report table with estimates and pvalues, similar to ANOVA test results, and a Dispersion table in \"Summary\" folder.\n\n\n\n\nFor the volcano plot, users can specify in \nView Controller\n which columns to show using \nSpecify Columns\n, and also add cutoff lines by \nSpecify Cutoff Lines\n.\n\n\n\n\nThe volcano plot view is fully customizable and includes the ability to change symbol size/color, add labels, change titles, and export into local programs (as an image or powerpoint slide). Please refer to the microarray tutorial documentation to see some of these features.\n\n\nReport Exon/Exon-Junction Counts\n\u00b6\n\n\nExon/exon junction level counting can be used for detection of alternative splicing.\n\n\nThere are two modules for exon level counting:\n\n\n\n\nReport known Exons/Exon Junctions\n\u00b6\n\n\nSummarize Exon/Exon Junction Count\n module will do quantification based on known gene models, i.e. exon junctions already annotated by gene model. Choose the NGS data and leave all other settings as their defaults and click \nSubmit\n to run the module.\n\n\n\n\nBy default, \nPerform RPKM normalization\n option is checked. Normalized counts in RPKM fashion are reported for known exons and exon junctions based on the specified gene model. In the output report, each row is one \nknown\n exon or exon junction annotated by genome coordinates, gene and transcript name.\n\n\n|exon_exon_output_png|\n\n\nReport All Exon Junctions\n\u00b6\n\n\nReport Exon Junctions\n module quantifies \nall\n exon junctions detected by the alignment step.\nChoose the NGS data and leave all other settings as their defaults and click \nSubmit\n to run the module.\n\n\n\n\nIn the output report, each row is one exon junction annotated by genome coordinates, intron size, and gene/transcript name.\nThe types of exon junctions include known (annotated by the gene model), novel (not contained in the gene model, or one side of the exon junction lies on a known exon boundary, while the other side of the exon junction is unknown).",
            "title": "RNA-Seq Quantification"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/#rna-seq-quantification",
            "text": "ArrayStudio provides a number of modules and options for RNA-Seq quantification at gene, transcript, exon and exon junction levels.",
            "title": "RNA-Seq Quantification"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/#report-genetranscript-counts",
            "text": "Given the alignment, one can summarize the gene expression at both gene and transcript levels, using the Quantification module in  NGS | Quantification | Report Gene/Transcript Counts .   Both RPKM and Count tables can be generated. In this tutorial we summarize the gene level expression values with both the RPKM and Counts in one step. User can also choose to quantify at transcript level by selecting it in the  Summary Level  option. By default, option  Count fragments instead of reads  is selected to use paired reads only (thus FPKM is calculated). Options to count reads based on strands are designed for datasets from strand-specific protocols. In this tutorial, the six samples are not strand-specific as shown in the strand metrics from aligned QC table. Both stranded counting options are checked, and ArrayStudio will quantify expression values based on all mapping data.   Choose the NGS data and leave all other settings as their defaults and click  Submit  to run the module.\nThe output includes two Omic datasets, Counts and FPKM.   Both Omic datasets have gene and transcript annotation attached which were pre-built when building gene model. The design table attached to Ngsdata previously is automatically attached to these new data. They are treated as  OmicData Data  and all microarray data analysis functions, such as  OmicData | Pattern | Hierarchical Clustering ,  OmicData | QC | Principal Component Analysis ,  OmicData | Inference | General Linear Model  and other modules can be used for downstream data analyses.\nPlease read the Microarray tutorial to get detailed analysis information.  Counts can be used to look for changes between groups of samples through DESeq analysis in  NGS | Inference | DESeq (V2) One Way Test  or  DESeq (V2) General Linear Model .  Below shows an example of DESeq One Way Test. DESeq One Way Test offers a statistical method to test whether a gene/transcript is differentially expressed between two or more groups of samples. Choose the newly generated Count table from the Quantification step and specify the analyses you would like performed. Here, we use the default parameters of DESeq, in which we compare the two tissue types (Bone marrow and breast, as specified in our design table). Output options can be customized to include separate lists for enrichment in one sample versus another, and to obtain additional analyses. This step can also be performed locally or on the server (check box if this is preferred). Click  Submit  to perform the analysis.   The results include an Inference Report table with estimates and pvalues, similar to ANOVA test results, and a Dispersion table in \"Summary\" folder.   For the volcano plot, users can specify in  View Controller  which columns to show using  Specify Columns , and also add cutoff lines by  Specify Cutoff Lines .   The volcano plot view is fully customizable and includes the ability to change symbol size/color, add labels, change titles, and export into local programs (as an image or powerpoint slide). Please refer to the microarray tutorial documentation to see some of these features.",
            "title": "Report Gene/Transcript Counts"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/#report-exonexon-junction-counts",
            "text": "Exon/exon junction level counting can be used for detection of alternative splicing.  There are two modules for exon level counting:",
            "title": "Report Exon/Exon-Junction Counts"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/#report-known-exonsexon-junctions",
            "text": "Summarize Exon/Exon Junction Count  module will do quantification based on known gene models, i.e. exon junctions already annotated by gene model. Choose the NGS data and leave all other settings as their defaults and click  Submit  to run the module.   By default,  Perform RPKM normalization  option is checked. Normalized counts in RPKM fashion are reported for known exons and exon junctions based on the specified gene model. In the output report, each row is one  known  exon or exon junction annotated by genome coordinates, gene and transcript name.  |exon_exon_output_png|",
            "title": "Report known Exons/Exon Junctions"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Quantification/#report-all-exon-junctions",
            "text": "Report Exon Junctions  module quantifies  all  exon junctions detected by the alignment step.\nChoose the NGS data and leave all other settings as their defaults and click  Submit  to run the module.   In the output report, each row is one exon junction annotated by genome coordinates, intron size, and gene/transcript name.\nThe types of exon junctions include known (annotated by the gene model), novel (not contained in the gene model, or one side of the exon junction lies on a known exon boundary, while the other side of the exon junction is unknown).",
            "title": "Report All Exon Junctions"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/",
            "text": "RNA-Seq Fusion Gene Detection\n\u00b6\n\n\nIn RNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events.\nIn paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion.\n\n\nThree fusion detection functions can be found in \nNGS | Fusion\n menu:\n\n\n\n\nReport Paired-End Fusion Genes\n\u00b6\n\n\nReport Fusion Genes (Paired End)\n module will detect fusion genes from inter-transcript paired-end reads based on RNA-Seq alignment (\nNgsData\n).\n\n\n\n\nChoose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check \nOutput fusion reads\n option and specify the directory path, supporting fusion reads will be saved as BAM files which can be used for visual checking in the genome browser. Leave all other settings as their defaults and click \nSubmit\n to run the module. The output is a paired fusion report table listed under \nTable\n in \nSolution Explorer\n:\n\n\n\n\nIn the report table, there are three columns for each sample.\nThe first column shows the number of \nUnique mapping positions\n from reads in \nGene1\n, the second column shows the number of \nUnique mapping positions\n from reads in \nGene2\n, while the third column shows the total \nCount\n of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*6=18 columns of data, as well as additional annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. The information in \nFilter\n column in the report table comes from a fusion black list.\nFor more information about the blacklist, please read the following wiki article:\n\nlink\n\n\nView Controller\n can be used to set row filters to list only genes of interest. Simply navigate to the \nView Controller\n, and under the \nRow\n tab, input genes of interest into the Gene1 and Gene2 filters. Below are rows for identified known \nBCR-ABL1\n and \nNUP214-XKR3\n fusion events in K562 samples:\n\n\n\n\nWhen fusion ID is right-clicked, there will be an option to open a new Genome Browser to view selected fusion.\n\n\n\n\nIn the genome browser view, this feature can be customized to look at individual samples, or to combine tracks within a group. For this example, all samples are examined individually. Use the zoom features (arrows below) or the click wheel of the mouse to zoom in and out of regions of interest. In the example below, notice that the three samples (SRR521461-521463) have a different read coverage of BCR (left) and ABL1 (right) at the 3' and 5' ends, respectively.\n\n\n\n\nReport Fusion Genes (Paired End)\n module reports fusion events by grouping gene pairs by rows in one table.\nIt provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.\n\n\nMap Fusion Reads\n\u00b6\n\n\nMap Fusion Reads\n module will detect fusion genes from fusion junction-spanning reads which can characterize fusion genes at base pair resolution. It is a preferred approach to detect fusion events, using OmicSoft s fusion alignment method (\nFusionMap, Ge,H, et al. Bioinformatics (2011): 1922-1928\n). The fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If user is using the original \nFASTQ\n files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click \nReads are paired\n option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample.\n\n\n\n\nIf user is using \nBAM\n files, potential fusion reads (such as reads spanning on two nearby genes) in alignment and unmapped reads will be extracted for fusion detection.\nIt is a preferred approach which saves running time of the filtering step when starting with \nFASTQ\n data.\n\n\n\n\nMinimal cut size\n is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners, see wiki page:\n\nlink\n\n\nThe default \nCut size\n is to use value min(25, max(18, readLength/3). For this tutorial dataset, read length is 76, so we use the default.\n\n\nThere are more fusion alignment options in the \nAdvanced\n tab. Leave all settings as their defaults and click \nSubmit\n to run the module. The output is a fusion report table listed under \nTable\n in \nSolution Explorer\n:\n\n\n\n\nIn the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion \nseed\n reads, while the third column shows number of fusion \nrescued\n reads.\nThere are 3*6=18 columns of data, and 21 \nannotation columns\n for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predicted fusion gene and open reading frame status, and a \"Filter\" column containing black list information.\nThe annotations characterize fusion events at base pair resolution. We also create rollup columns, such as \nSplicePatternClass\n (Canonical or NonCanonical), \nFrameShiftClass\n (Frame shift or inFrame), \nDistance\n (displayed as \"gap size\" between two breakpoints or \"-1\" if located on two different chromosomes) and \nOnExonBoundary\n (Both, Single or None), for users to further filter false positives.\n\n\nBelow are two rows for known \nBCR-ABL1\n and \nNUP214-XKR3\n fusion events identified in K562 samples:\n\n\n\n\nLike paired end fusions, users can also view fusions detected by \"Map Fusion Reads\" in genome browser by right-clicking the \"Fusion ID\".\n\n\nMap Fusion Reads\n module reports fusion events by grouping fusion junctions by rows in one table.\nIt provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.\n\n\nCombined Fusion Analysis\n\u00b6\n\n\nCombined Fusion Analysis\n will run fusion junction spanning + inter-transcript fusion read pairs detection at the same time. Combined fusion analysis can only be run on Paired end NgsData (Add or generate BAM files in ArrayStudio). It detects fusion junction spanning reads from unmapped reads in BAM files and detects inter-transcript fusion read pairs from singletons from BAM alignment entries. It will return a report showing potential fusion genes and counts for each fusion junction with columns showing the number of supporting junction spanning reads and inter-transcript fusion read pairs.\n\n\n\n\nFor more information about fusion gene detection, please read our \"best practice\" article in wiki:\n\nlink",
            "title": "RNA-Seq Fusion Gene Detection"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#rna-seq-fusion-gene-detection",
            "text": "In RNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events.\nIn paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion.  Three fusion detection functions can be found in  NGS | Fusion  menu:",
            "title": "RNA-Seq Fusion Gene Detection"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#report-paired-end-fusion-genes",
            "text": "Report Fusion Genes (Paired End)  module will detect fusion genes from inter-transcript paired-end reads based on RNA-Seq alignment ( NgsData ).   Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check  Output fusion reads  option and specify the directory path, supporting fusion reads will be saved as BAM files which can be used for visual checking in the genome browser. Leave all other settings as their defaults and click  Submit  to run the module. The output is a paired fusion report table listed under  Table  in  Solution Explorer :   In the report table, there are three columns for each sample.\nThe first column shows the number of  Unique mapping positions  from reads in  Gene1 , the second column shows the number of  Unique mapping positions  from reads in  Gene2 , while the third column shows the total  Count  of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*6=18 columns of data, as well as additional annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs. The information in  Filter  column in the report table comes from a fusion black list.\nFor more information about the blacklist, please read the following wiki article: link  View Controller  can be used to set row filters to list only genes of interest. Simply navigate to the  View Controller , and under the  Row  tab, input genes of interest into the Gene1 and Gene2 filters. Below are rows for identified known  BCR-ABL1  and  NUP214-XKR3  fusion events in K562 samples:   When fusion ID is right-clicked, there will be an option to open a new Genome Browser to view selected fusion.   In the genome browser view, this feature can be customized to look at individual samples, or to combine tracks within a group. For this example, all samples are examined individually. Use the zoom features (arrows below) or the click wheel of the mouse to zoom in and out of regions of interest. In the example below, notice that the three samples (SRR521461-521463) have a different read coverage of BCR (left) and ABL1 (right) at the 3' and 5' ends, respectively.   Report Fusion Genes (Paired End)  module reports fusion events by grouping gene pairs by rows in one table.\nIt provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.",
            "title": "Report Paired-End Fusion Genes"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#map-fusion-reads",
            "text": "Map Fusion Reads  module will detect fusion genes from fusion junction-spanning reads which can characterize fusion genes at base pair resolution. It is a preferred approach to detect fusion events, using OmicSoft s fusion alignment method ( FusionMap, Ge,H, et al. Bioinformatics (2011): 1922-1928 ). The fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM). If user is using the original  FASTQ  files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click  Reads are paired  option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample.   If user is using  BAM  files, potential fusion reads (such as reads spanning on two nearby genes) in alignment and unmapped reads will be extracted for fusion detection.\nIt is a preferred approach which saves running time of the filtering step when starting with  FASTQ  data.   Minimal cut size  is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners, see wiki page: link  The default  Cut size  is to use value min(25, max(18, readLength/3). For this tutorial dataset, read length is 76, so we use the default.  There are more fusion alignment options in the  Advanced  tab. Leave all settings as their defaults and click  Submit  to run the module. The output is a fusion report table listed under  Table  in  Solution Explorer :   In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion  seed  reads, while the third column shows number of fusion  rescued  reads.\nThere are 3*6=18 columns of data, and 21  annotation columns  for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predicted fusion gene and open reading frame status, and a \"Filter\" column containing black list information.\nThe annotations characterize fusion events at base pair resolution. We also create rollup columns, such as  SplicePatternClass  (Canonical or NonCanonical),  FrameShiftClass  (Frame shift or inFrame),  Distance  (displayed as \"gap size\" between two breakpoints or \"-1\" if located on two different chromosomes) and  OnExonBoundary  (Both, Single or None), for users to further filter false positives.  Below are two rows for known  BCR-ABL1  and  NUP214-XKR3  fusion events identified in K562 samples:   Like paired end fusions, users can also view fusions detected by \"Map Fusion Reads\" in genome browser by right-clicking the \"Fusion ID\".  Map Fusion Reads  module reports fusion events by grouping fusion junctions by rows in one table.\nIt provides an easy way to detecting recurrent fusion events when the analysis was run on multiple samples.",
            "title": "Map Fusion Reads"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Fusion_Gene_Detection/#combined-fusion-analysis",
            "text": "Combined Fusion Analysis  will run fusion junction spanning + inter-transcript fusion read pairs detection at the same time. Combined fusion analysis can only be run on Paired end NgsData (Add or generate BAM files in ArrayStudio). It detects fusion junction spanning reads from unmapped reads in BAM files and detects inter-transcript fusion read pairs from singletons from BAM alignment entries. It will return a report showing potential fusion genes and counts for each fusion junction with columns showing the number of supporting junction spanning reads and inter-transcript fusion read pairs.   For more information about fusion gene detection, please read our \"best practice\" article in wiki: link",
            "title": "Combined Fusion Analysis"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Mutation_Detection/",
            "text": "RNA-Seq Mutation Detection\n\u00b6\n\n\nMutation data can be generated for the RNA-Seq data.\nThis allows the user to compare frequencies of mutation, for individual sites, between groups of samples.\nAll mutation functions can be found in \nNGS | Variation\n.\n\n\n\n\nIn this tutorial, we will only cover \nSummarize Variant Data (Omicsoft)\n and \nAnnotate Variant Table Report\n functions and \nAnnotate Variant Files (VCF/BED/GTT/RS_ID)\n. User can find the documentation for other functions by click the \nHelp\n button in each function menu.\n\n\nSummarize Variant Data\n\u00b6\n\n\nVariants are reported based on the pileup data from alignment data (\nNgsData\n).\n\n\n\n\nChoose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on \"Gene list\" (a list of gene symbols from project lists), \"Customized regions\" (load a bed file), or a \"Filtered by region\" (i.e. chr9:133710831-133763062, or more regions separated by |). We will leave these selections as default in this tutorial.\n\n\nSpecify the base and mapping quality cutoff and choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20, # reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%.\n\n\n\n\nNote\n\n\nYou should lower the coverage cutoff if you are using the subset (5%) tutorial dataset.\n\n\n\n\nIn the \nAdvanced\n tab, users can specify whether to adjust quality based on neighbour base pairs at each position, can check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the mutation annotation step). Maximal frequency specifies the mutation read frequency needed in at least one sample to keep a mutation (i.e if none of the samples has a frequency over 0.10 at one position, then that mutation will not be kept). In addition to summarized reports, it is also helpful to choose \nGenerate merged VCF report for all samples\n and specify an output folder. That will generate a streamed VCF report for all samples in the output folder.\n\n\n\n\nLeave all settings as their defaults and click \nSubmit\n to run the module. The output is a Mutation2Snp report table listed under \nTable\n in solution explorer:\n\n\n\n\nIn the mutation report table, there are four columns for each sample:\n\n\n\n\nMinor allele \nMutationFrequency\n.\n\n\nCoverage\n at this genomic location.\n\n\nPercentage of mutation detected on the \nplus strand\n (MutationReadOnPlus/TotalMutationRead). Ideally, mutation should be detected evenly in both plus and minus strand. A percentage near 0 or 100 may imply a strand bias, which introduces false positive mutation calls.\n\n\nGenotype.\n\n\n\n\nIf there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows.\nThe report comes complete with annotation for each site, including chromosome, position, reference nucleotide and mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dot in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.\n\n\n\n\nAnnotate Variant\n\u00b6\n\n\nThe variants are then annotated with gene coding information, known SNPs and functional prediction databases.\n\n\nOpen \nNGS | Variation | Annotate Variant Table Report\n module; choose the mutation2snp report in \nData\n, Omicsoft gene model in \nGene model\n. Leave all settings as their defaults in this tab.\n\n\n\n\nIn the \nAnnotation Sources\n tab, user can specify more annotation sources, for example 1000Genome and ClinVar as shown below. User also has the option to write the annotated mutation result directly to a text file. Users also have the option to build custom mutation annotators in the \nAdditional Sources\n tab, using \nNGS | Build - Build Mutation Annotator\n.\n\n\n\n\nLeave all the other settings as their defaults and click \nSubmit\n to run the module. The output is a report table listed under \nTable\n in solution explorer:\n\n\n\n\nThe number of rows in annotated report table is more than that in mutation report table, because the annotation was done on each transcript. In the \nAdvanced\n tab, there is one option: \nAnnotate by the longest transcript only\n. If this option is checked, only the longest transcript of each gene will be used to perform the annotation.\n\n\nBesides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in the mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the \nAnnotation Sources\n prior to running the analysis. Using the \nView Controller\n, choose filters to focus on items of interest. For example, in this module, we have filtered the results for the gene SERPINB:\n\n\n\n\nAnnotate Variant Files (VCF/BED/GTT/RS_ID)\n\u00b6\n\n\n\n\nHere, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose annotators to further annotate VCF file.\n\n\n\n\nIn the \nAnnotation Source\n tab, users can choose from the following sources:\n\n\n|new_annotators_png|\n\n\n\n\n\n\n1000GenomesSimple\n - Output allele frequency, population allele frequency in 1000 Genomes data\n\n\n\n\n\n\nCADD\n - Combined Annotation Dependent Depletion (CADD); scoring the deleteriousness of variants in the human genome.\n\n\n\n\n\n\nClinVar\n - Output health related information based on ClinVar database\n\n\n\n\n\n\nConservation\n - Output conservation scores including GERP++, PhyloP, PhastCons, etc\n\n\n\n\n\n\nESP6500\n - Output allele frequency in ESP6500 (NHLBI Exome Sequencing Project) data\n\n\n\n\n\n\nExAC\n - Output allele frequency, population allele frequency in ExAC (The Exome Aggregation Consortium) data\n\n\n\n\n\n\nFunctionalMutation\n - Output functional mutation information based on dbNSFP (database for nonsynonymous SNPs' functional predictions)\n\n\n\n\n\n\nGRASP2\n - Genome-Wide Repository of Associations between SNPs and Phenotypes\n\n\n\n\n\n\nGTExEqtl\n - Output eQTL information based on GTEx project\n\n\n\n\n\n\nGWASCatalog\n - Genome-wide Association data from NHGRI-EBI\n\n\n\n\n\n\nGWAVA\n - Genome Wide Annotation of VAriants\n\n\n\n\n\n\nHaploreg\n - Output annotation on non-coding variants from HaploReg\n\n\n\n\n\n\nInterpro\n - Output protein domain based on InterPro database\n\n\n\n\n\n\nRegulomeDB\n - Output annotations for SNPs with known and predicted regulatory elements based on RegulomeDB\n\n\n\n\n\n\nUK10K\n - Frequency data from the UK10K project\n\n\n\n\n\n\nWellderly\n - applies frequency data from STSI to identify variants present (and absent) in individuals who have reached 80 years of age without chronic disease\n\n\n\n\n\n\nHGMD\n - gene lesions in the Human Gene Mutation Database\n\n\n\n\n\n\nIn addition, it is now possible to use alternate annotators, including Cancer-, Gene-, and Region-based versions.\n\n\nAfter submitting, an annotation file for vcf will be generated. Please note that this is a stream server file, instead of a local file to save searching and storing memory usage.",
            "title": "RNA-Seq Mutation Detection"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Mutation_Detection/#rna-seq-mutation-detection",
            "text": "Mutation data can be generated for the RNA-Seq data.\nThis allows the user to compare frequencies of mutation, for individual sites, between groups of samples.\nAll mutation functions can be found in  NGS | Variation .   In this tutorial, we will only cover  Summarize Variant Data (Omicsoft)  and  Annotate Variant Table Report  functions and  Annotate Variant Files (VCF/BED/GTT/RS_ID) . User can find the documentation for other functions by click the  Help  button in each function menu.",
            "title": "RNA-Seq Mutation Detection"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Mutation_Detection/#summarize-variant-data",
            "text": "Variants are reported based on the pileup data from alignment data ( NgsData ).   Choose the NGS data. In the reference section, all references are selected by default. User can select a list of regions to summarize mutations. Selections can be on \"Gene list\" (a list of gene symbols from project lists), \"Customized regions\" (load a bed file), or a \"Filtered by region\" (i.e. chr9:133710831-133763062, or more regions separated by |). We will leave these selections as default in this tutorial.  Specify the base and mapping quality cutoff and choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20, # reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%.   Note  You should lower the coverage cutoff if you are using the subset (5%) tutorial dataset.   In the  Advanced  tab, users can specify whether to adjust quality based on neighbour base pairs at each position, can check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the mutation annotation step). Maximal frequency specifies the mutation read frequency needed in at least one sample to keep a mutation (i.e if none of the samples has a frequency over 0.10 at one position, then that mutation will not be kept). In addition to summarized reports, it is also helpful to choose  Generate merged VCF report for all samples  and specify an output folder. That will generate a streamed VCF report for all samples in the output folder.   Leave all settings as their defaults and click  Submit  to run the module. The output is a Mutation2Snp report table listed under  Table  in solution explorer:   In the mutation report table, there are four columns for each sample:   Minor allele  MutationFrequency .  Coverage  at this genomic location.  Percentage of mutation detected on the  plus strand  (MutationReadOnPlus/TotalMutationRead). Ideally, mutation should be detected evenly in both plus and minus strand. A percentage near 0 or 100 may imply a strand bias, which introduces false positive mutation calls.  Genotype.   If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows.\nThe report comes complete with annotation for each site, including chromosome, position, reference nucleotide and mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dot in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.",
            "title": "Summarize Variant Data"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Mutation_Detection/#annotate-variant",
            "text": "The variants are then annotated with gene coding information, known SNPs and functional prediction databases.  Open  NGS | Variation | Annotate Variant Table Report  module; choose the mutation2snp report in  Data , Omicsoft gene model in  Gene model . Leave all settings as their defaults in this tab.   In the  Annotation Sources  tab, user can specify more annotation sources, for example 1000Genome and ClinVar as shown below. User also has the option to write the annotated mutation result directly to a text file. Users also have the option to build custom mutation annotators in the  Additional Sources  tab, using  NGS | Build - Build Mutation Annotator .   Leave all the other settings as their defaults and click  Submit  to run the module. The output is a report table listed under  Table  in solution explorer:   The number of rows in annotated report table is more than that in mutation report table, because the annotation was done on each transcript. In the  Advanced  tab, there is one option:  Annotate by the longest transcript only . If this option is checked, only the longest transcript of each gene will be used to perform the annotation.  Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in the mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the  Annotation Sources  prior to running the analysis. Using the  View Controller , choose filters to focus on items of interest. For example, in this module, we have filtered the results for the gene SERPINB:",
            "title": "Annotate Variant"
        },
        {
            "location": "/tutorials/RNASeq/RNA-Seq_Mutation_Detection/#annotate-variant-files-vcfbedgttrs_id",
            "text": "Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the Annotation Source Tab, users can choose annotators to further annotate VCF file.   In the  Annotation Source  tab, users can choose from the following sources:  |new_annotators_png|    1000GenomesSimple  - Output allele frequency, population allele frequency in 1000 Genomes data    CADD  - Combined Annotation Dependent Depletion (CADD); scoring the deleteriousness of variants in the human genome.    ClinVar  - Output health related information based on ClinVar database    Conservation  - Output conservation scores including GERP++, PhyloP, PhastCons, etc    ESP6500  - Output allele frequency in ESP6500 (NHLBI Exome Sequencing Project) data    ExAC  - Output allele frequency, population allele frequency in ExAC (The Exome Aggregation Consortium) data    FunctionalMutation  - Output functional mutation information based on dbNSFP (database for nonsynonymous SNPs' functional predictions)    GRASP2  - Genome-Wide Repository of Associations between SNPs and Phenotypes    GTExEqtl  - Output eQTL information based on GTEx project    GWASCatalog  - Genome-wide Association data from NHGRI-EBI    GWAVA  - Genome Wide Annotation of VAriants    Haploreg  - Output annotation on non-coding variants from HaploReg    Interpro  - Output protein domain based on InterPro database    RegulomeDB  - Output annotations for SNPs with known and predicted regulatory elements based on RegulomeDB    UK10K  - Frequency data from the UK10K project    Wellderly  - applies frequency data from STSI to identify variants present (and absent) in individuals who have reached 80 years of age without chronic disease    HGMD  - gene lesions in the Human Gene Mutation Database    In addition, it is now possible to use alternate annotators, including Cancer-, Gene-, and Region-based versions.  After submitting, an annotation file for vcf will be generated. Please note that this is a stream server file, instead of a local file to save searching and storing memory usage.",
            "title": "Annotate Variant Files (VCF/BED/GTT/RS_ID)"
        },
        {
            "location": "/tutorials/RNASeq/Others/",
            "text": "Others\n\u00b6\n\n\nDownstream Analyses On Quantification Values\n\u00b6\n\n\nAfter aligning data, there are a number of downstream analyses that can be done on the data. For instance, the generated RPKM(or FPKM) dataset can be used, as a \nMicroarray Data\n, for clustering (log2 transformation may be necessary). Counts can be used to look for changes between groups of samples through \nDESeq\n analysis. We also have a \nNGS | Inference | Normalize RNA-Seq Data\n module designed to further normalize RNA-Seq quantification data.\n\n\nAdditionally, the user can look for differences in splice alignment using exon and exon junction report table. Both results are stored in table format. They can be converted to \nMicroarray Data\n (\nOmicData\n) type via right-clicking on the table and choosing \nConvert to MicroArray Data\n:\n\n\n\n\nChoose count columns and click on \nData\n to specify them as data columns. Keep others as \nAnnotation\n.\n\n\n\n\nThere are more visualization and analysis functions/options available for \nMicroarray Data(OmicData\n). Users are encouraged to visit the Microarray Tutorial to examine additional ways to represent their data, such as principal component analysis and heat map clustering.\n\n\nBuild Reference and Gene Model\n\u00b6\n\n\nOmicsoft provides standard genome reference (such as Human.B37.3, hg19, mm10, Mouse.B38) and gene model (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis.\n\n\nIf genome or gene model are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model.\nBoth functions are located in NGS menu:\n\n\n\n\nMore details can be found in the following two wiki articles:\n\n\n\n\n\n\nBuild referencel library. \nlink\n\n\n\n\n\n\nBuild NGS general model. \nlink\n\n\n\n\n\n\nGenome Browser\n\u00b6\n\n\nOmicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio).\n\n\nIt can be used to visualize varied data type, including count/fpkm, exon/exon juncion data, fusion data and many other tracks which have genomic coordinate information.\n\n\nFor example, you can right click a gene/trancript ID in RNA-Seq count data and view tracks in Genome Browser.\n\n\n\n\nPlease read tutorial, \nOmicsoft Genome Browser\n, for more details.",
            "title": "Others"
        },
        {
            "location": "/tutorials/RNASeq/Others/#others",
            "text": "",
            "title": "Others"
        },
        {
            "location": "/tutorials/RNASeq/Others/#downstream-analyses-on-quantification-values",
            "text": "After aligning data, there are a number of downstream analyses that can be done on the data. For instance, the generated RPKM(or FPKM) dataset can be used, as a  Microarray Data , for clustering (log2 transformation may be necessary). Counts can be used to look for changes between groups of samples through  DESeq  analysis. We also have a  NGS | Inference | Normalize RNA-Seq Data  module designed to further normalize RNA-Seq quantification data.  Additionally, the user can look for differences in splice alignment using exon and exon junction report table. Both results are stored in table format. They can be converted to  Microarray Data  ( OmicData ) type via right-clicking on the table and choosing  Convert to MicroArray Data :   Choose count columns and click on  Data  to specify them as data columns. Keep others as  Annotation .   There are more visualization and analysis functions/options available for  Microarray Data(OmicData ). Users are encouraged to visit the Microarray Tutorial to examine additional ways to represent their data, such as principal component analysis and heat map clustering.",
            "title": "Downstream Analyses On Quantification Values"
        },
        {
            "location": "/tutorials/RNASeq/Others/#build-reference-and-gene-model",
            "text": "Omicsoft provides standard genome reference (such as Human.B37.3, hg19, mm10, Mouse.B38) and gene model (RefGene, Ensembl and UCSC). Prebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis.  If genome or gene model are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model.\nBoth functions are located in NGS menu:   More details can be found in the following two wiki articles:    Build referencel library.  link    Build NGS general model.  link",
            "title": "Build Reference and Gene Model"
        },
        {
            "location": "/tutorials/RNASeq/Others/#genome-browser",
            "text": "Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio).  It can be used to visualize varied data type, including count/fpkm, exon/exon juncion data, fusion data and many other tracks which have genomic coordinate information.  For example, you can right click a gene/trancript ID in RNA-Seq count data and view tracks in Genome Browser.   Please read tutorial,  Omicsoft Genome Browser , for more details.",
            "title": "Genome Browser"
        },
        {
            "location": "/tutorials/RNASeq/Save___Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results. Please refer to the MicroArray tutorial for more details on the \nAudit Trial\n, which records all the analysis steps in the form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/RNASeq/Save___Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results. Please refer to the MicroArray tutorial for more details on the  Audit Trial , which records all the analysis steps in the form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/DNASeq/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArray Studio\n\u00b6\n\n\nArray Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on Windows Server based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 40GB RAM.\n\n\nIt is highly recommend that the user complete the prerequisite for this tutorial, the Microarray tutorial, as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.\n\n\nTest Dataset\n\u00b6\n\n\nThis DNA-Seq tutorial will cover the importing and some analysis of three public datasets.\nWe have selected three SRR run .fastq files. The full dataset is available on the SRA archive:\n\n\nSRR097848 (MCF10A cell line):\n\nlink\n\n\nSRR097849 (MCF7 cell line):\n\nlink\n\n\nSRR064173 (K562 cell line):\n\nlink\n\n\nThe whole dataset is ~2.5GB. For convenience, we provide a subset (10% of reads) of the dataset which can be downloaded at:\n\nlink\n\n\n\n\nNote\n\n\nNote:\nThe tutorial is based on the whole dataset; results will be somewhat different if you are using the subset dataset. Also, Omicsoft keeps updating algorithms and data to make sure that users have the most accurate results. Therefore, you may have slightly different results when you compare your results with the results shown in this tutorial.\n\n\n\n\n\n\nDNA-Seq Analysis Workflow\n\u00b6\n\n\nIn this tutorial, we will introduce the DNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for DNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, detection of fusion and mutation, and copy number analysis, as shown in the schematic chart below:",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/DNASeq/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/DNASeq/Introduction/#array-studio",
            "text": "Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on Windows Server based NGS analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 40GB RAM.  It is highly recommend that the user complete the prerequisite for this tutorial, the Microarray tutorial, as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.",
            "title": "Array Studio"
        },
        {
            "location": "/tutorials/DNASeq/Introduction/#test-dataset",
            "text": "This DNA-Seq tutorial will cover the importing and some analysis of three public datasets.\nWe have selected three SRR run .fastq files. The full dataset is available on the SRA archive:  SRR097848 (MCF10A cell line): link  SRR097849 (MCF7 cell line): link  SRR064173 (K562 cell line): link  The whole dataset is ~2.5GB. For convenience, we provide a subset (10% of reads) of the dataset which can be downloaded at: link   Note  Note:\nThe tutorial is based on the whole dataset; results will be somewhat different if you are using the subset dataset. Also, Omicsoft keeps updating algorithms and data to make sure that users have the most accurate results. Therefore, you may have slightly different results when you compare your results with the results shown in this tutorial.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/DNASeq/Introduction/#dna-seq-analysis-workflow",
            "text": "In this tutorial, we will introduce the DNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for DNA-Seq data processing, including raw data quality control (QC), alignment, aligned data QC, detection of fusion and mutation, and copy number analysis, as shown in the schematic chart below:",
            "title": "DNA-Seq Analysis Workflow"
        },
        {
            "location": "/tutorials/DNASeq/Create_Array_Studio_Project/",
            "text": "Create Array Studio Project\n\u00b6\n\n\nCreate New Project\n\u00b6\n\n\nArray Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project (distributed) and analysis steps are almost the same as described in this tutorial. The interface of creating of new local project is different from creating a new server project, but the rest of the steps, such as data import, and data analysis share the same interface.\n\n\nDifferent project types tell Array Studio where to run the analysis:\nIf it is a local project, Array Studio will run the analysis in local machine;\nif it is a server project, Array Studio will run the analysis on server.\n\n\nOnce Array Studio has been opened, click \nFile | New Server Project\n from the File Menu (also can be accessed via the \nNew\n button on the toolbar).\n\n\nNote: For a local project, it is required that the user have approximately 10GB of available space on their hard drive for this tutorial.\nThe general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft\" home folder using \nTools Menu | Preferences | Advanced\n.\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. The reference library and index will take ~10Gb of space.\n\n\n\n\nUsers may enter some basic metadata and click Create to create an empty server project:\n\n\n\n\nAnother way to create a new project is by this icon:\n\n\n\n\nOnce a project is created, users can choose to follow the DNA-Seq Analysis Pipeline module (all-in-one, Chapter 3) or perform QC/filtering/alignment/mutation analyses (Chapters 4-6,8) all as individual steps.\n\n\nDNA-Seq Analysis Pipeline\n\u00b6\n\n\nArray studio provides an easy way for new users to do all analyses in one module:\n\n\n\n\nThis function has a similar interface to the DNAseq alignment module.\n\n\n\n\nUsers need to provide the DNA seq files and choose the genome. Then in the reporting section, users can choose which related analysis want to perform. The available analysis include\n\n\n\n\n\n\nPerform raw data QC\n\n\n\n\n\n\nFilter Raw data\n\n\n\n\n\n\nPerform post alignment QC\n\n\n\n\n\n\nSummarize mutation + SNP\n\n\n\n\n\n\nGenerate BAM Summary (.bas Files)\n\n\n\n\n\n\nEach analysis is done by default setting and will generate data objects in the Solution Explorer when the entire pipeline is complete. Users can perform step-by-step analysis with customized settings as described in later chapters.",
            "title": "Create Project"
        },
        {
            "location": "/tutorials/DNASeq/Create_Array_Studio_Project/#create-array-studio-project",
            "text": "",
            "title": "Create Array Studio Project"
        },
        {
            "location": "/tutorials/DNASeq/Create_Array_Studio_Project/#create-new-project",
            "text": "Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with its Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data. In this tutorial, we will create a server project to run the analyses. This assumes the user has Array Server installed - the user can run this tutorial as a local project (distributed) and analysis steps are almost the same as described in this tutorial. The interface of creating of new local project is different from creating a new server project, but the rest of the steps, such as data import, and data analysis share the same interface.  Different project types tell Array Studio where to run the analysis:\nIf it is a local project, Array Studio will run the analysis in local machine;\nif it is a server project, Array Studio will run the analysis on server.  Once Array Studio has been opened, click  File | New Server Project  from the File Menu (also can be accessed via the  New  button on the toolbar).  Note: For a local project, it is required that the user have approximately 10GB of available space on their hard drive for this tutorial.\nThe general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft\" home folder using  Tools Menu | Preferences | Advanced .\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location. The reference library and index will take ~10Gb of space.   Users may enter some basic metadata and click Create to create an empty server project:   Another way to create a new project is by this icon:   Once a project is created, users can choose to follow the DNA-Seq Analysis Pipeline module (all-in-one, Chapter 3) or perform QC/filtering/alignment/mutation analyses (Chapters 4-6,8) all as individual steps.",
            "title": "Create New Project"
        },
        {
            "location": "/tutorials/DNASeq/Create_Array_Studio_Project/#dna-seq-analysis-pipeline",
            "text": "Array studio provides an easy way for new users to do all analyses in one module:   This function has a similar interface to the DNAseq alignment module.   Users need to provide the DNA seq files and choose the genome. Then in the reporting section, users can choose which related analysis want to perform. The available analysis include    Perform raw data QC    Filter Raw data    Perform post alignment QC    Summarize mutation + SNP    Generate BAM Summary (.bas Files)    Each analysis is done by default setting and will generate data objects in the Solution Explorer when the entire pipeline is complete. Users can perform step-by-step analysis with customized settings as described in later chapters.",
            "title": "DNA-Seq Analysis Pipeline"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/",
            "text": "QC of Raw Data Files\n\u00b6\n\n\nArray Studio contains several modules for QC of raw data files. The easiest way is to run \nRaw Data QC Wizard\n, which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function individually, which offers more options to specify, such as adapter stripping and max read position.\n\n\n\n\nClick \nAdd\n to find all 6 files for the three samples. The Array Studio \nRaw Data QC Wizard\n provides lots of different QC metrics such as \nBasic statistics\n, \nBase Distribution\n etc. Users can select each QC metric they want to run. Optionally, for a quicker analysis, the user can choose \npreview mode\n to only generate QC on the 5% sampled reads. This is, in most cases, good enough to get an assessment of quality.\nLeave \nQuality encoding\n as \nAutomatic\n to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding).\n\n\nClick \nSubmit\n to begin the analysis.\n\n\n\n\nThe \nRaw Data QC\n module returns multiple raw data QC results/reports in \nRaw Data QC\n folder, which are described in the following subsections.\n\n\n\n\nBasic Statistics\n\u00b6\n\n\nThe basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.\n\n\nBase distribution QC results are located in the \nRaw Data QC\n folder with name \nBasicStats\n. Double-click the table view to open if you do not see the basic statistics table in the middle window:\n\n\n\n\nBase Distribution\n\u00b6\n\n\nBase distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the \nRaw Data QC\n folder with name \nBaseDistribution\n. By default, the BaseDistribution \nProfileView\n should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer.\n\n\n\n\nSwitch to the \nLegend\n in the \nView Controller\n to see the percentages of A, G, C, and T for each base pair position. Notice that there are a total of 6 charts (scroll through them to look at each sample), one for each file that was QC'ed. Selecting points on the chart will also show additional details in the Details Window, as shown below.\n\n\n\n\nOne can also switch to line plot view by going to \nView Controller | Task | Customize | Change To Line Type\n.\n\n\n\n\nRead Quality QC\n\u00b6\n\n\nThe QC results include a \nPerSequenceQuality\n (view and table), a \nQualityBoxPlot\n (view and table) and a \nOverallQualityReport\n (view and table) in the Solution Explorer.\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.\n\n\n\n\nIn Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples.\n\n\n\n\nFrom the \nQualityBoxPlot\n view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR097848. Scroll through each of the 6 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the \nDetails Window\n below the plot.\n\n\nThe Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.\n\n\n\n\nK-Mer analysis\n\u00b6\n\n\nThe K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer in a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short (\ne.g.\n miRNA-seq) and unfiltered adapter dimers.\n\n\n\n\nIn the \nKMerAnalysis\n profile view, Y-axis is the percentage of reads (0.01 means 1%) that contain each KMer. There is no significant (all less than 1.5%) enrichment of k mer in this tutorial dataset.",
            "title": "Raw Data QC"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/#qc-of-raw-data-files",
            "text": "Array Studio contains several modules for QC of raw data files. The easiest way is to run  Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function individually, which offers more options to specify, such as adapter stripping and max read position.   Click  Add  to find all 6 files for the three samples. The Array Studio  Raw Data QC Wizard  provides lots of different QC metrics such as  Basic statistics ,  Base Distribution  etc. Users can select each QC metric they want to run. Optionally, for a quicker analysis, the user can choose  preview mode  to only generate QC on the 5% sampled reads. This is, in most cases, good enough to get an assessment of quality.\nLeave  Quality encoding  as  Automatic  to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding).  Click  Submit  to begin the analysis.   The  Raw Data QC  module returns multiple raw data QC results/reports in  Raw Data QC  folder, which are described in the following subsections.",
            "title": "QC of Raw Data Files"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/#basic-statistics",
            "text": "The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.  Base distribution QC results are located in the  Raw Data QC  folder with name  BasicStats . Double-click the table view to open if you do not see the basic statistics table in the middle window:",
            "title": "Basic Statistics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/#base-distribution",
            "text": "Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file). Base distribution QC results are located in the  Raw Data QC  folder with name  BaseDistribution . By default, the BaseDistribution  ProfileView  should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer.   Switch to the  Legend  in the  View Controller  to see the percentages of A, G, C, and T for each base pair position. Notice that there are a total of 6 charts (scroll through them to look at each sample), one for each file that was QC'ed. Selecting points on the chart will also show additional details in the Details Window, as shown below.   One can also switch to line plot view by going to  View Controller | Task | Customize | Change To Line Type .",
            "title": "Base Distribution"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/#read-quality-qc",
            "text": "The QC results include a  PerSequenceQuality  (view and table), a  QualityBoxPlot  (view and table) and a  OverallQualityReport  (view and table) in the Solution Explorer.\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.   In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown. This gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples.   From the  QualityBoxPlot  view (shown above), it is clear that the quality of the read1 starts to drop off earlier than read 2 in sample SRR097848. Scroll through each of the 6 charts to see the quality BoxPlots for each individual fastq file. Selecting a point on the chart will show additional details in the  Details Window  below the plot.  The Overall Quality Report summarizes quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.",
            "title": "Read Quality QC"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Raw_Data_Files/#k-mer-analysis",
            "text": "The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads. This analysis identifies whether there is an enrichment of a kmer in a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short ( e.g.  miRNA-seq) and unfiltered adapter dimers.   In the  KMerAnalysis  profile view, Y-axis is the percentage of reads (0.01 means 1%) that contain each KMer. There is no significant (all less than 1.5%) enrichment of k mer in this tutorial dataset.",
            "title": "K-Mer analysis"
        },
        {
            "location": "/tutorials/DNASeq/Alignment_to_the_Genome/",
            "text": "Alignment to the Genome\n\u00b6\n\n\nThe second step in most DNA-Seq analysis is the alignment of the reads to the genome.\nAlternatively, if the data have already been aligned, the alignment (BAM/SAM) files can be imported through \nAdd NGS Data | Add DNA-Seq Data | Add Genome Mapped Reads\n.\n\n\nFor this experiment, we will align the data using Array Studio. To add aligned NGS data, go to the \nAdd Data\n dropdown menu on the toolbar, then choose \nAdd NGS Data | Add DNA-Seq Data | Map Reads to Genome (Illumina)\n.\n\n\n\n\nAt this point, the \nMap DNA-Seq Reads to Genome\n module appears.\nThe first step is to click the \nAdd\n button to specify the location of the files.\nChoose the 6 files that were downloaded from SRA or the subset of the dataset downloaded from OmicSoft website. Note that these files are in .gz (gzip) format. The alignment process takes this into account and it is an effective way to save some space when importing files, as there is no need to extract all files.\n\n\n\n\nAs this is a paired experiment,\n\nclick the Reads are paired checkbox\n.\nThis will ensure that the pairing information is used in the alignment and counting process.\n\n\nChoose the \nGenome\n for the experiment. In this case, use \nHuman.B37.3\n. Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome.\n\n\nLeave the \nquality encoding\n set to automatic.\nHowever for your information, these files were encoded using the Sanger quality scoring system.\n\nTotal penalty\n should be left on automatic, and is described completely in Omicsoft's white paper on alignment.\n\n\nThread number\n indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes).\n\n\nNon-unique mapping\n indicates how many ties? for non-unique reads should be reported, or if they should be excluded all together.\n\n\nOutput folder\n allows the user to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder).\nIn this tutorial, \nit is recommended to specify a folder\n, so that BAM files can be found easily in next step (for fusion detection).\n\n\nThere are a few options in the \nAdvanced\n Tab (e.g. detailed parameter settings for Indel detection). In general the default values have been tuned and should work well in most cases.\n\n\nLeave the \nExclude unmapped reads in BAM\n file \nunchecked\n, so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input to the single-end fusion detection algorithm (see the fusion chapter in this tutorial).\n\n\nClick Submit to \nSubmit\n the analysis.\nThis could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc.\n\n\nAfter the alignment, you will see a NgsData object and an alignment report table in the solution explorer:",
            "title": "Alignment"
        },
        {
            "location": "/tutorials/DNASeq/Alignment_to_the_Genome/#alignment-to-the-genome",
            "text": "The second step in most DNA-Seq analysis is the alignment of the reads to the genome.\nAlternatively, if the data have already been aligned, the alignment (BAM/SAM) files can be imported through  Add NGS Data | Add DNA-Seq Data | Add Genome Mapped Reads .  For this experiment, we will align the data using Array Studio. To add aligned NGS data, go to the  Add Data  dropdown menu on the toolbar, then choose  Add NGS Data | Add DNA-Seq Data | Map Reads to Genome (Illumina) .   At this point, the  Map DNA-Seq Reads to Genome  module appears.\nThe first step is to click the  Add  button to specify the location of the files.\nChoose the 6 files that were downloaded from SRA or the subset of the dataset downloaded from OmicSoft website. Note that these files are in .gz (gzip) format. The alignment process takes this into account and it is an effective way to save some space when importing files, as there is no need to extract all files.   As this is a paired experiment, click the Reads are paired checkbox .\nThis will ensure that the pairing information is used in the alignment and counting process.  Choose the  Genome  for the experiment. In this case, use  Human.B37.3 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome.  Leave the  quality encoding  set to automatic.\nHowever for your information, these files were encoded using the Sanger quality scoring system. Total penalty  should be left on automatic, and is described completely in Omicsoft's white paper on alignment.  Thread number  indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes).  Non-unique mapping  indicates how many ties? for non-unique reads should be reported, or if they should be excluded all together.  Output folder  allows the user to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder).\nIn this tutorial,  it is recommended to specify a folder , so that BAM files can be found easily in next step (for fusion detection).  There are a few options in the  Advanced  Tab (e.g. detailed parameter settings for Indel detection). In general the default values have been tuned and should work well in most cases.  Leave the  Exclude unmapped reads in BAM  file  unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped). The generated BAM files (which contain unmapped reads, possible fusion reads) can be directly used as input to the single-end fusion detection algorithm (see the fusion chapter in this tutorial).  Click Submit to  Submit  the analysis.\nThis could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc.  After the alignment, you will see a NgsData object and an alignment report table in the solution explorer:",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/",
            "text": "QC of Aligned Data\n\u00b6\n\n\nAlignment Report\n\u00b6\n\n\nBy default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the \nAlignmentReport\n table.\n\n\nThis will show, for each pair (or single file if the user did not do a paired alignment), some information regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired).\n\n\n\n\nDNA-Seq Aligned QC\n\u00b6\n\n\nThis module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. Also generates a \nProfileView\n showing a chart for each metric.\n\n\nHere we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to \nAdd Data | Add NGS Data | Add DNA-Seq Data | Add Genome-Mapped Reads\n. To run the DNA-Seq QC module, go to \nNGS | Aligned Data QC | DNA-Seq QC Metrics\n now.\n\n\n\n\nChoose the NGS data and leave all other settings as their defaults and click \nSubmit\n to run the module.\n\n\n\n\nProfile\n metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723.\n\n\nThe analysis returns a \nTable\n View of QC metrics and \nProfile\n view in the \nAligned Data QC\n folder:\n\n\n\n\nIn the \nTable\n view, you will find the following sections:\n\n\nAlignment Metrics\n\u00b6\n\n\nThese metrics can be used to give an overall idea of the quality of the alignment for your samples.\n\n\n\n\nDuplication Metrics\n\u00b6\n\n\nThe duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an DNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.\n\n\n\n\nFeatureMetrics\n\u00b6\n\n\nFeature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by DNA-Seq data.\n\n\n\n\nFlag Metrics\n\u00b6\n\n\nFlag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.\n\n\n\n\nGenome Coverage Metrics\n\u00b6\n\n\nGenome coverage metrics provides metrics for genome coverage with different depth, from 1X to 100X.\n\n\n\n\nInsert Size Metrics\n\u00b6\n\n\nInsert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values such as mean insert sizes that are significantly different from the library's size-selection range.\n\n\n\n\nProfile Metrics\n\u00b6\n\n\nProfile Metrics provide important overall statistics based on the provided gene model. It is usually used for RNA-Seq data, but it is also a useful metric for exon capture DNA-Seq sequencing, since DNA regions fragments are captured based on a gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.\n\n\n\n\nStrand Metrics\n\u00b6\n\n\nThe strand metrics give you the rates at which reads are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.\n\n\n\n\nIndividual Aligned Data QC\n\u00b6\n\n\nDNA-Seq QC Metrics\n provides comprehensive assessment of the alignment data. We also provide metrics such as \nFlag Summary Statistics\n, \nMapping Summary Statistics\n and \nPaired End Insert Size\n as separate functions, where users can specify more analysis options.\n\n\n\n\nCoverage Summary Statistics\n\u00b6\n\n\nAdditional coverage summary statistics can be generated by going to \nNGS | Coverage | Coverage Summary Statistics\n now.\n\n\n\n\nThe user can set the \nsize of the coverage for each bin\n, and whether to \noutput bedGraph files\n for use in outside programs.\n\n\nLeave options as-is and click Submit to continue.\n\n\n\n\nThis generates a new table, \nNgsCoverageReport\n, which can be used for downstream analysis and visualization.\n\n\n\n\nOpen the histogram; filter to Chromosome=22 only under \nView Controller|Row\n; layout three charts in 3*1 mode. You can get:\n\n\n\n\nThere is a clear enrichment at chr22:23600001-23700000 in SRR064173, which is expected since this sample is a targeted sequencing experiment of BCR-ABL1 fusion DNA fragment.\n\n\nIn the detail window, users can further check  read information in the Genome browser by right clicking the row:",
            "title": "Aligned QC"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#qc-of-aligned-data",
            "text": "",
            "title": "QC of Aligned Data"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#alignment-report",
            "text": "By default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the  AlignmentReport  table.  This will show, for each pair (or single file if the user did not do a paired alignment), some information regarding mapping. One of the key statistics is the uniquely paired reads (uniquely mapped and properly paired).",
            "title": "Alignment Report"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#dna-seq-aligned-qc",
            "text": "This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files. These metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table. Also generates a  ProfileView  showing a chart for each metric.  Here we assume that the alignment data (NGS data) exist in a project. If not, one can add bam files into a project by going to  Add Data | Add NGS Data | Add DNA-Seq Data | Add Genome-Mapped Reads . To run the DNA-Seq QC module, go to  NGS | Aligned Data QC | DNA-Seq QC Metrics  now.   Choose the NGS data and leave all other settings as their defaults and click  Submit  to run the module.   Profile  metric is based on the provided gene model. It provides the most information with gene models like Ensembl that have detailed information for the source of each transcript. Here, we specify to use gene model OmicsoftGene20130723.  The analysis returns a  Table  View of QC metrics and  Profile  view in the  Aligned Data QC  folder:   In the  Table  view, you will find the following sections:",
            "title": "DNA-Seq Aligned QC"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#alignment-metrics",
            "text": "These metrics can be used to give an overall idea of the quality of the alignment for your samples.",
            "title": "Alignment Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#duplication-metrics",
            "text": "The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment). This is based on coordinates (start position), rather than the raw data QC which was based on sequence. It is expected that an DNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.",
            "title": "Duplication Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#featuremetrics",
            "text": "Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by DNA-Seq data.",
            "title": "FeatureMetrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#flag-metrics",
            "text": "Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.",
            "title": "Flag Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#genome-coverage-metrics",
            "text": "Genome coverage metrics provides metrics for genome coverage with different depth, from 1X to 100X.",
            "title": "Genome Coverage Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#insert-size-metrics",
            "text": "Insert size metrics provide some basic metrics on the insert sizes for paired end experiments. Use these metrics to ensure that the paired end experiment is performing as expected, and to look for any outlier values such as mean insert sizes that are significantly different from the library's size-selection range.",
            "title": "Insert Size Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#profile-metrics",
            "text": "Profile Metrics provide important overall statistics based on the provided gene model. It is usually used for RNA-Seq data, but it is also a useful metric for exon capture DNA-Seq sequencing, since DNA regions fragments are captured based on a gene model. Metrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene, in a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion, inter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model). Use these metrics to determine the overall success of the profiling.",
            "title": "Profile Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#strand-metrics",
            "text": "The strand metrics give you the rates at which reads are aligned to the sense or anti-sense strands. For most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50). However, for some stranded protocols, this might not be the case.",
            "title": "Strand Metrics"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#individual-aligned-data-qc",
            "text": "DNA-Seq QC Metrics  provides comprehensive assessment of the alignment data. We also provide metrics such as  Flag Summary Statistics ,  Mapping Summary Statistics  and  Paired End Insert Size  as separate functions, where users can specify more analysis options.",
            "title": "Individual Aligned Data QC"
        },
        {
            "location": "/tutorials/DNASeq/QC_of_Aligned_Data/#coverage-summary-statistics",
            "text": "Additional coverage summary statistics can be generated by going to  NGS | Coverage | Coverage Summary Statistics  now.   The user can set the  size of the coverage for each bin , and whether to  output bedGraph files  for use in outside programs.  Leave options as-is and click Submit to continue.   This generates a new table,  NgsCoverageReport , which can be used for downstream analysis and visualization.   Open the histogram; filter to Chromosome=22 only under  View Controller|Row ; layout three charts in 3*1 mode. You can get:   There is a clear enrichment at chr22:23600001-23700000 in SRR064173, which is expected since this sample is a targeted sequencing experiment of BCR-ABL1 fusion DNA fragment.  In the detail window, users can further check  read information in the Genome browser by right clicking the row:",
            "title": "Coverage Summary Statistics"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/",
            "text": "DNA-Seq Fusion Gene Detection\n\u00b6\n\n\nIn DNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events.\nIn paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion.\n\n\nTwo fusion detection functions for DNAseq data can be found in \nNGS | Fusion\n menu: \nMap Fusion Reads (Illumina)\n and \nReport Fusion Genes (Paired End)\n. Note that the first function, \nCombined Fusion Analysis\n, is only designed for RNAseq data.\n\n\n\n\nReport Paired-End Fusion Genes\n\u00b6\n\n\nReport Fusion Genes (Paired End)\n module will detect fusion genes from inter-transcript paired-end reads based on DNA-Seq alignment (\nNgsData\n).\n\n\n\n\nChoose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check \nOutput fusion reads\n option and specify the directory path, supporting fusion reads will be saved as BAM files, which can be used for visual check in genome browser. Leave all other settings as their defaults and click \nSubmit\n to run the module. The output is a paired fusion report table listed under \nTable\n in solution explorer:\n\n\n\n\nThe information in \nFilter\n column in the report table comes from a fusion black list.\nFor more information about the blacklist, please read the following wiki article:\n\nlink\n\n\nIn the report table, there are three columns for each sample. The first column shows the number of \nunique mapping positions\n from reads in \nGene1\n, the second columns shows the number of \nunique mapping positions\n from reads in \nGene2\n, while the third column shows the total \ncount\n of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*3=9 columns of data, and annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs.\n\n\nBelow are rows for identified known fusion \nBCR-ABL1\n fusion in SRR064173 (K562) samples at the genomic level:\n\n\n\n\nReport Fusion Genes (Paired End)\n module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detect recurrent fusion events when the analysis was run on multiple samples.\n\n\nMap Fusion Reads\n\u00b6\n\n\nMap Fusion Reads\n module will detect fusion genes from fusion junction-spanning reads, which can characterize fusion genes at base pair resolution.\nIt is the preferred approach to detect fusion events, using OmicSoft's fusion alignment method (\nFusionMap, Ge, H, et al. Bioinformatics (2011): 1922-1928\n).\n\n\nIt is not recommend to run Map Fusion Reads module on multiple samples with different read lengths. In this tutorial, the read length of SRR064173 is 38bp and one of SRR097848/SRR097849 is 50bp. Thus, this tutorial step will focus on the fusion junction detection in data SRR064173, since it is enrichment on BCR-ABL1 fusion regions.\n\n\nFusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM).\nIf the user is using the original \nFASTQ\n files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click \nReads are paired\n option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample.\n\n\n\n\nIf user is using \nBAM\n files, potential fusion reads (such as reads spanning two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is the \npreferred\n approach, which saves running time at the filtering step.\n\n\n\n\nRemember to uncheck \nReads are RNA-Seq reads\n. By default, this module is used for RNA-Seq data.\n\n\nChoose the \nGene model\n to be OmicsoftGene20130723.\n\n\nMinimal cut size\n is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners. For details, see wiki page:\n\nlink\n\n\nThe default \nCut size\n is to use value min(25, max(18, readLength/3). However, the read length for dataset SRR064173 (K562) is 38. For this tutorial dataset, we use a \nFixed\n cut size of 16 to require at least 16 nucleotides to match each of the two genomic location, allowing 6 nucleotides in the middle of each read to detect fusion breakpoints.\n\n\nThere are more fusion alignment options. Leave all settings as their defaults and click \nSubmit\n to run the module. The output is a fusion report table listed under \nTable\n in solution explorer:\n\n\n\n\nIn the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion \nseed\n reads, while the third column shows number of fusion \nrescued\n reads. There are 3 columns of data, and 11\n\nannotation columns\n for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predict fusion gene.\n\n\nBelow is the result for identified known fusion \nBCR-ABL1\n in K562 samples at genomic level:",
            "title": "Fusion Detection"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#dna-seq-fusion-gene-detection",
            "text": "In DNA-Seq datasets, fusion genes can be detected based on both paired- and single-end reads. In a paired-end NGS dataset, a discordant read pair is one that is not aligned to the reference genome with the expected distance or orientation. If a set of discordant read pairs are mapped to two different genes, a fusion gene is suggested. On the other hand, single-end reads that span the fusion junctions provide base-pair evidence for the fusion events.\nIn paired-end datasets, two fusion reports from junction-spanning reads and discordant read pairs can be combined to eliminate false positives and provide accurate base pair resolution detection of fusion.  Two fusion detection functions for DNAseq data can be found in  NGS | Fusion  menu:  Map Fusion Reads (Illumina)  and  Report Fusion Genes (Paired End) . Note that the first function,  Combined Fusion Analysis , is only designed for RNAseq data.",
            "title": "DNA-Seq Fusion Gene Detection"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#report-paired-end-fusion-genes",
            "text": "Report Fusion Genes (Paired End)  module will detect fusion genes from inter-transcript paired-end reads based on DNA-Seq alignment ( NgsData ).   Choose the NGS data and Gene model; specify the fusion report cutoff and alignment tie cutoff. Check  Output fusion reads  option and specify the directory path, supporting fusion reads will be saved as BAM files, which can be used for visual check in genome browser. Leave all other settings as their defaults and click  Submit  to run the module. The output is a paired fusion report table listed under  Table  in solution explorer:   The information in  Filter  column in the report table comes from a fusion black list.\nFor more information about the blacklist, please read the following wiki article: link  In the report table, there are three columns for each sample. The first column shows the number of  unique mapping positions  from reads in  Gene1 , the second columns shows the number of  unique mapping positions  from reads in  Gene2 , while the third column shows the total  count  of read pairs mapped to that fusion. If reads map to only a small number of unique positions, this could indicate a false positive (potentially PCR duplicates). There are 3*3=9 columns of data, and annotation columns: gene name, strand and genomic locations. The start and end positions in the table describe the genomic coordinate of the gene, not the breakpoints of fusion gene. The exact breakpoint cannot be determined by fusion detection based on discordant read pairs.  Below are rows for identified known fusion  BCR-ABL1  fusion in SRR064173 (K562) samples at the genomic level:   Report Fusion Genes (Paired End)  module reports fusion events by grouping gene pairs by rows in one table. It provides an easy way to detect recurrent fusion events when the analysis was run on multiple samples.",
            "title": "Report Paired-End Fusion Genes"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Fusion_Gene_Detection/#map-fusion-reads",
            "text": "Map Fusion Reads  module will detect fusion genes from fusion junction-spanning reads, which can characterize fusion genes at base pair resolution.\nIt is the preferred approach to detect fusion events, using OmicSoft's fusion alignment method ( FusionMap, Ge, H, et al. Bioinformatics (2011): 1922-1928 ).  It is not recommend to run Map Fusion Reads module on multiple samples with different read lengths. In this tutorial, the read length of SRR064173 is 38bp and one of SRR097848/SRR097849 is 50bp. Thus, this tutorial step will focus on the fusion junction detection in data SRR064173, since it is enrichment on BCR-ABL1 fusion regions.  Fusion detection can use raw sequence files (Fastq, fasta, or qseq format) or alignment NGS data (BAM/SAM).\nIf the user is using the original  FASTQ  files, the first step is to filter out normal reads and get a pool of potential fusion reads. Make sure to click  Reads are paired  option so that a pair of files will be considered as one sample during fusion detection. The module will automatically pair two files based on file names. If it is unchecked, one file will be treated as one sample.   If user is using  BAM  files, potential fusion reads (such as reads spanning two nearby genes) in alignment and unmapped reads will be extracted for fusion detection. It is the  preferred  approach, which saves running time at the filtering step.   Remember to uncheck  Reads are RNA-Seq reads . By default, this module is used for RNA-Seq data.  Choose the  Gene model  to be OmicsoftGene20130723.  Minimal cut size  is the minimal seed length for fusion detection, which requires the minimal length of a fusion read mapped in two fusion partners. For details, see wiki page: link  The default  Cut size  is to use value min(25, max(18, readLength/3). However, the read length for dataset SRR064173 (K562) is 38. For this tutorial dataset, we use a  Fixed  cut size of 16 to require at least 16 nucleotides to match each of the two genomic location, allowing 6 nucleotides in the middle of each read to detect fusion breakpoints.  There are more fusion alignment options. Leave all settings as their defaults and click  Submit  to run the module. The output is a fusion report table listed under  Table  in solution explorer:   In the report table, there are three columns for each sample. The first column shows the number of unique mapping positions from fusion junction spanning reads, the second columns shows the number of fusion  seed  reads, while the third column shows number of fusion  rescued  reads. There are 3 columns of data, and 11 annotation columns  for fusion strand, fusion breakpoint, known gene/transcript names of two genes, fusion junction sequence, splice pattern, predict fusion gene.  Below is the result for identified known fusion  BCR-ABL1  in K562 samples at genomic level:",
            "title": "Map Fusion Reads"
        },
        {
            "location": "/tutorials/DNASeq/DNA-SeqMutation_Detection/",
            "text": "DNA-Seq Mutation Detection\n\u00b6\n\n\nMutation data can be generated from DNA-Seq data.\nThis allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in \nNGS | Variation\n.\n\n\n\n\nIn this tutorial, we will cover three mutation detection workflows:\n\n\n\n\nSummarize Variant Data + Annotated Variant Report\n\n\nGenerate VCF files + Annotated VCF files\n\n\nSummarize Matched Pair Variation Data + Annotated Mutation/SNP Report\n\n\n\n\nUser can find the documentation for other functions by clicking the \nHelp\n button in each function menu.\n\n\nSummarize/Annotate Variant\n\u00b6\n\n\nSummarize Variant Data\n is developed by OmicSoft.\nVariant (Mutations and SNPs) are reported based on the pileup data from alignment data (\nNgsData\n).\n\n\n\n\nChoose the NGS data. In the reference section, all references are selected by default.\nUser can select a list of regions to summarize mutations. Selections can be on \nGene list\n (a list of gene symbols from project lists), \nCustomized regions\n (load a bed file), or \nFiltered by region\n (e.g. chr9:133710831-133763062, or more regions separated by |).\nKeep the default selection for this tutorial.\n\n\nSpecify the base and mapping quality cutoff; choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20 reads, # of reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note: you should lower the coverage cutoff if you are using the subset (10%) tutorial dataset.\n\n\nIn the \nAdvanced\n tab, user can adjust quality by neighbours at each position, check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the next step) at this step. Users can also adjust \nScore cutoff\n and \nmaximal ratio\n for the SNP calls.\n\n\nAlso, Omicsoft provides the options to generate VCF files (both merged VCF and individual VCF files). Those generated VCF files can be used for futher annotation by Array Studio or other tools.  \n\n\n\n\nLeave all settings as their defaults and click \nSubmit\n to run the module. The output is a mutation2Snp report table listed under \nTable\n in solution explorer:\n\n\n\n\nIn the mutation2Snp report table, there are four columns for each sample:\n\n\n\n\n\n\nMutationFrequency\n;\n\n\n\n\n\n\nCoverage\n at this genomic location;\n\n\n\n\n\n\nPercentage of mutation detected on the \nplus strand\n (MutationReadOnPlus/MutationReadTotal).\n\n\n\n\n\n\nGenotype\n for this mutation allele.\n\n\n\n\n\n\nIf there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.\n\n\n\n\nThe variants are then annotated with gene coding information, known SNPs and functional prediction databases.\n\n\nOpen \nNGS | Variation | Annotate Variant Table Report\n module; choose the mutation2Snp report in \nData\n, OmicsoftGene20130723 as gene model in \nGene model\n. Leave all settings as their defaults in this tab. The first time the user specifies a reference/gene model, it will download files from Omicsoft.\n\n\n\n\nIn the \nAnnotation Sources\n and \nAdditional Sources\n tab, user can specify more annotation sources such as functional prediction and COSMIC annotation, or custom mutation annotators built using \nNGS | Build Mutation Annotator\n.\n\n\nUser also has the option to write the annotated mutation result directly to a text file.\n\n\n\n\nLeave all settings as their defaults and click \nSubmit\n to run the module. The output is a \nMutationAnnotation\n report table listed under \nTable\n in solution explorer:\n\n\n\n\nBesides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the \nAnnotation Sources\n prior to running the analysis. Using the \nView Controller\n, choose filters to focus on items of interest.\n\n\n\n\nGenerate VCF files + Annotated VCF files\n\u00b6\n\n\nWith \nSummarize Variant Data\n, user can choose to export VCF file on both merged file and individual file for further analysis.\n\n\nThe user can specify to generate a VCF for each observation or generate a merged VCF file under \nAdvanced\n tab. Also the user can change the output result folder by providing a directory path to the option \nOutput folder\n.\n\n\n\n\nLeave the options as defaults, and click \nSubmit\n. Both individual VCF files and a merged VCF file would be generated in specified output folder:\n\n\n\n\nNext, the user might want to further annotate the VCF variation. This can be accomplished by using \nNGS | Variation | Annotate Variant Files(VCF/BED/GTT/RS_ID)\n module.\n\n\nHere, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the \nAnnotation Source\n Tab, users can choose extra annotator to further annotate VCF file.\n\n\n\n\nLeave all other settings as-is, choosing to extract genotype only, and click \nSubmit\n to continue. A new table is output to the Solution Explorer.\n\n\n\n\nEach gene that shows variation in the mutation report is returned in the resulting table, along with further annotation for that gene, including any known dbSNPs at that position, annotation type, amino acid position (if AA change), AA Change, transcript ID, transcript name, transcript strand, and distance to 5'/3' ends and closest exon boundary.\n\n\n\n\nSummarize/Annotate Matched Pair Variation\n\u00b6\n\n\nSummarize Matched Pair Variation Data\n is implemented based on the principle of VarScan2, so the options are the same as in VarScan2, including a few pileup and filtering options.\n\n\nThe module requires a matched normal sample during the analysis. The module was initially designed to detect somatic mutation in tumor comparing to matched normal samples. It can also be applied to detect mutation in other cases, such as comparing induced pluripotent stem cells (iPSC) vs. somatic cells. To incorporate the sample information, user has to prepare a design table and import for \nNgsData\n. Double click the \nTable\n under \nDesign\n to show design table. To import new design table, right click on the \nDesign\n Folder under \nNgsData\n and choose \nImport\n:\n\n\n\n\nThe design file for this tutorial is located in the downloaded zip file. Once a design file (usually it is a tab delimited file) is selected and imported, user can choose to replace or append to existing design table:\n\n\n\n\nClick \nOK\n , the design table is imported.\n\n\n\n\nIn this tutorial,\nonly SRR097848 and SRR097849 are paired: SRR097849 is from breast cancer cell line MCF7 while SRR097848 is from non-tumor breast cell line MCF10A. Left click and select two NGS samples:\n\n\n\n\nBoth sample IDs will be highlighted; then open \nNGS | Variation | Summarize Matched Pair Variation Data\n module:\n\n\n\n\nChoose the NGS data, change the \nObservations\n to \nSelected observations\n only. The analysis will use two NGS samples selected in the design table.\n\n\nSpecify the \nPair\n based on \nTissue\n column (Breast for both),\n\nTumor\n \nstatus\n based on \ncell type\n column, and choose \nNon-tumor epithelium cell lines\n factor level to be \nNormal\n. There are more pileup, variation calling and filtering options in the \nAdvanced\n tab.\n\n\nLeave all settings as their defaults and click \nSubmit\n to run the module. The output is a matched pair variation (MPV) report table listed under \nTable\n in solution explorer:\n\n\n\n\nIn the MPV report table, there are ten columns for each sample:\n\n\n\n\n\n\nMinor allele \nMutationFrequency\n in normal\n\n\n\n\n\n\nCoverage\n in normal\n\n\n\n\n\n\nMinor allele \nMutationFrequency\n in tumor\n\n\n\n\n\n\nCoverage\n in tumor\n\n\n\n\n\n\nSomatic P value\n for somatic or LOH events\n\n\n\n\n\n\nVariant P value\n from testing whether the variant allele exists in at least one of the (two) samples\n\n\n\n\n\n\nFilters\n for the status of mutation calling, such as strandness and mapping quality difference\n\n\n\n\n\n\nSomatic status \ncall\n (Germline, Somatic, LOH, or Unknown)\n\n\n\n\n\n\nPredicted genotype in normal\n\n\n\n\n\n\nPredicted genotype in tumor\n\n\n\n\n\n\nIf there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with basic annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion).\n\n\n\n\nIn this tutorial, we only analyzed one pair of samples. If multiple pairs are analyzed in the same run, the whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency,\neven 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.\n\n\nAs with the mutation table, the MPV table can also be annotated by \nNGS | Variation | Annotate Variant Table Report\n module. Open the module; choose the MPV mutation report in \nData\n, UCSC gene model in \nGene model\n, v137 in \nDBSNP version\n. The user also needs to select the data columns in the mutation report; however Array Studio should in most cases select them automatically. Users can also specify an \nOutput name\n such as MPV?.\n\n\n\n\nLeave all other settings as-is and click \nSubmit\n to continue. An annotated MPV mutation table with the name specified (MPV) is output to the Solution Explorer:\n\n\n\n\nBesides the columns in MPV mutation table, there are following annotation columns: gene/transcript name, dbSNP name, mutation type, mutation position in the open reading frame, amino acid position and change in the transcript, distance to 5', 3' of the transcript and to the closest exon boundary. Annotation columns from functional prediction and COSMIC are also attached if these options are checked in the \nAdvanced\n tab.",
            "title": "Variant Detection"
        },
        {
            "location": "/tutorials/DNASeq/DNA-SeqMutation_Detection/#dna-seq-mutation-detection",
            "text": "Mutation data can be generated from DNA-Seq data.\nThis allows the user to compare frequencies of mutation, for individual sites, between groups of samples. All mutation functions can be found in  NGS | Variation .   In this tutorial, we will cover three mutation detection workflows:   Summarize Variant Data + Annotated Variant Report  Generate VCF files + Annotated VCF files  Summarize Matched Pair Variation Data + Annotated Mutation/SNP Report   User can find the documentation for other functions by clicking the  Help  button in each function menu.",
            "title": "DNA-Seq Mutation Detection"
        },
        {
            "location": "/tutorials/DNASeq/DNA-SeqMutation_Detection/#summarizeannotate-variant",
            "text": "Summarize Variant Data  is developed by OmicSoft.\nVariant (Mutations and SNPs) are reported based on the pileup data from alignment data ( NgsData ).   Choose the NGS data. In the reference section, all references are selected by default.\nUser can select a list of regions to summarize mutations. Selections can be on  Gene list  (a list of gene symbols from project lists),  Customized regions  (load a bed file), or  Filtered by region  (e.g. chr9:133710831-133763062, or more regions separated by |).\nKeep the default selection for this tutorial.  Specify the base and mapping quality cutoff; choose the minimal coverage and mutation options. By default, the module only counts a mutation if the coverage >= 20 reads, # of reads supporting the minor allele >= 5 and the minor allele read frequency >= 5%. Note: you should lower the coverage cutoff if you are using the subset (10%) tutorial dataset.  In the  Advanced  tab, user can adjust quality by neighbours at each position, check more output options and ask the module to add dbSNP information (dbSNP annotation can also be added in the next step) at this step. Users can also adjust  Score cutoff  and  maximal ratio  for the SNP calls.  Also, Omicsoft provides the options to generate VCF files (both merged VCF and individual VCF files). Those generated VCF files can be used for futher annotation by Array Studio or other tools.     Leave all settings as their defaults and click  Submit  to run the module. The output is a mutation2Snp report table listed under  Table  in solution explorer:   In the mutation2Snp report table, there are four columns for each sample:    MutationFrequency ;    Coverage  at this genomic location;    Percentage of mutation detected on the  plus strand  (MutationReadOnPlus/MutationReadTotal).    Genotype  for this mutation allele.    If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion). The whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency, even 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.   The variants are then annotated with gene coding information, known SNPs and functional prediction databases.  Open  NGS | Variation | Annotate Variant Table Report  module; choose the mutation2Snp report in  Data , OmicsoftGene20130723 as gene model in  Gene model . Leave all settings as their defaults in this tab. The first time the user specifies a reference/gene model, it will download files from Omicsoft.   In the  Annotation Sources  and  Additional Sources  tab, user can specify more annotation sources such as functional prediction and COSMIC annotation, or custom mutation annotators built using  NGS | Build Mutation Annotator .  User also has the option to write the annotated mutation result directly to a text file.   Leave all settings as their defaults and click  Submit  to run the module. The output is a  MutationAnnotation  report table listed under  Table  in solution explorer:   Besides the columns for each sample (mutation frequency, coverage, PlusStrand%, and Genotype) in mutation annotation table, there are a number of annotation columns: Dbsnp ID, Dbsnp Category, Gene name/Transcript ID, Type, Location, Consequence, mutation position in the open reading frame (Position On Cds), AAMutation and RS ID. In addition, there are columns that correspond to the annotations chosen in the  Annotation Sources  prior to running the analysis. Using the  View Controller , choose filters to focus on items of interest.",
            "title": "Summarize/Annotate Variant"
        },
        {
            "location": "/tutorials/DNASeq/DNA-SeqMutation_Detection/#generate-vcf-files-annotated-vcf-files",
            "text": "With  Summarize Variant Data , user can choose to export VCF file on both merged file and individual file for further analysis.  The user can specify to generate a VCF for each observation or generate a merged VCF file under  Advanced  tab. Also the user can change the output result folder by providing a directory path to the option  Output folder .   Leave the options as defaults, and click  Submit . Both individual VCF files and a merged VCF file would be generated in specified output folder:   Next, the user might want to further annotate the VCF variation. This can be accomplished by using  NGS | Variation | Annotate Variant Files(VCF/BED/GTT/RS_ID)  module.  Here, users need to specify the VCF file location, note that only merged VCF file is supported. Users need to specify the Reference and Gene model in the General Tab. And in the  Annotation Source  Tab, users can choose extra annotator to further annotate VCF file.   Leave all other settings as-is, choosing to extract genotype only, and click  Submit  to continue. A new table is output to the Solution Explorer.   Each gene that shows variation in the mutation report is returned in the resulting table, along with further annotation for that gene, including any known dbSNPs at that position, annotation type, amino acid position (if AA change), AA Change, transcript ID, transcript name, transcript strand, and distance to 5'/3' ends and closest exon boundary.",
            "title": "Generate VCF files + Annotated VCF files"
        },
        {
            "location": "/tutorials/DNASeq/DNA-SeqMutation_Detection/#summarizeannotate-matched-pair-variation",
            "text": "Summarize Matched Pair Variation Data  is implemented based on the principle of VarScan2, so the options are the same as in VarScan2, including a few pileup and filtering options.  The module requires a matched normal sample during the analysis. The module was initially designed to detect somatic mutation in tumor comparing to matched normal samples. It can also be applied to detect mutation in other cases, such as comparing induced pluripotent stem cells (iPSC) vs. somatic cells. To incorporate the sample information, user has to prepare a design table and import for  NgsData . Double click the  Table  under  Design  to show design table. To import new design table, right click on the  Design  Folder under  NgsData  and choose  Import :   The design file for this tutorial is located in the downloaded zip file. Once a design file (usually it is a tab delimited file) is selected and imported, user can choose to replace or append to existing design table:   Click  OK  , the design table is imported.   In this tutorial,\nonly SRR097848 and SRR097849 are paired: SRR097849 is from breast cancer cell line MCF7 while SRR097848 is from non-tumor breast cell line MCF10A. Left click and select two NGS samples:   Both sample IDs will be highlighted; then open  NGS | Variation | Summarize Matched Pair Variation Data  module:   Choose the NGS data, change the  Observations  to  Selected observations  only. The analysis will use two NGS samples selected in the design table.  Specify the  Pair  based on  Tissue  column (Breast for both), Tumor   status  based on  cell type  column, and choose  Non-tumor epithelium cell lines  factor level to be  Normal . There are more pileup, variation calling and filtering options in the  Advanced  tab.  Leave all settings as their defaults and click  Submit  to run the module. The output is a matched pair variation (MPV) report table listed under  Table  in solution explorer:   In the MPV report table, there are ten columns for each sample:    Minor allele  MutationFrequency  in normal    Coverage  in normal    Minor allele  MutationFrequency  in tumor    Coverage  in tumor    Somatic P value  for somatic or LOH events    Variant P value  from testing whether the variant allele exists in at least one of the (two) samples    Filters  for the status of mutation calling, such as strandness and mapping quality difference    Somatic status  call  (Germline, Somatic, LOH, or Unknown)    Predicted genotype in normal    Predicted genotype in tumor    If there are multiple minor alleles at the same location with frequency >= cutoff, they will be reported as different rows. The report comes complete with basic annotation for each site, including chromosome, position, and reference nucleotide, mutation (either a change in sequence or insertion/deletion).   In this tutorial, we only analyzed one pair of samples. If multiple pairs are analyzed in the same run, the whole table is a merged report from multiple samples grouping by mutation site (location + type) in rows. The mutation will be reported if at least one sample contains it with read frequency >= cutoff. The mutation read frequency,\neven 0%, and coverage in other samples will be also reported. Dots in the table are missing values, indicating that the coverage at this position in that sample is less than cutoff.  As with the mutation table, the MPV table can also be annotated by  NGS | Variation | Annotate Variant Table Report  module. Open the module; choose the MPV mutation report in  Data , UCSC gene model in  Gene model , v137 in  DBSNP version . The user also needs to select the data columns in the mutation report; however Array Studio should in most cases select them automatically. Users can also specify an  Output name  such as MPV?.   Leave all other settings as-is and click  Submit  to continue. An annotated MPV mutation table with the name specified (MPV) is output to the Solution Explorer:   Besides the columns in MPV mutation table, there are following annotation columns: gene/transcript name, dbSNP name, mutation type, mutation position in the open reading frame, amino acid position and change in the transcript, distance to 5', 3' of the transcript and to the closest exon boundary. Annotation columns from functional prediction and COSMIC are also attached if these options are checked in the  Advanced  tab.",
            "title": "Summarize/Annotate Matched Pair Variation"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/",
            "text": "DNA-Seq Copy Number Analysis\n\u00b6\n\n\nDNA-Seq Copy number analysis requires a matched normal sample during the analysis. The module was initially designed to detect copy number changes in tumor comparing to matched normal samples from Exon captured DNA-Seq data.\n\n\nThere are two steps in copy number analysis:\n\nSummarize Copy Number (Whole Exome Sequencing or Target Sequencing)\n and \nSegment Copy Number\n :\n\n\n\n\nSummarize Copy Number\n\u00b6\n\n\nCheck that the two samples are still selected in the \nNgsData Design Table\n .\n\n\n\n\nSummarize Copy Number\n will summarize the copy number log2ratio between two samples. In \nSummarize Copy Number\n, choose the NGS data, choose the \nObservations\n to \nSelected observations\n only. The analysis will use two NGS samples selected in the design table. If user does not follow  the instruction for Observations option in this tutorial data, there will be an error: Observation number cannot be divided by two (expecting matched pairs).\n\n\n\n\nSpecify the \nPair\n based on \nTissue\n column (Breast for both),\n\nTumor status\n based on \ncell type\n column, and choose \nNon-tumor epithelium cell lines\n factor level to be \nNormal\n. There are more pileup and copy number options in the \nAdvanced\n tab.\n\n\nLeave all other settings as their defaults and click \nSubmit\n to run the module. The output is a \ncopy number report\n table listed under \nTable\n in solution explorer:\n\n\n\n\nThe report contains observation ID, copy number log2Ratio, predicted copy number (normally having 2 copies in human), coverage in tumor and normal sample, and genomic bin start/end.\n\n\n\n\nAs shown in the GUI, user can also select a base line sample to be a common control and summarize copy number by comparing every other sample to the same control. Users can sort data by Log2 Ratio or Copy Number to find some regions with significant differences in copy number. Right-click the rowID of a CNV to visualize the pileup in the Genome Browser.\n\n\nSegment Copy Number\n\u00b6\n\n\nThe CNV Segmentation command will generate segmentation results for Log2Ratio copy number Data. The contiguous small segments/regions are processed and joined by a segmentation algorithm (similar to circular binary segmentation).\n\n\nIn \nNGS | Copy Number | Segment Copy Number\n , choose the \nCopyNumberReport\n data.\n\n\n\n\nLeave all other settings as their defaults and click \nSubmit\n to run the module. The output is a \nsegment report\n table listed under \nTable | Segment\n in solution explorer:\n\n\n\n\nBy default, there are \ntable\n, \nscatter\n, \nSegment\n and \nSegmentChromosome\n views for the report. Open the \nSegmentChromosome\n view and click on any segment to show details.",
            "title": "Copy Number Analysis"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#dna-seq-copy-number-analysis",
            "text": "DNA-Seq Copy number analysis requires a matched normal sample during the analysis. The module was initially designed to detect copy number changes in tumor comparing to matched normal samples from Exon captured DNA-Seq data.  There are two steps in copy number analysis: Summarize Copy Number (Whole Exome Sequencing or Target Sequencing)  and  Segment Copy Number  :",
            "title": "DNA-Seq Copy Number Analysis"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#summarize-copy-number",
            "text": "Check that the two samples are still selected in the  NgsData Design Table  .   Summarize Copy Number  will summarize the copy number log2ratio between two samples. In  Summarize Copy Number , choose the NGS data, choose the  Observations  to  Selected observations  only. The analysis will use two NGS samples selected in the design table. If user does not follow  the instruction for Observations option in this tutorial data, there will be an error: Observation number cannot be divided by two (expecting matched pairs).   Specify the  Pair  based on  Tissue  column (Breast for both), Tumor status  based on  cell type  column, and choose  Non-tumor epithelium cell lines  factor level to be  Normal . There are more pileup and copy number options in the  Advanced  tab.  Leave all other settings as their defaults and click  Submit  to run the module. The output is a  copy number report  table listed under  Table  in solution explorer:   The report contains observation ID, copy number log2Ratio, predicted copy number (normally having 2 copies in human), coverage in tumor and normal sample, and genomic bin start/end.   As shown in the GUI, user can also select a base line sample to be a common control and summarize copy number by comparing every other sample to the same control. Users can sort data by Log2 Ratio or Copy Number to find some regions with significant differences in copy number. Right-click the rowID of a CNV to visualize the pileup in the Genome Browser.",
            "title": "Summarize Copy Number"
        },
        {
            "location": "/tutorials/DNASeq/DNA-Seq_Copy_Number_Analysis/#segment-copy-number",
            "text": "The CNV Segmentation command will generate segmentation results for Log2Ratio copy number Data. The contiguous small segments/regions are processed and joined by a segmentation algorithm (similar to circular binary segmentation).  In  NGS | Copy Number | Segment Copy Number  , choose the  CopyNumberReport  data.   Leave all other settings as their defaults and click  Submit  to run the module. The output is a  segment report  table listed under  Table | Segment  in solution explorer:   By default, there are  table ,  scatter ,  Segment  and  SegmentChromosome  views for the report. Open the  SegmentChromosome  view and click on any segment to show details.",
            "title": "Segment Copy Number"
        },
        {
            "location": "/tutorials/DNASeq/Save___Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results. Please refer to the MicroArray tutorial for more details on the \nAudit Trial\n , which records all the analysis steps in for form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft's support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.\n\n\nPlease contact Omicsoft Support (\n \nsupport@omicsoft.com\n \n) or Omicsoft Sales (\n \nsales@omicsoft.com\n \n) if you have any questions questions.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/DNASeq/Save___Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results. Please refer to the MicroArray tutorial for more details on the  Audit Trial  , which records all the analysis steps in for form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of. Feel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do.\nFor additional information, don't hesitate to contact Omicsoft's support team ( support@omicsoft.com ).  Thank you for using Array Studio.  Please contact Omicsoft Support (   support@omicsoft.com   ) or Omicsoft Sales (   sales@omicsoft.com   ) if you have any questions questions.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/miRNAseq/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArrayStudio\n\u00b6\n\n\nArray Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThis tutorial is based on local NGS analysis using a Windows Workstation with\n3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM.\n\n\nIt is highly recommend that the user complete the prerequisite for this tutorial:\n\nthe Microarray tutorial\n, as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software.\nAs many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.\n\n\nTest Dataset\n\u00b6\n\n\nThis miRNA-Seq tutorial will cover the importing and analysis of a published dataset.\nThis dataset was run on the Illumina HiSeq platform.\nWe selected three miRNA-seq files each from involved and uninvolved psoriatic skin, as well as three normal skin samples, for use in this analysis.\nThe full dataset is available from 'SRA SRP007825'.\n\n\nSRA SRP007825: \nhttp://www.ncbi.nlm.nih.gov/sra?term=SRP007825\n\n\n|         Sample Type         |    Accession IDs    |       SRA IDs       |      Run IDs      |\n|:----------------------------|:--------------------|:--------------------|:------------------+\n|         Normal Skin         | GSM768988-GSM768990 | SRX091742-SRX091744 |SRR330904-SRR330906|\n| Uninvolved Psoriatic Skin   | GSM768965-GSM768967 | SRX091719-SRX091721 |SRR330881-SRR330883|\n|  Involved Psoriatic Skin    | GSM768941-GSM768943 | SRX091695-SRX091697 |SRR330857-SRR330859|\n\n\nThese data can be downloaded from the NCBI web site, using SRA toolkit, or directly through Array Studio:\n\n\n\n\nAfter retrieving these data, you can begin the tutorial.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/miRNAseq/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/miRNAseq/Introduction/#arraystudio",
            "text": "Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThis tutorial is based on local NGS analysis using a Windows Workstation with\n3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM.  It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio.\nThis tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software.\nAs many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.",
            "title": "ArrayStudio"
        },
        {
            "location": "/tutorials/miRNAseq/Introduction/#test-dataset",
            "text": "This miRNA-Seq tutorial will cover the importing and analysis of a published dataset.\nThis dataset was run on the Illumina HiSeq platform.\nWe selected three miRNA-seq files each from involved and uninvolved psoriatic skin, as well as three normal skin samples, for use in this analysis.\nThe full dataset is available from 'SRA SRP007825'.  SRA SRP007825:  http://www.ncbi.nlm.nih.gov/sra?term=SRP007825  |         Sample Type         |    Accession IDs    |       SRA IDs       |      Run IDs      |\n|:----------------------------|:--------------------|:--------------------|:------------------+\n|         Normal Skin         | GSM768988-GSM768990 | SRX091742-SRX091744 |SRR330904-SRR330906|\n| Uninvolved Psoriatic Skin   | GSM768965-GSM768967 | SRX091719-SRX091721 |SRR330881-SRR330883|\n|  Involved Psoriatic Skin    | GSM768941-GSM768943 | SRX091695-SRX091697 |SRR330857-SRR330859|  These data can be downloaded from the NCBI web site, using SRA toolkit, or directly through Array Studio:   After retrieving these data, you can begin the tutorial.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/miRNAseq/CreateArray_Studio_Project/",
            "text": "Create Array Studio Project\n\u00b6\n\n\nArray Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results\nas projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server.\nIn this tutorial, we are using local projects. If user has Array Server installed, user can run the tutorial as a server project and analysis steps are almost the same as described in this tutorial.\n\n\nOnce Array Studio has been opened, click \nFile | New Local Project\n from the File Menu (also can be accessed via the \nNew\n button on the toolbar).\n\n\nFor any Next Generation Sequencing datasets, the user should choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset.\n\n\nNote: It is required that the user has approximately 3GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using \nTools Menu | Preferences | Advanced\n.\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location.\n\n\n\n\nClick \nBrowse\n to choose a location to store the data and click \nOK\n to create an empty project:",
            "title": "CreateArray Studio Project"
        },
        {
            "location": "/tutorials/miRNAseq/CreateArray_Studio_Project/#create-array-studio-project",
            "text": "Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results\nas projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server.\nIn this tutorial, we are using local projects. If user has Array Server installed, user can run the tutorial as a server project and analysis steps are almost the same as described in this tutorial.  Once Array Studio has been opened, click  File | New Local Project  from the File Menu (also can be accessed via the  New  button on the toolbar).  For any Next Generation Sequencing datasets, the user should choose the option to create a distributed project. Clicking the Browse button will allow the user to specify the location for the dataset.  Note: It is required that the user has approximately 3GB of available space on their hard drive for this experiment. The general rule of thumb is that the user has 3x the size of the raw data files available for the import of data. The user might also want to specify a different location for the \"Omicsoft Home\" folder using  Tools Menu | Preferences | Advanced .\nThis will place the Omicsoft folder, which is used as storage for any genome reference index and temp files for the process, at a specified user location.   Click  Browse  to choose a location to store the data and click  OK  to create an empty project:",
            "title": "Create Array Studio Project"
        },
        {
            "location": "/tutorials/miRNAseq/workflow_and_pipeline/",
            "text": "miRNA-Seq Analysis Workflow\n\u00b6\n\n\nIn this tutorial, we will introduce the miRNA-Seq data analysis workflow in ArrayStudio, step by step.\nThe workflow consists of a number of modules for miRNA-Seq data processing, including raw data quality control (QC), adapter trimming, alignment, aligned data QC, quantification, and differential expression\n\n\nThis workflow can be followed by the steps listed in the Workflow window:\n\n\n\n\nor by running the individual modules from the menu items.\n\n\nFor convenience, especially for new users, we also have a single-command pipeline that will use default settings to take miRNA-seq data from raw fastq files to mapped, QC'd, and quantified data, which follows the workflow below:\n\n\n\n\n\n\nIn this tutorial, we will go step by step through all the options specified in this pipeline to give users a detailed understanding of each option selected above and how they can impact your study.",
            "title": "workflow and pipeline"
        },
        {
            "location": "/tutorials/miRNAseq/workflow_and_pipeline/#mirna-seq-analysis-workflow",
            "text": "In this tutorial, we will introduce the miRNA-Seq data analysis workflow in ArrayStudio, step by step.\nThe workflow consists of a number of modules for miRNA-Seq data processing, including raw data quality control (QC), adapter trimming, alignment, aligned data QC, quantification, and differential expression  This workflow can be followed by the steps listed in the Workflow window:   or by running the individual modules from the menu items.  For convenience, especially for new users, we also have a single-command pipeline that will use default settings to take miRNA-seq data from raw fastq files to mapped, QC'd, and quantified data, which follows the workflow below:    In this tutorial, we will go step by step through all the options specified in this pipeline to give users a detailed understanding of each option selected above and how they can impact your study.",
            "title": "miRNA-Seq Analysis Workflow"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/",
            "text": "QC of Raw Data Files\n\u00b6\n\n\nThe first step to ensure reliable miRNA-seq results is to check and filter the raw data, to use only high-quality reads.\n\n\nArray Studio contains several modules for QC of raw data files. The easiest way is to run \nRaw Data QC Wizard\n which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position.\n\n\nAdapter detection and trimming\n\u00b6\n\n\nA QC step especially important to miRNA-seq is checking for/stripping adapter sequences.\nBecause miRNAs are ~22 nucleotides long, standard high-throughput sequencing read lengths will read the entire miRNA, as well as the 3' adapter.\nIn the tutorial set, reads are 36 nucleotides long.\nThus, it is important to check that these adapters have been removed before continuing.\nThis module is not included in the \nRaw Data QC Wizard\n, so must be run separately before mapping reads.\n\n\nYou will find the \"Search Adapters\" module under \nNGS | Preprocess | Search Adapters\n\n\n\n\nClick \nAdd\n to add the fastq files for the nine samples.\n\n\n\n\nYou can choose to search for the default set of Illumina adapters, or search for a custom list of FASTA-formatted sequences.\nSpecify the \nJob Number\n as the number of processes to run.\nSpecify \nSampling Percentage\n to change what fraction of your data to sample for adapter sequences. In this dataset, 1% is sufficient to capture adapter sequences.\nBy default, this module searches for matches to adapter sequences at the 3' ends of reads, but does not allow additional bases to the right of the read match.\nTo enable a Smith-Waterman algorithm to identify adapters with additional bases to the right, check \"Search right adapters\".\nIn this sample, no additional adapters will be found by this procedure, so we will leave this option unchecked.\nConfirm that the Zip format is correct, optionally specify the Output name, and click \"Submit\".\n\n\nWhen the analysis is complete, a new table will be available in the Solution Explorer, under \nTable | Preprocessing\n:\n\n\n\n\nThis table contains a list of all identified adapter sequences in each file, along with occurrence count and percentage per-file.\n\n\n\n\nIn these samples, the majority of reads contain an adapter sequence, so this should be stripped before mapping. We will explore this in the next chapter.\n\n\nRaw Data QC Wizard\n\u00b6\n\n\nTo check overall sequence quality, n-mer over-representation, and sequence length, the Raw Data QC Wizard can be run. Alternatively, each module within can be run, enabling additional options.\n\n\nTo run the wizard, click \nNGS | Raw Data QC | Raw Data QC Wizard\n.\n\n\n\n\nClick \nAdd\n to find all 9 files for the  samples, and check the boxes for each QC metric to run. For a quicker analysis, the user can choose \nPreview mode\n to only generate QC on the first one million reads.\nThis is, in most cases, good enough to get an assessment of quality.\nLeave \nQuality encoding\n as \nAutomatic\n to automatically set the correct quality encoding method.\nSpecify \nJob Number\n as the number of processes to run in parallel.\nLeave \nMaximal duplication level\n at the default of \n10\n.\nSpecify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.\n\n\nThen click \nSubmit\n to begin the analysis.\n\n\nThe raw data QC returns multiple raw data QC Views and tables in the \nTable\n Data section, under the \nRaw Data QC\n folder.\n\n\n\n\nIn this screenshot, new subfolders were generated to cluster different QC analyses, by right-clicking the \nRaw Data QC\n folder and selecting \nNew Folder\n.\n\n\n\n\nBasic Statistics\n\u00b6\n\n\nThe basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%.\nUse this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.\nIn this example, you will see that the reads (if untrimmed) are all 36 nucleotides long.\n\n\n\n\nBase distribution QC results are located in the \nRaw Data QC\n folder with name \nBasicStats\n.\nDouble click the table view to open if you do not see basic statistics table in the middle window:\n\n\nBase Distribution\n\u00b6\n\n\nBase distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file).\nBase distribution QC results are located in the \nRaw Data QC\n folder with name \nBaseDistribution\n.\nBy default, the BaseDistribution \nProfileView\n should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer.\n\n\n\n\nIn \nView Controller\n, \nLegend\n section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot.\n\n\nNotice that there are a total of 9 charts (scroll through them to look at each sample), one for each file that was QC d.\n\n\nSelecting points on the chart will also show additional details in the Details Window.\n\n\nOne can also switch to line plot view by going to \nView Controller | Task | Customize | Change To Line Type\n.\n\n\n\n\nRead Quality QC\n\u00b6\n\n\nThe QC results include a \nPerSequenceQuality\n (view and table), a \nQualityBoxPlot\n (view and table) and a \nOverallQualityReport\n (view and table) in the Solution Explorer.\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.\n\n\n\n\nNote that the first two files have far more poor-quality reads than the other files.\n\n\nIn Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown.\nThis gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples.\n\n\n\n\nFrom the \nQualityBoxPlot\n view (shown above), it is clear that the quality of two files drops off earlier than the others. Scroll through each of the 9 charts to see the quality BoxPlots for each individual fastq file.\nSelecting a point on the chart will show additional details in the \nDetails Window\n below the plot.\n\n\nThe Overall Quality Report summarizes the quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.\n\n\n\n\nK-Mer analysis\n\u00b6\n\n\nThe K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.\n\n\n\n\nIn the \nKMerAnalysis\n profile view, Y-axis is the percentage of reads (0.1 means 10%) that contain each KMer. Without filtering, there is significant Kmer enrichment at the ends. For a miRNA-seq experiment, this is expected - in the next step, we will trim and filter reads to clean up the raw read data.",
            "title": "QC of Raw Data Files"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#qc-of-raw-data-files",
            "text": "The first step to ensure reliable miRNA-seq results is to check and filter the raw data, to use only high-quality reads.  Array Studio contains several modules for QC of raw data files. The easiest way is to run  Raw Data QC Wizard  which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis. User can also try each function which has more options to specify, such as adapter stripping and max read position.",
            "title": "QC of Raw Data Files"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#adapter-detection-and-trimming",
            "text": "A QC step especially important to miRNA-seq is checking for/stripping adapter sequences.\nBecause miRNAs are ~22 nucleotides long, standard high-throughput sequencing read lengths will read the entire miRNA, as well as the 3' adapter.\nIn the tutorial set, reads are 36 nucleotides long.\nThus, it is important to check that these adapters have been removed before continuing.\nThis module is not included in the  Raw Data QC Wizard , so must be run separately before mapping reads.  You will find the \"Search Adapters\" module under  NGS | Preprocess | Search Adapters   Click  Add  to add the fastq files for the nine samples.   You can choose to search for the default set of Illumina adapters, or search for a custom list of FASTA-formatted sequences.\nSpecify the  Job Number  as the number of processes to run.\nSpecify  Sampling Percentage  to change what fraction of your data to sample for adapter sequences. In this dataset, 1% is sufficient to capture adapter sequences.\nBy default, this module searches for matches to adapter sequences at the 3' ends of reads, but does not allow additional bases to the right of the read match.\nTo enable a Smith-Waterman algorithm to identify adapters with additional bases to the right, check \"Search right adapters\".\nIn this sample, no additional adapters will be found by this procedure, so we will leave this option unchecked.\nConfirm that the Zip format is correct, optionally specify the Output name, and click \"Submit\".  When the analysis is complete, a new table will be available in the Solution Explorer, under  Table | Preprocessing :   This table contains a list of all identified adapter sequences in each file, along with occurrence count and percentage per-file.   In these samples, the majority of reads contain an adapter sequence, so this should be stripped before mapping. We will explore this in the next chapter.",
            "title": "Adapter detection and trimming"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#raw-data-qc-wizard",
            "text": "To check overall sequence quality, n-mer over-representation, and sequence length, the Raw Data QC Wizard can be run. Alternatively, each module within can be run, enabling additional options.  To run the wizard, click  NGS | Raw Data QC | Raw Data QC Wizard .   Click  Add  to find all 9 files for the  samples, and check the boxes for each QC metric to run. For a quicker analysis, the user can choose  Preview mode  to only generate QC on the first one million reads.\nThis is, in most cases, good enough to get an assessment of quality.\nLeave  Quality encoding  as  Automatic  to automatically set the correct quality encoding method.\nSpecify  Job Number  as the number of processes to run in parallel.\nLeave  Maximal duplication level  at the default of  10 .\nSpecify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.  Then click  Submit  to begin the analysis.  The raw data QC returns multiple raw data QC Views and tables in the  Table  Data section, under the  Raw Data QC  folder.   In this screenshot, new subfolders were generated to cluster different QC analyses, by right-clicking the  Raw Data QC  folder and selecting  New Folder .",
            "title": "Raw Data QC Wizard"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#basic-statistics",
            "text": "The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%.\nUse this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.\nIn this example, you will see that the reads (if untrimmed) are all 36 nucleotides long.   Base distribution QC results are located in the  Raw Data QC  folder with name  BasicStats .\nDouble click the table view to open if you do not see basic statistics table in the middle window:",
            "title": "Basic Statistics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#base-distribution",
            "text": "Base distribution of each raw data file is useful for ensuring that the base distribution is expected (sometimes can be used to notice adapter sequences if the user is not aware that adapter sequences are in the read file).\nBase distribution QC results are located in the  Raw Data QC  folder with name  BaseDistribution .\nBy default, the BaseDistribution  ProfileView  should be shown, but if not, open it by double-clicking the Profile view from the Solution Explorer.   In  View Controller ,  Legend  section shows the color representations of A, G, C, and T. Based on the legend, it is easy to see the percentages of A, G, C, and T for each base pair position from the plot.  Notice that there are a total of 9 charts (scroll through them to look at each sample), one for each file that was QC d.  Selecting points on the chart will also show additional details in the Details Window.  One can also switch to line plot view by going to  View Controller | Task | Customize | Change To Line Type .",
            "title": "Base Distribution"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#read-quality-qc",
            "text": "The QC results include a  PerSequenceQuality  (view and table), a  QualityBoxPlot  (view and table) and a  OverallQualityReport  (view and table) in the Solution Explorer.\nPer Sequence Quality calculates the average quality score for each read and shows the distribution of quality for all reads in each file.   Note that the first two files have far more poor-quality reads than the other files.  In Quality BoxPlot, all reads in a file are overlaid and box plot for each base pair position is shown.\nThis gives the user an idea where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality for multiple samples.   From the  QualityBoxPlot  view (shown above), it is clear that the quality of two files drops off earlier than the others. Scroll through each of the 9 charts to see the quality BoxPlots for each individual fastq file.\nSelecting a point on the chart will show additional details in the  Details Window  below the plot.  The Overall Quality Report summarizes the quality of each base pair. It shows the total number of base pairs in one input file that have a certain quality score.",
            "title": "Read Quality QC"
        },
        {
            "location": "/tutorials/miRNAseq/QC_ofRaw_Data_Files/#k-mer-analysis",
            "text": "The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of kmer on a particular region of the read. It can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.   In the  KMerAnalysis  profile view, Y-axis is the percentage of reads (0.1 means 10%) that contain each KMer. Without filtering, there is significant Kmer enrichment at the ends. For a miRNA-seq experiment, this is expected - in the next step, we will trim and filter reads to clean up the raw read data.",
            "title": "K-Mer analysis"
        },
        {
            "location": "/tutorials/miRNAseq/Filtering_Trimming_Reads/",
            "text": "Filtering And Trimming Raw Reads\n\u00b6\n\n\nIf we look closely at the Kmer pattern from the raw QC report, it is clear that the same sequence is at the 5' and 3' ends, and that these sequences both match the Illumina 3' adapter sequence.\n\n\nIt is likely that reads with the adapter sequence toward the 5' end are simply adapter-dimers. In contrast, reads with adapters at the 3' end, starting ~22-24 nucleotides, are the reads we want to map.\nHowever, the user must strip (remove) the adapters before mapping these reads. This can be performed multiple ways in Array Studio.\n\n\n\n\nTrim the last 36 - 22 = 14 nucleotides (read length - processed miRNA length), which will remove adapters from proper reads.\n\n\nUse the Array Studio Adapter Stripping method to dynamically detect and remove substrings matching adapter sequences.\n\n\n\n\nRegardless of which technique is used, we can also filter out reads that are comprised entirely of adapter sequences,\nor match common NGS contaminants such as rRNA and tRNA.\n\n\nTo filter and strip the raw reads, open the Filtering module by clicking \nNGS | Preprocess | Filter\n:\n\n\n\n\nThis will open a window with multiple methods for stripping, trimming, and filtering our reads:\n\n\n\n\nClick \nAdd\n to find all 9 files for the samples, then select filtering options:\n\n\n\n\nFilter by read length (\nset to <20 in this case\n)\n\n\nPer-read quality scores\n\n\nAbnormally high single-nucleotide frequency\n\n\nPaired-end quality filtering (tutorial reads are not paired, so this option is not used)\n\n\n\n\nIf the user wants to generate a new set of fastq files containing filtered/trimmed reads,\nspecify the full path to the output folder.\n\n\nAlternatively, the user can choose \"Generate flag files only\",\nwhich will generate a flat file with filter status for reads in each file, instead of generating new fastq files.\n\n\nHowever, \"Generate flag files only\" is overridden if adapter stripping is enabled.\n\n\nTo perform adapter stripping or trimming, the user should click on the \nAdvanced\n tab,\nrevealing several additional options:\n\n\n\n\nTo trim reads to 22 nucleotides, select the \nAdvanced trimming\n radio button, and click the \nCustomize\n button:\n\n\n\n\nAlternatively, to dynamically strip away 3' adapter sequences, Click \nCustomize\n in the Adapter Stripping section,\nthen change the radio button to \nStrip 3' end adapters\n:\n\n\n\n\nEnter in the sequence \nATCTCGTATGCCGTCTTCTGCTTG\n, which was found in the miRNA \nadapter search\n module (or you can copy-paste from this document).\nThis sequence matches the 3' adapter used by the study authors.\nIf multiple adapter sequences were found by the \nadapter search\n module, they could also be entered as a list in \nStrip multiple 3' end adapters\n.\n\n\nAn additional option within \nAdapter Stripping\n is \nTrim reads first\n.\n\n\nTrim reads first\n controls the Order of Operations for Trimming and Stripping.\nFor example, if reads were 3' barcoded  such that the read was miRNA-Barcode-Adapter,\nsetting \nTrim reads first\n to false would allow stripping of the adapter, followed by removal of the barcoded portion.\n\n\nThe final set of \nAdvanced Options\n is \nFilter By Source\n, where common contaminant sequences can be automatically removed.\nBy default, several sets of sequences are included (e.g. adapters, rRNA, tRNA), but additional sequences can be also included as a FASTA file.\n\n\nFor this tutorial, we will take a simple approach to sequencing trimming:\nWe will trim to 22 nucleotides (i.e. select \nTrim Reads First\n under \nAdapter Stripping\n),\nthen strip any 3' nucleotides exactly matching 3' adapters,\nthen filter reads that are <20 nucleotides or match known adapter sequences,\nand save fastq files to a new folder.\n\n\nRe-running \nRaw Data QC\n will reveal that the reads are now all trimmed to 22 nucleotides,\nand the frequency of kmers has been significantly reduced (notice the Y-axis scale).\n\n\n\n\nWe can now move on to mapping the reads to the genome.",
            "title": "Filtering Trimming Reads"
        },
        {
            "location": "/tutorials/miRNAseq/Filtering_Trimming_Reads/#filtering-and-trimming-raw-reads",
            "text": "If we look closely at the Kmer pattern from the raw QC report, it is clear that the same sequence is at the 5' and 3' ends, and that these sequences both match the Illumina 3' adapter sequence.  It is likely that reads with the adapter sequence toward the 5' end are simply adapter-dimers. In contrast, reads with adapters at the 3' end, starting ~22-24 nucleotides, are the reads we want to map.\nHowever, the user must strip (remove) the adapters before mapping these reads. This can be performed multiple ways in Array Studio.   Trim the last 36 - 22 = 14 nucleotides (read length - processed miRNA length), which will remove adapters from proper reads.  Use the Array Studio Adapter Stripping method to dynamically detect and remove substrings matching adapter sequences.   Regardless of which technique is used, we can also filter out reads that are comprised entirely of adapter sequences,\nor match common NGS contaminants such as rRNA and tRNA.  To filter and strip the raw reads, open the Filtering module by clicking  NGS | Preprocess | Filter :   This will open a window with multiple methods for stripping, trimming, and filtering our reads:   Click  Add  to find all 9 files for the samples, then select filtering options:   Filter by read length ( set to <20 in this case )  Per-read quality scores  Abnormally high single-nucleotide frequency  Paired-end quality filtering (tutorial reads are not paired, so this option is not used)   If the user wants to generate a new set of fastq files containing filtered/trimmed reads,\nspecify the full path to the output folder.  Alternatively, the user can choose \"Generate flag files only\",\nwhich will generate a flat file with filter status for reads in each file, instead of generating new fastq files.  However, \"Generate flag files only\" is overridden if adapter stripping is enabled.  To perform adapter stripping or trimming, the user should click on the  Advanced  tab,\nrevealing several additional options:   To trim reads to 22 nucleotides, select the  Advanced trimming  radio button, and click the  Customize  button:   Alternatively, to dynamically strip away 3' adapter sequences, Click  Customize  in the Adapter Stripping section,\nthen change the radio button to  Strip 3' end adapters :   Enter in the sequence  ATCTCGTATGCCGTCTTCTGCTTG , which was found in the miRNA  adapter search  module (or you can copy-paste from this document).\nThis sequence matches the 3' adapter used by the study authors.\nIf multiple adapter sequences were found by the  adapter search  module, they could also be entered as a list in  Strip multiple 3' end adapters .  An additional option within  Adapter Stripping  is  Trim reads first .  Trim reads first  controls the Order of Operations for Trimming and Stripping.\nFor example, if reads were 3' barcoded  such that the read was miRNA-Barcode-Adapter,\nsetting  Trim reads first  to false would allow stripping of the adapter, followed by removal of the barcoded portion.  The final set of  Advanced Options  is  Filter By Source , where common contaminant sequences can be automatically removed.\nBy default, several sets of sequences are included (e.g. adapters, rRNA, tRNA), but additional sequences can be also included as a FASTA file.  For this tutorial, we will take a simple approach to sequencing trimming:\nWe will trim to 22 nucleotides (i.e. select  Trim Reads First  under  Adapter Stripping ),\nthen strip any 3' nucleotides exactly matching 3' adapters,\nthen filter reads that are <20 nucleotides or match known adapter sequences,\nand save fastq files to a new folder.  Re-running  Raw Data QC  will reveal that the reads are now all trimmed to 22 nucleotides,\nand the frequency of kmers has been significantly reduced (notice the Y-axis scale).   We can now move on to mapping the reads to the genome.",
            "title": "Filtering And Trimming Raw Reads"
        },
        {
            "location": "/tutorials/miRNAseq/Alignment_to_the_Genome/",
            "text": "Alignment to the Genome\n\u00b6\n\n\nAfter QC and filtering raw reads, the next step in most miRNA-Seq analysis is the alignment of the reads to the genome.\n\n\nPlease go to the \nAdd Data\n dropdown menu on the toolbar, then choose \nAdd NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina)\n.\n\n\n\n\nAt this point, the Map miRNA-Seq Reads to Genome module appears.\n\n\n\n\nFirst click the \nAdd\n button to specify the location of the filtered fastq files from the previous section.\n\n\nNote that these files are in .gz format.\nThe alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files.\n\n\nChoose the \nGenome\n for the experiment. In this analysis, we will use \nHuman.hg38\n.\nChoose the \nGene model\n. We will use miRBase.R21. In general for miRNA-seq, results will be much more successful when mapping exclusively to known miRNAs.\n\n\n\n\nNote\n\n\nIf your goal is miRNA discovery, there are several specialized tools for this purpose, such as miRDeep2.\n\n\n\n\n\n\nLeave the \nquality encoding\n set to automatic. However for your information, these files were encoded using the Sanger quality scoring system.\n\n\nAdapter Stripping\n allows trimming (under \nAdvanced\n) and adapter-stripping of reads.\nSince we have already trimmed and stripped the tutorial reads, there is no need to do it again here.\n\n\nIn \nPerformance and Reporting\n,\n\nTotal penalty\n should be left as automatic, and is described completely in Omicsoft's white paper on alignment.\n\n\nThread number\n indicates the number of threads to use per alignment, and usually this number should be less than 6.\nJob number refers to the number of parallel jobs (independent processes).\n\n\nNon-unique mapping\n indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together.\n\n\nOnly BAM files will be output.\nIf users also want SAM files, there is a tool (\nNGS | Tools | Convert Files\n) in ArrayStudio to generate SAM files from BAM files.\n\n\nOutput folder\n is the place if one wants to explicitly specify a location to store the alignment BAM files.\nOtherwise the bam files will be saved in a default location (a random number/letter folder in the project folder).\nIn this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step.\n\n\nThere are a few options in the \nAdvanced\n Tab.\nIn general the default values have been tuned and should work well in most cases.\n\n\n\n\nLeave the \nExclude unmapped reads\n \nunchecked\n, so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped).\nThe generated BAM files (which contain mapped and unmapped reads) can be directly used as input for subsequent steps.\n\n\nClick \nSubmit\n to start mapping.\n\n\nThe mapping stage could take anywhere from several minutes to over an hour, depending on the number of threads, type of computer (64-bit/32-bit), etc.\n\n\nAfter the alignment, you will see a NgsData object with an alignment report table (1) and design table (2) in the solution explorer,\n\n\n\n\nand BAM files as well as alignment report summary files in the specified output folder.\n\n\n\n\nTo help downstream analysis, we will add grouping columns to the design table.\n\n\nFirst, double-click the new NGS data \nDesign table\n in the \nSolution Explorer\n to view the \nDesign Table\n in Array Studio.\nNext, click either the (1) \nOpen as Text\n or (2) \nOpen as Excel\n buttons:\n\n\n\n\nTo the design table, add a column named \nGroup\n, then enter group labels \"Normal\", \"Psoriatic_Uninvolved\", and \"Psoriatic_Involved\" as follows:\n\n\n\n\nSRX091742-SRX091744\n are \nNormal\n\n\nSRX091719-SRX091721\n are \nPsoriatic_Uninvolved\n\n\nSRX091695-SRX091697\n are \nPsoriatic_Involved\n\n\n\n\nYou may add additional columns if you like, such as the StudyID, source organism, etc.\n\n\nSave the file as a tab-delimited file, named \"Design.txt\", in the same folder as your .BAM files.\n\n\nThen, right click on the \nDesign\n folder for the NgsData, and select \nImport | Tab delimited file\n:\n\n\n\n\nNavigate to \"Design.txt\". Two options for importing will be offered:\n\n\n\n\nAppend to the existing covariate table\n: checking this option will append the selected design file contents to the existing design table, using the first column to match rows.\n\n\nUse the name order in the new covariate table\n: checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table.\n\n\nThese two options should be left unchecked for this tutorial (as we will just over-write the design table).\n\n\nNow save your project, then we can quantify reads mapped to each known miRNA and identify differentially-expressed miRNAs.",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/miRNAseq/Alignment_to_the_Genome/#alignment-to-the-genome",
            "text": "After QC and filtering raw reads, the next step in most miRNA-Seq analysis is the alignment of the reads to the genome.  Please go to the  Add Data  dropdown menu on the toolbar, then choose  Add NGS Data | Add RNA-Seq Data | Map Reads to Genome (Illumina) .   At this point, the Map miRNA-Seq Reads to Genome module appears.   First click the  Add  button to specify the location of the filtered fastq files from the previous section.  Note that these files are in .gz format.\nThe alignment process takes this into account and supporting .gz format is an effective way to save some space when importing files, as there is no need to extract all files.  Choose the  Genome  for the experiment. In this analysis, we will use  Human.hg38 .\nChoose the  Gene model . We will use miRBase.R21. In general for miRNA-seq, results will be much more successful when mapping exclusively to known miRNAs.   Note  If your goal is miRNA discovery, there are several specialized tools for this purpose, such as miRDeep2.    Leave the  quality encoding  set to automatic. However for your information, these files were encoded using the Sanger quality scoring system.  Adapter Stripping  allows trimming (under  Advanced ) and adapter-stripping of reads.\nSince we have already trimmed and stripped the tutorial reads, there is no need to do it again here.  In  Performance and Reporting , Total penalty  should be left as automatic, and is described completely in Omicsoft's white paper on alignment.  Thread number  indicates the number of threads to use per alignment, and usually this number should be less than 6.\nJob number refers to the number of parallel jobs (independent processes).  Non-unique mapping  indicates how many \"ties\" for non-unique reads should be reported, or whether they should be excluded all together.  Only BAM files will be output.\nIf users also want SAM files, there is a tool ( NGS | Tools | Convert Files ) in ArrayStudio to generate SAM files from BAM files.  Output folder  is the place if one wants to explicitly specify a location to store the alignment BAM files.\nOtherwise the bam files will be saved in a default location (a random number/letter folder in the project folder).\nIn this tutorial, it is recommended to specify a folder so that BAM files can be found easily in next step.  There are a few options in the  Advanced  Tab.\nIn general the default values have been tuned and should work well in most cases.   Leave the  Exclude unmapped reads   unchecked , so that the generated BAM file will contain the information for all the reads (i.e. mapped and unmapped).\nThe generated BAM files (which contain mapped and unmapped reads) can be directly used as input for subsequent steps.  Click  Submit  to start mapping.  The mapping stage could take anywhere from several minutes to over an hour, depending on the number of threads, type of computer (64-bit/32-bit), etc.  After the alignment, you will see a NgsData object with an alignment report table (1) and design table (2) in the solution explorer,   and BAM files as well as alignment report summary files in the specified output folder.   To help downstream analysis, we will add grouping columns to the design table.  First, double-click the new NGS data  Design table  in the  Solution Explorer  to view the  Design Table  in Array Studio.\nNext, click either the (1)  Open as Text  or (2)  Open as Excel  buttons:   To the design table, add a column named  Group , then enter group labels \"Normal\", \"Psoriatic_Uninvolved\", and \"Psoriatic_Involved\" as follows:   SRX091742-SRX091744  are  Normal  SRX091719-SRX091721  are  Psoriatic_Uninvolved  SRX091695-SRX091697  are  Psoriatic_Involved   You may add additional columns if you like, such as the StudyID, source organism, etc.  Save the file as a tab-delimited file, named \"Design.txt\", in the same folder as your .BAM files.  Then, right click on the  Design  folder for the NgsData, and select  Import | Tab delimited file :   Navigate to \"Design.txt\". Two options for importing will be offered:   Append to the existing covariate table : checking this option will append the selected design file contents to the existing design table, using the first column to match rows.  Use the name order in the new covariate table : checking this option will use the name orders in the selected design file, instead of using the name orders in the existing design table.  These two options should be left unchecked for this tutorial (as we will just over-write the design table).  Now save your project, then we can quantify reads mapped to each known miRNA and identify differentially-expressed miRNAs.",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/",
            "text": "QC of Aligned Data\n\u00b6\n\n\nAlignment Report\n\u00b6\n\n\nBy default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the \nAlignmentReport\n table.\n\n\n\n\nThis will show, for each file, some statistics regarding mapping. One of the key statistics is the uniquely mapped reads.\n\n\nmiRNA-Seq Aligned QC\n\u00b6\n\n\nTo get more detailed statistics of mapping rate, the RNA-Seq QC metrics can be used:\n\n\n\n\nThis module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files.\nThese metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table.\nIt also generates a \nProfileView\n showing a chart for each metric.\n\n\nTo run the RNA-Seq QC module, go to \nNGS | Aligned Data QC | RNA-Seq QC Metrics\n now.\n\n\n\n\nChoose the NGS data object and leave all other settings as their defaults and click \nSubmit\n to run the module.\n\n\nSource\n metric is based on the provided gene model.\nIt provides the most information with gene models like Ensembl that have detailed information for the source of each transcript.\nHere, we will use the same gene model as with mapping (\nmiRBase.R21\n).\n\n\nThe analysis returns a \nTable\n View of QC metrics and \nProfile\n view in the \nAligned Data QC\n folder:\n\n\nIn the \nTable\n view, you will find the following sections:\n\n\nAlignment Metrics\n\u00b6\n\n\nThese metrics can be used to give an overall idea of the quality of the alignment for your samples.\n\n\n\n\n\n\nCoverage Metrics\n\u00b6\n\n\nThe coverage metrics give you an overall idea of the mean coverage of your experiment.\nFor RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model).\nIt also gives metrics on the number and percentage of genes with coverage.\nFinally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.\n\n\n\n\nDuplication Metrics\n\u00b6\n\n\nThe duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment).\nThis is based on coordinates (start position), rather than the raw data QC which was based on sequence.\nIt is expected that an miRNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.\n\n\n\n\nFlag Metrics\n\u00b6\n\n\nFlag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.\n\n\nInsert Size Metrics\n\u00b6\n\n\nInsert size metrics provide some basic metrics on the insert sizes for paired end experiments.\n\n\nProfile Metrics\n\u00b6\n\n\nProfile Metrics provide important overall statistics based on the provided gene model.\nMetrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene,\nin a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion,\ninter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model).\n\n\nSince we mapped only to known miRNAs, this should be reflected in the profile metrics (i.e. all mapped reads are in exons).\n\n\nSource Metrics\n\u00b6\n\n\nThese metrics can be used to get a sense of the overall types of transcripts that are being aligned.\nFor miRNAs, these statistics will not reflect anything informative.\n\n\nStrand Metrics\n\u00b6\n\n\nThe strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands.\nFor most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50).\nHowever, for some stranded protocols, such as the small rna sample prep kit that generated these data, this is not the case.\n\n\n\n\nFeature Metrics\n\u00b6\n\n\nFeature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.\n\n\n\n\nOther Aligned Data QC\n\u00b6\n\n\nRNA-Seq QC Metrics\n provides comprehensive assessment of the alignment data.\nWe also provide metrics such as \nFlag Summary Statistics\n, \nMapping Summary Statistics\n,\n\nPaired End Insert Size\n, \nRNA-Seq Mapping Profile\n as separate functions,\nwhere users can specify more analysis options.",
            "title": "QC of Aligned Data"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#qc-of-aligned-data",
            "text": "",
            "title": "QC of Aligned Data"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#alignment-report",
            "text": "By default, an alignment report is generated anytime an alignment is done in Array Studio.\nIf it is not already open, go to your Solution Explorer and double click on Report from the  AlignmentReport  table.   This will show, for each file, some statistics regarding mapping. One of the key statistics is the uniquely mapped reads.",
            "title": "Alignment Report"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#mirna-seq-aligned-qc",
            "text": "To get more detailed statistics of mapping rate, the RNA-Seq QC metrics can be used:   This module can be used to generate a table of metrics, along with visualization for each metric by scanning the alignment BAM files.\nThese metrics can be used to provide an overview of different statistics on alignment, coverage, Flag, mapping location, insert size strandness, and more, in a single table.\nIt also generates a  ProfileView  showing a chart for each metric.  To run the RNA-Seq QC module, go to  NGS | Aligned Data QC | RNA-Seq QC Metrics  now.   Choose the NGS data object and leave all other settings as their defaults and click  Submit  to run the module.  Source  metric is based on the provided gene model.\nIt provides the most information with gene models like Ensembl that have detailed information for the source of each transcript.\nHere, we will use the same gene model as with mapping ( miRBase.R21 ).  The analysis returns a  Table  View of QC metrics and  Profile  view in the  Aligned Data QC  folder:  In the  Table  view, you will find the following sections:",
            "title": "miRNA-Seq Aligned QC"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#alignment-metrics",
            "text": "These metrics can be used to give an overall idea of the quality of the alignment for your samples.",
            "title": "Alignment Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#coverage-metrics",
            "text": "The coverage metrics give you an overall idea of the mean coverage of your experiment.\nFor RNA-Seq, it looks at the (total length of aligned reads/total exon length of your gene model).\nIt also gives metrics on the number and percentage of genes with coverage.\nFinally, it gives a metric on the number of genes with at least 1 RPKM of coverage, as well as 10 RPKM of coverage.",
            "title": "Coverage Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#duplication-metrics",
            "text": "The duplication metrics can give you an idea of the total level of duplication for an experiment (after alignment).\nThis is based on coordinates (start position), rather than the raw data QC which was based on sequence.\nIt is expected that an miRNA-Seq experiment will have a large amount of duplication, so do not be alarmed if these metrics show high values.",
            "title": "Duplication Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#flag-metrics",
            "text": "Flag metrics are generally only useful for paired end reads when data has been aligned with OSA. It provides metrics using the SAM Flags.",
            "title": "Flag Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#insert-size-metrics",
            "text": "Insert size metrics provide some basic metrics on the insert sizes for paired end experiments.",
            "title": "Insert Size Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#profile-metrics",
            "text": "Profile Metrics provide important overall statistics based on the provided gene model.\nMetrics include the rate of reads mapped to an exon, exon junction, intron, anywhere in a known gene,\nin a known gene with an insertion or deletion, an inter-gene region, inter-gene region with insertion,\ninter-gene region with deletion, or a deep inter-gene region (>5kb outside the known gene model).  Since we mapped only to known miRNAs, this should be reflected in the profile metrics (i.e. all mapped reads are in exons).",
            "title": "Profile Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#source-metrics",
            "text": "These metrics can be used to get a sense of the overall types of transcripts that are being aligned.\nFor miRNAs, these statistics will not reflect anything informative.",
            "title": "Source Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#strand-metrics",
            "text": "The strand metrics give you the percentage of reads that are aligned to the sense or anti-sense strands.\nFor most Illumina RNA-Seq experiments (in which the reads are unstranded, it is expected that reads would align in equal portion (50/50).\nHowever, for some stranded protocols, such as the small rna sample prep kit that generated these data, this is not the case.",
            "title": "Strand Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#feature-metrics",
            "text": "Feature metrics measure the rate of CDS/Exon/Gene/Transcript coverage by RNA-Seq data.",
            "title": "Feature Metrics"
        },
        {
            "location": "/tutorials/miRNAseq/QC_of_Aligned_Data/#other-aligned-data-qc",
            "text": "RNA-Seq QC Metrics  provides comprehensive assessment of the alignment data.\nWe also provide metrics such as  Flag Summary Statistics ,  Mapping Summary Statistics , Paired End Insert Size ,  RNA-Seq Mapping Profile  as separate functions,\nwhere users can specify more analysis options.",
            "title": "Other Aligned Data QC"
        },
        {
            "location": "/tutorials/miRNAseq/miRNA-Seq_Quantification/",
            "text": "miRNA-Seq Quantification\n\u00b6\n\n\nArrayStudio provides modules and options for miRNA-Seq quantification.\n\n\nReport miRNA Counts\n\u00b6\n\n\nGiven the alignment, one can summarize miRNA expression, using the Quantification module in \nNGS | Quantification | Report Gene/Transcript Counts\n.\n\n\n\n\n\n\nUser can choose to quantify at transcript level by selecting it in the \nExpression measurement\n option. At \nSummary Level\n, If \nGene level\n is selected,\nmiRNA expression will be quantified at pre-miRNA gene level.  If \nTranscript level\n is selected, miRNA expression will be quantified at mature miRNA transcript level.\n\nBy default, option \nCount fragments instead of reads\n is selected, unselect as this is not paired-end (in this case, it makes no difference).\n\nExclude multi-reads\n does not count non-unique mapped reads.\nIn the source paper, multi-reads were distributed to all matching sites, so we will also use multi-reads.\nOptions to count reads based on strand are design for dataset from strand-specific protocol.\nIn this tutorial, the  samples are strand-specific, as shown in the strand metrics from aligned QC table. Only the first strand counting option is checked. We will examine mature miRNA expression levels, so select \nTranscript level\n.\n\n\nClick \nSubmit\n to run the module.\n\n\nThe output counts can be found under the \n-Omic\n data header in the \nSolution Explorer\n.\n\n\n\n\nThe counts table has miRNA IDs listed down the first column, and the sample IDs listed across the top row.\n\n-Omic\n data have an L-shaped metadata structure, where the row IDs are linked to the Annotation table (provided by the gene model),\nand the column IDs are linked to the Design table (which we attached after aligning).\n\n\n-Omic\n data can be treated as \nMicroArray Data\n and all microarray data analysis functions, such as \nOmicData | Pattern | Hierarchical Clustering\n,\n\nOmicData | QC | Principal Component Analysis\n, \nOmicData | Inference | General Linear Model\n and other modules can be used for downstream data analyses.\nPlease read the Microarray tutorial to get detailed analysis information.\n\n\nFor this tutorial, we will look for changes between groups of samples, but first\nwe recommended that you normalize the data by total counts.\nThis normalization function can be found in \nNGS | Inference | Normalize RNASeq data\n.\n\n\n\n\nThe \nNormalize RNA-Seq Data\n module provides a number of different ways to normalize data; we will use TotalCount.\n\n\n\n\nSelect \nTotalCount\n in the \nNormalization method\n list, set the \nScale Target\n to 1,000,000 and click submit.\n\n\nIf you choose, you can check the normalization by selecting \nOmicData | Summarize | Summary Statistics\n,\nthen summarizing by \nObservation\n, using \nSum\n (it should equal 1,000,000).\n\n\nANOVA to identify differentially-expressed miRNAs\n\u00b6\n\n\nNow that our miRNA-seq count data are normalized, we can now use ANOVA to identify differentially-expressed miRNAs.\nPlease be aware that our small sample set is not large enough to give a robust test.\nIf the user wishes, the full set of miRNA-seq data can be run through this tutorial, and be compared to the original paper's results.\n\n\nFor example, this volcano plot of a One-way ANOVA of Psoriatic Involved vs Normal samples, using all miRNA-seq data (instead of the tutorial subset),\nknown miRNAs that were reported as being most up- or down-regulated in Joyce \net al.\n are color-coded as purple and blue, respectively.\n\n\n\n\nAlthough using only the tutorial subset is not statistically robust, let's walk through the process.\nFirst, we will log2-transform our scaled data, using \nOmicData | Preprocess | Transform\n:\n\n\n\n\n\n\nSpecify an output name \n(otherwise the normalized count data will be over-written)\n,\nadd a constant of 0.1 (to avoid Log2 of \n0\n),\nand select \"Log2\" as the \nTransformation method\n.\n\n\nOnce we have transformed our data, several tests, including ANOVA, can be performed.\nThese can be found under \nOmicData | Inference | Standard Tests\n:\n\n\n\n\nIn the \nOne-Way ANOVA\n Window, first ensure that the scaled data set is selected, and specify an output name.\n\n\n\n\nSelect \"Group\" as our \nGroup\n (specified when we modified the \nDesign Table\n).\n\n\nSelect \"Pairwise\" \nComparison\n, to compare between each pair of groups.\n\n\nWe will use \"FDR_BH\" multiplicity correction.\n\n\nLeave \nFC transformation\n as \"Exp2\", and click \nSubmit\n.\n\n\nVolcano plots will show fold-change vs P-values for the 2813 miRNAs measured, across each pairwise comparison of normal, uninvolved, and involved psoriasis samples.\n\n\n\n\nCut-off lines can be selected in \nView Controller | Specify Cutoff Lines\n for p value cut-offs (y-axis) and fold-change (x-axis) as shown above. Select a few dots on the Psoriatic_Involved vs Normal plot. Detailed information about the measurements will be displayed in the \nDetails *Window\n,\nincluding the Estimate, which is the difference in means of log2-transformed miRNA expression in the samples,\nfold-change, which is unlogged Estimate, but the value's sign indicates whether the treatment sample is increased (+) or decreased (-),\nas well as raw and adjusted P-values.\n\n\nIn the details window, hover the mouse over one of the miRNA genes; the corresponding point on the volcano plot will be indicated.\n\n\nAlthough this tutorial used only a subset of the original study's data, this analysis detects many of the same differentially-expressed miRNAs,\nincluding upregulation of miR-135b.\n\n\nThese genes can be found in the Volcano plot by searching in the search box.\n(1) Type \"mir-135b\" in the search box, (2) click the \nsearch\n icon (binoculars).\nAll matches to this string (in this case, two miR-135b transcripts) will be selected in the Volcano plot,\nand details will be displayed in the the \nDetails\n window.",
            "title": "miRNA-Seq Quantification"
        },
        {
            "location": "/tutorials/miRNAseq/miRNA-Seq_Quantification/#mirna-seq-quantification",
            "text": "ArrayStudio provides modules and options for miRNA-Seq quantification.",
            "title": "miRNA-Seq Quantification"
        },
        {
            "location": "/tutorials/miRNAseq/miRNA-Seq_Quantification/#report-mirna-counts",
            "text": "Given the alignment, one can summarize miRNA expression, using the Quantification module in  NGS | Quantification | Report Gene/Transcript Counts .    User can choose to quantify at transcript level by selecting it in the  Expression measurement  option. At  Summary Level , If  Gene level  is selected,\nmiRNA expression will be quantified at pre-miRNA gene level.  If  Transcript level  is selected, miRNA expression will be quantified at mature miRNA transcript level. \nBy default, option  Count fragments instead of reads  is selected, unselect as this is not paired-end (in this case, it makes no difference). Exclude multi-reads  does not count non-unique mapped reads.\nIn the source paper, multi-reads were distributed to all matching sites, so we will also use multi-reads.\nOptions to count reads based on strand are design for dataset from strand-specific protocol.\nIn this tutorial, the  samples are strand-specific, as shown in the strand metrics from aligned QC table. Only the first strand counting option is checked. We will examine mature miRNA expression levels, so select  Transcript level .  Click  Submit  to run the module.  The output counts can be found under the  -Omic  data header in the  Solution Explorer .   The counts table has miRNA IDs listed down the first column, and the sample IDs listed across the top row. -Omic  data have an L-shaped metadata structure, where the row IDs are linked to the Annotation table (provided by the gene model),\nand the column IDs are linked to the Design table (which we attached after aligning).  -Omic  data can be treated as  MicroArray Data  and all microarray data analysis functions, such as  OmicData | Pattern | Hierarchical Clustering , OmicData | QC | Principal Component Analysis ,  OmicData | Inference | General Linear Model  and other modules can be used for downstream data analyses.\nPlease read the Microarray tutorial to get detailed analysis information.  For this tutorial, we will look for changes between groups of samples, but first\nwe recommended that you normalize the data by total counts.\nThis normalization function can be found in  NGS | Inference | Normalize RNASeq data .   The  Normalize RNA-Seq Data  module provides a number of different ways to normalize data; we will use TotalCount.   Select  TotalCount  in the  Normalization method  list, set the  Scale Target  to 1,000,000 and click submit.  If you choose, you can check the normalization by selecting  OmicData | Summarize | Summary Statistics ,\nthen summarizing by  Observation , using  Sum  (it should equal 1,000,000).",
            "title": "Report miRNA Counts"
        },
        {
            "location": "/tutorials/miRNAseq/miRNA-Seq_Quantification/#anova-to-identify-differentially-expressed-mirnas",
            "text": "Now that our miRNA-seq count data are normalized, we can now use ANOVA to identify differentially-expressed miRNAs.\nPlease be aware that our small sample set is not large enough to give a robust test.\nIf the user wishes, the full set of miRNA-seq data can be run through this tutorial, and be compared to the original paper's results.  For example, this volcano plot of a One-way ANOVA of Psoriatic Involved vs Normal samples, using all miRNA-seq data (instead of the tutorial subset),\nknown miRNAs that were reported as being most up- or down-regulated in Joyce  et al.  are color-coded as purple and blue, respectively.   Although using only the tutorial subset is not statistically robust, let's walk through the process.\nFirst, we will log2-transform our scaled data, using  OmicData | Preprocess | Transform :    Specify an output name  (otherwise the normalized count data will be over-written) ,\nadd a constant of 0.1 (to avoid Log2 of  0 ),\nand select \"Log2\" as the  Transformation method .  Once we have transformed our data, several tests, including ANOVA, can be performed.\nThese can be found under  OmicData | Inference | Standard Tests :   In the  One-Way ANOVA  Window, first ensure that the scaled data set is selected, and specify an output name.   Select \"Group\" as our  Group  (specified when we modified the  Design Table ).  Select \"Pairwise\"  Comparison , to compare between each pair of groups.  We will use \"FDR_BH\" multiplicity correction.  Leave  FC transformation  as \"Exp2\", and click  Submit .  Volcano plots will show fold-change vs P-values for the 2813 miRNAs measured, across each pairwise comparison of normal, uninvolved, and involved psoriasis samples.   Cut-off lines can be selected in  View Controller | Specify Cutoff Lines  for p value cut-offs (y-axis) and fold-change (x-axis) as shown above. Select a few dots on the Psoriatic_Involved vs Normal plot. Detailed information about the measurements will be displayed in the  Details *Window ,\nincluding the Estimate, which is the difference in means of log2-transformed miRNA expression in the samples,\nfold-change, which is unlogged Estimate, but the value's sign indicates whether the treatment sample is increased (+) or decreased (-),\nas well as raw and adjusted P-values.  In the details window, hover the mouse over one of the miRNA genes; the corresponding point on the volcano plot will be indicated.  Although this tutorial used only a subset of the original study's data, this analysis detects many of the same differentially-expressed miRNAs,\nincluding upregulation of miR-135b.  These genes can be found in the Volcano plot by searching in the search box.\n(1) Type \"mir-135b\" in the search box, (2) click the  search  icon (binoculars).\nAll matches to this string (in this case, two miR-135b transcripts) will be selected in the Volcano plot,\nand details will be displayed in the the  Details  window.",
            "title": "ANOVA to identify differentially-expressed miRNAs"
        },
        {
            "location": "/tutorials/miRNAseq/Others/",
            "text": "Others\n\u00b6\n\n\nDownstream Analyses On Quantification Values\n\u00b6\n\n\nAfter aligning data, there are a number of downstream analyses that can be done on the data.\nIn particular, the normalized \nCount\n \n-Omic\n data can be used in the analyses designed for \nMicroArray Data\n,\nincluding several visualization and analysis functions.\n\n\nBuild Reference and Gene Model\n\u00b6\n\n\nOmicsoft provides standard genome reference (such as Human.B37.3, hg38, mm10, Mouse.B38) and gene models (RefGene, Ensembl and UCSC).\nPrebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis.\n\n\nIf genome or gene models are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model.\nBoth functions are located in NGS menu.\n\n\nMore details can be found in the following two wiki articles:\n\n\n\n\n\n\nBuild reference library. \nlink\n\n\n\n\n\n\nBuild Gene model. \nlink\n\n\n\n\n\n\nServer-based Analysis\n\u00b6\n\n\nServer-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data.\n\n\nAll the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces and workflow are almost the same. Please read tutorial, \nServer-Based Analysis Basics\n, for more details. Users are encouraged to use Server-based Analyses for larger data sets (for example, with the entire dataset used for the miRNA study here). This also allows users to easily share access to analyses to other users within the same user group. We recommend users read through the \nServer Explorer\n and \nServer Analysis Basics\n Tutorials to familiarize themselves with these features.\n\n\nGenome Browser\n\u00b6\n\n\nOmicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio).\n\n\nIt can be used to visualize varied data types, including count/fpkm, exon/exon junction data, fusion data and many other tracks which have genomic coordinate information.\n\n\nFor example, you can right click a transcript ID (e.g. miR-135) in miRNA-Seq count data and view tracks in Genome Browser.\n\n\n\n\nYou can, by default, either view each track independently, or by \nGroup\n (select \nCreate a track for each group\n and choose \nGroup\n).\n\n\n\n\nBy default, the coverage tracks will be auto-scaled, so differences in coverage between groups may not be apparent.\n\n\nFirst, use the scroll wheel to zoom out.\n\n\n\n\nThen, right-click a track and select \nSet Track Properties\n. This will open a window to control details of how each track is displayed.\nHold down shift and select \nNGSData_Normal\n, \nNGSData_Psoriatic_Uninvolved\n, and \nNGSData_Psoriatic_Involved\n.\nThis way, the changes will be applied to all three tracks.\n\n\n\n\nChange \nAuto Scale\n to \"False\", change \nCustom Max Value\n to \"500\", and change \nHeight\n to \"100\". Then close the \nProperties\n window.\n\n\nNow, the \nGenome Browser\n shows that \nPsoriatic Involved\n samples express \nmir-135b\n much more highly (in raw reads) than the other two samples.\n\n\n\n\nPlease read the tutorial for the \nOmicsoft Genome Browser\n for more details.",
            "title": "Others"
        },
        {
            "location": "/tutorials/miRNAseq/Others/#others",
            "text": "",
            "title": "Others"
        },
        {
            "location": "/tutorials/miRNAseq/Others/#downstream-analyses-on-quantification-values",
            "text": "After aligning data, there are a number of downstream analyses that can be done on the data.\nIn particular, the normalized  Count   -Omic  data can be used in the analyses designed for  MicroArray Data ,\nincluding several visualization and analysis functions.",
            "title": "Downstream Analyses On Quantification Values"
        },
        {
            "location": "/tutorials/miRNAseq/Others/#build-reference-and-gene-model",
            "text": "Omicsoft provides standard genome reference (such as Human.B37.3, hg38, mm10, Mouse.B38) and gene models (RefGene, Ensembl and UCSC).\nPrebuilt index files will be downloaded from Omicsoft website and cached in local machine for all future data analysis.  If genome or gene models are not shown in the dropdown list, users can build their reference library with a FASTA file for genome reference and a GTF file for gene model.\nBoth functions are located in NGS menu.  More details can be found in the following two wiki articles:    Build reference library.  link    Build Gene model.  link",
            "title": "Build Reference and Gene Model"
        },
        {
            "location": "/tutorials/miRNAseq/Others/#server-based-analysis",
            "text": "Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. The Array Studio client software, installed on a local desktop machine, is used to interact with the ArrayServer (like a server terminal). Tasks such as job submission, monitoring, file transfer and data visualization can be done through the client software. Moreover, ArrayServer has a built-in scheduling system supports high performance computing cluster (both SGE and PBS/Torque), accelerating the analysis of tremendous amounts of NGS data.  All the Array Studio modules available for local analysis are also accessible for server-based analysis. The graphic interfaces and workflow are almost the same. Please read tutorial,  Server-Based Analysis Basics , for more details. Users are encouraged to use Server-based Analyses for larger data sets (for example, with the entire dataset used for the miRNA study here). This also allows users to easily share access to analyses to other users within the same user group. We recommend users read through the  Server Explorer  and  Server Analysis Basics  Tutorials to familiarize themselves with these features.",
            "title": "Server-based Analysis"
        },
        {
            "location": "/tutorials/miRNAseq/Others/#genome-browser",
            "text": "Omicsoft's Genome Browser is fully integrated with Omicsoft's Array Suite package (Array Server and Array Studio).  It can be used to visualize varied data types, including count/fpkm, exon/exon junction data, fusion data and many other tracks which have genomic coordinate information.  For example, you can right click a transcript ID (e.g. miR-135) in miRNA-Seq count data and view tracks in Genome Browser.   You can, by default, either view each track independently, or by  Group  (select  Create a track for each group  and choose  Group ).   By default, the coverage tracks will be auto-scaled, so differences in coverage between groups may not be apparent.  First, use the scroll wheel to zoom out.   Then, right-click a track and select  Set Track Properties . This will open a window to control details of how each track is displayed.\nHold down shift and select  NGSData_Normal ,  NGSData_Psoriatic_Uninvolved , and  NGSData_Psoriatic_Involved .\nThis way, the changes will be applied to all three tracks.   Change  Auto Scale  to \"False\", change  Custom Max Value  to \"500\", and change  Height  to \"100\". Then close the  Properties  window.  Now, the  Genome Browser  shows that  Psoriatic Involved  samples express  mir-135b  much more highly (in raw reads) than the other two samples.   Please read the tutorial for the  Omicsoft Genome Browser  for more details.",
            "title": "Genome Browser"
        },
        {
            "location": "/tutorials/miRNAseq/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results.\nPlease refer to the MicroArray tutorial for more details on the \nAudit Trial\n,\nwhich records all the analysis steps in the form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Save and Close Project"
        },
        {
            "location": "/tutorials/miRNAseq/Save_Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results.\nPlease refer to the MicroArray tutorial for more details on the  Audit Trial ,\nwhich records all the analysis steps in the form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/scRNAseq/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArrayStudio\n\u00b6\n\n\nArray Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThis tutorial is based on local NGS analysis using a Windows Workstation with (Window 10 Pro) with 3.60GHz Intel\u00ae Core TM i7-4790 Processor (# of cores: 4; # of threads: 8) with 16GB RAM.\n\n\nIt is highly recommend that the user complete the prerequisite for this tutorial:\n\nthe Microarray tutorial\n, as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.\n\n\nTest Dataset\n\u00b6\n\n\nThis Single Cell RNA-Seq (scRNA-Seq) tutorial will cover the importing and some analysis of a public dataset. This dataset can be accessed from NCBI GEO database: \nGEO GSE85241\n which was run on the Illumina NextSeq 500(GPL18573) platform, and adopting the method of CEL-Seq2. There are 32 samples in total and each sample has 2 fastq files as input, as it\u2019s paired-end sequencing data.\n\n\nAs described in the document (GSE85241_readme_demultiplexing_Cel-seq_data.pdf) downloaded from GEO database, read 1 should be parsed in the following manner: \u201cthe first 8 basepairs are the Cel-Seq cell barcodes (see list at the bottom of the same document). The following four basepairs are random basepairs of the unique molecular identifier, which can be used to count individual molecules for each transcript. The rest of read 1 consists of mostly polyT and is not used. Read two is then mapped to the reference genome of choice (hg19 in our case).\u201d\n\n\nWe will extract cell barcode and UMI information from read1, align read2 to human genome, and do the following analysis.\n\n\nIf users are interested in testing with this project, the data can be download from NCBI: \nSRP0809914\n. Or using our GUI for downloading SRA to download the fastq files: \nDownload SRA in ArrayStudio\n.\nAfter retrieving these data, you can begin the tutorial.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/scRNAseq/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/scRNAseq/Introduction/#arraystudio",
            "text": "Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThis tutorial is based on local NGS analysis using a Windows Workstation with (Window 10 Pro) with 3.60GHz Intel\u00ae Core TM i7-4790 Processor (# of cores: 4; # of threads: 8) with 16GB RAM.  It is highly recommend that the user complete the prerequisite for this tutorial: the Microarray tutorial , as a way to learn the basics in Array Studio. This tutorial assumes working knowledge of Array Studio, standard visualizations, and different modules within the software. As many of the downstream data types from next generation sequencing are \"Microarray\" datasets, the Microarray tutorial is an invaluable starting tool.",
            "title": "ArrayStudio"
        },
        {
            "location": "/tutorials/scRNAseq/Introduction/#test-dataset",
            "text": "This Single Cell RNA-Seq (scRNA-Seq) tutorial will cover the importing and some analysis of a public dataset. This dataset can be accessed from NCBI GEO database:  GEO GSE85241  which was run on the Illumina NextSeq 500(GPL18573) platform, and adopting the method of CEL-Seq2. There are 32 samples in total and each sample has 2 fastq files as input, as it\u2019s paired-end sequencing data.  As described in the document (GSE85241_readme_demultiplexing_Cel-seq_data.pdf) downloaded from GEO database, read 1 should be parsed in the following manner: \u201cthe first 8 basepairs are the Cel-Seq cell barcodes (see list at the bottom of the same document). The following four basepairs are random basepairs of the unique molecular identifier, which can be used to count individual molecules for each transcript. The rest of read 1 consists of mostly polyT and is not used. Read two is then mapped to the reference genome of choice (hg19 in our case).\u201d  We will extract cell barcode and UMI information from read1, align read2 to human genome, and do the following analysis.  If users are interested in testing with this project, the data can be download from NCBI:  SRP0809914 . Or using our GUI for downloading SRA to download the fastq files:  Download SRA in ArrayStudio .\nAfter retrieving these data, you can begin the tutorial.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/scRNAseq/Create_ArrayStudio_Project/",
            "text": "Create Server Project\n\u00b6\n\n\nArray Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using server projects. If user don\u2019t have Array Server installed, user can run the tutorial as a local project and analysis steps are almost the same as described in this tutorial.\n\n\n\n\nNote\n\n\nIf user is using local project to analyze the SingleCell data in this tutorial, please refer to our tutorial for \u201cRNA-Seq Analysis\u201d about creating ArrayStudio local Project: \nCreate Projects\n.\n\n\n\n\nIn order to analyze the data in server project, user should firstly connect to a server and upload the fastq files if they are not accessible on server folder: \nConnect to Server and Upload Files\n\n\nThen user can create a server project following analysis: \nCreate Server Project\n  for",
            "title": "CreateArray Studio Project"
        },
        {
            "location": "/tutorials/scRNAseq/Create_ArrayStudio_Project/#create-server-project",
            "text": "Array Studio provides an integrated environment for analyzing and visualizing high dimensional data. It is convenient in organizing and visualizing data with Solution Explorer, which organizes data/results as projects. User can create a local project which uses the local computer power to do analysis, or create a server project which will run all analyses in Array Server. In this tutorial, we are using server projects. If user don\u2019t have Array Server installed, user can run the tutorial as a local project and analysis steps are almost the same as described in this tutorial.   Note  If user is using local project to analyze the SingleCell data in this tutorial, please refer to our tutorial for \u201cRNA-Seq Analysis\u201d about creating ArrayStudio local Project:  Create Projects .   In order to analyze the data in server project, user should firstly connect to a server and upload the fastq files if they are not accessible on server folder:  Connect to Server and Upload Files  Then user can create a server project following analysis:  Create Server Project   for",
            "title": "Create Server Project"
        },
        {
            "location": "/tutorials/scRNAseq/scRNA_Analysis_Workflow/",
            "text": "Single Cell RNASeq Analysis Workflow\n\u00b6\n\n\nIn this tutorial, we will introduce the SCRNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for SCRNA-Seq data processing, including pre-process, filter SC reads, Tag Based QC, alignment, quantification, and a series of optional downstream analysis, as shown in the schematic chart below:",
            "title": "scRNA analysis workflow"
        },
        {
            "location": "/tutorials/scRNAseq/scRNA_Analysis_Workflow/#single-cell-rnaseq-analysis-workflow",
            "text": "In this tutorial, we will introduce the SCRNA-Seq data analysis workflow in ArrayStudio, step by step. The workflow consists of a number of modules for SCRNA-Seq data processing, including pre-process, filter SC reads, Tag Based QC, alignment, quantification, and a series of optional downstream analysis, as shown in the schematic chart below:",
            "title": "Single Cell RNASeq Analysis Workflow"
        },
        {
            "location": "/tutorials/scRNAseq/Preprocess_scRNA_Data/",
            "text": "Pre-Process\n\u00b6\n\n\nPre-process\n\u00b6\n\n\nCompared to normal fastq files, Single-Cell RNASeq fastq files contain extra information for barcode and Unique Molecular Identifiers (UMIs). The purpose of pre-processing fastq files is to extract these features from fastq files, and store them into a tag file.\n\n\nThis module can be accessed by going to \nNGS | SingleCell RNA-Seq | Single Cell Preprocessing:\n\n\n\n\nClick \nAdd\n to find all fastq files for these 32 samples (64 fastq files). Leave \nQuality encoding\n as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify \nJob Number\n as the number of processes to run in parallel. Specify the output folder where the results files (.fastq.gz and .tag.gz) will be saved, otherwise the files will go to the project folder by default.\n\n\nCheck the option for \nReads are paired\n as we are using paired end data in this tutorial, and check the option for \nReads contain UMI\n. Leave the box for \nDemultiplex with cell barcode\n empty here, as we don\u2019t want to demultiplex at fastq file level, which will generate too many files.\n\n\n\n\nBarcode UMI Source\n\u00b6\n\n\nIn the \nBarcode/UMI Source\n section, check the option for \nRead Sequences\n as the barcode and UMI are included in the read1 for our data, then click \nR1 pattern\n to bring up the regular expression window:\n\n\n\n\nFor our testing data, in the read 1 files, the first \n8\n basepairs are the Cel-Seq \ncell barcodes\n, and the following \n4\n basepairs are random basepairs of the \nunique molecular identifier\n. We can modify the length for barcode and UMI like this in the box, and click \nMatch\n, user can see how the fastq read1 sequences get mapped by this regular expression pattern:\n\n\n\n\nClick \nOK\n will bring this regular expression phrase to the Single Cell Preprocessing window. In the last option, choose \nRead2\n as the read sequence exists in Read2 for our testing data.\n\n\n\n\nClick \nSend To Queue\n to run this job on server.\nWhen the job is done, user can find four files generated for each sample in the output folder:\n\n\n\n\nMainly, we will use \n_prepReads.fastq.gz\n file and \n_prepReads.tag.gz\n file for the following analysis.\n\n\nFilter Raw reads\n\u00b6\n\n\nAfter the pre-processing of SC fastq files (resulting \nprepReads.fastq.gz\n and \n_prepReads.tag.gz\n files), user can filter the reads based on several criteria as follows:\n  1. Fastq read sequence quality\n  2. A valid barcode list to filter for the barcode in the tag file for valid read\n  3. A barcode remap file to group different barcode sequences (normally containing 1 mismatch) to be the same barcode\n  4. Filter reads by cell barcode quality (General tab)\n  5. Filter reads by UMI quality (General tab)\n\n\nTo open this module, user can go to \nAnalysis | NGS | Single Cell RNA-Seq | Filter Single Cell Raw Reads\n.\n\n\n\n\nClick Add to find all 32 files, pay attention to the files names, and make sure you are loading the \n.prepReads.fastq.gz\n files. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.\n\n\nIn this window, user can provide a ValidBarcode list if they have such list to verify valid barcode sequence, and provide a barcode remap file to group different barcode sequence to be the same barcode. For out tutorial project, the valid barcode list can be found in the GEO website: \nhttps://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE85241&format=file&file=GSE85241%5Freadme%5Fdemultiplexing%5FCel%2Dseq%5Fdata%2Epdf%2Egz\n. To make it more convenient, we have created a \nvalidbarcode.txt\n file on our server and user can go to this link (\nhttp://omicsoft.com/downloads/data/Tutorial/Help/SCTest/\n) to download the \nGSE85241_ValidBarcode.txt\n to your local folder.\n\n\nBrowse\n to load the downloaded \nGSE85241_validbarcode.txt\n file. Check the option for \nFilter reads with cell barcode quality\n and \nFilter reads with UMI quality\n.\n\n\nLeave the box for \n\u201cReads are paired\u201d\n empty, and check \nRead2\n for \nSingle end read source\n, as our fastq data is originated from paired end data and Read2 is read source.\n\n\n\n\nClick \nSend To Queue\n to run the module on server.\n\n\nWhen the job is done, user will be able to see 5 files generated for each sample:\n\n\n\n\nThe \nprepReads.filter.fastq.gz\n file and \nfilterReads.filter.tag.gz\n files will be used for the following analysis. User can move the rest of the files into a sub-folder for better management.",
            "title": "Pre-process of scRNA-Seq data"
        },
        {
            "location": "/tutorials/scRNAseq/Preprocess_scRNA_Data/#pre-process",
            "text": "",
            "title": "Pre-Process"
        },
        {
            "location": "/tutorials/scRNAseq/Preprocess_scRNA_Data/#pre-process_1",
            "text": "Compared to normal fastq files, Single-Cell RNASeq fastq files contain extra information for barcode and Unique Molecular Identifiers (UMIs). The purpose of pre-processing fastq files is to extract these features from fastq files, and store them into a tag file.  This module can be accessed by going to  NGS | SingleCell RNA-Seq | Single Cell Preprocessing:   Click  Add  to find all fastq files for these 32 samples (64 fastq files). Leave  Quality encoding  as Automatic to automatically set the correct quality encoding method (this tutorial has fastq files with the Sanger method of quality encoding). Specify  Job Number  as the number of processes to run in parallel. Specify the output folder where the results files (.fastq.gz and .tag.gz) will be saved, otherwise the files will go to the project folder by default.  Check the option for  Reads are paired  as we are using paired end data in this tutorial, and check the option for  Reads contain UMI . Leave the box for  Demultiplex with cell barcode  empty here, as we don\u2019t want to demultiplex at fastq file level, which will generate too many files.",
            "title": "Pre-process"
        },
        {
            "location": "/tutorials/scRNAseq/Preprocess_scRNA_Data/#barcode-umi-source",
            "text": "In the  Barcode/UMI Source  section, check the option for  Read Sequences  as the barcode and UMI are included in the read1 for our data, then click  R1 pattern  to bring up the regular expression window:   For our testing data, in the read 1 files, the first  8  basepairs are the Cel-Seq  cell barcodes , and the following  4  basepairs are random basepairs of the  unique molecular identifier . We can modify the length for barcode and UMI like this in the box, and click  Match , user can see how the fastq read1 sequences get mapped by this regular expression pattern:   Click  OK  will bring this regular expression phrase to the Single Cell Preprocessing window. In the last option, choose  Read2  as the read sequence exists in Read2 for our testing data.   Click  Send To Queue  to run this job on server.\nWhen the job is done, user can find four files generated for each sample in the output folder:   Mainly, we will use  _prepReads.fastq.gz  file and  _prepReads.tag.gz  file for the following analysis.",
            "title": "Barcode UMI Source"
        },
        {
            "location": "/tutorials/scRNAseq/Preprocess_scRNA_Data/#filter-raw-reads",
            "text": "After the pre-processing of SC fastq files (resulting  prepReads.fastq.gz  and  _prepReads.tag.gz  files), user can filter the reads based on several criteria as follows:\n  1. Fastq read sequence quality\n  2. A valid barcode list to filter for the barcode in the tag file for valid read\n  3. A barcode remap file to group different barcode sequences (normally containing 1 mismatch) to be the same barcode\n  4. Filter reads by cell barcode quality (General tab)\n  5. Filter reads by UMI quality (General tab)  To open this module, user can go to  Analysis | NGS | Single Cell RNA-Seq | Filter Single Cell Raw Reads .   Click Add to find all 32 files, pay attention to the files names, and make sure you are loading the  .prepReads.fastq.gz  files. Specify Job Number as the number of processes to run in parallel. Specify the output folder where the results files (.ngs) will be saved, otherwise the files will go the project folder by default.  In this window, user can provide a ValidBarcode list if they have such list to verify valid barcode sequence, and provide a barcode remap file to group different barcode sequence to be the same barcode. For out tutorial project, the valid barcode list can be found in the GEO website:  https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE85241&format=file&file=GSE85241%5Freadme%5Fdemultiplexing%5FCel%2Dseq%5Fdata%2Epdf%2Egz . To make it more convenient, we have created a  validbarcode.txt  file on our server and user can go to this link ( http://omicsoft.com/downloads/data/Tutorial/Help/SCTest/ ) to download the  GSE85241_ValidBarcode.txt  to your local folder.  Browse  to load the downloaded  GSE85241_validbarcode.txt  file. Check the option for  Filter reads with cell barcode quality  and  Filter reads with UMI quality .  Leave the box for  \u201cReads are paired\u201d  empty, and check  Read2  for  Single end read source , as our fastq data is originated from paired end data and Read2 is read source.   Click  Send To Queue  to run the module on server.  When the job is done, user will be able to see 5 files generated for each sample:   The  prepReads.filter.fastq.gz  file and  filterReads.filter.tag.gz  files will be used for the following analysis. User can move the rest of the files into a sub-folder for better management.",
            "title": "Filter Raw reads"
        },
        {
            "location": "/tutorials/scRNAseq/Tag_based_QC/",
            "text": "TAG Based QC\n\u00b6\n\n\nWe can use this module to summarize the data quality based on the tag file.\nGo to \nAnalysis | NGS | Single Cell RNA-Seq | Tag Based QC:\n\n\n\n\nClick \nAdd\n to load the tag.gz files generated from the former step; Leave \nQuality encoding\n as Automatic to automatically set the correct quality encoding method. Specify \nJob Number\n as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default.\n\n\nIn the box of \n# of quantiles for QC summary\n, set the number to be \n20\n, which means there will be 20 quantiles (0, 0.05, 0.10, 0.15 \u2026\u2026, 0.95, 1) for the cells for each sample, ranked based on the count for each cell.\n\n\nscRNA Read Count Report\n\u00b6\n\n\nCheck the option for \nExport all cell barcode counts\n, and leave others as default. Click \nSend To Queue\n to run this module on server.\n\n\n\n\nOnce the analysis is done, user can see two tables generated under the Table section, in the folder named \u201cSC Raw Data QC\u201d, each has a corresponding view:\n\n\n\n\nThe \nSCReadCountReport\n table will have 3 columns, for each sample, there will be 21 rows (20 quantiles), and the Column of Cell Read Counts shows the read counts for the corresponding cells:\n\n\n\n\nCell Read Counts View\n\u00b6\n\n\nAnd the CellReadCounts view is the variable view trellis by samples, which shows the read count across different quantiles of the cells for each sample in a more straightforward manner.\n\n\n\n\nSimilarly, the SCReadQSReport table shows the quality score for each quantile of the cells for each sample:\n\n\n\n\nAnd the corresponding view shows a more straightforward view, during which user can see the green line for cell barcode quality (CY), and blue line for UMI quality (UY):",
            "title": "TAG Based QC"
        },
        {
            "location": "/tutorials/scRNAseq/Tag_based_QC/#tag-based-qc",
            "text": "We can use this module to summarize the data quality based on the tag file.\nGo to  Analysis | NGS | Single Cell RNA-Seq | Tag Based QC:   Click  Add  to load the tag.gz files generated from the former step; Leave  Quality encoding  as Automatic to automatically set the correct quality encoding method. Specify  Job Number  as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default.  In the box of  # of quantiles for QC summary , set the number to be  20 , which means there will be 20 quantiles (0, 0.05, 0.10, 0.15 \u2026\u2026, 0.95, 1) for the cells for each sample, ranked based on the count for each cell.",
            "title": "TAG Based QC"
        },
        {
            "location": "/tutorials/scRNAseq/Tag_based_QC/#scrna-read-count-report",
            "text": "Check the option for  Export all cell barcode counts , and leave others as default. Click  Send To Queue  to run this module on server.   Once the analysis is done, user can see two tables generated under the Table section, in the folder named \u201cSC Raw Data QC\u201d, each has a corresponding view:   The  SCReadCountReport  table will have 3 columns, for each sample, there will be 21 rows (20 quantiles), and the Column of Cell Read Counts shows the read counts for the corresponding cells:",
            "title": "scRNA Read Count Report"
        },
        {
            "location": "/tutorials/scRNAseq/Tag_based_QC/#cell-read-counts-view",
            "text": "And the CellReadCounts view is the variable view trellis by samples, which shows the read count across different quantiles of the cells for each sample in a more straightforward manner.   Similarly, the SCReadQSReport table shows the quality score for each quantile of the cells for each sample:   And the corresponding view shows a more straightforward view, during which user can see the green line for cell barcode quality (CY), and blue line for UMI quality (UY):",
            "title": "Cell Read Counts View"
        },
        {
            "location": "/tutorials/scRNAseq/Alignment_to_the_Genome/",
            "text": "Alignment to the Genome\n\u00b6\n\n\nAfter the preprocess of single cell fastq file, the major step of the SC RNASeq analysis is the alignment of the reads to the genome. For this tutorial, we will align the data using OShell (same to normal RNASeq alignment), but with a special module to include the information in the tag file. To access this module, please go to \nNGS | Single Cell RNA-Seq | Barcoded Alignment:\n  \n\n\n\n\nAdd filtered reads\n\u00b6\n\n\nClick the \nAdd\n button to specify the location of the files. If user has followed this tutorial to run the filtering step, use the fastq files resulted from filtering process. The associated tag.gz file will be expected in the same folder as fastq.gz file.\n\n\n\n\nAlthough our original fastq files are paired end reads, while the read1 only contains cell barcode and UMI information, the fastq file after preprocessing is now single end reads now, so leave the option for \nReads are paired\n empty.\n\n\nChoose the Genome for the experiment. In this analysis, we used \nHuman.hg19\n. Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use \nEnsembl.R75\n, but the user can always choose to use their own gene model.\n\n\nLeave the quality encoding set to automatic. However, for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left as automatic, and is described completely in Omicsoft\u2019s white paper on alignment.\nThread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \u201cties\u201d for non-unique reads should be reported, or whether they should be excluded all together.\n\n\nDifferent from the normal RNASeq alignment, in this module, Barcoded BAM files will be generated. Basically, there will be several extra columns in the bam file for each read, showing the corresponding information about cell barcode and UMI.\n\n\nOutput folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in the next step (for fusion detection).\n\n\nThere are a few options in the Advanced Tab (e.g. Indel detection). In general, the default values have been tuned and should work well in most cases.\n\n\n\n\nClick \nSend To Queue\n to submit the analysis.\n\n\nThis could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc.\n\n\nAlignment reports and output files\n\u00b6\n\n\nAfter the alignment, you will see a NgsData object and an alignment report table in the solution explorer.\n\n\n\n\nBAM files as well as alignment report summary files will be generated in the specified output folder:",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/scRNAseq/Alignment_to_the_Genome/#alignment-to-the-genome",
            "text": "After the preprocess of single cell fastq file, the major step of the SC RNASeq analysis is the alignment of the reads to the genome. For this tutorial, we will align the data using OShell (same to normal RNASeq alignment), but with a special module to include the information in the tag file. To access this module, please go to  NGS | Single Cell RNA-Seq | Barcoded Alignment:",
            "title": "Alignment to the Genome"
        },
        {
            "location": "/tutorials/scRNAseq/Alignment_to_the_Genome/#add-filtered-reads",
            "text": "Click the  Add  button to specify the location of the files. If user has followed this tutorial to run the filtering step, use the fastq files resulted from filtering process. The associated tag.gz file will be expected in the same folder as fastq.gz file.   Although our original fastq files are paired end reads, while the read1 only contains cell barcode and UMI information, the fastq file after preprocessing is now single end reads now, so leave the option for  Reads are paired  empty.  Choose the Genome for the experiment. In this analysis, we used  Human.hg19 . Omicsoft supplies standard genome builds for common organisms, but the user can always choose to build and use their own genome. Similarly, choose the Gene Model to be used for alignment. Here we use  Ensembl.R75 , but the user can always choose to use their own gene model.  Leave the quality encoding set to automatic. However, for your information, these files were encoded using the Sanger quality scoring system. Total penalty should be left as automatic, and is described completely in Omicsoft\u2019s white paper on alignment.\nThread number indicates the number of threads to use per alignment, and usually this number should be less than 6. Job number refers to the number of parallel jobs (independent processes). Non-unique mapping indicates how many \u201cties\u201d for non-unique reads should be reported, or whether they should be excluded all together.  Different from the normal RNASeq alignment, in this module, Barcoded BAM files will be generated. Basically, there will be several extra columns in the bam file for each read, showing the corresponding information about cell barcode and UMI.  Output folder is the place if one wants to explicitly specify a location to store the alignment BAM files. Otherwise the bam files will be saved in a default location (a random number/letter folder in the project folder). In this tutorial, it is recommended to specify a folder so that BAM files can be found easily in the next step (for fusion detection).  There are a few options in the Advanced Tab (e.g. Indel detection). In general, the default values have been tuned and should work well in most cases.   Click  Send To Queue  to submit the analysis.  This could take hours, depending on the number of threads, type of computer (64-bit/32-bit), etc.",
            "title": "Add filtered reads"
        },
        {
            "location": "/tutorials/scRNAseq/Alignment_to_the_Genome/#alignment-reports-and-output-files",
            "text": "After the alignment, you will see a NgsData object and an alignment report table in the solution explorer.   BAM files as well as alignment report summary files will be generated in the specified output folder:",
            "title": "Alignment reports and output files"
        },
        {
            "location": "/tutorials/scRNAseq/Remove_Duplicate/",
            "text": "Remove Duplicate\n\u00b6\n\n\nThis module is optional for this tutorial, user can run this or just skip this part, and jump to the step for Quantification.\n Remove Duplicate can be used to remove duplication for Single Cell Bam files. The module will be useful if the user wants to have a clean (duplicate removed) BAM file for downstream analysis.\n\n\nTo access this module, user can go to \nAnalysis | NGS | Single Cell RNA-Seq | Remove Duplicates\n:\n\n\n\n\nUse the default options and just input the Output name and output folder, then click \nSend To Queue\n to submit this job:\n\n\n\n\nOnce this job is finished, user should be able to see a new NgsData object in Array Studio GUI, as well as new BAM files in the specified output folder:",
            "title": "Remove Duplicate"
        },
        {
            "location": "/tutorials/scRNAseq/Remove_Duplicate/#remove-duplicate",
            "text": "This module is optional for this tutorial, user can run this or just skip this part, and jump to the step for Quantification.  Remove Duplicate can be used to remove duplication for Single Cell Bam files. The module will be useful if the user wants to have a clean (duplicate removed) BAM file for downstream analysis.  To access this module, user can go to  Analysis | NGS | Single Cell RNA-Seq | Remove Duplicates :   Use the default options and just input the Output name and output folder, then click  Send To Queue  to submit this job:   Once this job is finished, user should be able to see a new NgsData object in Array Studio GUI, as well as new BAM files in the specified output folder:",
            "title": "Remove Duplicate"
        },
        {
            "location": "/tutorials/scRNAseq/scRNASeq_Quantification/",
            "text": "scRNA-Seq Quantification\n\u00b6\n\n\nArrayStudio provides modules and options for scRNA-Seq quantification.\n\n\nReport Barcoded BAM Counts\n\u00b6\n\n\nFor single cell sequencing data analysis, one of the most important parts is to get the transcript count for each cell, and this module in ArrayStudio can be accessed by going to Analysis | NGS | Single Cell RNA-Seq | Barcoded BAM Based Counting:\n\n\n\n\nThis window will be similar to the normal RNASeq quantification, user can leave all the settings on the left as default. For the Options on the right section, \nGene model\n and \nCell barcode tag\n will be automatically assigned based on the bam file information; User can modify the setting for \nCell count safe harbor\n, for the cells that have count in total less then this harbor, such cells will be filtered out in the reporting table. We will use set this value as 1000 for this tutorial.  \n\n\nLeave settings as default and specify \nJob Number\n as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default.\n\n\n\n\nAnd then go to the Advanced tab, check the option for \nConvert UMI count transcript number\n.\n\n\nConvert UMI count to transcript number\n is an option we designed for the correction of \u201cUMI saturation\u201d, please refer to our wiki: \nUMI to Transcript\n for the detail explanation.\n\n\nWe will check this option \u201cConvert UMI count to transcript number\u201d in the advanced tab as our UMI is only 4nt in this project, it will easily get saturated:\n\n\n\n\nClick \nSend To Queue\n to submit the job.\n\n\nOutput files and tables\n\u00b6\n\n\nWhen the job is done, there will be two -Omic type data objects show up in the GUI of project: a zero inflated binary matrix (ZIM) data object to store the UMI count, and another MicroArray type data object to store the converted UMI count:\n\n\n\n\nThis is the ZIM data object file which has 256 as the maximum UMI count:\n\n\n\n\nAnd this will be the normal MicroArray type -Omic data which store the converted theoretical UMI count, which has the maximum UMI as 1420:",
            "title": "scRNA-Seq Quantification"
        },
        {
            "location": "/tutorials/scRNAseq/scRNASeq_Quantification/#scrna-seq-quantification",
            "text": "ArrayStudio provides modules and options for scRNA-Seq quantification.",
            "title": "scRNA-Seq Quantification"
        },
        {
            "location": "/tutorials/scRNAseq/scRNASeq_Quantification/#report-barcoded-bam-counts",
            "text": "For single cell sequencing data analysis, one of the most important parts is to get the transcript count for each cell, and this module in ArrayStudio can be accessed by going to Analysis | NGS | Single Cell RNA-Seq | Barcoded BAM Based Counting:   This window will be similar to the normal RNASeq quantification, user can leave all the settings on the left as default. For the Options on the right section,  Gene model  and  Cell barcode tag  will be automatically assigned based on the bam file information; User can modify the setting for  Cell count safe harbor , for the cells that have count in total less then this harbor, such cells will be filtered out in the reporting table. We will use set this value as 1000 for this tutorial.    Leave settings as default and specify  Job Number  as the number of processes to run in parallel. Specify the output folder where the results files will be saved, otherwise the files will go the project folder by default.   And then go to the Advanced tab, check the option for  Convert UMI count transcript number .  Convert UMI count to transcript number  is an option we designed for the correction of \u201cUMI saturation\u201d, please refer to our wiki:  UMI to Transcript  for the detail explanation.  We will check this option \u201cConvert UMI count to transcript number\u201d in the advanced tab as our UMI is only 4nt in this project, it will easily get saturated:   Click  Send To Queue  to submit the job.",
            "title": "Report Barcoded BAM Counts"
        },
        {
            "location": "/tutorials/scRNAseq/scRNASeq_Quantification/#output-files-and-tables",
            "text": "When the job is done, there will be two -Omic type data objects show up in the GUI of project: a zero inflated binary matrix (ZIM) data object to store the UMI count, and another MicroArray type data object to store the converted UMI count:   This is the ZIM data object file which has 256 as the maximum UMI count:   And this will be the normal MicroArray type -Omic data which store the converted theoretical UMI count, which has the maximum UMI as 1420:",
            "title": "Output files and tables"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/",
            "text": "Other Downstream Analysis\n\u00b6\n\n\nQuality control on the cells\n\u00b6\n\n\nSingle Cell alignment/quantification will result in hundreds/thousands of cells, during which there will be various qualities for different cells. Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results. We would like to propose this criteria for filtering low quality cells, with which we have been used for curating our data for SingleCell land:\n\n\n\uf071 Mapped rate:     >=40% for \nhuman\n; >=30% for \nmouse\n\n\n\uf071 Mapped reads:     >=50,000 for Non \nUMI\n; >= 1000 for \nUMI\n\n\n\uf071 Gene coverage:     >=1000 for Non \nUMI\n; >=250 for \nUMI\n\n\n\uf071 Mitochondrial rate: < 20%\n\n\n\uf071 Spike-in RNA rate (if there is Spike-in and calculated): < 20%\n\n\nBased on this criterion, we consider the cells with small number of mapped reads have low quality, as well as the alignment mapped rate. The minimal gene coverage is defined as the number of genes with non-zero counts for that cell, and we set the threshold as 1000 for reads containing UMI, 50,000 for reads don\u2019t have UMI. Any cells with very few expressed genes are considered with poor quality, probable due to the failure of capturing the diverse transcript population.  \n\n\nBesides that, we also measure the proportion of reads mapped to genes in the mitochondrial genome. High proportion of reads mapped to mitochondrial might be an indication of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells. Similar consideration applies to the ratio of genes mapped to Spike-in RNA. If the portion mapped to spike-in RNA is high, these cells might have lost the major portion of endogenous RNA, thus considered as low quality. If there is no spike-in RNA included in the sample, then this part can be removed from the criteria.\n\n\nscRNA-Seq QC Metrics:\n\u00b6\n\n\nArrayStudio has provided a module to do Alignment data QC especially designed for Single Cell RNA-seq, which can be accessed by going to NGS | Single Cell RNA-seq | SC RNA-seq QC Metrics:\n\n\n\n\nThis module takes bam file resulted from barcoded alignment as input file, user can click \nAdd\n to import the formally aligned bam files, and choose the corresponding genome and gene model used for the alignment, and input the output folder to run the job:\n\n\n\n\nWhen the job finishes, an SC RNA Seq QC Metrics Table will be generated. Different from the RNASeq QC metrics report for bulk RNASeq, this SC RNA Seq QC Metrics Table will have cell name as the row ID, and different alignment statistics as the column name. Other than that, all of the content will be same to the RNA Seq QC Metrics Table:\n\n\n\n\nUser can filter for these columns for the quality control accordingly:\n  \uf071 Mapped rate \u2013 \nAlignment_MappedRate\n: >=40% for \nhuman\n; >=30% for \nmouse\n\n\n\uf071 Mapped reads \u2013 \nAlignment_Mapped\n: >=50,000 for \nNon UMI\n; >= 1000 for \nUMI\n\n\n\uf071 Gene coverage \u2013 \nCoverage_GeneWithCoverage\n: >=1000 for \nNon UMI\n; >=250 for \nUMI\n\n\n\uf071 Mitochondrial rate \u2013 \nSource_MitochondrialRate\n: < 20%\n\n\n\uf071 Spike-in RNA rate \u2013 \nSource_SpikeInRate\n: < 20%\n\n\nNormalization\n\u00b6\n\n\nIn ArrayStudio, we provide different methods for normalization. For Single cell RNA-seq data, we use TPM (transcript per million) for samples without UMI incorporated, and RPM (Counts/reads per million) for samples that contain UMI (due to the 5\u2019 or 3\u2019 biases).  In this tutorial, we will use RPM to normalize the data as we do have UMI for these samples.\n\n\nIf user haven\u2019t check the option for \nConvert UMI count to transcript number\n in the advanced option for \nReport Single Cell Counts (which is different from what we did in this tutorial)\n, the Quantification module will only output one ZIM file and ZIM data object in GUI, and different from microarray type data, ZIM data might be not compatible with several other modules we are going to use, so before we do the normalization, user should right click on the UMI count data object, and convert it to MicroArray Data:\n\n\n\n\nWhile in our tutorial case, if use did check the option for \nConvert UMI count to transcript number\n in the advanced option for \nReport Single Cell Counts\n, the Quantification module will output a ZIM data object and a normal microarray type data object for the converted count in GUI, user can just use the converted count data directly to do the normalization as follows.\n\n\n\n\nFor RPM normalization, we can go to NGS | Inference | Normalize RNA-Seq Data:\n\n\n\n\nAnd choose \nTotalCount\n for the Normalization method, setting the \nscale target\n to 1,000,000, so the resulted data will be reads per million:\n\n\n\n\nClassification for subgroup\n\u00b6\n\n\nThe \nRtsne\n module in Array Studio will allow the user to cluster different cells with UMI counts, using the \nRtsne\n package in R: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation \nRTSNE\n. To access this module, please go to \nAnalysis | NGS | Sing Cell RNA-Seq | t-SNE Clustering\n:\n\n\n\nLeave all other options as default and run the R t-SNE:\n\n\n\n\nIf user found that the \nPackage compatibility\n is not ready for either local job or server job, please follow our instruction to set it up: R implementation of t-SNE \nt-SNE Module in ArrayStudio\n.\n\n\nOnce the job is finished, user can find a table report and a scatter plot view for this table in ArrayStudio:\n\n\n\n\nThe table report will look like this:\n\n\n\n\nAnd the scatter plot will use \u201cV1\u201d as x-axis and \u201cV2\u201d as y-axis based on the table report:\n\n\n\n\nIt\u2019s highly recommend for users to follow the steps in our wiki \nRTSNE Options\n to go through some additional steps to achieve a figure like this:\n\n\n\n\nDifferential expression analysis\n\u00b6\n\n\nIf user want to analyze the differential gene expression across different subset of cells, for instance, in upper chart, user want to see which genes show different expression level significantly between cluster 1 cluster 2, they can use the SCDE module in ArrayStudio. This function is intended to use Single Cell UMI count data, and directly runs the R implementation of \nSCDE\n.\n\n\nTo run the SCDE to compare different clusters, user should have a design table to include the cluster information for each cell. Here are the steps to add the cluster information (based on the t-SNE result) to the design table:\n\n\nOnce the R-TSNE is done and the scatter plot is generated, user can try to manually select cells that belongs to the same cluster, and add a list name to these clusters:\n\n\n\n\nUser can manually assign the cluster name to these clusters like this.\n\n\nIf all the cells have been assigned a list name based on their distribution in the scatter plot, user can select all the lists defined from this scatter plot and right click to choose to add the list membership to the design table of the data object that we want to do SCDE:\n\n\n\n\nAnd choose the target design talbe:\n\n\n\n\nNow user can run SCDE. To open this module, please go to \nAnalysis | NGS | Sing Cell RNA-Seq | Single Cell Differential Expression Analysis\n.\n\n\n\n\nUser can set the comparisons in options like this and leave all other options in default and submit the job:\n\n\n\n\nif user found that  the package compatibility is not OK, it means that the R integrated with ArrayStudio is not ready to run scde package, please check with How to setup SCDE in R engine \nSCDE in R Engine\n to configure the scde in ArrayStudio.\n\n\nThe Rtsne module will generate a table and a scatter plot view for this table in ArrayStudio:\n\n\n\n\nA SCDE report table similar to DESeq Inference Report will be generated, containing fold-change and p-values for each tested variable. The default visualization, a volcano plot, will also be generated. Here is an example of output table:\n\n\n\n\n\n\n\n\nAn example of volcano plot is shown below:\n\n\n\n\n\n\nOther functions in the future\n\u00b6\n\n\nOur developers are still actively developing more modules for Single Cell RNA-Seq data downstream analysis.",
            "title": "Other Downstream Analysis"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#other-downstream-analysis",
            "text": "",
            "title": "Other Downstream Analysis"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#quality-control-on-the-cells",
            "text": "Single Cell alignment/quantification will result in hundreds/thousands of cells, during which there will be various qualities for different cells. Low-quality cells need to be removed to ensure that technical effects do not distort downstream analysis results. We would like to propose this criteria for filtering low quality cells, with which we have been used for curating our data for SingleCell land:  \uf071 Mapped rate:     >=40% for  human ; >=30% for  mouse  \uf071 Mapped reads:     >=50,000 for Non  UMI ; >= 1000 for  UMI  \uf071 Gene coverage:     >=1000 for Non  UMI ; >=250 for  UMI  \uf071 Mitochondrial rate: < 20%  \uf071 Spike-in RNA rate (if there is Spike-in and calculated): < 20%  Based on this criterion, we consider the cells with small number of mapped reads have low quality, as well as the alignment mapped rate. The minimal gene coverage is defined as the number of genes with non-zero counts for that cell, and we set the threshold as 1000 for reads containing UMI, 50,000 for reads don\u2019t have UMI. Any cells with very few expressed genes are considered with poor quality, probable due to the failure of capturing the diverse transcript population.    Besides that, we also measure the proportion of reads mapped to genes in the mitochondrial genome. High proportion of reads mapped to mitochondrial might be an indication of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells. Similar consideration applies to the ratio of genes mapped to Spike-in RNA. If the portion mapped to spike-in RNA is high, these cells might have lost the major portion of endogenous RNA, thus considered as low quality. If there is no spike-in RNA included in the sample, then this part can be removed from the criteria.",
            "title": "Quality control on the cells"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#scrna-seq-qc-metrics",
            "text": "ArrayStudio has provided a module to do Alignment data QC especially designed for Single Cell RNA-seq, which can be accessed by going to NGS | Single Cell RNA-seq | SC RNA-seq QC Metrics:   This module takes bam file resulted from barcoded alignment as input file, user can click  Add  to import the formally aligned bam files, and choose the corresponding genome and gene model used for the alignment, and input the output folder to run the job:   When the job finishes, an SC RNA Seq QC Metrics Table will be generated. Different from the RNASeq QC metrics report for bulk RNASeq, this SC RNA Seq QC Metrics Table will have cell name as the row ID, and different alignment statistics as the column name. Other than that, all of the content will be same to the RNA Seq QC Metrics Table:   User can filter for these columns for the quality control accordingly:\n  \uf071 Mapped rate \u2013  Alignment_MappedRate : >=40% for  human ; >=30% for  mouse  \uf071 Mapped reads \u2013  Alignment_Mapped : >=50,000 for  Non UMI ; >= 1000 for  UMI  \uf071 Gene coverage \u2013  Coverage_GeneWithCoverage : >=1000 for  Non UMI ; >=250 for  UMI  \uf071 Mitochondrial rate \u2013  Source_MitochondrialRate : < 20%  \uf071 Spike-in RNA rate \u2013  Source_SpikeInRate : < 20%",
            "title": "scRNA-Seq QC Metrics:"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#normalization",
            "text": "In ArrayStudio, we provide different methods for normalization. For Single cell RNA-seq data, we use TPM (transcript per million) for samples without UMI incorporated, and RPM (Counts/reads per million) for samples that contain UMI (due to the 5\u2019 or 3\u2019 biases).  In this tutorial, we will use RPM to normalize the data as we do have UMI for these samples.  If user haven\u2019t check the option for  Convert UMI count to transcript number  in the advanced option for  Report Single Cell Counts (which is different from what we did in this tutorial) , the Quantification module will only output one ZIM file and ZIM data object in GUI, and different from microarray type data, ZIM data might be not compatible with several other modules we are going to use, so before we do the normalization, user should right click on the UMI count data object, and convert it to MicroArray Data:   While in our tutorial case, if use did check the option for  Convert UMI count to transcript number  in the advanced option for  Report Single Cell Counts , the Quantification module will output a ZIM data object and a normal microarray type data object for the converted count in GUI, user can just use the converted count data directly to do the normalization as follows.   For RPM normalization, we can go to NGS | Inference | Normalize RNA-Seq Data:   And choose  TotalCount  for the Normalization method, setting the  scale target  to 1,000,000, so the resulted data will be reads per million:",
            "title": "Normalization"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#classification-for-subgroup",
            "text": "The  Rtsne  module in Array Studio will allow the user to cluster different cells with UMI counts, using the  Rtsne  package in R: T-Distributed Stochastic Neighbor Embedding using a Barnes-Hut Implementation  RTSNE . To access this module, please go to  Analysis | NGS | Sing Cell RNA-Seq | t-SNE Clustering :  \nLeave all other options as default and run the R t-SNE:   If user found that the  Package compatibility  is not ready for either local job or server job, please follow our instruction to set it up: R implementation of t-SNE  t-SNE Module in ArrayStudio .  Once the job is finished, user can find a table report and a scatter plot view for this table in ArrayStudio:   The table report will look like this:   And the scatter plot will use \u201cV1\u201d as x-axis and \u201cV2\u201d as y-axis based on the table report:   It\u2019s highly recommend for users to follow the steps in our wiki  RTSNE Options  to go through some additional steps to achieve a figure like this:",
            "title": "Classification for subgroup"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#differential-expression-analysis",
            "text": "If user want to analyze the differential gene expression across different subset of cells, for instance, in upper chart, user want to see which genes show different expression level significantly between cluster 1 cluster 2, they can use the SCDE module in ArrayStudio. This function is intended to use Single Cell UMI count data, and directly runs the R implementation of  SCDE .  To run the SCDE to compare different clusters, user should have a design table to include the cluster information for each cell. Here are the steps to add the cluster information (based on the t-SNE result) to the design table:  Once the R-TSNE is done and the scatter plot is generated, user can try to manually select cells that belongs to the same cluster, and add a list name to these clusters:   User can manually assign the cluster name to these clusters like this.  If all the cells have been assigned a list name based on their distribution in the scatter plot, user can select all the lists defined from this scatter plot and right click to choose to add the list membership to the design table of the data object that we want to do SCDE:   And choose the target design talbe:   Now user can run SCDE. To open this module, please go to  Analysis | NGS | Sing Cell RNA-Seq | Single Cell Differential Expression Analysis .   User can set the comparisons in options like this and leave all other options in default and submit the job:   if user found that  the package compatibility is not OK, it means that the R integrated with ArrayStudio is not ready to run scde package, please check with How to setup SCDE in R engine  SCDE in R Engine  to configure the scde in ArrayStudio.  The Rtsne module will generate a table and a scatter plot view for this table in ArrayStudio:   A SCDE report table similar to DESeq Inference Report will be generated, containing fold-change and p-values for each tested variable. The default visualization, a volcano plot, will also be generated. Here is an example of output table:     An example of volcano plot is shown below:",
            "title": "Differential expression analysis"
        },
        {
            "location": "/tutorials/scRNAseq/Other_Downstream_Analysis/#other-functions-in-the-future",
            "text": "Our developers are still actively developing more modules for Single Cell RNA-Seq data downstream analysis.",
            "title": "Other functions in the future"
        },
        {
            "location": "/tutorials/scRNAseq/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nGo to the \nFile Menu | Save\n to save your results.\nPlease refer to the MicroArray tutorial for more details on the \nAudit Trial\n,\nwhich records all the analysis steps in the form of Omic script.\n\n\nCongratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.\n\n\nThis tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Save and Close Project"
        },
        {
            "location": "/tutorials/scRNAseq/Save_Close_Project/#save-close-project",
            "text": "Go to the  File Menu | Save  to save your results.\nPlease refer to the MicroArray tutorial for more details on the  Audit Trial ,\nwhich records all the analysis steps in the form of Omic script.  Congratulations! You are done with the analysis. You can reopen this project later on to get back to the same state as you saved. This includes all views, filters, analyses, etc.  This tutorial represents just a piece of what Array Studio is capable of.\nFeel free to try different options in the Task tab or the NGS menu to get a feel for what Array Studio can do. For additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/GWAS/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nIn this document, we will provide step-by-step tutorials on how to create a server project for server-based GWAS analysis.\nStarting with a plink dataset, this tutorial will teach you how to strand-normalize, filter by quality control (QC) parameters,\nimpute for untested genotypes in samples, and perform association analysis between genotype and phenotypes of interest.\n\n\nArrayServer\n\u00b6\n\n\nThe GWAS module needs to be run on OmicSoft Array Server,\nthe OmicSoft enterprise solution that allows users to store, share, search, and integrate their GWAS projects and data.\nThe same solution has been applied to microarray/SNP/CNV/NGS projects and data to easily share analyzed data with clients and colleagues.\nArrayServer also hosts shared genome browsers.\nThe following diagram demonstrates the functionality of Array Server:\n\n\n\n\nServer-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThe Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal).\nTasks such as job submission, monitoring, file transfer and data visualization can be done through the client software.\nMoreover, Array Server has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque),\naccelerating the analysis of tremendous amounts of GWAS/imputed data.\nAll the Array Studio modules available for local analysis are also accessible for server-based analysis, with similar graphic interfaces.\n\n\nServer Project\n\u00b6\n\n\nA  Server Project  is a project that is created on the server, rather than on the user s client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the \nsave\n button. The cache is stored in the user s home folder, typically \nMyDocuments/Omicsoft/ServerProjects\n. A Server Project, when stored locally in the cache folder, has a different filename suffix (.ossprj) compared to a regular project (.osprj), and can only be opened when the user is connected to the server.\n\n\nThe concept behind a Server Project is that any data that is added to a project is first stored on the server. When the user adds a new dataset (whether it is GWAS, Gene Expression, CNV, or NextGen sequencing data), the user will be prompted with the folder structure of the Array Server instead of the local file system. If a user wishes to use a file from their local file system, the user must first upload the file to the server file system or ask an Admin to map the corresponding storage. Most companies store data on network drives, so they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the user s client machine. This allows the user to use the power of the server, instead of the user s individual client machine for the importing of data. This is extremely important for some memory/CPU-intensive importing operations (such as imputation). After data QC, imputation and analysis, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc.\nAnytime the user saves the project, it is synchronized with the version on the server.\n\n\nTest Dataset\n\u00b6\n\n\nThe user should first download the demo data file for use in the tutorial and save it to the local machine.\nThe file can be accessed from the following URL:\n\nlink\n\n\nThe dataset is based on The Geuvadis Project that combined transcriptomics and genomics for a subset of 465 individuals from the 1000 Genomes Project.\nThe input phase 3 1000 Genomes Project data is in plink format \nlink\n.\n\nCPNE1\n gene expression data for these individuals can be found in file  Phenotype.txt  in the Phenotype folder\nand is based on the normalized gene-level expression provided by The Geuvadis mRNA sequencing\n( \nhttp://www.ebi.ac.uk/arrayexpress/files/E-GEUV-1/analysis_results/\n).\nThe expression data file also contains gender information and principal component scores, which we will discuss in detail later.\n\n\nNote: Omicsoft constantly updates the GWAS module in order to meet continued requests of our customers. Therefore, you may note slightly different results when you compare your results to the results in this tutorial.\nPlease contact customer support (\nsupport@omicsoft.com\n) if you have any questions as you go through this tutorial.\n\n\nAfter this tutorial, users will be able to perform GWAS analysis to find the SNPs significantly associated with the expression level of a gene of interest (e.g. \nCPNE1\n).",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/GWAS/Introduction/#introduction",
            "text": "In this document, we will provide step-by-step tutorials on how to create a server project for server-based GWAS analysis.\nStarting with a plink dataset, this tutorial will teach you how to strand-normalize, filter by quality control (QC) parameters,\nimpute for untested genotypes in samples, and perform association analysis between genotype and phenotypes of interest.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/GWAS/Introduction/#arrayserver",
            "text": "The GWAS module needs to be run on OmicSoft Array Server,\nthe OmicSoft enterprise solution that allows users to store, share, search, and integrate their GWAS projects and data.\nThe same solution has been applied to microarray/SNP/CNV/NGS projects and data to easily share analyzed data with clients and colleagues.\nArrayServer also hosts shared genome browsers.\nThe following diagram demonstrates the functionality of Array Server:   Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer.\nThe Array Studio client software, installed on a local desktop machine, is used to interact with the Array Server (like a server terminal).\nTasks such as job submission, monitoring, file transfer and data visualization can be done through the client software.\nMoreover, Array Server has a built-in scheduling system that supports high performance computing clusters (both SGE and PBS/Torque),\naccelerating the analysis of tremendous amounts of GWAS/imputed data.\nAll the Array Studio modules available for local analysis are also accessible for server-based analysis, with similar graphic interfaces.",
            "title": "ArrayServer"
        },
        {
            "location": "/tutorials/GWAS/Introduction/#server-project",
            "text": "A  Server Project  is a project that is created on the server, rather than on the user s client machine. This project is cached locally on the client machine, in case of loss of connection to the server, but is automatically updated each time the user logs in or clicks the  save  button. The cache is stored in the user s home folder, typically  MyDocuments/Omicsoft/ServerProjects . A Server Project, when stored locally in the cache folder, has a different filename suffix (.ossprj) compared to a regular project (.osprj), and can only be opened when the user is connected to the server.  The concept behind a Server Project is that any data that is added to a project is first stored on the server. When the user adds a new dataset (whether it is GWAS, Gene Expression, CNV, or NextGen sequencing data), the user will be prompted with the folder structure of the Array Server instead of the local file system. If a user wishes to use a file from their local file system, the user must first upload the file to the server file system or ask an Admin to map the corresponding storage. Most companies store data on network drives, so they can map these drives directly in Array Server and all users will be able to access data easily during server analysis. All data addition and extraction is done on the server side, by Array Server, instead of the user s client machine. This allows the user to use the power of the server, instead of the user s individual client machine for the importing of data. This is extremely important for some memory/CPU-intensive importing operations (such as imputation). After data QC, imputation and analysis, data can be downloaded to the client machine, where the user can add views, run additional statistical analysis, etc.\nAnytime the user saves the project, it is synchronized with the version on the server.",
            "title": "Server Project"
        },
        {
            "location": "/tutorials/GWAS/Introduction/#test-dataset",
            "text": "The user should first download the demo data file for use in the tutorial and save it to the local machine.\nThe file can be accessed from the following URL: link  The dataset is based on The Geuvadis Project that combined transcriptomics and genomics for a subset of 465 individuals from the 1000 Genomes Project.\nThe input phase 3 1000 Genomes Project data is in plink format  link . CPNE1  gene expression data for these individuals can be found in file  Phenotype.txt  in the Phenotype folder\nand is based on the normalized gene-level expression provided by The Geuvadis mRNA sequencing\n(  http://www.ebi.ac.uk/arrayexpress/files/E-GEUV-1/analysis_results/ ).\nThe expression data file also contains gender information and principal component scores, which we will discuss in detail later.  Note: Omicsoft constantly updates the GWAS module in order to meet continued requests of our customers. Therefore, you may note slightly different results when you compare your results to the results in this tutorial.\nPlease contact customer support ( support@omicsoft.com ) if you have any questions as you go through this tutorial.  After this tutorial, users will be able to perform GWAS analysis to find the SNPs significantly associated with the expression level of a gene of interest (e.g.  CPNE1 ).",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/",
            "text": "Connecting to a Server and Uploading Files\n\u00b6\n\n\nConnection to a Server\n\u00b6\n\n\nBefore creating a server project, first connect to a server by clicking the \nServer\n tab at the top of Array Studio.\nYou may need to log off first if you do not see this interface.\n\n\n\n\nFill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. \nSelect the \nConnect\n button.\nIn some company server configurations, it will use your computer account to login and it does not require user authorization.\n\n\nCreate a server project\n\u00b6\n\n\nUpon successful login, go to the Analysis tab and click \nNew\n to create a \nNew Server Project\n. \nYou will need to provide Project ID and Title to this new server project. \nThen click the \nCreate\n button to complete this step.\n\n\n\n\n\n\nOnce the server project is successfully created, you will see it in the \"Solution Explorer\" window. \nIn the example above, it is called \"Tutorial_GWAS (Server Project   Distributed)\".\n\n\nUpload local files\n\u00b6\n\n\nAfter the server project is created, the next step is to upload plink raw data into the project if they are not already on the server. \nThis can be done by using the \nupload\n feature under the \nserver\n tab. \nYou will be prompted to browse folders and select the files that are needed for uploading.\nYou can upload multiple files at a time.\nIn this case, \"plink_all_var_lefted_cleaned.bed\", \"plink_all_var_lefted_cleaned.bim\", \"plink_all_var_lefted_cleaned.fam\" and \"Phenotype.txt\" files should be uploaded at this time.\n\n\n\n\nIf the \nServerFiles\n tab is not visible, select \nServer File | Browse Files\n.",
            "title": "Connecting To A Server And Uploading Files"
        },
        {
            "location": "/tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#connecting-to-a-server-and-uploading-files",
            "text": "",
            "title": "Connecting to a Server and Uploading Files"
        },
        {
            "location": "/tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#connection-to-a-server",
            "text": "Before creating a server project, first connect to a server by clicking the  Server  tab at the top of Array Studio.\nYou may need to log off first if you do not see this interface.   Fill in the server information (where Server name can be anything given by the user to help remember the server) and log-in credentials. \nSelect the  Connect  button.\nIn some company server configurations, it will use your computer account to login and it does not require user authorization.",
            "title": "Connection to a Server"
        },
        {
            "location": "/tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#create-a-server-project",
            "text": "Upon successful login, go to the Analysis tab and click  New  to create a  New Server Project . \nYou will need to provide Project ID and Title to this new server project. \nThen click the  Create  button to complete this step.    Once the server project is successfully created, you will see it in the \"Solution Explorer\" window. \nIn the example above, it is called \"Tutorial_GWAS (Server Project   Distributed)\".",
            "title": "Create a server project"
        },
        {
            "location": "/tutorials/GWAS/Connecting_To_A_Server_And_Uploading_Files/#upload-local-files",
            "text": "After the server project is created, the next step is to upload plink raw data into the project if they are not already on the server. \nThis can be done by using the  upload  feature under the  server  tab. \nYou will be prompted to browse folders and select the files that are needed for uploading.\nYou can upload multiple files at a time.\nIn this case, \"plink_all_var_lefted_cleaned.bed\", \"plink_all_var_lefted_cleaned.bim\", \"plink_all_var_lefted_cleaned.fam\" and \"Phenotype.txt\" files should be uploaded at this time.   If the  ServerFiles  tab is not visible, select  Server File | Browse Files .",
            "title": "Upload local files"
        },
        {
            "location": "/tutorials/GWAS/Preprocessing/",
            "text": "Preprocessing\n\u00b6\n\n\nStrand normalization\n\u00b6\n\n\nOnce the tutorial plink files are available on the server, you can proceed to the Preprocessing step.\nTo mirror the sequential process of the overall work flow, the GWAS module is designed to automatically include output of the previous step as the input of the subsequent step. \nFor example, the output of the Preprocess step will be loaded as the input of the QC step by default. \nSubsequently, the output of the QC step will be loaded as the input for the imputation step, which will generate input for the association step.\nThis streamlined process enables users to efficiently conduct GWAS analysis from raw input data to association analysis.\n\n\nTo facilitate GWAS data imputation and downstream variant annotation, we recommend that users first perform the  normalize strand  step. \nThis is to ensure that all the genotypes are reported on the forward strand of the reference genome.\nThis is a crucial step to ensure the accuracy of the imputation and variant annotations. \nOmicSoft builds SNP panels to allow users to select a specific GWAS platform to  normalize strand . \nIf you do not see your GWAS panel listed as one of the SNP panel options, please contact OmicSoft support (\nsupport@omicsoft.com\n ) and we will be able to build one for you.\n\n\nPlease note that if there is only a very little proportion of markers (less than 2%) having inconsistent strands, flipping will NOT be automatically attempted. \nIf there is a flipping issue, you will see a significant proportion of inconsistent SNPs.\n\n\nTo normalize strand, go to the Analysis tab, then select \nGWAS | Preprocess | Normalize .BED Files\n.\n\n\n\n\nOnce you click Normalize .BED Files, a new window will show up. \nHere, you need to add the plink Binary PED (BED) file using the  Add  button, then select the corresponding SNP panel, Reference library and specify an output folder path.\nFor this tutorial, please select Human.B37.3 as the reference library, and  Illumina.HumanOmni2.5-8v1  as the SNP panel.\n\n\n\n\nThere are two options users can select:\n\n\n\n\n\n\nOverride mapping information\n: Checking this option will recreate mapping positions based on SNP panel. \n    To do a liftover, this option has to be selected. \n\n\n\n\n\n\nUse dbsnp information to infer mapping\n: \n    If this option is checked, Array Studio will ignore any coordinate information in the source file. Array Studio will search the latest dbSNP database and recover the chromosome and position information from the \"rs\" IDs. \n\n\n\n\n\n\nFor this tutorial, please leave both options unchecked. You will need to uncheck to override mapping information to remove default settings.\nPlease ensure that you specify an output folder. \nIt is good practice to name the output folder, for example 'StrandNormalize' so that it can be identified for the following QC steps.\nThen click \nSend To Queue\n to submit your job.\nAfter your job is submitted, it will run on the server and you will be able to monitor its progress under the \nServer Jobs\n tab.\n\n\n\n\nOnce this job is complete, you will find a new set of plink files in the output folder previously specified. \nThis folder can be found under the \nServerFiles\n tab.",
            "title": "Preprocessing"
        },
        {
            "location": "/tutorials/GWAS/Preprocessing/#preprocessing",
            "text": "",
            "title": "Preprocessing"
        },
        {
            "location": "/tutorials/GWAS/Preprocessing/#strand-normalization",
            "text": "Once the tutorial plink files are available on the server, you can proceed to the Preprocessing step.\nTo mirror the sequential process of the overall work flow, the GWAS module is designed to automatically include output of the previous step as the input of the subsequent step. \nFor example, the output of the Preprocess step will be loaded as the input of the QC step by default. \nSubsequently, the output of the QC step will be loaded as the input for the imputation step, which will generate input for the association step.\nThis streamlined process enables users to efficiently conduct GWAS analysis from raw input data to association analysis.  To facilitate GWAS data imputation and downstream variant annotation, we recommend that users first perform the  normalize strand  step. \nThis is to ensure that all the genotypes are reported on the forward strand of the reference genome.\nThis is a crucial step to ensure the accuracy of the imputation and variant annotations. \nOmicSoft builds SNP panels to allow users to select a specific GWAS platform to  normalize strand . \nIf you do not see your GWAS panel listed as one of the SNP panel options, please contact OmicSoft support ( support@omicsoft.com  ) and we will be able to build one for you.  Please note that if there is only a very little proportion of markers (less than 2%) having inconsistent strands, flipping will NOT be automatically attempted. \nIf there is a flipping issue, you will see a significant proportion of inconsistent SNPs.  To normalize strand, go to the Analysis tab, then select  GWAS | Preprocess | Normalize .BED Files .   Once you click Normalize .BED Files, a new window will show up. \nHere, you need to add the plink Binary PED (BED) file using the  Add  button, then select the corresponding SNP panel, Reference library and specify an output folder path.\nFor this tutorial, please select Human.B37.3 as the reference library, and  Illumina.HumanOmni2.5-8v1  as the SNP panel.   There are two options users can select:    Override mapping information : Checking this option will recreate mapping positions based on SNP panel. \n    To do a liftover, this option has to be selected.     Use dbsnp information to infer mapping : \n    If this option is checked, Array Studio will ignore any coordinate information in the source file. Array Studio will search the latest dbSNP database and recover the chromosome and position information from the \"rs\" IDs.     For this tutorial, please leave both options unchecked. You will need to uncheck to override mapping information to remove default settings.\nPlease ensure that you specify an output folder. \nIt is good practice to name the output folder, for example 'StrandNormalize' so that it can be identified for the following QC steps.\nThen click  Send To Queue  to submit your job.\nAfter your job is submitted, it will run on the server and you will be able to monitor its progress under the  Server Jobs  tab.   Once this job is complete, you will find a new set of plink files in the output folder previously specified. \nThis folder can be found under the  ServerFiles  tab.",
            "title": "Strand normalization"
        },
        {
            "location": "/tutorials/GWAS/QC_of_GWAS_data/",
            "text": "QC of GWAS data\n\u00b6\n\n\nThe data QC module offers a suite of standard data QC procedures to help prepare GWAS data for imputation or association analysis.\nThe main purpose of the QC is to identify problematic subjects or markers for follow-up investigation or data exclusion.\n\n\nThe output of the preprocessing step can be used as the input for the QC step. \nGo to the \nAnalysis\n tab, then select \nGWAS | QC\n;\nyou will be prompted to add the input files for the QC pipeline, which consists of a sequential set of QC steps. \nThe \nAdd\n button allows you to add the set of plink files that have been pre-processed. \nIf the file names are the same as the raw data, please ensure that you select the set of files that have been saved in the output folder specified in the pre-processing step.\n\n\n\n\nGWAS QC steps\n\u00b6\n\n\nThere are six QC options you can specify at the QC stage; default values are given in the above figure. \nA more or less stringent threshold can be specified for each QC step.\n\n\nMarker missing rate threshold (round 1)\n\n\nTwo rounds of marker missing rate QCs are conducted. \nDefault cut-off for the first round is set at 25%. \nMarkers with missing data more than 25% will be identified and removed. \nThis cut-off value is deliberately set at a relatively high level to flag markers with high missing rate. \nThe main purpose of this step is to identify markers with poor quality due to high missing rate and to exclude these markers from subject-level missing rate calculation.\n\n\nSubject missing rate threshold (round 1)\n\n\nThis step identified subjects with relatively high missing rate. \nA default value of 0.05 is given to identify and remove subjects with at least 5% missing data rate.\nA more stringent cut-off value can also be used.\n\n\nMarker missing rate threshold (round 2)\n\n\nIn the second round of marker level missing rate QC, a default value of 0.05 is set to identify and remove markers with at least 5% missing data rate. \nA more stringent cut-off value can also be used.\n\n\nCutoff of kinship coefficient (relatedness)\n\n\nThe aim of this QC step is to identify cryptic related subjects which are established by testing pair-wise identity by state. \nRelated samples are inferred based on the range of estimated kinship coefficients: >0.354, 0.354-0.177, 0.177-0.0884, and 0.0884-0.0442 that\ncorresponds to duplicate/MZ twin, 1\nst\n-degree, 2\nnd\n-degree, and 3\nrd\n-degree relationships, respectively. \nA default kinship value of 0.0442 is set to identify pairs of subjects with 3\nrd\n-degree or closer relationships.\nBy default, any subject pair with kinship value > 0.0442 will be removed.\n\n\nMAF threshold for the pruning step\n\n\nThis cut-off is set for Linkage Disequilibrium (LD)-based pruning to select an independent set of common markers for Principle Component Analysis (PCA). \nA default value of 0.05 is given, which means the markers with minor allele frequency (MAF) more than 0.05 will be included in the pruning step.\nAfter pruning, the set of independent markers are used to conduct PCA analysis which include all the study subjects and 2504 1000Genomes subjects. \nJoint analysis of study subjects and 1000Genomes subjects allows inference of genetic ancestry of study subjects based on 1000Genomes subjects with known genetic ancestry information.\n\n\nHWE p-value cutoff\n\n\nChecking for Hardy-Weinberg Equilibrium (HWE) is the final step in quality control analysis of genetic markers. \nUnder HWE assumptions, allele and genotype frequencies can be estimated from one generation to the next. \nIn genetic association studies, HWE principles can be applied to detect genotyping errors. \nIt is critical to conduct this QC step in a subset of subjects with similar genetic ancestry. \nTo do this, a subject s genetic ancestry is first inferred from PCA analysis results based on study subjects and ~2K 1000 genomes subjects from the five super populations\n--\nAfricans, Ad Mixed Americans, East Asians, Europeans and South Asians. \nGenetic ancestry of a GWAS subject is predicted using the \nk-Nearest Neighbors\n algorithm. \nHWE testing is subsequently conducted in the largest subgroup of GWAS subjects.\nThe default cut-off is set at 1e-8; a more stringent cut-off can be set. \nMarkers not passing this threshold will be excluded from the imputation step.\n\n\nThere is also an internal \nGender QC\n check, but parameters are fixed, so no options are displayed in the \nSNP QC Pipeline\n window.\nHeterozygosity rates based on X chromosome markers are used to determine genders. \nA male call is made if heterozygosity rate is more than 0.8, while a female call is made if it is less than 0.2.\nSamples that fail the gender QC will be removed.\n\n\nReference library\n is needed here as to make sure in the PCA analysis, the genetic positions of the study subjects match with the 1000Genomes samples.\n\n\nFor this tutorial, please leave the options as default, specify an output folder, and click  Send To Queue  to submit your job.\n\n\nAfter the job is finished, please click  Update Project  to view the results.\n\n\n\n\nGWAS QC results\n\u00b6\n\n\nUpon completion of GWAS data QC, QC results will be summarized as shown below.\n\n\nOn the left side of the screen under the Solution Explorer tab, you will see a list of QC results that are organized into the following four sections.\nThree results are presented in the format of tables, and another one is a scatter plot which is fully interactive.\n\n\n\n\n\n\n\n\nMarker exclusion list\n\n\nThe set of markers that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions.\n\n\n\n\n\n\nReplicate Sample Check\n\n\nFor samples that are identified as technical replicates, a test of within family relatedness is performed to confirm that pairs of samples are identical.\nSamples that fail this test are output in this file and are excluded.\n\n\n\n\n\n\nSubject exclusion list\n\n\nThe set of subjects that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions.\n\n\n\n\n\n\nUnexpected Sample Relatedness list**\n\n\nThis table contains any subject pair with estimated kinship coefficient >0.0442.\nThe output is generated by testing for pairwise relationship across families.\nN SNP (the number of SNPs that do not have missing genotypes for either individual, Z0 (the probability that IBD=0), Phi (the kinship coefficient), IBS0 (the proportion of SNPs with zero identity-by-state), \nKinship (estimated kinship coefficient from the SNP data, and error (indicates a difference between the estimated and specified kinship coefficients). \n\n\n\n\n\n\nPCA results\n\n\nPCA analysis is based on a set of LD-pruned independent common markers in 1000 Genomes subjects and GWAS subjects.\nThere are two PCA results in the view. \nThe first one corresponds to the combined results with both post-QC study subjects and the 1000 Genomes subjects (which will be discussed in detail soon), \nand the second one corresponds to the post-QC study samples only. \nIn the latter case, top 100 PC scores are shown. \nYou can export this table by selecting one of the options in the menu bar (shown in the red rectangle) in the figure below. \nThese results are needed in the downstream association analysis. \nTherefore, you should save this table as  PCA_results.txt , which would later be merged\nwith phenotype data. \nIn this tutorial, however, a combined file ( Phenotype.txt ) is provided with the sample data, so this merge step will not be needed.\n\n\n\n\n\n\n\n\n\n\n\n\nPCA plot\n\n\nThe combined PCA result with both post-QC study subjects and the 1000 Genomes subjects is shown in the form of PCA scatter plot.\nPCA scatter plots are generated from pairs of selected PC scores (also called eigenvectors). \nIn the below example, PC1 (or Eigen1 on the X-axis) is plotted against PC2 (or Eigen2 on the Y-axis). \nSubjects from the 1000 Genomes project are represented by the square symbols and study subjects are denoted by filled circles. \nThe five super-populations, Africans (AFR), Ad Mixed Americans (AMR), East Asians (EAS), Europeans (EUR) and South Asians (SAS), \nare represented by different colors as shown in the right hand \nView Controller\n. \nIn this example, the vast majority of the study subjects are clustered with Europeans. \nGenetic ancestry of a study subject is further predicted using the \nk-Nearest Neighbors\n algorithm.\nThe legends of the colors and symbols can be found on the right-hand of the screen under the View Controller tab. \nPCA plot is fully interactive. \nAs shown in the example above, detailed information of the highlighted subject is shown in the table right below the PCA plot in the middle panel of the screen. \nYou can also review genetic ancestry information of all the study samples by selecting the filled circle symbol in the View Controller. \nAll of the study subjects will be highlighted in red color and detailed information on all the study subjects will be presented in the table format in the Details window.\nYou can view the table in Excel, or perform other actions by selecting symbols shown on the menu bar of the table. \nThis can be handy if you would like to export the inferred race information for further comparison to self-reported race data.\n\n\n\n\n\n\n\n\nIn addition to QC results under GWAS_QC, there will also be a BED file containing the genetic information after QC step.",
            "title": "QC of GWAS data"
        },
        {
            "location": "/tutorials/GWAS/QC_of_GWAS_data/#qc-of-gwas-data",
            "text": "The data QC module offers a suite of standard data QC procedures to help prepare GWAS data for imputation or association analysis.\nThe main purpose of the QC is to identify problematic subjects or markers for follow-up investigation or data exclusion.  The output of the preprocessing step can be used as the input for the QC step. \nGo to the  Analysis  tab, then select  GWAS | QC ;\nyou will be prompted to add the input files for the QC pipeline, which consists of a sequential set of QC steps. \nThe  Add  button allows you to add the set of plink files that have been pre-processed. \nIf the file names are the same as the raw data, please ensure that you select the set of files that have been saved in the output folder specified in the pre-processing step.",
            "title": "QC of GWAS data"
        },
        {
            "location": "/tutorials/GWAS/QC_of_GWAS_data/#gwas-qc-steps",
            "text": "There are six QC options you can specify at the QC stage; default values are given in the above figure. \nA more or less stringent threshold can be specified for each QC step.  Marker missing rate threshold (round 1)  Two rounds of marker missing rate QCs are conducted. \nDefault cut-off for the first round is set at 25%. \nMarkers with missing data more than 25% will be identified and removed. \nThis cut-off value is deliberately set at a relatively high level to flag markers with high missing rate. \nThe main purpose of this step is to identify markers with poor quality due to high missing rate and to exclude these markers from subject-level missing rate calculation.  Subject missing rate threshold (round 1)  This step identified subjects with relatively high missing rate. \nA default value of 0.05 is given to identify and remove subjects with at least 5% missing data rate.\nA more stringent cut-off value can also be used.  Marker missing rate threshold (round 2)  In the second round of marker level missing rate QC, a default value of 0.05 is set to identify and remove markers with at least 5% missing data rate. \nA more stringent cut-off value can also be used.  Cutoff of kinship coefficient (relatedness)  The aim of this QC step is to identify cryptic related subjects which are established by testing pair-wise identity by state. \nRelated samples are inferred based on the range of estimated kinship coefficients: >0.354, 0.354-0.177, 0.177-0.0884, and 0.0884-0.0442 that\ncorresponds to duplicate/MZ twin, 1 st -degree, 2 nd -degree, and 3 rd -degree relationships, respectively. \nA default kinship value of 0.0442 is set to identify pairs of subjects with 3 rd -degree or closer relationships.\nBy default, any subject pair with kinship value > 0.0442 will be removed.  MAF threshold for the pruning step  This cut-off is set for Linkage Disequilibrium (LD)-based pruning to select an independent set of common markers for Principle Component Analysis (PCA). \nA default value of 0.05 is given, which means the markers with minor allele frequency (MAF) more than 0.05 will be included in the pruning step.\nAfter pruning, the set of independent markers are used to conduct PCA analysis which include all the study subjects and 2504 1000Genomes subjects. \nJoint analysis of study subjects and 1000Genomes subjects allows inference of genetic ancestry of study subjects based on 1000Genomes subjects with known genetic ancestry information.  HWE p-value cutoff  Checking for Hardy-Weinberg Equilibrium (HWE) is the final step in quality control analysis of genetic markers. \nUnder HWE assumptions, allele and genotype frequencies can be estimated from one generation to the next. \nIn genetic association studies, HWE principles can be applied to detect genotyping errors. \nIt is critical to conduct this QC step in a subset of subjects with similar genetic ancestry. \nTo do this, a subject s genetic ancestry is first inferred from PCA analysis results based on study subjects and ~2K 1000 genomes subjects from the five super populations\n--\nAfricans, Ad Mixed Americans, East Asians, Europeans and South Asians. \nGenetic ancestry of a GWAS subject is predicted using the  k-Nearest Neighbors  algorithm. \nHWE testing is subsequently conducted in the largest subgroup of GWAS subjects.\nThe default cut-off is set at 1e-8; a more stringent cut-off can be set. \nMarkers not passing this threshold will be excluded from the imputation step.  There is also an internal  Gender QC  check, but parameters are fixed, so no options are displayed in the  SNP QC Pipeline  window.\nHeterozygosity rates based on X chromosome markers are used to determine genders. \nA male call is made if heterozygosity rate is more than 0.8, while a female call is made if it is less than 0.2.\nSamples that fail the gender QC will be removed.  Reference library  is needed here as to make sure in the PCA analysis, the genetic positions of the study subjects match with the 1000Genomes samples.  For this tutorial, please leave the options as default, specify an output folder, and click  Send To Queue  to submit your job.  After the job is finished, please click  Update Project  to view the results.",
            "title": "GWAS QC steps"
        },
        {
            "location": "/tutorials/GWAS/QC_of_GWAS_data/#gwas-qc-results",
            "text": "Upon completion of GWAS data QC, QC results will be summarized as shown below.  On the left side of the screen under the Solution Explorer tab, you will see a list of QC results that are organized into the following four sections.\nThree results are presented in the format of tables, and another one is a scatter plot which is fully interactive.     Marker exclusion list  The set of markers that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions.    Replicate Sample Check  For samples that are identified as technical replicates, a test of within family relatedness is performed to confirm that pairs of samples are identical.\nSamples that fail this test are output in this file and are excluded.    Subject exclusion list  The set of subjects that did not meet marker QC thresholds are summarized in the marker exclusion list along with reasons for exclusions.    Unexpected Sample Relatedness list**  This table contains any subject pair with estimated kinship coefficient >0.0442.\nThe output is generated by testing for pairwise relationship across families.\nN SNP (the number of SNPs that do not have missing genotypes for either individual, Z0 (the probability that IBD=0), Phi (the kinship coefficient), IBS0 (the proportion of SNPs with zero identity-by-state), \nKinship (estimated kinship coefficient from the SNP data, and error (indicates a difference between the estimated and specified kinship coefficients).     PCA results  PCA analysis is based on a set of LD-pruned independent common markers in 1000 Genomes subjects and GWAS subjects.\nThere are two PCA results in the view. \nThe first one corresponds to the combined results with both post-QC study subjects and the 1000 Genomes subjects (which will be discussed in detail soon), \nand the second one corresponds to the post-QC study samples only. \nIn the latter case, top 100 PC scores are shown. \nYou can export this table by selecting one of the options in the menu bar (shown in the red rectangle) in the figure below. \nThese results are needed in the downstream association analysis. \nTherefore, you should save this table as  PCA_results.txt , which would later be merged\nwith phenotype data. \nIn this tutorial, however, a combined file ( Phenotype.txt ) is provided with the sample data, so this merge step will not be needed.       PCA plot  The combined PCA result with both post-QC study subjects and the 1000 Genomes subjects is shown in the form of PCA scatter plot.\nPCA scatter plots are generated from pairs of selected PC scores (also called eigenvectors). \nIn the below example, PC1 (or Eigen1 on the X-axis) is plotted against PC2 (or Eigen2 on the Y-axis). \nSubjects from the 1000 Genomes project are represented by the square symbols and study subjects are denoted by filled circles. \nThe five super-populations, Africans (AFR), Ad Mixed Americans (AMR), East Asians (EAS), Europeans (EUR) and South Asians (SAS), \nare represented by different colors as shown in the right hand  View Controller . \nIn this example, the vast majority of the study subjects are clustered with Europeans. \nGenetic ancestry of a study subject is further predicted using the  k-Nearest Neighbors  algorithm.\nThe legends of the colors and symbols can be found on the right-hand of the screen under the View Controller tab. \nPCA plot is fully interactive. \nAs shown in the example above, detailed information of the highlighted subject is shown in the table right below the PCA plot in the middle panel of the screen. \nYou can also review genetic ancestry information of all the study samples by selecting the filled circle symbol in the View Controller. \nAll of the study subjects will be highlighted in red color and detailed information on all the study subjects will be presented in the table format in the Details window.\nYou can view the table in Excel, or perform other actions by selecting symbols shown on the menu bar of the table. \nThis can be handy if you would like to export the inferred race information for further comparison to self-reported race data.     In addition to QC results under GWAS_QC, there will also be a BED file containing the genetic information after QC step.",
            "title": "GWAS QC results"
        },
        {
            "location": "/tutorials/GWAS/Imputation/",
            "text": "Imputation\n\u00b6\n\n\nImputation process\n\u00b6\n\n\n\n\nIn the imputation step, it is \nabsolutely essential\n that you are using the strand-normalized and post-QC data for this step.\nGenotype imputation makes statistical inferences of unobserved genotypes based on reference haplotypes. \nCurrently, haplotypes from 2504 1000 Genomes Phase 3 subjects are used as reference panel. \nFuture implementation may include larger reference panels to allow more powerful and accurate imputation. \nThe entire process can be divided into two stages. \nIn the first stage, GWAS subjects are pre-phased. \nTo achieve memory and speed efficiency, this pre-phasing step is carried out in parallel for chunks of chromosomes. \nAfter pre-phasing, imputation is conducted in parallel for each chunk of the chromosome and imputed data are subsequently combined into one VCF file. \nSimilar to QC pipeline, imputation needs to run on Linux server.\n\n\nDuring the pre-phasing step, there are three methods to choose   HAPI-UR, MaCH and Automatic \nFor automatic method, MaCH is used for studies with less than 1000 subjects and HAPI-UR is used for studies with at least 1000 subjects.\nThe choice of HAPI-UR for bigger studies is primarily due to computational speed reason. \nPre-phasing is the most time-consuming step. \nIt is estimated that using MaCH, 40~50 hours on 40-node cluster are needed to phase ~180 subjects based on ~4 million markers. \nIt is highly advisable that users find out the number of nodes available on their servers/clusters to determine an optimal number of jobs (Job number) for this step.\n\n\nUsers can also try it out by running imputation for one chromosome region (e.g. 50 mb) to estimate the number needed. \nThis can be achieved by entering \n in the SNP list field as shown in the figure below.\n\n\nUsers can specify a subset of subjects instead of the entire set of subjects available in the plink files for imputation. \nThis allows flexibility to impute data for a subset of subjects should there be a need to exclude certain subjects from the post-QC plink files.\n\n\nThe following options can be specified for the imputation process.\n\n\n\n\n\n\nNumber of iterations\n: \n    This is one of the two key parameters used to infer haplotypes during the phasing stage. \n    It specifies how many iterations of the Markov sampler should be run. \n    These iterations are used to simultaneously update the crossover map, to update the error rate map and to estimate the missing genotypes. \n    A set value of 20 is given.\n\n\n\n\n\n\nNumber of haplotypes\n: \n    This is the other key parameter used to infer haplotypes during the phasing stage. \n    It specifies how many haplotypes should be considered when updating each individual. \n    A set value of 200 is given.\n\n\n\n\n\n\nNumber of markers per chunk\n: \n    This option specifies the number of markers to be included in a chromosome chunk during the phasing stage.\n    It is recommended that hundreds (not thousands) of chunks be generated for a given GWAS panel. \n    For example, 5000 markers/chunk can be specified for a 5M GWAS panel.\n\n\n\n\n\n\nNumber of markers in the overlap region\n: \n    It is crucial that adjacent chunks are overlapped such that phasing is done correctly. \n    It is recommended that the overlap is at least 100kb. \n    This is often achieved by specifying the overlap no less than one fourth of the chunk size. \n    For example, 1500 markers/chunk can be specified with 5000 markers/chunk for a 5M GWAS panel.\n\n\n\n\n\n\nReference library\n:\n    Human B37.3 is currently used for the reference panel.\n\n\n\n\n\n\nJob number\n: \n    This needs to be determined by the number of core processors on the server. \n    A higher number would improve the overall speed of the process.\n\n\n\n\n\n\nThe output of the imputation step will be saved in the output folder specified.\nUsers can use the \nBrowse\n button to choose output folder.\nIn this tutorial, chromosome 20 is imputed with HAPI-UR using 8 nodes (Job number = 8) on the server. \nPlease click \nSend To Queue\n to run imputation step.\n\n\n\n\nImputation Output\n\u00b6\n\n\nAt the end of the imputation process, a single VCF file is generated that combines data from all the chromosome chunks.\nIn the VCF file, chromosome, position, reference allele, alternative allele, marker ID, imputation quality (R2), minor allele frequency (MAF), \ngenotyped or imputed (Is Genotype), and allelic dosage data are included.\nThe VCF table will show under Table.\n\n\nIn this table, rows correspond to variants.\nColumns provide aforementioned information on variants and from column 10 and onwards, subjects  genotype and dose information are presented.\nA subject s ID is represented by  Family ID -> Individual ID  as provided in the original plink files. \nIn this instance (as pointed by the red arrow), the first subject is NA18524->NA18524 with both Family ID and Individual ID being NA18524.\nImputed data of the first marker for this subject is 0|0:0.000 as shown in the red rectangle in the figure below. \nThe notation is based on output of GT:DS where GT is imputed genotype and DS is the imputed dosage data.\nIn the \"Is Genotype\" column, \"False\" means this marker is imputed, while  True  means this marker is included in genotyping file and not from imputation result.",
            "title": "Imputation"
        },
        {
            "location": "/tutorials/GWAS/Imputation/#imputation",
            "text": "",
            "title": "Imputation"
        },
        {
            "location": "/tutorials/GWAS/Imputation/#imputation-process",
            "text": "In the imputation step, it is  absolutely essential  that you are using the strand-normalized and post-QC data for this step.\nGenotype imputation makes statistical inferences of unobserved genotypes based on reference haplotypes. \nCurrently, haplotypes from 2504 1000 Genomes Phase 3 subjects are used as reference panel. \nFuture implementation may include larger reference panels to allow more powerful and accurate imputation. \nThe entire process can be divided into two stages. \nIn the first stage, GWAS subjects are pre-phased. \nTo achieve memory and speed efficiency, this pre-phasing step is carried out in parallel for chunks of chromosomes. \nAfter pre-phasing, imputation is conducted in parallel for each chunk of the chromosome and imputed data are subsequently combined into one VCF file. \nSimilar to QC pipeline, imputation needs to run on Linux server.  During the pre-phasing step, there are three methods to choose   HAPI-UR, MaCH and Automatic \nFor automatic method, MaCH is used for studies with less than 1000 subjects and HAPI-UR is used for studies with at least 1000 subjects.\nThe choice of HAPI-UR for bigger studies is primarily due to computational speed reason. \nPre-phasing is the most time-consuming step. \nIt is estimated that using MaCH, 40~50 hours on 40-node cluster are needed to phase ~180 subjects based on ~4 million markers. \nIt is highly advisable that users find out the number of nodes available on their servers/clusters to determine an optimal number of jobs (Job number) for this step.  Users can also try it out by running imputation for one chromosome region (e.g. 50 mb) to estimate the number needed. \nThis can be achieved by entering   in the SNP list field as shown in the figure below.  Users can specify a subset of subjects instead of the entire set of subjects available in the plink files for imputation. \nThis allows flexibility to impute data for a subset of subjects should there be a need to exclude certain subjects from the post-QC plink files.  The following options can be specified for the imputation process.    Number of iterations : \n    This is one of the two key parameters used to infer haplotypes during the phasing stage. \n    It specifies how many iterations of the Markov sampler should be run. \n    These iterations are used to simultaneously update the crossover map, to update the error rate map and to estimate the missing genotypes. \n    A set value of 20 is given.    Number of haplotypes : \n    This is the other key parameter used to infer haplotypes during the phasing stage. \n    It specifies how many haplotypes should be considered when updating each individual. \n    A set value of 200 is given.    Number of markers per chunk : \n    This option specifies the number of markers to be included in a chromosome chunk during the phasing stage.\n    It is recommended that hundreds (not thousands) of chunks be generated for a given GWAS panel. \n    For example, 5000 markers/chunk can be specified for a 5M GWAS panel.    Number of markers in the overlap region : \n    It is crucial that adjacent chunks are overlapped such that phasing is done correctly. \n    It is recommended that the overlap is at least 100kb. \n    This is often achieved by specifying the overlap no less than one fourth of the chunk size. \n    For example, 1500 markers/chunk can be specified with 5000 markers/chunk for a 5M GWAS panel.    Reference library :\n    Human B37.3 is currently used for the reference panel.    Job number : \n    This needs to be determined by the number of core processors on the server. \n    A higher number would improve the overall speed of the process.    The output of the imputation step will be saved in the output folder specified.\nUsers can use the  Browse  button to choose output folder.\nIn this tutorial, chromosome 20 is imputed with HAPI-UR using 8 nodes (Job number = 8) on the server. \nPlease click  Send To Queue  to run imputation step.",
            "title": "Imputation process"
        },
        {
            "location": "/tutorials/GWAS/Imputation/#imputation-output",
            "text": "At the end of the imputation process, a single VCF file is generated that combines data from all the chromosome chunks.\nIn the VCF file, chromosome, position, reference allele, alternative allele, marker ID, imputation quality (R2), minor allele frequency (MAF), \ngenotyped or imputed (Is Genotype), and allelic dosage data are included.\nThe VCF table will show under Table.  In this table, rows correspond to variants.\nColumns provide aforementioned information on variants and from column 10 and onwards, subjects  genotype and dose information are presented.\nA subject s ID is represented by  Family ID -> Individual ID  as provided in the original plink files. \nIn this instance (as pointed by the red arrow), the first subject is NA18524->NA18524 with both Family ID and Individual ID being NA18524.\nImputed data of the first marker for this subject is 0|0:0.000 as shown in the red rectangle in the figure below. \nThe notation is based on output of GT:DS where GT is imputed genotype and DS is the imputed dosage data.\nIn the \"Is Genotype\" column, \"False\" means this marker is imputed, while  True  means this marker is included in genotyping file and not from imputation result.",
            "title": "Imputation Output"
        },
        {
            "location": "/tutorials/GWAS/Association/",
            "text": "Association\n\u00b6\n\n\nThe association analysis module provides a high-throughput genetic association analysis pipeline for tens of millions of genetic variants.\nUsers can build genetic association analysis models for continuous, binary and survival endpoints with or without covariates and interaction terms.\nStratified analysis is also available for survival model.\n\n\nThroughout, additive genetic models will be used, which means genotype data are coded as 0, 1 or 2, \nwhile imputed dosage data will range from 0 to 2 on a continuous scale to reflect the estimates of the imputed dose.\nTo ensure consistent analysis and annotation of the results, 0, 1 or 2 always refer to 0, 1 or 2 copies of the alternative allele.\n\n\nInput file format\n\u00b6\n\n\nAs shown in the figure below, input files for genetic data can be genotypes in VCF or Plink BED format, or dose data in the VCF format.\n\n\nAn input \nphenotype file\n needs to be specified separately, where subject IDs need to be in the first column, followed by phenotype and covariates. \nSubject IDs need to be the same as those in the genetic data file. \nIn the case of the plink format, subject IDs need to match individual IDs if they are different from family IDs. \nIt is possible to specify a region of SNPs for analysis by using a special syntax in the  SNP list  field. \nFor example, by specifying  <15:1-10000> , analysis will only be based on the region on chromosome 15 from base pair position 1 to 10000.\n\n\nIn the current version of the analysis module, users need to combine PCA results from the QC step ( PCA_results.txt ) with phenotype data,\nand provide this combined dataset along with the genotype data, to be used in the association analysis.\nFor the purposes of this tutorial, a combined Phenotype file ( Phenotype.txt ) has been provided, so can be directly used with the imputed genotype data from the previous section.\n\n\nIn this tutorial, we use the imputed VCF file (as VCF dose type) as genotype input.\nThe phenotype file in the downloaded zip folder contains the CPNE1 gene expression data downloaded from the Geuvadis RNA sequencing project, gender information, and the first 3 principal components from the previous QC step.\n\n\n\n\nAnalysis model\n\u00b6\n\n\nCurrently, three statistical models are supported in the association analysis module: Linear model for continuous traits, \nlogistic regression for binary traits and Cox proportional hazard model for survival endpoints.\n\n\nBy clicking \nSpecify Model (Phenotypes and Covariates)\n, users can specify phenotype trait and covariates in the phenotype file. \nPhenotype and covariates can be in any order in the phenotype file.\n\n\nThe model below shows how to analyze a continuous trait, \nCPNE1\n gene expression data.\nThis analysis is an eQTL analysis to find the SNPs in chr20 that are significantly associated with \nCPNE1\n gene expression. \nIn this step, please first add the file containing imputed dosage vcf data (from the previous step), and the expression file that is in the downloaded zipped folder (\"Phenotype.txt\").\nAfter selecting \nSpecify Model (Phenotypes and Covariates)\n, the following interface will appear.\n\n\n\n\nColumns shown are those included in the phenotype file, which includes gender, first 3 PC scores and CPNE1 expression levels. \nIn this instance, please select CPNE1 expression level as the \ntrait\n.\n\nSNP\n is automatically selected to include in model. \nUsers can then highlight all the covariates for the model; \nin this example, they are \ngender\n, \nEigen1\n, \nEigen2\n and \nEigen3\n, which represent gender and the first three principle component scores.\nThe phenotype file includes all 210 samples. \nWhen performing association analysis, the subjects that are not in input VCF file will be excluded automatically.\n\n\nOnce the model is constructed, press OK and General window will appear again. \nNote now under \nSpecify Model (Phenotypes and Covariates)\n, the complete model is shown. \nUsers may inspect this model and make sure that this is correct. \nUsers may \nSpecify Model\n again to make changes to the model shown.\n\n\n\n\nIn the \nOptions\n panel, users can specify the following three options prior to analysis. \nOnly markers meeting the pre-specified thresholds will be included in the analysis.\n\n\n\n\n\n\nR2 cutoff (dose data only): only markers with imputation quality score R2 greater than the specified value will be included in the association analysis.\n\n\n\n\n\n\nHWE p-value cutoff (1 means no cutoff): \n    only markers with HWE p-value more significant than the specified cutoff value will be included in the association analysis.\n\n\n\n\n\n\nAllele count cutoff (0 means no cutoff): \n    only markers with at least the specified number of minor alleles will be included in the analysis. \n    For example, when 1 is specified as the cutoff value, all the monomorphic markers will be excluded from the analysis.\n\n\n\n\n\n\nP-values generated for both genotype and dose data are based on a likelihood test.\nFor binary and survival trait association test, if wald tests are desired, users can uncheck the box  Use likelihood test instead of wald test . \nLikelihood ratio tests can be more robust than wald tests for low frequency and rare markers.\n\n\n\n\nA variety of options for multiple testing adjustment are available. \nBonferroni correction is often used for a GWAS study where P-value < 5E-08 is considered as statistically significant. \nThe same significance threshold can be applied to genome-wide analysis based on imputed data.\n\n\nAs the association analysis is computationally intensive, especially for imputed data, users can specify a large  Job number , as long as it is supported by the server.\n\n\nLogistic regression and survival analysis can be carried out similarly.\nBy default, all the variables are numerical. \nA categorical variable can be specified by checking the box in the  Class  column by the  Term  of interest.\nBelow is an example (not in tutorial data).\nThe response variable (Term = binary trait) in the figure below is coded as 1 and 2. \nBy checking the box in the  Class  column beside it, the trait will be treated as a binary trait with two levels, 1 and 2.\n\n\n\n\n\n\nSimilar to continuous trait analysis, users can add covariates, interactions and nested models.\n\n\nIn this tutorial, we keep other options as default, specify an output name and output folder (as in the screenshot shown below), then click  Send To Queue  to submit the job.\n\n\n\n\nAssociation output\n\u00b6\n\n\nOnce an association analysis is complete, the results table will be available in the main window.\nThe name of this table will be shown in the Solution Explorer window ending with  .AssociationReport(GTT) . \nIn the report, you will find information on chromosome, position, variant ID, reference allele, alternative allele, analyzed subject number (N),\nalternative allele count (AC), alternative allele frequency (AF), Call Rate (CR), HWE p-value, SNP SE, SNP effect (or SNP Beta), raw p-value,\nBonferroni adjusted p-value, etc.\n\n\n\n\nIn the case of analysis of a binary trait or survival endpoint, reported effect estimates will be OR (Odds Ratio) or HR (Hazards Ratio), SE, 95% CI for OR or HR.\n\n\nThese results can be filtered based on SNP ID or chromosome position using the filter feature in the \nView Controller\n window.\n\n\nThe NCBI eQTL browser \nlink\n \nis a browser containing the information of expression quantitative trait loci (eQTL). \nUsers can use NCBI eQTL browser to find out the expression associated SNPs.\n\n\nIf we search for CPNE1 eQTL in chr20 in NCBI eQTL browser, \n\n\n\n\nWe will find the significant SNPs associated with CPNE1 gene expression level.\n\n\n\n\nPlease note that the positions shown in this browser are 0-based, while in our association result (and the input VCF file), the SNP positions are 1-based.\nTherefore, the SNP position shown in association result table should be adding 1 base to the position shown in eQTL browser.\neQTL browser shows rs6060535 (chr20:34235521) as the top SNP associated with CPNE1 which has the p-value of 2.3233e-28. \nWe can search position of rs6060535 (chr20:34235522) in the association report table. \nIt shows a very significant association with raw p-value in the order of e-27 which is quite comparable to NCBI eQTL browser.\n\n\n\n\nUsers can also try looking for the p-value of other significant SNPs shown in eQTL browser. \nPlease note that due to different study subjects, sample size, and study tissues, the p-values may show discrepancy when comparing our association result to NCBI eQTL browser.\n\n\nOne additional handy feature of the served-based analysis is the availability of the full log information.\nAs with all the served-based jobs, log information is available under the Server Jobs tab. \nAn example is shown below. \nBy right clicking the name of the job, a new window will pop up with the option to \nView Full Log\n.\nDetailed information on the analysis job is outlined in the log file step-by-step. \nThe full path name to the output folder is also listed just in case you forget which Output folder was specified during the analysis step.",
            "title": "Association"
        },
        {
            "location": "/tutorials/GWAS/Association/#association",
            "text": "The association analysis module provides a high-throughput genetic association analysis pipeline for tens of millions of genetic variants.\nUsers can build genetic association analysis models for continuous, binary and survival endpoints with or without covariates and interaction terms.\nStratified analysis is also available for survival model.  Throughout, additive genetic models will be used, which means genotype data are coded as 0, 1 or 2, \nwhile imputed dosage data will range from 0 to 2 on a continuous scale to reflect the estimates of the imputed dose.\nTo ensure consistent analysis and annotation of the results, 0, 1 or 2 always refer to 0, 1 or 2 copies of the alternative allele.",
            "title": "Association"
        },
        {
            "location": "/tutorials/GWAS/Association/#input-file-format",
            "text": "As shown in the figure below, input files for genetic data can be genotypes in VCF or Plink BED format, or dose data in the VCF format.  An input  phenotype file  needs to be specified separately, where subject IDs need to be in the first column, followed by phenotype and covariates. \nSubject IDs need to be the same as those in the genetic data file. \nIn the case of the plink format, subject IDs need to match individual IDs if they are different from family IDs. \nIt is possible to specify a region of SNPs for analysis by using a special syntax in the  SNP list  field. \nFor example, by specifying  <15:1-10000> , analysis will only be based on the region on chromosome 15 from base pair position 1 to 10000.  In the current version of the analysis module, users need to combine PCA results from the QC step ( PCA_results.txt ) with phenotype data,\nand provide this combined dataset along with the genotype data, to be used in the association analysis.\nFor the purposes of this tutorial, a combined Phenotype file ( Phenotype.txt ) has been provided, so can be directly used with the imputed genotype data from the previous section.  In this tutorial, we use the imputed VCF file (as VCF dose type) as genotype input.\nThe phenotype file in the downloaded zip folder contains the CPNE1 gene expression data downloaded from the Geuvadis RNA sequencing project, gender information, and the first 3 principal components from the previous QC step.",
            "title": "Input file format"
        },
        {
            "location": "/tutorials/GWAS/Association/#analysis-model",
            "text": "Currently, three statistical models are supported in the association analysis module: Linear model for continuous traits, \nlogistic regression for binary traits and Cox proportional hazard model for survival endpoints.  By clicking  Specify Model (Phenotypes and Covariates) , users can specify phenotype trait and covariates in the phenotype file. \nPhenotype and covariates can be in any order in the phenotype file.  The model below shows how to analyze a continuous trait,  CPNE1  gene expression data.\nThis analysis is an eQTL analysis to find the SNPs in chr20 that are significantly associated with  CPNE1  gene expression. \nIn this step, please first add the file containing imputed dosage vcf data (from the previous step), and the expression file that is in the downloaded zipped folder (\"Phenotype.txt\").\nAfter selecting  Specify Model (Phenotypes and Covariates) , the following interface will appear.   Columns shown are those included in the phenotype file, which includes gender, first 3 PC scores and CPNE1 expression levels. \nIn this instance, please select CPNE1 expression level as the  trait . SNP  is automatically selected to include in model. \nUsers can then highlight all the covariates for the model; \nin this example, they are  gender ,  Eigen1 ,  Eigen2  and  Eigen3 , which represent gender and the first three principle component scores.\nThe phenotype file includes all 210 samples. \nWhen performing association analysis, the subjects that are not in input VCF file will be excluded automatically.  Once the model is constructed, press OK and General window will appear again. \nNote now under  Specify Model (Phenotypes and Covariates) , the complete model is shown. \nUsers may inspect this model and make sure that this is correct. \nUsers may  Specify Model  again to make changes to the model shown.   In the  Options  panel, users can specify the following three options prior to analysis. \nOnly markers meeting the pre-specified thresholds will be included in the analysis.    R2 cutoff (dose data only): only markers with imputation quality score R2 greater than the specified value will be included in the association analysis.    HWE p-value cutoff (1 means no cutoff): \n    only markers with HWE p-value more significant than the specified cutoff value will be included in the association analysis.    Allele count cutoff (0 means no cutoff): \n    only markers with at least the specified number of minor alleles will be included in the analysis. \n    For example, when 1 is specified as the cutoff value, all the monomorphic markers will be excluded from the analysis.    P-values generated for both genotype and dose data are based on a likelihood test.\nFor binary and survival trait association test, if wald tests are desired, users can uncheck the box  Use likelihood test instead of wald test . \nLikelihood ratio tests can be more robust than wald tests for low frequency and rare markers.   A variety of options for multiple testing adjustment are available. \nBonferroni correction is often used for a GWAS study where P-value < 5E-08 is considered as statistically significant. \nThe same significance threshold can be applied to genome-wide analysis based on imputed data.  As the association analysis is computationally intensive, especially for imputed data, users can specify a large  Job number , as long as it is supported by the server.  Logistic regression and survival analysis can be carried out similarly.\nBy default, all the variables are numerical. \nA categorical variable can be specified by checking the box in the  Class  column by the  Term  of interest.\nBelow is an example (not in tutorial data).\nThe response variable (Term = binary trait) in the figure below is coded as 1 and 2. \nBy checking the box in the  Class  column beside it, the trait will be treated as a binary trait with two levels, 1 and 2.    Similar to continuous trait analysis, users can add covariates, interactions and nested models.  In this tutorial, we keep other options as default, specify an output name and output folder (as in the screenshot shown below), then click  Send To Queue  to submit the job.",
            "title": "Analysis model"
        },
        {
            "location": "/tutorials/GWAS/Association/#association-output",
            "text": "Once an association analysis is complete, the results table will be available in the main window.\nThe name of this table will be shown in the Solution Explorer window ending with  .AssociationReport(GTT) . \nIn the report, you will find information on chromosome, position, variant ID, reference allele, alternative allele, analyzed subject number (N),\nalternative allele count (AC), alternative allele frequency (AF), Call Rate (CR), HWE p-value, SNP SE, SNP effect (or SNP Beta), raw p-value,\nBonferroni adjusted p-value, etc.   In the case of analysis of a binary trait or survival endpoint, reported effect estimates will be OR (Odds Ratio) or HR (Hazards Ratio), SE, 95% CI for OR or HR.  These results can be filtered based on SNP ID or chromosome position using the filter feature in the  View Controller  window.  The NCBI eQTL browser  link  \nis a browser containing the information of expression quantitative trait loci (eQTL). \nUsers can use NCBI eQTL browser to find out the expression associated SNPs.  If we search for CPNE1 eQTL in chr20 in NCBI eQTL browser,    We will find the significant SNPs associated with CPNE1 gene expression level.   Please note that the positions shown in this browser are 0-based, while in our association result (and the input VCF file), the SNP positions are 1-based.\nTherefore, the SNP position shown in association result table should be adding 1 base to the position shown in eQTL browser.\neQTL browser shows rs6060535 (chr20:34235521) as the top SNP associated with CPNE1 which has the p-value of 2.3233e-28. \nWe can search position of rs6060535 (chr20:34235522) in the association report table. \nIt shows a very significant association with raw p-value in the order of e-27 which is quite comparable to NCBI eQTL browser.   Users can also try looking for the p-value of other significant SNPs shown in eQTL browser. \nPlease note that due to different study subjects, sample size, and study tissues, the p-values may show discrepancy when comparing our association result to NCBI eQTL browser.  One additional handy feature of the served-based analysis is the availability of the full log information.\nAs with all the served-based jobs, log information is available under the Server Jobs tab. \nAn example is shown below. \nBy right clicking the name of the job, a new window will pop up with the option to  View Full Log .\nDetailed information on the analysis job is outlined in the log file step-by-step. \nThe full path name to the output folder is also listed just in case you forget which Output folder was specified during the analysis step.",
            "title": "Association output"
        },
        {
            "location": "/tutorials/GWAS/Annotation/",
            "text": "Annotation\n\u00b6\n\n\nThe annotation feature enables variant-by-variant annotations based on genetic association results file or an input file provided by users that are in GTT, VCF, or BED format. The input can also be a set of RS_IDs. Annotated results will be available in the output folder specified if the Generate text files box is checked.\n\n\n\n\nAnnotation sources\n\u00b6\n\n\nUnder the annotation tab, the Variant based annotators 1000GenomesSimple_20170501 and ClinVar_20170501 are selected by default. But, all the available annotation sources are shown and users have the option to make selections. After annotation sources are selected, users can go back to the General tab to confirm all the options selected are as desired before submitting the job to the server.\n\n\n\n\nIf you would like to include additional annotation sources, please contact Omicsoft support team (\nsupport@omicsoft.com\n ). Requests will be reviewed and new features may be added in future releases of Array Suite.\n\n\nPlease keep other options as default, and click  Send To Queue  to submit the job.\n\n\nAnnotation output\n\u00b6\n\n\nAfter the job is finished, there will be an annotation result table (OSCR) that contains all the annotation information.\n\n\n\n\nBy right clicking the row ID, users can conveniently go to GeneCard, dbSNP, HaploregV2 and RegulomeDB to view corresponding information of that SNP.\n\n\nResults filtering\n\u00b6\n\n\nPlease note that for annotated Omicsoft SNP Classification Results\n('oscr \nhttp://www.arrayserver.com/wiki/index.php?title=Oscr\n'), variant annotation columns are fully interactive and can be filtered by mutation type, AA position and MAF etc.\n\n\nIn the Association chapter,we found the top SNP rs6060535 shown in NCBI eQTL browser also showed significant association with CPNE1 expression in our test Hapmap data. Now we can look for more detailed information about this SNP.\n\n\nBy searching the SNP ID and scrolling to the last annotation term (RegulomeDB), we will find rs6060535 is in class 1f,\nwhich means this SNP is an eQTL, and also in transcription factor (TF) binding site or a DNase hypersensitive peak.\nThis also provides evidence to support our finding that rs6060535 is significantly associated with CPNE1 gene expression level.\n\n\n\n\nWe can also find all the significant SNPs associated with CPNE1 gene expression level by setting up a cutoff.\nFor example, we can find all the SNPs which show Bonferroni P-value smaller than 5E-8.\nFrom the result, there are 162 SNPs in chr20 that show significant association with CPNE1 expression level in our tutorial Hapmap data in the level of Bonferroni P-value smaller than 5E-8.",
            "title": "Annotation"
        },
        {
            "location": "/tutorials/GWAS/Annotation/#annotation",
            "text": "The annotation feature enables variant-by-variant annotations based on genetic association results file or an input file provided by users that are in GTT, VCF, or BED format. The input can also be a set of RS_IDs. Annotated results will be available in the output folder specified if the Generate text files box is checked.",
            "title": "Annotation"
        },
        {
            "location": "/tutorials/GWAS/Annotation/#annotation-sources",
            "text": "Under the annotation tab, the Variant based annotators 1000GenomesSimple_20170501 and ClinVar_20170501 are selected by default. But, all the available annotation sources are shown and users have the option to make selections. After annotation sources are selected, users can go back to the General tab to confirm all the options selected are as desired before submitting the job to the server.   If you would like to include additional annotation sources, please contact Omicsoft support team ( support@omicsoft.com  ). Requests will be reviewed and new features may be added in future releases of Array Suite.  Please keep other options as default, and click  Send To Queue  to submit the job.",
            "title": "Annotation sources"
        },
        {
            "location": "/tutorials/GWAS/Annotation/#annotation-output",
            "text": "After the job is finished, there will be an annotation result table (OSCR) that contains all the annotation information.   By right clicking the row ID, users can conveniently go to GeneCard, dbSNP, HaploregV2 and RegulomeDB to view corresponding information of that SNP.",
            "title": "Annotation output"
        },
        {
            "location": "/tutorials/GWAS/Annotation/#results-filtering",
            "text": "Please note that for annotated Omicsoft SNP Classification Results\n('oscr  http://www.arrayserver.com/wiki/index.php?title=Oscr '), variant annotation columns are fully interactive and can be filtered by mutation type, AA position and MAF etc.  In the Association chapter,we found the top SNP rs6060535 shown in NCBI eQTL browser also showed significant association with CPNE1 expression in our test Hapmap data. Now we can look for more detailed information about this SNP.  By searching the SNP ID and scrolling to the last annotation term (RegulomeDB), we will find rs6060535 is in class 1f,\nwhich means this SNP is an eQTL, and also in transcription factor (TF) binding site or a DNase hypersensitive peak.\nThis also provides evidence to support our finding that rs6060535 is significantly associated with CPNE1 gene expression level.   We can also find all the significant SNPs associated with CPNE1 gene expression level by setting up a cutoff.\nFor example, we can find all the SNPs which show Bonferroni P-value smaller than 5E-8.\nFrom the result, there are 162 SNPs in chr20 that show significant association with CPNE1 expression level in our tutorial Hapmap data in the level of Bonferroni P-value smaller than 5E-8.",
            "title": "Results filtering"
        },
        {
            "location": "/tutorials/GWAS/Save_Close_Project/",
            "text": "Save & Close Project\n\u00b6\n\n\nAs one last step, users may need to save the project.\nThis is especially important if users made changes to a table view that need to be saved on the server.\nUsers can access all the information saved in this project in the future by selecting Open Server Project in the File menu.\n\n\n\n\nCongratulations! You are done with the analysis.\nYou can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.\n\n\nThank you for using Array Studio.\n\n\nPlease contact Omicsoft Support (\n \nsupport@omicsoft.com\n \n) or Omicsoft Sales (\n \nsales@omicsoft.com\n \n) if you have any questions questions.",
            "title": "Save/Close Project"
        },
        {
            "location": "/tutorials/GWAS/Save_Close_Project/#save-close-project",
            "text": "As one last step, users may need to save the project.\nThis is especially important if users made changes to a table view that need to be saved on the server.\nUsers can access all the information saved in this project in the future by selecting Open Server Project in the File menu.   Congratulations! You are done with the analysis.\nYou can reopen this project later on to get back to the same state as you saved.\nThis includes all views, filters, analyses, etc.  Thank you for using Array Studio.  Please contact Omicsoft Support (   support@omicsoft.com   ) or Omicsoft Sales (   sales@omicsoft.com   ) if you have any questions questions.",
            "title": "Save &amp; Close Project"
        },
        {
            "location": "/tutorials/Transgene/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nTransgene\n\u00b6\n\n\nA transgene is genetic material transferred to a host genome by genetic engineering techniques, either by (1) integration by insertion or (2) integration by homologous recombination.\n\n\n\n\nThe transgene detection functions described here are designed to identify transgene integration. The workflow reports a list of detected transgene integration sites, statistics of supporting reads, as well as genomic locations of breakpoints, which characterize transgene sites comprehensively at base-pair resolution. Alignment files (NgsData) will also be generated to visualize transgene events in the genome browser, and variation detection of the product.\n\n\nTest Dataset\n\u00b6\n\n\nDownload link: \nhttp://omicsoft.com/downloads/data/Tutorial/Transgene.zip\n\n\nThe test data contains files below\n\n\n\n\nPlasmid reference sequence in FASTA format\n\n\nPlasmid gene model in GTF format.\n\n\nPlasmid gene location in BED format\n\n\n2x100bp paired end fastq.gz files containing NGS reads from regions surrounding the transgene.\n\n\n\n\nIt is a semi-simulated dataset mimicking enrichment of transgene regions using pull down techniques.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Transgene/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/Transgene/Introduction/#transgene",
            "text": "A transgene is genetic material transferred to a host genome by genetic engineering techniques, either by (1) integration by insertion or (2) integration by homologous recombination.   The transgene detection functions described here are designed to identify transgene integration. The workflow reports a list of detected transgene integration sites, statistics of supporting reads, as well as genomic locations of breakpoints, which characterize transgene sites comprehensively at base-pair resolution. Alignment files (NgsData) will also be generated to visualize transgene events in the genome browser, and variation detection of the product.",
            "title": "Transgene"
        },
        {
            "location": "/tutorials/Transgene/Introduction/#test-dataset",
            "text": "Download link:  http://omicsoft.com/downloads/data/Tutorial/Transgene.zip  The test data contains files below   Plasmid reference sequence in FASTA format  Plasmid gene model in GTF format.  Plasmid gene location in BED format  2x100bp paired end fastq.gz files containing NGS reads from regions surrounding the transgene.   It is a semi-simulated dataset mimicking enrichment of transgene regions using pull down techniques.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/",
            "text": "Data Analysis\n\u00b6\n\n\nIn this tutorial, we will show how to run the following analysis: build genome reference, raw data QC, pre-processing, coverage analysis, transgene detection, consensus inference and variation detection, . The general analysis workflow can be illustrated as below:\n\n\n\n\nWe will show each step one by one in this tutorial. All these steps can be concatenated together using OmicScript to be a standard pipeline and generate report using ExportToReport function.\n\n\nBuild plasmid Reference and Gene Model\n\u00b6\n\n\nFor transgene analysis, the user has to build a genome reference for the plasmid sequence. To build a reference library, use \nNGS | Build | Build Reference Library\n to build the reference from a FASTA file:\n\n\n\n\nInput any name for Reference Library ID:\n\n\n\n\nIf the user also has the gene model files (GTF or GFF) for the plasmid, a gene model can also be built in \nNGS | Build | Build Gene Model\n. It is optional for transgene analysis.\nWith a gene model, the genome browser can show the transgene integration site along with gene annotation on the genome. The mutation analysis can also use a gene model to assess the impact of the variation (in order to check whether it is causing amino acid changes or not).\n\n\n\n\nOnce built, the user can check how the reference and gene model look like in the Genome Browser:\n\n\n\n\n\n\nNote\n\n\nIf you do not see your new reference in the drop-down menu, de-select the option \"List Server components\". This is because the reference you have build that is stored in your local cache, not the server.  If you wish to perform this tutorial, please connect to ArrayServer, and create a Server Project before building your reference genome and gene model.\n\n\n\n\nYou will get a genome browser view of the plasmid in linear scale:\n\n\n\n\nRaw Data QC\n\u00b6\n\n\nOnce user gets raw data from NGS machine, it is best to go through the raw data QC step to check data quality.\n\n\nArray Studio contains modules for QC of raw data files. The easiest way is to run \nRaw Data QC Wizard\n, which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis.\n\n\n\n\nClick \nAdd\n to find all fastq files, and check the QC metrics to run. Optionally, for a faster analysis, the user can choose \npreview mode\n to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave File format to AUTO and \nQuality encoding\n as \nAutomatic\n to automatically set the correct quality encoding method.\n\n\n\n\nClick \nSubmit\n to begin the analysis.\n\n\nThe raw data QC returns multiple raw data QC results/reports in \nRaw Data QC\n folder:\n\n\n\n\nThe basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.\n\n\nThe Sequence length report shows the distribution of read length. For original data from the sequencer, read length should be the same. After the user runs pre-processing such as trimming and adapter stripping, the read lengths will be different. The distribution of sequence length will show the final read length after trimming and stripping.\n\n\nBase distribution of each raw data file is useful for ensuring that the base distribution is as expected\n(sometimes can be used to notice adapter sequences if the user is not aware that they are there as well).\n\n\nQuality BoxPlot shows, for each base pair position in a file, information on the quality scoring at that position.\nThis gives the user an idea of where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality of multiple samples.\n\n\nThe K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of a kmer on a particular region of the read.\nIt can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.\nIn the \nKMerAnalysis\n profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each KMer.\nThere is no significant (all less than 1%) enrichment of k-mer in this tutorial dataset.\n\n\nAlignment\n\u00b6\n\n\nAlign to Host\n\u00b6\n\n\nUser should then align reads to host genome. At this moment, we provided two CHO reference genomes:\n\n\n\n\nCriGri.B1.0: the original BGI version\n\n\nCriGri.B1.1: based on NCBI, Genome reference \"C_griseus_v1.0\".\n\n\n\n\n\n\nCheck \"\nReads are paired\n\", and specify output name in the \nAdvanced\n tab.\nThe user can leave all other options as default in general tab. Some companies may require users to specify the output folder too.\n\n\n\n\nThe Advanced menu has more options to specify the indel length. By default, it detects deletion up to 1000bp and insertion up to 10bp. However, it is designed for regular human/mouse DNA-Seq samples. For mutation detection in plasmids, it is recommended to decrease the upper limit of deletion length to 10bp. The expected insert size in this dataset is 800bp since the data was simulated based on SRA dataset SRX091184.\n\n\n\n\nIt will align to host, CHO reference, and generate NgsData (BAM files) and alignment statistics.\n\n\nNgsData in ArrayStudio Projects:\n\n\n\n\nAlignment reports summarize the alignment statistics, such as fragment size of paired end reads, # and % of reads uniquely aligned.\n\n\n\n\nIn the coverage analysis step, users can further use the NgsData to count the # of reads mapped to each contig, and get coverage report/views at base pair resolution.\n\n\nAlign to Plasmid\n\u00b6\n\n\nBefore alignment to plasmid, the user will have to pre-build plasmid genome reference from FASTA files.\nAs mentioned in the previous step, the user has to build a plasmid reference: pGRG36, for this tutorial.\n\n\n\n\n\n\nMore options can be found under the \nAdvanced\n tab:\n\n\n\n\nIt will align to plasmid reference, and generate NgsData (BAM files) and alignment statistics.\n\n\nNgsData in ArrayStudio Projects:\n\n\n\n\nAlignment reports:\n\n\n\n\nCoverage analysis on host genome\n\u00b6\n\n\nQuantify Coverage on contigs\n\u00b6\n\n\nSince the CHO genome reference is not yet well defined, there are many contigs from CHO, and the user will get lost by looking at coverage directly. The user can first quantify the coverage on each contig, and get the percentage of mapped reads in each contig.\n\n\nThe \nNGS | Quantification | Report Gene/Transcript Count\n function is designed to quantify gene expression from RNA-Seq data. If the input is DNA-Seq data, it will quantify the read counts on each contig/chr:\n\n\n\n\nChoose the host alignment NgsData, and choose expression measurement to be \nCount\n; \nCount fragments\n instead of reads will count properly paired reads only; \nEM algorithm\n will assign reads mapped to multiple contigs based on EM iterations.\n\n\nIt will generate an OmicData with rows for contigs and columns for samples:\n\n\n\n\nThe default data object name still contains \"Transcript\" since it was designed for RNA-Seq. User can always rename it to other names such as \nAlignToHost.ContigReadCount\n.\n\n\nThe data values are EM read counts for each contig. User can further convert them to percentages of mapped reads in each contig by using \nNGS | Inference | Normalize RNA-Seq Data\n (again, the function was designed for RNA-Seq, but can be applied to DNA-Seq data).\n\n\n\n\nUse the \nTotalCount\n method and scale the total count to 1, then the count of reads will be normalized as percentage of reads mapped to each contigs.\n\n\n\n\nIn the table, user can right click the header and sort the table column descending.\nIt shows top contigs which have been enriched in the NGS library.\n\n\nBy selecting top contigs, user can create a list of them for filtering purpose in other tables.\nRight click on \nList\n, \"Add list from selected rows\" and name it \"TopContigs\":\n\n\n\n\nSummarize Coverage\n\u00b6\n\n\nThe \nNGS | Coverage | Coverage Summary Statistics\n module can be used to calculate the coverage of the mapping at defined bin resolution or export as a bedgraph file at base pair resolution.\n\n\n\n\nPick the \nHost alignment\n NgsData as Data input.\n\n\nExclude multi-reads: Multi reads are considered non-unique (i.e. reads that align to multiple genomic locations with equal or similar numbers of mismatches). Selecting this option will include unique reads only when performing the coverage summarization.\n\n\nExclude duplicates: duplicate reads are reads mapped to the exact same location. Duplicated reads are excluded by default in most NGS modules.\n\n\nThe coverage will be summarized in each bin size specified. If user wants to have the basepair resolution coverage, he/she can choose to output \nbedGraph\n files.\n\n\nThe output is a table of coverage values in each bin for each sample.\n\n\n\n\nIt also generates a histogram of coverage on all contigs.\nHowever, there are so many contigs in CHO, it is recommended to use top contigs as a filter to filter the table, then open the histogram plot.\n\n\nIn the View Controller on the right, select the Row tab, then right-click on \"Chromosome\" and select \"Add List Filter\". For some tables, it has been set as check box by default. If you do not see \"Add list Filter\", please change the column to \"String Filter\". User can also type the following contigs in the String filter in to check contigs:\n\n\n\n\nCheck coverage at base pair resolution using BedGraph file in Genome Browser\n\u00b6\n\n\nThe bedGraph files contain continuous coverage data in track format. It is generated by the coverage analysis and loads much faster in genome browser than loading the actual BAM files.\n\n\nSteps:\n\n\nCreate new genome browser:\n\n\n\n\nAdd Track | Add Track from Server Files | Numeric Tracks | BedGraph file\n\n\n\n\nSelect the bedgraph files generated in the output folder:\n\n\n\n\nJump to contigs of interest to browse coverage at base pair resolution:\n\n\n\n\nIntegration Detection\n\u00b6\n\n\nTag Split\n\u00b6\n\n\nIf the NGS library fragments are generated from digestion with a cutting enzyme, it may generate random chimeric DNA fragments which results in false positives in  transgene detection. If the cutting enzyme relies on short restriction NT sites, it can bring a lot of false positives in the downstream analysis. If we know the restriction NT combinations, users can first split the reads when finding an enzyme cutting site. It can greatly reduce the false positives in transgene detection.\n\n\nUsers can split reads by Tag in the Analysis tab by navigating to \nNGS | Preprocess | Split by Tag\n:\n\n\n\n\nAdd the sample fastq data from server folder:\n\n\n\n\n\n\nInput format:\n\n    choose AUTO and it will check file format automatically\n\n\n\n\n\n\nQuality encoding:\n\n    the encoding for quality score; recommend using Automatic.\n\n\n\n\n\n\nTag sequence:\n\n    The sequence tag which will be recognized by restriction enzyme.\n\n\n\n\n\n\nMinimal sequence length:\n\n    The read will be thrown again if length < MinLength after split\n\n\n\n\n\n\nZip format:\n\n    no gzip or bzip format.\n\n\n\n\n\n\nThe program will go over each fastq file and split reads recursively based on the tag:\n\n\n\n\nNew fastq.gz files will be generated in the output folder.\n\n\nNote, it is also possible that there are enzyme sites near the true integration site. These sites will not be detected when running Transgene Detection using split reads.\n\n\nTransgene Detection\n\u00b6\n\n\nFrom the raw data (or split read data if Split by Tag has been run), user can start to run transgene detection in \nNGS | Fusion | Transgene Integration Analysis\n:\n\n\n\n\n\n\nAdd data from server folder and follow the following options:\n\n\n\n\n\n\nInput format:\n\n    choose AUTO and it will check file format automatically\n\n\n\n\n\n\nReads are paired Check box:\n\n    if the box is checked, read1 and read2 files will be automatically paired based on read names as one sample for integration analysis.\n\n\n\n\n\n\nHost genome:\n\n    the host genome to detect integration; Make sure you pick the same host reference as in the previous alignment step.\n\n\n\n\n\n\nPlasmid genome:\n\n    the custom plasmid genome built by user.\n\n\n\n\n\n\nQuality encoding:\n\n    the encoding for quality score; we recommend using Automatic.\n\n\n\n\n\n\nZip format:\n\n    no gzip or bzip format.\n\n\n\n\n\n\nThread number:\n\n    Number of Threads for each job.\n\n\n\n\n\n\nJob number:\n\n    Number of parallel jobs to run.\n\n\n\n\n\n\nCut size:\n\n    the minimum size of read end to be aligned to host or plasmid. For read length > 75 bp, we recommend using 25. If read length is less than 75bp, please use\n    the formula (ReadLength/3).\n\n\n\n\n\n\nExtension:\n\n    display the left and right extension length of integration junction sequence in the report; will be used to filter false positives caused by restriction enzyme.\n\n\n\n\n\n\nPerform consensus analysis for partially aligned reads:\n\n    If checked, the function will scan reads partilly aligned to plasmid reference, and infer the consensus on soft clipped read sequences. Since the CHO genome is not a complete reference, the consensus analysis for partially aligned reads potentially will find integration sites which are not part of the current CHO genome reference.\n\n\n\n\n\n\nMinimal clipping:\n\n    The minimal length of clipping region of the read to be used for consensus analysis\n\n\n\n\n\n\nMinimal read#:\n\n    The minmal number of reads to report a integration site from consensus analysis\n\n\n\n\n\n\nOutput folder:\n\n    Browse to specify the output folder.\n\n\n\n\n\n\nIn the \nAdvanced\n tab:\n\n\n\n\nMore options:\n\n\n\n\n\n\nRead Trimming\n: We recommend the default settings as filtering will typically be done before users get to this step.\n\n\n\n\n\n\nMask fuzzy plasmid/host fusion\n: check this box if user wants to mask regions that are the same in plasmid and host, such as the EASE region in CHO.\n\n\n\n\n\n\nExclude fusion if cutting position#\n: number of cutting position means number of unique reads. The default cut off is one single read support.\n\n\n\n\n\n\nMisc\n: generate table land to support big report tables; checking this option will make it easier to share this data with others when complete.\n\n\n\n\n\n\nSet an output name in ArraySuite project.\n\n\n\n\n\n\nClick \nSend to Queue\n and it will send the job to run on server.\n\n\nOnce the job finishes, you can update the project with results and will see three NgsData objects and three result tables:\n\n\n\n\nTransgeneReport_PlasmidHost\n: reports the number of support reads for each transgene integration site for each sample, with information of the integration positions in host and plasmid.\n\n\n\n\nFor better characterization of integration site, a column named \"Integration Type\" is reported, based on the definition in the schematic below:\n\n\n\n\nExample:\n\n\nTRANS_1140_165663373(--) is an integration site between plasmid position 1141 to CHO NW_003613610.1, with 9 reads (8 unique read sequences) supporting from the this dataset. From integration type, user can tell that plasmid sequence starting 1141 has been integrated after CHO NW_003613610.1 position 3346702.\n\n\nTRANS_10161_165672719(++) is an integration site between plasmid position 10162 to CHO NW_003613610.1, with 23 reads (19 unique read sequences) supporting from this dataset. From integration type, user can tell that integration of plasmid ends at 10162 and then continues with CHO seqeunce starting from NW_003613610.1 position 3356048.\n\n\nThis data is quite clean and does not have any false positives. Due to the nature of enrichment technology, it is possible to have many false positives introduced, as mentioned in the \"Split by Tag\" section. If user does not run the transgene detection using fastq files from \"Split by Tag\" run, user should filter the detection table based on integration junction sequence (such as not containing \"CATG\" for Targeted Locus Amplification (TLA) datasets, using filter \"not catg\" in the junction sequence), top contigs, and # of supporting reads. Note that the \"Split by Tag\" option, while useful to filter out false positives, has the potential to generate false negatives. Users of this tutorial will notice that only one of the two fusions are detected when using the split fastq files. Thus, filtering of false positives should be done on a case-by-case basis, with users defining how many false positives they can tolerate.\n\n\nFor a table with multiple samples, user can get the summary statistics on read counts, such as max of unique reads in any samples,\nusing \nTable | Columns | Add Columns | Column Summarization | Pick columns and pick summarization method\n.\n\n\n\n\nTransgeneReport_PlasmidPlasmid\n: report the number of support reads for each plasmid-to-plasmid integration in each sample, with information of the integration positions in host and plasmid.\n\n\nTransgene.TransgeneReport_Consensus\n: report the number of supporting reads from consensus analysis. The direction indicates the location of consensus sequence relative to the plasmid breakpoint. The consensus sequences that are inferred from soft clipped reads should be part of the host (such as CHO) genome. It reports the number of supporting clipped reads and total number of reads (the total coverage) at the breakpoint.\n\n\n\n\nUsers can further visualize these integration sites in genome browser based on the NgsData.\n\n\nGenome Browser Of Transgene Integration\n\u00b6\n\n\nWithin the transgene report, right click on the row ID, user will have the option to open a new genome browser:\n\n\n\n\nIn the example above, right click on TRANS_1140_165663373(--), which it has option to open one of two NgsData objects.\nBecause we are in the plasmid-to-host transgene report table, choose to open the PlasmidHostFusion NgsData object.\nIt will jump to the Genome browser tab, and list available NGS samples to open:\n\n\n\n\nLeave all samples checked and click \nOK\n.\nIt will first load the coverage of these supporting reads on two panels, one for plasmid and the other for the host:\n\n\n\n\nUser can switch the two panes to have the breakpoints facing each other if necessary.\n\n\nNote, although we jump to this genome browser based on one transgene integration site, it loads the NgsData containing all integration site supporting reads.\nIf the current region contains multiple integration sites, the genome browser will show all supporting reads for them.\nUser can filter reads by transgene integration ID in the tag filter in genome browser track property:\n\n\n\n\nUser can mouse over the sample genome browser track name and it will pop up a tooltip allowing user to display the supporting reads. If the option is grey, please zoom in a little bit\nto < 200bp region:\n\n\n\n\nStrikethrough of part of the read means the read part is not aligned to the region: Part of the read is aligned to plasmid and the rest of the read is aligned to host.\n\n\nUser can also view the consensus inference in genome browser.\n\n\n\n\nUser can filter genome browser alignment by Cigar filter to softclipping reads only, and set minimal length of softclip to be 5 or 10.\n\n\n\n\nFrom the alignment of softclipped region (read parts with strike), the genome view can help user visually check the consensus seqeunce, starting with ACATCAGCCCACGTTTCCAGTTGATGA. User can use PCR to verify the integration site if the reported consensus sequence is not a part of current host genome sequence.\n\n\nFor more information about genome browser such as sharing a genome browser, please read \nOmicsoft Genome Browser Tutorial\n\nHere is a general key for genome browser:\n\n\n\n\nVariation detection on transgene\n\u00b6\n\n\nBased on the alignment of NGS data to plasmid, we can further detect variation based on consensus mutations calls.\nTo do so, user can use the \nNGS | Variation | Summarize Variant Data (Omicsoft)\n:\n\n\n\n\n\n\nPick the Data to the NgsData of Plasmid alignment, change the \nMutation options\n.\nThe default mutation options are designed for regular human/mouse studies.\nFor production cell lines with enrichment on transgene regions, user should use high cutoff of position coverage and # of reads supporting mutation,\nwhile lowering the cutoff for mutation frequency.\nIn this way, user can detect confident variation, at very low frequency level since there might be hundreds of plasmid integrations to the host.\n\n\nAlso make sure to reduce the \"exclude mutation if maximal frequency\" option to zero to maximize the sensitivity:\n\n\n\n\nThe mutation report will contain three columns (coverage, read frequency and %Plus strand) for each data file, and additional annotation for the mutation,\nsuch as positions, reference and mutations:\n\n\n\n\nSorting this table by the mutation frequency, we can see that the most frequent mutation is MUT00000026. The mutation position on the plasmid is base pair 6930, reference is A and Variation is G, or an A->G. The position is covered by 87 reads and 87*0.6667=58 reads are supporting G in this position.\n\n\nUser can also create a view of Mutation Frequency vs. Coverage by adding a scatterplot view:\n\n\n\n\nSelecting data points will show details for these positions.\nUser can further customize the view using options highlighted in the screenshot below:\n\n\n\n\nRight click on the row names and show the mutation in genome browser with detailed pile-ups from reads:\n\n\n\n\nThe genome browser might be slow due to high coverage on these regions:\n\n\n\n\nIf gene model was built with CDS information for the plasmid, user can add the gene model in the genome browser using:\n\n\n\n\nWith the gene model, user can further use \nNGS | Variation | Annotate Variant Table Report\n to find Non-Synonymous changes.\nIf any exist, it will also annotate the exact amino acid changes.\n\n\n\n\nThe annotated mutation report will look like below, and can be filtered for certain mutation types (i.e. synonymous) in the View Controller on the right:",
            "title": "Analysis Workflow"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#data-analysis",
            "text": "In this tutorial, we will show how to run the following analysis: build genome reference, raw data QC, pre-processing, coverage analysis, transgene detection, consensus inference and variation detection, . The general analysis workflow can be illustrated as below:   We will show each step one by one in this tutorial. All these steps can be concatenated together using OmicScript to be a standard pipeline and generate report using ExportToReport function.",
            "title": "Data Analysis"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#build-plasmid-reference-and-gene-model",
            "text": "For transgene analysis, the user has to build a genome reference for the plasmid sequence. To build a reference library, use  NGS | Build | Build Reference Library  to build the reference from a FASTA file:   Input any name for Reference Library ID:   If the user also has the gene model files (GTF or GFF) for the plasmid, a gene model can also be built in  NGS | Build | Build Gene Model . It is optional for transgene analysis.\nWith a gene model, the genome browser can show the transgene integration site along with gene annotation on the genome. The mutation analysis can also use a gene model to assess the impact of the variation (in order to check whether it is causing amino acid changes or not).   Once built, the user can check how the reference and gene model look like in the Genome Browser:    Note  If you do not see your new reference in the drop-down menu, de-select the option \"List Server components\". This is because the reference you have build that is stored in your local cache, not the server.  If you wish to perform this tutorial, please connect to ArrayServer, and create a Server Project before building your reference genome and gene model.   You will get a genome browser view of the plasmid in linear scale:",
            "title": "Build plasmid Reference and Gene Model"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#raw-data-qc",
            "text": "Once user gets raw data from NGS machine, it is best to go through the raw data QC step to check data quality.  Array Studio contains modules for QC of raw data files. The easiest way is to run  Raw Data QC Wizard , which scans each file once to calculate all quality statistics such as GC content, per position nucleotide distribution, read length distribution, quality box plot, sequence duplication and K-mer analysis.   Click  Add  to find all fastq files, and check the QC metrics to run. Optionally, for a faster analysis, the user can choose  preview mode  to only generate QC on the first one million reads. This is, in most cases, good enough to get an assessment of quality. Leave File format to AUTO and  Quality encoding  as  Automatic  to automatically set the correct quality encoding method.   Click  Submit  to begin the analysis.  The raw data QC returns multiple raw data QC results/reports in  Raw Data QC  folder:   The basic statistics table contains some important information about your samples, including total Sample #, Minimum and Maximum read length (if pre-filtering has occurred), total Nucleotide #, and GC%. Use this table to confirm any expected values, as well as to get an idea of the overall size of your experiment.  The Sequence length report shows the distribution of read length. For original data from the sequencer, read length should be the same. After the user runs pre-processing such as trimming and adapter stripping, the read lengths will be different. The distribution of sequence length will show the final read length after trimming and stripping.  Base distribution of each raw data file is useful for ensuring that the base distribution is as expected\n(sometimes can be used to notice adapter sequences if the user is not aware that they are there as well).  Quality BoxPlot shows, for each base pair position in a file, information on the quality scoring at that position.\nThis gives the user an idea of where the quality starts to drop for most reads in a sample. It is useful to compare plots when evaluating sequencing quality of multiple samples.  The K-Mer Analysis module counts the enrichment of every possible 5-mer across the positions of the reads.\nThis analysis identifies whether there is an enrichment of a kmer on a particular region of the read.\nIt can help find overrepresented patterns, such as adapters being read through when inserted fragment is short.\nIn the  KMerAnalysis  profile view, Y-axis is the percentage of reads (0.001 means 0.1%) that contain each KMer.\nThere is no significant (all less than 1%) enrichment of k-mer in this tutorial dataset.",
            "title": "Raw Data QC"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#alignment",
            "text": "",
            "title": "Alignment"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#align-to-host",
            "text": "User should then align reads to host genome. At this moment, we provided two CHO reference genomes:   CriGri.B1.0: the original BGI version  CriGri.B1.1: based on NCBI, Genome reference \"C_griseus_v1.0\".    Check \" Reads are paired \", and specify output name in the  Advanced  tab.\nThe user can leave all other options as default in general tab. Some companies may require users to specify the output folder too.   The Advanced menu has more options to specify the indel length. By default, it detects deletion up to 1000bp and insertion up to 10bp. However, it is designed for regular human/mouse DNA-Seq samples. For mutation detection in plasmids, it is recommended to decrease the upper limit of deletion length to 10bp. The expected insert size in this dataset is 800bp since the data was simulated based on SRA dataset SRX091184.   It will align to host, CHO reference, and generate NgsData (BAM files) and alignment statistics.  NgsData in ArrayStudio Projects:   Alignment reports summarize the alignment statistics, such as fragment size of paired end reads, # and % of reads uniquely aligned.   In the coverage analysis step, users can further use the NgsData to count the # of reads mapped to each contig, and get coverage report/views at base pair resolution.",
            "title": "Align to Host"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#align-to-plasmid",
            "text": "Before alignment to plasmid, the user will have to pre-build plasmid genome reference from FASTA files.\nAs mentioned in the previous step, the user has to build a plasmid reference: pGRG36, for this tutorial.    More options can be found under the  Advanced  tab:   It will align to plasmid reference, and generate NgsData (BAM files) and alignment statistics.  NgsData in ArrayStudio Projects:   Alignment reports:",
            "title": "Align to Plasmid"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#coverage-analysis-on-host-genome",
            "text": "",
            "title": "Coverage analysis on host genome"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#quantify-coverage-on-contigs",
            "text": "Since the CHO genome reference is not yet well defined, there are many contigs from CHO, and the user will get lost by looking at coverage directly. The user can first quantify the coverage on each contig, and get the percentage of mapped reads in each contig.  The  NGS | Quantification | Report Gene/Transcript Count  function is designed to quantify gene expression from RNA-Seq data. If the input is DNA-Seq data, it will quantify the read counts on each contig/chr:   Choose the host alignment NgsData, and choose expression measurement to be  Count ;  Count fragments  instead of reads will count properly paired reads only;  EM algorithm  will assign reads mapped to multiple contigs based on EM iterations.  It will generate an OmicData with rows for contigs and columns for samples:   The default data object name still contains \"Transcript\" since it was designed for RNA-Seq. User can always rename it to other names such as  AlignToHost.ContigReadCount .  The data values are EM read counts for each contig. User can further convert them to percentages of mapped reads in each contig by using  NGS | Inference | Normalize RNA-Seq Data  (again, the function was designed for RNA-Seq, but can be applied to DNA-Seq data).   Use the  TotalCount  method and scale the total count to 1, then the count of reads will be normalized as percentage of reads mapped to each contigs.   In the table, user can right click the header and sort the table column descending.\nIt shows top contigs which have been enriched in the NGS library.  By selecting top contigs, user can create a list of them for filtering purpose in other tables.\nRight click on  List , \"Add list from selected rows\" and name it \"TopContigs\":",
            "title": "Quantify Coverage on contigs"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#summarize-coverage",
            "text": "The  NGS | Coverage | Coverage Summary Statistics  module can be used to calculate the coverage of the mapping at defined bin resolution or export as a bedgraph file at base pair resolution.   Pick the  Host alignment  NgsData as Data input.  Exclude multi-reads: Multi reads are considered non-unique (i.e. reads that align to multiple genomic locations with equal or similar numbers of mismatches). Selecting this option will include unique reads only when performing the coverage summarization.  Exclude duplicates: duplicate reads are reads mapped to the exact same location. Duplicated reads are excluded by default in most NGS modules.  The coverage will be summarized in each bin size specified. If user wants to have the basepair resolution coverage, he/she can choose to output  bedGraph  files.  The output is a table of coverage values in each bin for each sample.   It also generates a histogram of coverage on all contigs.\nHowever, there are so many contigs in CHO, it is recommended to use top contigs as a filter to filter the table, then open the histogram plot.  In the View Controller on the right, select the Row tab, then right-click on \"Chromosome\" and select \"Add List Filter\". For some tables, it has been set as check box by default. If you do not see \"Add list Filter\", please change the column to \"String Filter\". User can also type the following contigs in the String filter in to check contigs:",
            "title": "Summarize Coverage"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#check-coverage-at-base-pair-resolution-using-bedgraph-file-in-genome-browser",
            "text": "The bedGraph files contain continuous coverage data in track format. It is generated by the coverage analysis and loads much faster in genome browser than loading the actual BAM files.  Steps:  Create new genome browser:   Add Track | Add Track from Server Files | Numeric Tracks | BedGraph file   Select the bedgraph files generated in the output folder:   Jump to contigs of interest to browse coverage at base pair resolution:",
            "title": "Check coverage at base pair resolution using BedGraph file in Genome Browser"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#integration-detection",
            "text": "",
            "title": "Integration Detection"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#tag-split",
            "text": "If the NGS library fragments are generated from digestion with a cutting enzyme, it may generate random chimeric DNA fragments which results in false positives in  transgene detection. If the cutting enzyme relies on short restriction NT sites, it can bring a lot of false positives in the downstream analysis. If we know the restriction NT combinations, users can first split the reads when finding an enzyme cutting site. It can greatly reduce the false positives in transgene detection.  Users can split reads by Tag in the Analysis tab by navigating to  NGS | Preprocess | Split by Tag :   Add the sample fastq data from server folder:    Input format: \n    choose AUTO and it will check file format automatically    Quality encoding: \n    the encoding for quality score; recommend using Automatic.    Tag sequence: \n    The sequence tag which will be recognized by restriction enzyme.    Minimal sequence length: \n    The read will be thrown again if length < MinLength after split    Zip format: \n    no gzip or bzip format.    The program will go over each fastq file and split reads recursively based on the tag:   New fastq.gz files will be generated in the output folder.  Note, it is also possible that there are enzyme sites near the true integration site. These sites will not be detected when running Transgene Detection using split reads.",
            "title": "Tag Split"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#transgene-detection",
            "text": "From the raw data (or split read data if Split by Tag has been run), user can start to run transgene detection in  NGS | Fusion | Transgene Integration Analysis :    Add data from server folder and follow the following options:    Input format: \n    choose AUTO and it will check file format automatically    Reads are paired Check box: \n    if the box is checked, read1 and read2 files will be automatically paired based on read names as one sample for integration analysis.    Host genome: \n    the host genome to detect integration; Make sure you pick the same host reference as in the previous alignment step.    Plasmid genome: \n    the custom plasmid genome built by user.    Quality encoding: \n    the encoding for quality score; we recommend using Automatic.    Zip format: \n    no gzip or bzip format.    Thread number: \n    Number of Threads for each job.    Job number: \n    Number of parallel jobs to run.    Cut size: \n    the minimum size of read end to be aligned to host or plasmid. For read length > 75 bp, we recommend using 25. If read length is less than 75bp, please use\n    the formula (ReadLength/3).    Extension: \n    display the left and right extension length of integration junction sequence in the report; will be used to filter false positives caused by restriction enzyme.    Perform consensus analysis for partially aligned reads: \n    If checked, the function will scan reads partilly aligned to plasmid reference, and infer the consensus on soft clipped read sequences. Since the CHO genome is not a complete reference, the consensus analysis for partially aligned reads potentially will find integration sites which are not part of the current CHO genome reference.    Minimal clipping: \n    The minimal length of clipping region of the read to be used for consensus analysis    Minimal read#: \n    The minmal number of reads to report a integration site from consensus analysis    Output folder: \n    Browse to specify the output folder.    In the  Advanced  tab:   More options:    Read Trimming : We recommend the default settings as filtering will typically be done before users get to this step.    Mask fuzzy plasmid/host fusion : check this box if user wants to mask regions that are the same in plasmid and host, such as the EASE region in CHO.    Exclude fusion if cutting position# : number of cutting position means number of unique reads. The default cut off is one single read support.    Misc : generate table land to support big report tables; checking this option will make it easier to share this data with others when complete.    Set an output name in ArraySuite project.    Click  Send to Queue  and it will send the job to run on server.  Once the job finishes, you can update the project with results and will see three NgsData objects and three result tables:   TransgeneReport_PlasmidHost : reports the number of support reads for each transgene integration site for each sample, with information of the integration positions in host and plasmid.   For better characterization of integration site, a column named \"Integration Type\" is reported, based on the definition in the schematic below:   Example:  TRANS_1140_165663373(--) is an integration site between plasmid position 1141 to CHO NW_003613610.1, with 9 reads (8 unique read sequences) supporting from the this dataset. From integration type, user can tell that plasmid sequence starting 1141 has been integrated after CHO NW_003613610.1 position 3346702.  TRANS_10161_165672719(++) is an integration site between plasmid position 10162 to CHO NW_003613610.1, with 23 reads (19 unique read sequences) supporting from this dataset. From integration type, user can tell that integration of plasmid ends at 10162 and then continues with CHO seqeunce starting from NW_003613610.1 position 3356048.  This data is quite clean and does not have any false positives. Due to the nature of enrichment technology, it is possible to have many false positives introduced, as mentioned in the \"Split by Tag\" section. If user does not run the transgene detection using fastq files from \"Split by Tag\" run, user should filter the detection table based on integration junction sequence (such as not containing \"CATG\" for Targeted Locus Amplification (TLA) datasets, using filter \"not catg\" in the junction sequence), top contigs, and # of supporting reads. Note that the \"Split by Tag\" option, while useful to filter out false positives, has the potential to generate false negatives. Users of this tutorial will notice that only one of the two fusions are detected when using the split fastq files. Thus, filtering of false positives should be done on a case-by-case basis, with users defining how many false positives they can tolerate.  For a table with multiple samples, user can get the summary statistics on read counts, such as max of unique reads in any samples,\nusing  Table | Columns | Add Columns | Column Summarization | Pick columns and pick summarization method .   TransgeneReport_PlasmidPlasmid : report the number of support reads for each plasmid-to-plasmid integration in each sample, with information of the integration positions in host and plasmid.  Transgene.TransgeneReport_Consensus : report the number of supporting reads from consensus analysis. The direction indicates the location of consensus sequence relative to the plasmid breakpoint. The consensus sequences that are inferred from soft clipped reads should be part of the host (such as CHO) genome. It reports the number of supporting clipped reads and total number of reads (the total coverage) at the breakpoint.   Users can further visualize these integration sites in genome browser based on the NgsData.",
            "title": "Transgene Detection"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#genome-browser-of-transgene-integration",
            "text": "Within the transgene report, right click on the row ID, user will have the option to open a new genome browser:   In the example above, right click on TRANS_1140_165663373(--), which it has option to open one of two NgsData objects.\nBecause we are in the plasmid-to-host transgene report table, choose to open the PlasmidHostFusion NgsData object.\nIt will jump to the Genome browser tab, and list available NGS samples to open:   Leave all samples checked and click  OK .\nIt will first load the coverage of these supporting reads on two panels, one for plasmid and the other for the host:   User can switch the two panes to have the breakpoints facing each other if necessary.  Note, although we jump to this genome browser based on one transgene integration site, it loads the NgsData containing all integration site supporting reads.\nIf the current region contains multiple integration sites, the genome browser will show all supporting reads for them.\nUser can filter reads by transgene integration ID in the tag filter in genome browser track property:   User can mouse over the sample genome browser track name and it will pop up a tooltip allowing user to display the supporting reads. If the option is grey, please zoom in a little bit\nto < 200bp region:   Strikethrough of part of the read means the read part is not aligned to the region: Part of the read is aligned to plasmid and the rest of the read is aligned to host.  User can also view the consensus inference in genome browser.   User can filter genome browser alignment by Cigar filter to softclipping reads only, and set minimal length of softclip to be 5 or 10.   From the alignment of softclipped region (read parts with strike), the genome view can help user visually check the consensus seqeunce, starting with ACATCAGCCCACGTTTCCAGTTGATGA. User can use PCR to verify the integration site if the reported consensus sequence is not a part of current host genome sequence.  For more information about genome browser such as sharing a genome browser, please read  Omicsoft Genome Browser Tutorial \nHere is a general key for genome browser:",
            "title": "Genome Browser Of Transgene Integration"
        },
        {
            "location": "/tutorials/Transgene/DataAnalysis/#variation-detection-on-transgene",
            "text": "Based on the alignment of NGS data to plasmid, we can further detect variation based on consensus mutations calls.\nTo do so, user can use the  NGS | Variation | Summarize Variant Data (Omicsoft) :    Pick the Data to the NgsData of Plasmid alignment, change the  Mutation options .\nThe default mutation options are designed for regular human/mouse studies.\nFor production cell lines with enrichment on transgene regions, user should use high cutoff of position coverage and # of reads supporting mutation,\nwhile lowering the cutoff for mutation frequency.\nIn this way, user can detect confident variation, at very low frequency level since there might be hundreds of plasmid integrations to the host.  Also make sure to reduce the \"exclude mutation if maximal frequency\" option to zero to maximize the sensitivity:   The mutation report will contain three columns (coverage, read frequency and %Plus strand) for each data file, and additional annotation for the mutation,\nsuch as positions, reference and mutations:   Sorting this table by the mutation frequency, we can see that the most frequent mutation is MUT00000026. The mutation position on the plasmid is base pair 6930, reference is A and Variation is G, or an A->G. The position is covered by 87 reads and 87*0.6667=58 reads are supporting G in this position.  User can also create a view of Mutation Frequency vs. Coverage by adding a scatterplot view:   Selecting data points will show details for these positions.\nUser can further customize the view using options highlighted in the screenshot below:   Right click on the row names and show the mutation in genome browser with detailed pile-ups from reads:   The genome browser might be slow due to high coverage on these regions:   If gene model was built with CDS information for the plasmid, user can add the gene model in the genome browser using:   With the gene model, user can further use  NGS | Variation | Annotate Variant Table Report  to find Non-Synonymous changes.\nIf any exist, it will also annotate the exact amino acid changes.   The annotated mutation report will look like below, and can be filtered for certain mutation types (i.e. synonymous) in the View Controller on the right:",
            "title": "Variation detection on transgene"
        },
        {
            "location": "/tutorials/Transgene/Others/",
            "text": "Others\n\u00b6\n\n\nBelow are some other useful options/functions.\n\n\nNGS Pre-Processing: Filter Reads\n\u00b6\n\n\nBesides split read by tags, there are a few of NGS data pre-processing steps which can improve the data quality and reduce background noise.  To filter bad reads and remove adapter sequences, use \nNGS | Preprocess | Filter\n:\n\n\n\n\nChoose the appropriate file format: AUTO or FASTQ based on your data, then click \nAdd\n to find input data.\nUse the default options but check \"\ninput files are paired\n\" option if your data is paired end or mate pair reads.\n\nChoose an Output folder for new fastq files\n:\n\n\n\n\nIn the \nAdvanced\n tab, click \nCustomize\n for the \nadapter Stripping\n section. There are two adapter types users can specify:\n\n\n3' end adapters\n: these are usually the type of adapters used in paired end reads. When NGS read length is short, the sequencer will get the adapter sequence as part of read sequences. The 3' adapter stripping does a localized alignment at the right end of the read and removes the adapter part of read ends. More details can be found in this wiki page: \nhttp://www.arrayserver.com/wiki/index.php?title=AdapterStripping_3%27End\n\n\nRight adapter:\n it is usually the type of short adapters used in mate pair reads. The adapter sequence has become a part of read sequence, in the middle of the read, but close to the 3' end. Array Studio aligns the adapter sequence against read sequence to strip up to where the best alignment to the adapter ends. All nucleotides after the adapter sequence are stripped away. More details can be found in this wiki page:\n\nhttp://www.arrayserver.com/wiki/index.php?title=AdapterStripping_Right\n\n\n\n\nAfter the filtering step, new fastq files will be generated. Again, this step is optional if data quality is good.\n\n\nUse Grouping File\n\u00b6\n\n\nIn Omicsoft, we consider one file as one sample, or two files as one sample if option \"reads are paired\" is checked.\nIn some cases, the user may have multiple files from multiple lanes for one NGS sample, such as one flow cell as one sample. Omicsoft provides a solution to input multiple files for one sample using the GroupingFile parameter.\nThe parameter should work for any NGS modules that take raw read files as input.\n\n\nFor more information about grouping files, please read:\n\nhttp://www.arrayserver.com/wiki/index.php?title=How_to_use_multiple_sequence_files_for_one_sample%3F\n\n\nIntegration Site Repository\n\u00b6\n\n\nUsers can export selected integration sites and save them to tab-delimitated text files. The flat file can serve as an integration site repository. Users can also use the file to annotate new transgene detection reports.\n\n\nTo export, select integration site Fusion ID, and click \"Export Integration Sites\". It will ask user to either create a new file or select an exisiting repository to append.\n\n\n\n\nTo annotate new tables with repository file, click \"Append Integration Sites Project Info\", select the repository text file, then two new columns (Project Name and Sample) will be appended to the report. It annotates the table with names of old samples analyzed in old projects having the same integration site. It is matched by the same host and plasmid reference ID, and their integration locations/directions.\n\n\n\n\nTarget Reads Extraction\n\u00b6\n\n\nTarget reads extraction is designed to extract target reads based on the read pair connectivity, such as pair-end and mate-pair linkage. Below is one example using mate pair, the Target Reads Extraction function is trying to extract target reads with its mate mapped to the designed capture region (transgene region):\n\n\n\n\nThis tool is useful when there are multiple transgene regions, such as tnsA and tnsD in the tutorial dataset.\nUser can design the capture region to be specific to the transgene and then use the target reads to do transgene integration site analysis. The result (integration site) will be transgene-specific since we only use the reads that are uniquely linked to the transgene region.\n\n\nTo run transgene target reads extraction, go to the NGS menu below:\n\n\n\n\nIn the analysis menu:\n\n\n\n\nSelect input format and click \"Add\" to add paired-end or mate pair raw data. It is better to add a filtered (filtered + adapter stripped) data set.\n\n\n\n\n\n\nInput format:\n the read file format, fastq, qseq or fasta;\n    most datasets from current next-generation sequencing machines are fastq\n\n\n\n\n\n\nAdd data from server; input files have to be paired based on regular paired or mate pair read file names\n\n\n\n\n\n\nHost genome:\n\n    the host genome to detect integration;\n\n\n\n\n\n\nPlasmid genome:\n\n    the plasmid genome built by user;\n\n\n\n\n\n\nQuality encoding:\n\n    the encoding for quality score; recommend using Automatic;\n\n\n\n\n\n\nZip format:\n\n    no gzip or gzip format;\n\n\n\n\n\n\nBait BED file\n\n    : Bait file defines regions that are used to capture read pairs. For transgene studies, it is usually a file listing the transgene regions in the plasmid genome. Taking the tutorial data as one example, the following bed file defined tnsA and tnsD region on the plasmid:\n\n\n\n\n\n\n\n\n\n\n\n\nPlasmid\n\n\nStart\n\n\nEnd\n\n\nName\n\n\n\n\n\n\n\n\n\n\npGRG36\n\n\n1453\n\n\n2274\n\n\ntnsA\n\n\n\n\n\n\npGRG36\n\n\n6036\n\n\n7562\n\n\ntnsD\n\n\n\n\n\n\n\n\nThe file extension is .bed and is a tab-delimited text file. The BED file contains four columns: chr, start, end and region name.\n\n\n\n\n\n\nAlignment length:\n\n    the length of read that required to be aligned to the bait region. It is designed to align part of the reads in case there are low quality nucleotides on the right side of read ends. For example, when read length is 100bp and alignment length set to 50, it only requires the first 50bp of the read aligned to the bait region.\n\n\n\n\n\n\nMultiple hit cutoff\n: usually, we set cutoff=1, requiring one read uniquely aligned to the bait region and it cannot be aligned to any other locations in plasmid and host genome. When there is a known similarity between the bait region and other regions, such as a region shared in two plasmid backbones, user can set the cutoff to be 2 to allow multiple mapping of the bait reads.\n\n\n\n\n\n\nThread number:\n\n    Number of Threads for each job;\n\n\n\n\n\n\nJob number:\n\n    Number of parallel jobs to run\n\n\n\n\n\n\nOutput folder:\n\n    Browse to specify the output folder\n\n\n\n\n\n\nUser will get two files for each target region from every sample: .bait.fastq and .target.fastq. Below, for the same input sample, there is a bait.fastq and a target.fastq for the tnsA region and tnsD region as defined by the BED file.\n\n\n\n\nUser can run raw data QC and also align the fastq files to plasmid genome and check the read coverage statistics and enrichment efficiency. The figure below is one example from a mate pair dataset.\n\n\n\n\nCongratulations! Now you can successfully run a transgene detection analysis!\n\n\nIf you have any questions, please feel free to contact Omicsoft \nsupport@omicsoft.com\n.",
            "title": "Others"
        },
        {
            "location": "/tutorials/Transgene/Others/#others",
            "text": "Below are some other useful options/functions.",
            "title": "Others"
        },
        {
            "location": "/tutorials/Transgene/Others/#ngs-pre-processing-filter-reads",
            "text": "Besides split read by tags, there are a few of NGS data pre-processing steps which can improve the data quality and reduce background noise.  To filter bad reads and remove adapter sequences, use  NGS | Preprocess | Filter :   Choose the appropriate file format: AUTO or FASTQ based on your data, then click  Add  to find input data.\nUse the default options but check \" input files are paired \" option if your data is paired end or mate pair reads. Choose an Output folder for new fastq files :   In the  Advanced  tab, click  Customize  for the  adapter Stripping  section. There are two adapter types users can specify:  3' end adapters : these are usually the type of adapters used in paired end reads. When NGS read length is short, the sequencer will get the adapter sequence as part of read sequences. The 3' adapter stripping does a localized alignment at the right end of the read and removes the adapter part of read ends. More details can be found in this wiki page:  http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_3%27End  Right adapter:  it is usually the type of short adapters used in mate pair reads. The adapter sequence has become a part of read sequence, in the middle of the read, but close to the 3' end. Array Studio aligns the adapter sequence against read sequence to strip up to where the best alignment to the adapter ends. All nucleotides after the adapter sequence are stripped away. More details can be found in this wiki page: http://www.arrayserver.com/wiki/index.php?title=AdapterStripping_Right   After the filtering step, new fastq files will be generated. Again, this step is optional if data quality is good.",
            "title": "NGS Pre-Processing: Filter Reads"
        },
        {
            "location": "/tutorials/Transgene/Others/#use-grouping-file",
            "text": "In Omicsoft, we consider one file as one sample, or two files as one sample if option \"reads are paired\" is checked.\nIn some cases, the user may have multiple files from multiple lanes for one NGS sample, such as one flow cell as one sample. Omicsoft provides a solution to input multiple files for one sample using the GroupingFile parameter.\nThe parameter should work for any NGS modules that take raw read files as input.  For more information about grouping files, please read: http://www.arrayserver.com/wiki/index.php?title=How_to_use_multiple_sequence_files_for_one_sample%3F",
            "title": "Use Grouping File"
        },
        {
            "location": "/tutorials/Transgene/Others/#integration-site-repository",
            "text": "Users can export selected integration sites and save them to tab-delimitated text files. The flat file can serve as an integration site repository. Users can also use the file to annotate new transgene detection reports.  To export, select integration site Fusion ID, and click \"Export Integration Sites\". It will ask user to either create a new file or select an exisiting repository to append.   To annotate new tables with repository file, click \"Append Integration Sites Project Info\", select the repository text file, then two new columns (Project Name and Sample) will be appended to the report. It annotates the table with names of old samples analyzed in old projects having the same integration site. It is matched by the same host and plasmid reference ID, and their integration locations/directions.",
            "title": "Integration Site Repository"
        },
        {
            "location": "/tutorials/Transgene/Others/#target-reads-extraction",
            "text": "Target reads extraction is designed to extract target reads based on the read pair connectivity, such as pair-end and mate-pair linkage. Below is one example using mate pair, the Target Reads Extraction function is trying to extract target reads with its mate mapped to the designed capture region (transgene region):   This tool is useful when there are multiple transgene regions, such as tnsA and tnsD in the tutorial dataset.\nUser can design the capture region to be specific to the transgene and then use the target reads to do transgene integration site analysis. The result (integration site) will be transgene-specific since we only use the reads that are uniquely linked to the transgene region.  To run transgene target reads extraction, go to the NGS menu below:   In the analysis menu:   Select input format and click \"Add\" to add paired-end or mate pair raw data. It is better to add a filtered (filtered + adapter stripped) data set.    Input format:  the read file format, fastq, qseq or fasta;\n    most datasets from current next-generation sequencing machines are fastq    Add data from server; input files have to be paired based on regular paired or mate pair read file names    Host genome: \n    the host genome to detect integration;    Plasmid genome: \n    the plasmid genome built by user;    Quality encoding: \n    the encoding for quality score; recommend using Automatic;    Zip format: \n    no gzip or gzip format;    Bait BED file \n    : Bait file defines regions that are used to capture read pairs. For transgene studies, it is usually a file listing the transgene regions in the plasmid genome. Taking the tutorial data as one example, the following bed file defined tnsA and tnsD region on the plasmid:       Plasmid  Start  End  Name      pGRG36  1453  2274  tnsA    pGRG36  6036  7562  tnsD     The file extension is .bed and is a tab-delimited text file. The BED file contains four columns: chr, start, end and region name.    Alignment length: \n    the length of read that required to be aligned to the bait region. It is designed to align part of the reads in case there are low quality nucleotides on the right side of read ends. For example, when read length is 100bp and alignment length set to 50, it only requires the first 50bp of the read aligned to the bait region.    Multiple hit cutoff : usually, we set cutoff=1, requiring one read uniquely aligned to the bait region and it cannot be aligned to any other locations in plasmid and host genome. When there is a known similarity between the bait region and other regions, such as a region shared in two plasmid backbones, user can set the cutoff to be 2 to allow multiple mapping of the bait reads.    Thread number: \n    Number of Threads for each job;    Job number: \n    Number of parallel jobs to run    Output folder: \n    Browse to specify the output folder    User will get two files for each target region from every sample: .bait.fastq and .target.fastq. Below, for the same input sample, there is a bait.fastq and a target.fastq for the tnsA region and tnsD region as defined by the BED file.   User can run raw data QC and also align the fastq files to plasmid genome and check the read coverage statistics and enrichment efficiency. The figure below is one example from a mate pair dataset.   Congratulations! Now you can successfully run a transgene detection analysis!  If you have any questions, please feel free to contact Omicsoft  support@omicsoft.com .",
            "title": "Target Reads Extraction"
        },
        {
            "location": "/tutorials/OncoLand/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nOncoLand\n\u00b6\n\n\nOmicSoft uses ArrayLand framework to deliver large data service results. OncoLand is an important part of ArrayLand specifically focused on oncology data. Land files are built up based on OmicSoft File System (OFS), which stores genomics data in database files and different layers of indexes for gene/markers and samples. It is a revolutionary google-like storage for vector data. The goal of OncoLand is to provide fast data access in both sample and gene directions.\n\n\nOnce users configured Land data on ArrayServer internally, all ArrayStudio/ArrayLand users can search all types of genomics profiles of a single gene or a set of genes instantly with rich visualizations.\n\n\nThis tutorial is mainly based on TCGA Land and CCLE Land. Please refer to the OncoLand Whitepaper, available through the Help menu item, for descriptions of all available lands within OncoLand.\n\n\nTCGALand\n\u00b6\n\n\nThe Cancer Genome Atlas (TCGA) is a project, begun in 2006, to collect cancer samples and generate genomic profiling dataset for bioinformatics and biomedical researchers. There are a number of different techniques/platforms used to generate genomics datasets, including expression microarray, copy number variation profiling, SNP genotyping, methylation profiling, microRNA sequencing, transcriptome and exon sequencing.\n\n\nOnce you connect to the server, you can find the TCGA land data by clicking \nSelect Land\n:\n\n\n\n\nThe default view is \nSamples\n view showing the number of samples in each tumor type. Other views are also available for users to query the sample data at a general level:\n\n\n\n\nOne useful view is \nClinical Significance - Group Association\n. It is a dynamic view showing the association of all clinical variables with the selected grouping (sample variable).\n\n\n\n\nSurvival Data\n view is a plot of percent survival across time (Kaplan-Meier Survival Curve) using a specific grouping (e.g. Tumor Type)\n\n\n\n\nCCLELand\n\u00b6\n\n\nThe Cancer Cell Line Encylopedia (CCLE) project is an effort to conduct a detailed genetic and pharmacologic characterization of a large panel of human cancer cell lines. The CCLE provides public access to genomic data, analysis and visualization of DNA copy number, mRNA expression, mutation data and more, for about 1000 cell lines.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/OncoLand/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/OncoLand/Introduction/#oncoland",
            "text": "OmicSoft uses ArrayLand framework to deliver large data service results. OncoLand is an important part of ArrayLand specifically focused on oncology data. Land files are built up based on OmicSoft File System (OFS), which stores genomics data in database files and different layers of indexes for gene/markers and samples. It is a revolutionary google-like storage for vector data. The goal of OncoLand is to provide fast data access in both sample and gene directions.  Once users configured Land data on ArrayServer internally, all ArrayStudio/ArrayLand users can search all types of genomics profiles of a single gene or a set of genes instantly with rich visualizations.  This tutorial is mainly based on TCGA Land and CCLE Land. Please refer to the OncoLand Whitepaper, available through the Help menu item, for descriptions of all available lands within OncoLand.",
            "title": "OncoLand"
        },
        {
            "location": "/tutorials/OncoLand/Introduction/#tcgaland",
            "text": "The Cancer Genome Atlas (TCGA) is a project, begun in 2006, to collect cancer samples and generate genomic profiling dataset for bioinformatics and biomedical researchers. There are a number of different techniques/platforms used to generate genomics datasets, including expression microarray, copy number variation profiling, SNP genotyping, methylation profiling, microRNA sequencing, transcriptome and exon sequencing.  Once you connect to the server, you can find the TCGA land data by clicking  Select Land :   The default view is  Samples  view showing the number of samples in each tumor type. Other views are also available for users to query the sample data at a general level:   One useful view is  Clinical Significance - Group Association . It is a dynamic view showing the association of all clinical variables with the selected grouping (sample variable).   Survival Data  view is a plot of percent survival across time (Kaplan-Meier Survival Curve) using a specific grouping (e.g. Tumor Type)",
            "title": "TCGALand"
        },
        {
            "location": "/tutorials/OncoLand/Introduction/#ccleland",
            "text": "The Cancer Cell Line Encylopedia (CCLE) project is an effort to conduct a detailed genetic and pharmacologic characterization of a large panel of human cancer cell lines. The CCLE provides public access to genomic data, analysis and visualization of DNA copy number, mRNA expression, mutation data and more, for about 1000 cell lines.",
            "title": "CCLELand"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/",
            "text": "Search Basics\n\u00b6\n\n\nSearch a single gene\n\u00b6\n\n\nOpen TCGALand, then type a gene name, such as \nnusap1\n, in the search box. Notice that the auto fill box will assist you to complete the full gene name. Click the green arrow then select \"Search\",  or press \"Enter\" to search gene \nNUSAP1\n in TCGA land.\n\n\n\n\nA figure showing DNA Alteration Distribution for gene \nNUSAP1\n is returned. This shows the number of different Alteration types, organized by primary group type (in \nTCGA\n, the primary group type is Tumor Type.)  \n\n\n\n\nOn the left panel, \nSample\n, \nMutation\n and \nCNV\n tabs are used to filter samples depending on different filter criteria. Under \nMutation\n, clicking \"View Filtered Table\" will show detailed mutation information matching with the selected filter criteria.\n\n\n\n\nOn the right panel, \nLegend\n tab shows legend by color. The color can be changed by right-clicking each level.\n\n\n\n\nTask\n tab can be used to change data shown in the view, change profile columns, specify data summarization method, change chart properties, etc. The data used in the view can be exported to txt or excel files.\n\n\n\n\nOncoLand provides bunches of data views which can be accessed in \nSelect View\n. Data are organized into sections based on platform types as well as an \nIntegration\n section. In each customized view, there will be a tooltip, describing the view when moused over:\n\n\n\n\nBy clicking a different view, the default setting is to replace the current view with the newly selected view. If users prefer to keep all views, there is an option:\n\n\n\n\nDNA-Seq\n\u00b6\n\n\n\n\nSomatic Mutation is based on MAF (Mutation Annotation Format) files downloaded from TCGA. By definition, somatic is present in tumor but not control.\n\n\nSomatic Mutation Distribution\n view shows the percentage of mutant samples in each grouping (e.g. Tumor Type).\n\n\n\n\nSomatic mutations can be visualized in built-in ArrayLand genome browser. Visualizations will be automatically refreshed in response to the filters on mutation features and sample meta data.\n\n\n\n\nRNA-Seq Quantification\n\u00b6\n\n\n\n\nRNA-Seq gene and transcript FPKM\n\u00b6\n\n\nGene FPKM\n Charts return visualizations based on FPKM (Fragments Per Kilobase of transcript per Million mapped fragments).\nAll FPKM data calculated at the transcript level, using an EM algorithm based on RSEM \nlink\n. Data are further normalized for each sample by firstly adding 0.1 to FPKM and then taking log 2. This makes FPKM values comparable across all samples in the Land. Data are summarized at the gene level, by taking the sum of all transcript FPKM values.\n\n\n\n\nVisualization is further configurable in the task tab, including chart/symbol properties (shape, color and size).\n\n\nSummary (gene FPKM)\n view shows percentage of tumor samples whose RNA-Seq log2(FPKM+0.1) expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type).\n\n\n\n\nThe default fold change cutoff 2x can be changed under \nExpression\n tab in the left panel.\n\n\nRNA-Seq Exon Details\n\u00b6\n\n\nRNA-Seq details on exon and exon junction level are visualized in the built-in genome browser. It can help the user answer questions such as \u201c\nAre there FGF12 transcript expression differences between PRAD tumor samples?\n\n\nSearch \nFGF12\n and open \nRNA-Seq Quantification| Genome Browser (Exon Details)\n.\nIn Sample tab, filter to PRAD:\n\n\n\n\nUser can change \nthe grouping to Sample Type\n (In this case, Normal, Primary Tumor, Metastatic) since we have filtered to show one tumor type (PRAD) only:\n\n\n\n\nThe coverage is at exon level and colored by grouping (Sample Type), as illustrated in \nLegend\n. The genome browser \ntranscripts are painted as stack bars\n\nrepresenting the relative expression ratios between two sample types. From this view, normal tissue clearly expresses the first transcript; while tumor tissue expresses the second transcript, with more obvious expression of the second transcript in metastatic tumor tissue.\n\n\nRNA-Seq Fusion\n\u00b6\n\n\nGene fusion events in tumor samples can be identified using Omicsoft\u2019s FusionMap \nlink\n algorithm.\n\n\nThere are two main algorithms:\n\n\n\n\n\n\nRead spanning algorithm - using a cutting-edge technique, a read must map partially to one gene and partially to the second gene. At least 1 read must be fusion-spanning for it to be returned in ArrayLand views;\n\n\n\n\n\n\nDiscordant pair algorithm \u2013 if one read is mapped to one gene, and another read is mapped to a second gene, this is considered a potential fusion.\n\n\n\n\n\n\nHere is the Fusion (RPKM) view by searching gene \nerg\n in the search box:\n\n\n\n\nFor the TCGA land version in this tutorial, to be sensitive, we report all fusions with at least one junction-spanning read support. But by default, we apply some filters to show the more interesting fusions. We provide varied options to filter false positives? in the \nFusion\n tab, such as\n\n\n\n\nCanonical splice junctions\n (GT-AG, GC-AG and AT-AC) are considered to be more likely than other splice junction patterns.\n\n\nIn-frame\n fusions are more likely to be real than frame shift fusions.\n\n\nOn Exon Boundary\n indicates whether one or both breakpoints are on an exon boundary (more likely for real fusions).\n\n\nIn Control\n means in normal samples. By default it is checked and any fusions shown in normal samples are filtered out. You can relax this option if you want to explore more.\nLoading of fusion results might be slow in this version since there are too many fusion candidates with relaxed (require only one junction spanning read) parameters.\n\n\nFor more details about fusion detection and filters on fusion features, please read the following wiki page:\n\nlink\n\n\nIn the fusion views at fusion junction level (\nFusion Site Frequency\n), user can get more fusion details by clicking the link on the upper right:\n\n\n\n\nFusion data of this particular form will be added to the Analysis solution tab:\n\n\n\n\nUser gets the expression pattern views of gene A, gene B and fusion gene A->B, such as the variable view:\n\n\n\n\nRNA-Seq Mutation\n\u00b6\n\n\nViews in this section are based on results using Omicsoft\u2019s mutation detection algorithm, summarized by frequency of the mutation. TCGA Land only stores mutations with at least 10 total hits, 5 mutation hits, and mutation read frequency >0.20. There are summary views as well as a built-in ArrayLand genome browser view:\n\n\n\n\nRNA-Seq Somatic Mutation\n\u00b6\n\n\nIf there are both tumor and normal RNA-Seq samples for a patient, Omicsoft\u2019s \nSummarize Matched Pair Variation\n method is used to call mutations as somatic. For more details, please read the following wiki article:\n\nlink\n\n\nSame as RNA-Seq Mutation, there are summary views as well as built-in ArrayLand genome browser view.\n\n\nRNA-Seq (Survival View)\n\u00b6\n\n\nSurvival View is a quick way to check if a gene's expression status affects the survival of individuals. For example, when searching for the gene tgif1 and filtering for LGG tumor types and primary tumors, we see that high levels of tgif1 appear to correlate with poor survival. (Try removing these filters and looking at all tumor types - you will notice that there is no longer a nice separation of these groups):\n\n\n\n\nExpression\n\u00b6\n\n\nExpression Ratio is from Agilent data, comparing Tumor or normal sample to universal human reference.\n\n\n\n\nSummary (Expression Ratio) view shows a plot of percentage of tumor samples showing 2x up-regulation and 2x down-regulation, organized by group (e.g. Tumor Type). The default fold change cutoff 2x can be changed to other fold of cutoff under Expression tab.\n\n\n\n\nProtein\n\u00b6\n\n\nProtein data, reverse phase protein array (RPPA), is only available for a subset of genes (like BRAF). Normalized RPPA (RPPA_RBN) is the Replicates Based Normalized RPPA. For more information about RPPA technology, please read the following webpage in MD Anderson Cancer Center:\n\nlink\n\n\n\n\nCopy Number\n\u00b6\n\n\nCopy number data is based on Affymetrix SNP 6.0 data, in Log2 Ratio values.\n\n\n\n\nIn built-in ArrayLand genome browser, copy number data is shown as segments. Genome browser tracks can be filtered by sample or CNV features. Samples in tumor group are sortable by log2Ratio values.\n\n\n\n\nMethylation\n\u00b6\n\n\nMethylation data is from the Illumina Methylation 450 platform, summarized at the probe level.\nFuture improvements may summarize at promoter regions or transcript regions.\n\n\n\n\nIntegration\n\u00b6\n\n\n\n\nIntegration section includes integrative visualization of expression correlation of CNV-expression, expression in array VS RNA-Seq.\nHere is an example:\n\n\ncopy number VS expression (from RNA-Seq) for \nMET\n\n\n\n\nIntegration (Scan All Genes)\n\u00b6\n\n\nIntegration section includes integrative visualization of a selected gene's RNA-seq expression, somatic expression, cnv etc in comparison with all other genes' RNA-seq expression, RPPA etc.\n\n\nFor example, below shows RNA-Seq expression of other genes vs copy number of BRAF. By default, the gene with the highest correlation will show in the plot. The left window shows the correlation coefficients for all other genes. By clicking one of them, the plot will dynamically change to the selected gene. More details can be seen by clicking \"View Correlation Table\".\n\n\n\n\nAction\n\u00b6\n\n\n\n\nWhen samples are selected on a plot or summary tables, detailed sample meta data for selected samples will be displayed in a window below.\n\n\n\n\nAfter clicking the small '+' symbol on the left side of the detail window, multiple options for Selection Details will appear. For example, clicking \nCopy Number Details\n will return copy number details.\n\n\n\n\nThe user can also select one or more samples in an RNA-Seq related charts, such as \nGene FPKM\n, then click \nBrowse Selected Samples | Open RNA-Seq BAS Files for selection\n. BAS (BAM summary) files contains coverage at base pair resolution, exon junction and mutation information. On average, it is 64x smaller than BAM file and does not contain sequence information.\n\n\n\n\nClick \nOK\n after selecting the grouping. It will open a genome browser in the \nBrowser\n tab:\n\n\n\n\nUser can further remove the grouping and split the genome browser track to samples from the option in right click menu. For more information about genome browser, please read \nGenome Browser Tutorial\n.\n\n\nSelect any samples in \nRNA-Seq  Fusion| Fusion (RPKM)\n, and click \nBrowse Selected Samples |Open Fusion BAS Files for selection\n. It will open genome browser views for fusion alignments based on fusion junction spanning reads and inter-transcript fusion reads:\n\n\n\n\nIf user gets TCGA approval with level 1 data access, they can further link their BAM files in ArrayLand. Two more options will show in the Selection by specifying \nEnableBam=TRUE\n in land configuration:\n\n\n\n\nSearch Two or More Genes\n\u00b6\n\n\nUser can search two or more genes by typing \ngeneA,geneB,geneC\n (separated by commas) in the search box:\n\n\n\n\nOr input the gene list in \nSearch Multiple Genes\n\n\n\n\nSearching for multiple genes enables different views compared to single gene search. There are new charts, such as \nCo-Mutation Frequency\n views:\n\n\n\n\nMulti-Gene Correlation\n views in Expression, CNV, and RNA-Seq  Quantification sections. The regression line mode can be changed under \nTask\n tab.\n\n\nThe example below shows RNA-Seq FPKM correlation between ERG and TMPRSS2 for TGCT tumor samples.\n\n\n\n\nHeatmap\n Views in Expression, CNV, RNA-Seq Quantification, DNA-Seq and RNA-Seq Mutation sections:\n\n\n\n\nFusion (Genepair Frequency)\n Charts will only show fusions between these multiple genes. \nBrowse Selected Samples | Open fusion BAM/BAS Files\n for selected samples will remain  but \nBrowse Selected Samples |Open BAM/BAS Files\n for select samples will not be allowed since there are multiple gene regions.\n\n\nFusion Genome Browser\n will show the fusion information between the searched genes.\n\n\n\n\nFusion Negative Exon Coverage\n shows the exon coverage for samples without fusion. \nFusion Positive Exon Coverage\n shows the exon coverage for samples with fusion. The genome browser clearly shows the first few exons of ERG have less coverage in fusion positive samples in comparison with those in fusion negative samples, due to fusion with TMPRSS2.\n\n\nEach circle represents each fusion ID. By clicking one circle, the corresponding fusion in the other gene panel will also be highlighted. Fusion details will show in the detail window.\n\n\n\n\nGene Set\n\u00b6\n\n\nIn ArrayLand, each user can create a set of genes they are interested in, such as a set of genes in one pathway.\nTo create a gene set, go to \nLand | Manage | Genes | Manage Gene Sets\n.\n\n\n\n\nUser can add a new Gene Set by clicking \nAdd\n\n\n\n\nUser can specify the GeneSet name, tags, and read/editor permissions.\n\n\n\n\nIn the MetaData, user can load a list of genes from a file or ArrayStudio analysis with certain meta data:\n\n\n\n\nCreated Gene Sets are organized in the Land by tags\n\n\n\n\nThe whole set of genes is searchable in Land by typing the gene set name in the search box:\n\n\n\n\nAll multiple-gene views will be based on the whole set of genes, such as the expression (FPKM) heatmap:",
            "title": "Basic Search"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#search-basics",
            "text": "",
            "title": "Search Basics"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#search-a-single-gene",
            "text": "Open TCGALand, then type a gene name, such as  nusap1 , in the search box. Notice that the auto fill box will assist you to complete the full gene name. Click the green arrow then select \"Search\",  or press \"Enter\" to search gene  NUSAP1  in TCGA land.   A figure showing DNA Alteration Distribution for gene  NUSAP1  is returned. This shows the number of different Alteration types, organized by primary group type (in  TCGA , the primary group type is Tumor Type.)     On the left panel,  Sample ,  Mutation  and  CNV  tabs are used to filter samples depending on different filter criteria. Under  Mutation , clicking \"View Filtered Table\" will show detailed mutation information matching with the selected filter criteria.   On the right panel,  Legend  tab shows legend by color. The color can be changed by right-clicking each level.   Task  tab can be used to change data shown in the view, change profile columns, specify data summarization method, change chart properties, etc. The data used in the view can be exported to txt or excel files.   OncoLand provides bunches of data views which can be accessed in  Select View . Data are organized into sections based on platform types as well as an  Integration  section. In each customized view, there will be a tooltip, describing the view when moused over:   By clicking a different view, the default setting is to replace the current view with the newly selected view. If users prefer to keep all views, there is an option:",
            "title": "Search a single gene"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#dna-seq",
            "text": "Somatic Mutation is based on MAF (Mutation Annotation Format) files downloaded from TCGA. By definition, somatic is present in tumor but not control.  Somatic Mutation Distribution  view shows the percentage of mutant samples in each grouping (e.g. Tumor Type).   Somatic mutations can be visualized in built-in ArrayLand genome browser. Visualizations will be automatically refreshed in response to the filters on mutation features and sample meta data.",
            "title": "DNA-Seq"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-quantification",
            "text": "",
            "title": "RNA-Seq Quantification"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-gene-and-transcript-fpkm",
            "text": "Gene FPKM  Charts return visualizations based on FPKM (Fragments Per Kilobase of transcript per Million mapped fragments).\nAll FPKM data calculated at the transcript level, using an EM algorithm based on RSEM  link . Data are further normalized for each sample by firstly adding 0.1 to FPKM and then taking log 2. This makes FPKM values comparable across all samples in the Land. Data are summarized at the gene level, by taking the sum of all transcript FPKM values.   Visualization is further configurable in the task tab, including chart/symbol properties (shape, color and size).  Summary (gene FPKM)  view shows percentage of tumor samples whose RNA-Seq log2(FPKM+0.1) expression is 2x up-regulated or 2x down-regulated, compared to normal samples in each group (e.g. Tumor Type).   The default fold change cutoff 2x can be changed under  Expression  tab in the left panel.",
            "title": "RNA-Seq gene and transcript FPKM"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-exon-details",
            "text": "RNA-Seq details on exon and exon junction level are visualized in the built-in genome browser. It can help the user answer questions such as \u201c Are there FGF12 transcript expression differences between PRAD tumor samples?  Search  FGF12  and open  RNA-Seq Quantification| Genome Browser (Exon Details) .\nIn Sample tab, filter to PRAD:   User can change  the grouping to Sample Type  (In this case, Normal, Primary Tumor, Metastatic) since we have filtered to show one tumor type (PRAD) only:   The coverage is at exon level and colored by grouping (Sample Type), as illustrated in  Legend . The genome browser  transcripts are painted as stack bars \nrepresenting the relative expression ratios between two sample types. From this view, normal tissue clearly expresses the first transcript; while tumor tissue expresses the second transcript, with more obvious expression of the second transcript in metastatic tumor tissue.",
            "title": "RNA-Seq Exon Details"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-fusion",
            "text": "Gene fusion events in tumor samples can be identified using Omicsoft\u2019s FusionMap  link  algorithm.  There are two main algorithms:    Read spanning algorithm - using a cutting-edge technique, a read must map partially to one gene and partially to the second gene. At least 1 read must be fusion-spanning for it to be returned in ArrayLand views;    Discordant pair algorithm \u2013 if one read is mapped to one gene, and another read is mapped to a second gene, this is considered a potential fusion.    Here is the Fusion (RPKM) view by searching gene  erg  in the search box:   For the TCGA land version in this tutorial, to be sensitive, we report all fusions with at least one junction-spanning read support. But by default, we apply some filters to show the more interesting fusions. We provide varied options to filter false positives? in the  Fusion  tab, such as   Canonical splice junctions  (GT-AG, GC-AG and AT-AC) are considered to be more likely than other splice junction patterns.  In-frame  fusions are more likely to be real than frame shift fusions.  On Exon Boundary  indicates whether one or both breakpoints are on an exon boundary (more likely for real fusions).  In Control  means in normal samples. By default it is checked and any fusions shown in normal samples are filtered out. You can relax this option if you want to explore more.\nLoading of fusion results might be slow in this version since there are too many fusion candidates with relaxed (require only one junction spanning read) parameters.  For more details about fusion detection and filters on fusion features, please read the following wiki page: link  In the fusion views at fusion junction level ( Fusion Site Frequency ), user can get more fusion details by clicking the link on the upper right:   Fusion data of this particular form will be added to the Analysis solution tab:   User gets the expression pattern views of gene A, gene B and fusion gene A->B, such as the variable view:",
            "title": "RNA-Seq Fusion"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-mutation",
            "text": "Views in this section are based on results using Omicsoft\u2019s mutation detection algorithm, summarized by frequency of the mutation. TCGA Land only stores mutations with at least 10 total hits, 5 mutation hits, and mutation read frequency >0.20. There are summary views as well as a built-in ArrayLand genome browser view:",
            "title": "RNA-Seq Mutation"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-somatic-mutation",
            "text": "If there are both tumor and normal RNA-Seq samples for a patient, Omicsoft\u2019s  Summarize Matched Pair Variation  method is used to call mutations as somatic. For more details, please read the following wiki article: link  Same as RNA-Seq Mutation, there are summary views as well as built-in ArrayLand genome browser view.",
            "title": "RNA-Seq Somatic Mutation"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#rna-seq-survival-view",
            "text": "Survival View is a quick way to check if a gene's expression status affects the survival of individuals. For example, when searching for the gene tgif1 and filtering for LGG tumor types and primary tumors, we see that high levels of tgif1 appear to correlate with poor survival. (Try removing these filters and looking at all tumor types - you will notice that there is no longer a nice separation of these groups):",
            "title": "RNA-Seq (Survival View)"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#expression",
            "text": "Expression Ratio is from Agilent data, comparing Tumor or normal sample to universal human reference.   Summary (Expression Ratio) view shows a plot of percentage of tumor samples showing 2x up-regulation and 2x down-regulation, organized by group (e.g. Tumor Type). The default fold change cutoff 2x can be changed to other fold of cutoff under Expression tab.",
            "title": "Expression"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#protein",
            "text": "Protein data, reverse phase protein array (RPPA), is only available for a subset of genes (like BRAF). Normalized RPPA (RPPA_RBN) is the Replicates Based Normalized RPPA. For more information about RPPA technology, please read the following webpage in MD Anderson Cancer Center: link",
            "title": "Protein"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#copy-number",
            "text": "Copy number data is based on Affymetrix SNP 6.0 data, in Log2 Ratio values.   In built-in ArrayLand genome browser, copy number data is shown as segments. Genome browser tracks can be filtered by sample or CNV features. Samples in tumor group are sortable by log2Ratio values.",
            "title": "Copy Number"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#methylation",
            "text": "Methylation data is from the Illumina Methylation 450 platform, summarized at the probe level.\nFuture improvements may summarize at promoter regions or transcript regions.",
            "title": "Methylation"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#integration",
            "text": "Integration section includes integrative visualization of expression correlation of CNV-expression, expression in array VS RNA-Seq.\nHere is an example:  copy number VS expression (from RNA-Seq) for  MET",
            "title": "Integration"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#integration-scan-all-genes",
            "text": "Integration section includes integrative visualization of a selected gene's RNA-seq expression, somatic expression, cnv etc in comparison with all other genes' RNA-seq expression, RPPA etc.  For example, below shows RNA-Seq expression of other genes vs copy number of BRAF. By default, the gene with the highest correlation will show in the plot. The left window shows the correlation coefficients for all other genes. By clicking one of them, the plot will dynamically change to the selected gene. More details can be seen by clicking \"View Correlation Table\".",
            "title": "Integration (Scan All Genes)"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#action",
            "text": "When samples are selected on a plot or summary tables, detailed sample meta data for selected samples will be displayed in a window below.   After clicking the small '+' symbol on the left side of the detail window, multiple options for Selection Details will appear. For example, clicking  Copy Number Details  will return copy number details.   The user can also select one or more samples in an RNA-Seq related charts, such as  Gene FPKM , then click  Browse Selected Samples | Open RNA-Seq BAS Files for selection . BAS (BAM summary) files contains coverage at base pair resolution, exon junction and mutation information. On average, it is 64x smaller than BAM file and does not contain sequence information.   Click  OK  after selecting the grouping. It will open a genome browser in the  Browser  tab:   User can further remove the grouping and split the genome browser track to samples from the option in right click menu. For more information about genome browser, please read  Genome Browser Tutorial .  Select any samples in  RNA-Seq  Fusion| Fusion (RPKM) , and click  Browse Selected Samples |Open Fusion BAS Files for selection . It will open genome browser views for fusion alignments based on fusion junction spanning reads and inter-transcript fusion reads:   If user gets TCGA approval with level 1 data access, they can further link their BAM files in ArrayLand. Two more options will show in the Selection by specifying  EnableBam=TRUE  in land configuration:",
            "title": "Action"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#search-two-or-more-genes",
            "text": "User can search two or more genes by typing  geneA,geneB,geneC  (separated by commas) in the search box:   Or input the gene list in  Search Multiple Genes   Searching for multiple genes enables different views compared to single gene search. There are new charts, such as  Co-Mutation Frequency  views:   Multi-Gene Correlation  views in Expression, CNV, and RNA-Seq  Quantification sections. The regression line mode can be changed under  Task  tab.  The example below shows RNA-Seq FPKM correlation between ERG and TMPRSS2 for TGCT tumor samples.   Heatmap  Views in Expression, CNV, RNA-Seq Quantification, DNA-Seq and RNA-Seq Mutation sections:   Fusion (Genepair Frequency)  Charts will only show fusions between these multiple genes.  Browse Selected Samples | Open fusion BAM/BAS Files  for selected samples will remain  but  Browse Selected Samples |Open BAM/BAS Files  for select samples will not be allowed since there are multiple gene regions.  Fusion Genome Browser  will show the fusion information between the searched genes.   Fusion Negative Exon Coverage  shows the exon coverage for samples without fusion.  Fusion Positive Exon Coverage  shows the exon coverage for samples with fusion. The genome browser clearly shows the first few exons of ERG have less coverage in fusion positive samples in comparison with those in fusion negative samples, due to fusion with TMPRSS2.  Each circle represents each fusion ID. By clicking one circle, the corresponding fusion in the other gene panel will also be highlighted. Fusion details will show in the detail window.",
            "title": "Search Two or More Genes"
        },
        {
            "location": "/tutorials/OncoLand/Search_Basics/#gene-set",
            "text": "In ArrayLand, each user can create a set of genes they are interested in, such as a set of genes in one pathway.\nTo create a gene set, go to  Land | Manage | Genes | Manage Gene Sets .   User can add a new Gene Set by clicking  Add   User can specify the GeneSet name, tags, and read/editor permissions.   In the MetaData, user can load a list of genes from a file or ArrayStudio analysis with certain meta data:   Created Gene Sets are organized in the Land by tags   The whole set of genes is searchable in Land by typing the gene set name in the search box:   All multiple-gene views will be based on the whole set of genes, such as the expression (FPKM) heatmap:",
            "title": "Gene Set"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/",
            "text": "Advanced Analytics\n\u00b6\n\n\nSample Set\n\u00b6\n\n\nLike Gene Set, user can also create a sample set, a collection of Samples. Sample sets can contain additional sample meta data, which are supplementary to the meta data shipped with Land.\n\n\nUnlike meta data and clinical data, which are normally controlled by administrators, sample sets can be created and managed by all users. Users can share the sample sets they created with other users and can also subscribe/unsubscribe sample sets.\n\n\nUser can create a sample set based on imported sample design table, selection in land or query analytics.\n\n\nCreate A Sample Set by Importing\n\u00b6\n\n\nTo create sample set, go to \nLand | Manage | Samples | Manage Sample Set\n:\n\n\n\n\nSame as gene set, sample sets are organized by tags, user can add a new sample set by clicking \nAdd\n and the following window will show up:\n\n\n\n\nIn the MetaData tab, user can upload sample set from file, local analysis or an omicsoft data object (.osobj) file:\n\n\n\n\nCreate A Sample Set by selection\n\u00b6\n\n\nUser can create sample set directly by selection/filter using the following four options in \nSample Set\n:\n\n\n\n\nCreate sample set will only create a set of samples selected (marked as red in views) or visible after filter:\n\n\n\n\nGroup sample set will include all samples but mark them as Yes/No as meta data:\n\n\n\n\nIn the Info tab, user will name sampleset (such as \nNUSAP1 upregulated samples\n ), tag the sampleset (such as \nPRAD, NUSAP1\n ) and set Readers and Editors access.\n\n\nCreate A Sample Set by Land Analytics\n\u00b6\n\n\nArrayLand also provides a list of powerful analytic functions to query the whole land database and create sample set, based on mutation, copy number status:\n\n\n\n\nTaking generating \nGenerate Site Mutation Status Sample Set\n as one example, it will open a query window:\n\n\n\n\nSite mutation query allows user to input mutation ID (in the format of \nchr.position.alteration\n ) or mutation amino acid change, such as \nBRAF.V600E\n. In the example above, we query four types of mutations together, including IDH1.R132* (IDH1 mutations change 132th amino acid position from R to anything).\n\n\nOnce click \nSend to Queue\n, the analytic job will send to ArrayServer job queue:\n\n\n\n\nOnce job finishes, the sample set, \nTest BRAF IDH RNASeq Mutation SampleSet\n, will show in \nLand | Manage | Samples | Manage Sample Sets\n. Mutation status, MUT or WT, is marked for each mutation site in the sample set.\n\n\n\n\nUser can modify the permission, sample set tags by clicking Edit/Update after a sample set is created.\n\n\n\n\nOnce a sample set is created, users can subscribe the sample set.\n\n\n\n\nOnce a sample set is subscribed, a check mark will appear in front of the sample set name.\n\n\n\n\nOnce you subscribe to a sample set, you will see it in \nall future\n land queries, as a filter column in Sample tab under \"Sample Set\", and also a profile column to trellis and split samples in the visualization.\n\n\nBelow is the \nIDH1\n expression boxplot, categorized by Tumor Type (filter to SKCM only), Sample Type and \nBRAF\n mutation status:\n\n\n\n\nCustom Query\n\u00b6\n\n\nCustom query\n provides another approach to query genes/features quickly.\n\n\nCustom queries are created by dynamic land database query. Custom queries can be combined and they can be viewed by OmicPrint. But unlike sample sets, custom queries cannot be shared, nor can they be used to limit samples used in \nAnalytics\n.\n\n\nAdd Omic Data Query\n\u00b6\n\n\nTo add a custom query, click the icon besides \nSelect View\n and choose from the list:\n\n\n\n\nWe provide custom queries of a gene on expression, CNV, mutation, fusion and RPPA.\n\n\nThe following example shows how to query the expression level of \nERG\n and \nTMPRSS2\n in RNA-Seq dataset, separated by ',':\n\n\n\n\nWe can also query the \nTMPRSS2->ERG\n fusion in RNA-Seq dataset:\n\n\n\n\nThree query results are immediately available to do customizations for the current view.\n\n\n\n\nIn the view above for ERG \nGene FPKM\n, we filter \nTumor Type\n to PRAD, \nspecify multiple profile columns\n to Tumor Type and Fusion Status\n\n\n\n\nAnd \nChange Symbol Properties\n to color by \nERG\n expression status:\n\n\n\n\nThe color legend is shown on the Legend tab, where you can change color for each category:\n\n\n\n\nNumeric data (Like Expression Ratio, RPPA, FPKM etc) can also be categorized by user-defined breakpoints. Say we want the samples with FPKM less than 10% as \"Low\", larger than 90% as \"High\" and Others as \"Middle\", the breakpoints can be set as this\n\n\n\n\nThen the custom query will show as\n\n\n\n\nThe categorization is based on the overall samples. If users want the categorization based on each group, then check \nDiscretization for each group\n.\n\n\nThe custom query can also be performed using summarized numeric data in multiple genes by checking \nSummarize multiple genes by\n and choosing a summarization method.\n\n\n\n\nAdd Measurement Data Query\n\u00b6\n\n\nIn addition to Omic Data Query, measurement data query can also be added if measurement data has been imported. Detailed information about measurement data will be described in the next chapter.\n\n\nCombine Multiple Queries\n\u00b6\n\n\nAfter creating multiple Custom Queries in Land Sample tab, users can use AND/OR logic to combine multiple custom queries.\n\n\nFrom the left panel, users can select multiple levels in different queries to combine. The default logic is \nOR\n.\n\n\n\n\nIf users want to use \nAND\n logic to combine queries, please check \nMatch all\n option.\n\n\n\n\nOther\n\u00b6\n\n\nUsers can also add SampleSet query (for the sample sets, regardless of whether they are subscribed or not) and MetaData query.\n\n\nSample Sets can also be created from custom queries:\n\n\n\n\nMoreover, ArrayLand provides an overview of all custom query results as an \nOmicPrint\n view:\n\n\n\n\nOmicPrint view is a tree, categorized by tumor type, then gene names and queries. The same sample is aligned vertically. It will show the sample ID when users mouse over the block. Sample blocks are colored by alteration types, such as mutation (MUT), amplified, deleted, etc.\n\n\nFrom the view above, we can see clear the correlation between \nERG\n up-regulation and presence of \nTMPRSS2->ERG\n fusion.\n\n\nReport Top Gene List\n\u00b6\n\n\nIn Land analytics, we also provide tools to scan all or a subset of samples for top mutated, amplified or deleted genes, top fusion and top transcripts:\n\n\n\n\nBelow is one example of scanning COAD samples for top mutated genes (only select important mutation types shown in at least 10% of samples). The COAD sample set can be created by \"Create Sample Set From Selection\", described in the sample set chapter. By clicking \nSend to Queue\n, the job will run on ArrayServer. Depending on the number of samples in the chosen sample set (or maybe all samples), it may take more than 30 min to traverse all genes in all samples to generate the report.\n\n\n\n\nGenerated top-gene reports are stored in \nLand | Analytics | Open Result Set\n:",
            "title": "Advanced Analytics"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#advanced-analytics",
            "text": "",
            "title": "Advanced Analytics"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#sample-set",
            "text": "Like Gene Set, user can also create a sample set, a collection of Samples. Sample sets can contain additional sample meta data, which are supplementary to the meta data shipped with Land.  Unlike meta data and clinical data, which are normally controlled by administrators, sample sets can be created and managed by all users. Users can share the sample sets they created with other users and can also subscribe/unsubscribe sample sets.  User can create a sample set based on imported sample design table, selection in land or query analytics.",
            "title": "Sample Set"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-importing",
            "text": "To create sample set, go to  Land | Manage | Samples | Manage Sample Set :   Same as gene set, sample sets are organized by tags, user can add a new sample set by clicking  Add  and the following window will show up:   In the MetaData tab, user can upload sample set from file, local analysis or an omicsoft data object (.osobj) file:",
            "title": "Create A Sample Set by Importing"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-selection",
            "text": "User can create sample set directly by selection/filter using the following four options in  Sample Set :   Create sample set will only create a set of samples selected (marked as red in views) or visible after filter:   Group sample set will include all samples but mark them as Yes/No as meta data:   In the Info tab, user will name sampleset (such as  NUSAP1 upregulated samples  ), tag the sampleset (such as  PRAD, NUSAP1  ) and set Readers and Editors access.",
            "title": "Create A Sample Set by selection"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#create-a-sample-set-by-land-analytics",
            "text": "ArrayLand also provides a list of powerful analytic functions to query the whole land database and create sample set, based on mutation, copy number status:   Taking generating  Generate Site Mutation Status Sample Set  as one example, it will open a query window:   Site mutation query allows user to input mutation ID (in the format of  chr.position.alteration  ) or mutation amino acid change, such as  BRAF.V600E . In the example above, we query four types of mutations together, including IDH1.R132* (IDH1 mutations change 132th amino acid position from R to anything).  Once click  Send to Queue , the analytic job will send to ArrayServer job queue:   Once job finishes, the sample set,  Test BRAF IDH RNASeq Mutation SampleSet , will show in  Land | Manage | Samples | Manage Sample Sets . Mutation status, MUT or WT, is marked for each mutation site in the sample set.   User can modify the permission, sample set tags by clicking Edit/Update after a sample set is created.   Once a sample set is created, users can subscribe the sample set.   Once a sample set is subscribed, a check mark will appear in front of the sample set name.   Once you subscribe to a sample set, you will see it in  all future  land queries, as a filter column in Sample tab under \"Sample Set\", and also a profile column to trellis and split samples in the visualization.  Below is the  IDH1  expression boxplot, categorized by Tumor Type (filter to SKCM only), Sample Type and  BRAF  mutation status:",
            "title": "Create A Sample Set by Land Analytics"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#custom-query",
            "text": "Custom query  provides another approach to query genes/features quickly.  Custom queries are created by dynamic land database query. Custom queries can be combined and they can be viewed by OmicPrint. But unlike sample sets, custom queries cannot be shared, nor can they be used to limit samples used in  Analytics .",
            "title": "Custom Query"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#add-omic-data-query",
            "text": "To add a custom query, click the icon besides  Select View  and choose from the list:   We provide custom queries of a gene on expression, CNV, mutation, fusion and RPPA.  The following example shows how to query the expression level of  ERG  and  TMPRSS2  in RNA-Seq dataset, separated by ',':   We can also query the  TMPRSS2->ERG  fusion in RNA-Seq dataset:   Three query results are immediately available to do customizations for the current view.   In the view above for ERG  Gene FPKM , we filter  Tumor Type  to PRAD,  specify multiple profile columns  to Tumor Type and Fusion Status   And  Change Symbol Properties  to color by  ERG  expression status:   The color legend is shown on the Legend tab, where you can change color for each category:   Numeric data (Like Expression Ratio, RPPA, FPKM etc) can also be categorized by user-defined breakpoints. Say we want the samples with FPKM less than 10% as \"Low\", larger than 90% as \"High\" and Others as \"Middle\", the breakpoints can be set as this   Then the custom query will show as   The categorization is based on the overall samples. If users want the categorization based on each group, then check  Discretization for each group .  The custom query can also be performed using summarized numeric data in multiple genes by checking  Summarize multiple genes by  and choosing a summarization method.",
            "title": "Add Omic Data Query"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#add-measurement-data-query",
            "text": "In addition to Omic Data Query, measurement data query can also be added if measurement data has been imported. Detailed information about measurement data will be described in the next chapter.",
            "title": "Add Measurement Data Query"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#combine-multiple-queries",
            "text": "After creating multiple Custom Queries in Land Sample tab, users can use AND/OR logic to combine multiple custom queries.  From the left panel, users can select multiple levels in different queries to combine. The default logic is  OR .   If users want to use  AND  logic to combine queries, please check  Match all  option.",
            "title": "Combine Multiple Queries"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#other",
            "text": "Users can also add SampleSet query (for the sample sets, regardless of whether they are subscribed or not) and MetaData query.  Sample Sets can also be created from custom queries:   Moreover, ArrayLand provides an overview of all custom query results as an  OmicPrint  view:   OmicPrint view is a tree, categorized by tumor type, then gene names and queries. The same sample is aligned vertically. It will show the sample ID when users mouse over the block. Sample blocks are colored by alteration types, such as mutation (MUT), amplified, deleted, etc.  From the view above, we can see clear the correlation between  ERG  up-regulation and presence of  TMPRSS2->ERG  fusion.",
            "title": "Other"
        },
        {
            "location": "/tutorials/OncoLand/Advanced_Analytics/#report-top-gene-list",
            "text": "In Land analytics, we also provide tools to scan all or a subset of samples for top mutated, amplified or deleted genes, top fusion and top transcripts:   Below is one example of scanning COAD samples for top mutated genes (only select important mutation types shown in at least 10% of samples). The COAD sample set can be created by \"Create Sample Set From Selection\", described in the sample set chapter. By clicking  Send to Queue , the job will run on ArrayServer. Depending on the number of samples in the chosen sample set (or maybe all samples), it may take more than 30 min to traverse all genes in all samples to generate the report.   Generated top-gene reports are stored in  Land | Analytics | Open Result Set :",
            "title": "Report Top Gene List"
        },
        {
            "location": "/tutorials/OncoLand/Measurement_Data/",
            "text": "Measurement Data\n\u00b6\n\n\nMeasurement data is orthogonal data associated with Land Omics Data, such as compound/drug screening and RNAi data.\nUser can add measurement data to create views and query the land omics data.\n\n\nImport Measurement Data\n\u00b6\n\n\nIn this tutorial, we are using a cell line land data as one example since it has drug screening data.\nUser can add measurement data in \nManage | Measurement | Add Measurement Data\n:\n\n\n\n\nThe measurement data source file should have columns for Sample ID matching Land samples, measurement label column containing compound/screening names, and one or more measurement columns. Example of IC50 table below:\n\n\n\n\nUser can browse the measurement data using \nManage | Measurement | Manage Measurement Data\n:\n\n\n\n\nUser can also add measurement meta data in \nManage | Measurement | Add Measurement Meta Data\n\n\n\n\nThese meta data will be attached to each compound when browsing them in \nManage Measurement Data\n window.\n\n\nSearch/Visualize Measurement Data\n\u00b6\n\n\nOnce measurement data is imported, the measurement labels (such as compound names) are searchable in the search box:\n\n\n\n\nThere are boxplot and heatmap views for this compound:\n\n\n\n\nMeasurement Data Query\n\u00b6\n\n\nMeasurement data can also be used to query Land Omic Data in \ncustom query\n in any \nSample\n tab:\n\n\n\n\nUser can categorize the measurement data into categories, such as sensitive and resistant, using numeric break points or directly labeling. Here we categorize the drug IC50 values for Nutlin-3a by:\n\n\n\n\n<3: sensitive\n\n\nBetween 3 and 6: middle\n\n\n\n\n\n\n6 Resistant\n\n\n\n\n\n\n\n\n\n\nThe custom query results can be used as a filter and profile column in views for Omics data.",
            "title": "Measurement Data"
        },
        {
            "location": "/tutorials/OncoLand/Measurement_Data/#measurement-data",
            "text": "Measurement data is orthogonal data associated with Land Omics Data, such as compound/drug screening and RNAi data.\nUser can add measurement data to create views and query the land omics data.",
            "title": "Measurement Data"
        },
        {
            "location": "/tutorials/OncoLand/Measurement_Data/#import-measurement-data",
            "text": "In this tutorial, we are using a cell line land data as one example since it has drug screening data.\nUser can add measurement data in  Manage | Measurement | Add Measurement Data :   The measurement data source file should have columns for Sample ID matching Land samples, measurement label column containing compound/screening names, and one or more measurement columns. Example of IC50 table below:   User can browse the measurement data using  Manage | Measurement | Manage Measurement Data :   User can also add measurement meta data in  Manage | Measurement | Add Measurement Meta Data   These meta data will be attached to each compound when browsing them in  Manage Measurement Data  window.",
            "title": "Import Measurement Data"
        },
        {
            "location": "/tutorials/OncoLand/Measurement_Data/#searchvisualize-measurement-data",
            "text": "Once measurement data is imported, the measurement labels (such as compound names) are searchable in the search box:   There are boxplot and heatmap views for this compound:",
            "title": "Search/Visualize Measurement Data"
        },
        {
            "location": "/tutorials/OncoLand/Measurement_Data/#measurement-data-query",
            "text": "Measurement data can also be used to query Land Omic Data in  custom query  in any  Sample  tab:   User can categorize the measurement data into categories, such as sensitive and resistant, using numeric break points or directly labeling. Here we categorize the drug IC50 values for Nutlin-3a by:   <3: sensitive  Between 3 and 6: middle    6 Resistant      The custom query results can be used as a filter and profile column in views for Omics data.",
            "title": "Measurement Data Query"
        },
        {
            "location": "/tutorials/OncoLand/Land_Tools/",
            "text": "Land Tools\n\u00b6\n\n\nArrayLand provides other Tools to download a slice of Land to ArrayStudio local analysis:\n\n\n\n\nDownload Sample Data To Local Analysis\n\u00b6\n\n\nThe \nDownload Sample Data To Local Analysis\n function allows users to query the Land database with a list of genes or a list of samples and download them as OmicData/Table to Local Analysis project.\n\n\nUsers must first open or create a project in ArrayStudio Analysis:\n\n\n\n\nThen open the \nDownload Sample Data To Local Analysis\n window in the \nLand\n tab. There are two options. Users can download selected genes across all samples, and can also download selected samples across all genes. Specify the target ArrayStudio project to store downloaded Land data, a collection of samples (sampleSet) or get all samples. Choose the land data type to download, each one will be an OmicData/Table in ArrayStudio project. Note:\n\n\n\n\nOriginal data\n is the original values stored in Land, such as RNA-Seq FRKM at transcript level and microarray data at probeset level.\n\n\nGene level\n data are values summarized at gene level.\n\n\nMatrix data\n is to organize output as \nfeature by Samples\n in \"MicroArray\" format if possible.\n\n\nBy default, only \nPrimaryGrouping\n and \nSecondaryGrouping\n columns are attached as design in each generated OmicData. Check \nFull meta data\n box will be download all sample meta data as a table in the project.\n\n\n\n\n\n\nDownloaded data are shown as project contents:\n\n\n\n\nUser can do more advanced data analysis and visualizations on downloaded data objects use ArrayStudio functions.\n\n\nDownload Sample Data To Text Files\n\u00b6\n\n\nUser can also download land data to text files through \nLand | Download | Download Sample Data To Text Files\n:",
            "title": "Land Tools"
        },
        {
            "location": "/tutorials/OncoLand/Land_Tools/#land-tools",
            "text": "ArrayLand provides other Tools to download a slice of Land to ArrayStudio local analysis:",
            "title": "Land Tools"
        },
        {
            "location": "/tutorials/OncoLand/Land_Tools/#download-sample-data-to-local-analysis",
            "text": "The  Download Sample Data To Local Analysis  function allows users to query the Land database with a list of genes or a list of samples and download them as OmicData/Table to Local Analysis project.  Users must first open or create a project in ArrayStudio Analysis:   Then open the  Download Sample Data To Local Analysis  window in the  Land  tab. There are two options. Users can download selected genes across all samples, and can also download selected samples across all genes. Specify the target ArrayStudio project to store downloaded Land data, a collection of samples (sampleSet) or get all samples. Choose the land data type to download, each one will be an OmicData/Table in ArrayStudio project. Note:   Original data  is the original values stored in Land, such as RNA-Seq FRKM at transcript level and microarray data at probeset level.  Gene level  data are values summarized at gene level.  Matrix data  is to organize output as  feature by Samples  in \"MicroArray\" format if possible.  By default, only  PrimaryGrouping  and  SecondaryGrouping  columns are attached as design in each generated OmicData. Check  Full meta data  box will be download all sample meta data as a table in the project.    Downloaded data are shown as project contents:   User can do more advanced data analysis and visualizations on downloaded data objects use ArrayStudio functions.",
            "title": "Download Sample Data To Local Analysis"
        },
        {
            "location": "/tutorials/OncoLand/Land_Tools/#download-sample-data-to-text-files",
            "text": "User can also download land data to text files through  Land | Download | Download Sample Data To Text Files :",
            "title": "Download Sample Data To Text Files"
        },
        {
            "location": "/tutorials/OncoLand/Virtual_Land/",
            "text": "Virtual Land\n\u00b6\n\n\nVirtual Land is a virtual link between multiple Array Lands. By creating a virtual land, users can search and compare across multiple lands.\n\n\nCreate Virtual Land\n\u00b6\n\n\nTo create a virtual land, go to \nTools | Create Virtual Land\n. Please note that the default server setting only allows administrators to be able to create virtual land.\n\n\n\n\nSelect multiple lands and enter a virtual land name:\n\n\n\n\nThe created virtual land will be listed in the land collection (right panel):\n\n\n\n\nCross Land Search\n\u00b6\n\n\nOpen a virtual land and search for one or multiple genes. The search includes data and samples from all Array Lands in this virtual land.\n\n\nThere is a column \"Source Land\" automatically added to the virtual land when it is created.\n\n\nData will be able to compare between different Array Lands by \nSpecify Multiple Profile Columns\n and add \nSourceLand\n in.\n\n\n\n\nThis tutorial represents just a piece of what ArraySuite is capable of. Feel free to try different options to get a feel for what the software can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team (\nsupport@omicsoft.com\n).",
            "title": "Virtual Land"
        },
        {
            "location": "/tutorials/OncoLand/Virtual_Land/#virtual-land",
            "text": "Virtual Land is a virtual link between multiple Array Lands. By creating a virtual land, users can search and compare across multiple lands.",
            "title": "Virtual Land"
        },
        {
            "location": "/tutorials/OncoLand/Virtual_Land/#create-virtual-land",
            "text": "To create a virtual land, go to  Tools | Create Virtual Land . Please note that the default server setting only allows administrators to be able to create virtual land.   Select multiple lands and enter a virtual land name:   The created virtual land will be listed in the land collection (right panel):",
            "title": "Create Virtual Land"
        },
        {
            "location": "/tutorials/OncoLand/Virtual_Land/#cross-land-search",
            "text": "Open a virtual land and search for one or multiple genes. The search includes data and samples from all Array Lands in this virtual land.  There is a column \"Source Land\" automatically added to the virtual land when it is created.  Data will be able to compare between different Array Lands by  Specify Multiple Profile Columns  and add  SourceLand  in.   This tutorial represents just a piece of what ArraySuite is capable of. Feel free to try different options to get a feel for what the software can do. For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ).",
            "title": "Cross Land Search"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nIn this tutorial we will explore several Lands in the \"DiseaseLand\" collection: Body Map (GTEx and Blueprint), DiseaseLand (Human and Mouse curated disease-centric studies), scLand (Human and Mouse single-cell RNA studies), and LINCS (Cell line pharmacologic perturbation using the Broad L1000 profiling system). Each Land has its own advantages, and all serve as great tools for exploring high impact disease-centric studies. Further details are available in the DiseaseLand release White Paper.\n\n\n\n\nTo get the access to these lands, user should first connect to a server:\n\n\n\n\nAnd then click the \nLand\n tab and click on \"Select Land\":\n\n\n\n\nBody Map Collection\n\u00b6\n\n\nIn the current release, \nBody Map\n includes two lands: GTEx and Blueprint. Samples in the Body Map collection are from normal tissue; these Lands are great for answering questions such as:\n* In what tissue is my gene expressed?\n* Which transcripts are usually expressed from that gene for my tissue of my interest?\n* Are there any genes with differential transcript usage between tissues, etc.\n\n\nGTEx\n\u00b6\n\n\nThe data in GTEx Land come from the Genotype Tissue Expression (GTEx) program, which aims to study human gene expression and regulation in multiple tissues. GTEx is a map of normal tissue, revealing the genetic variation, gene expression, and other molecular phenotypes in specific human tissues.\nIt is a great tool to provide biological interpretations of disease related genetic variations.\nCurrently, GTEx covers microarray and RNA-Seq expression data for nearly 10,000 samples.\n\n\nBlueprint\n\u00b6\n\n\nThe Blueprint dataset contains RNA-Seq data from a European epigenetic study \nlink\n, which focused on distinct types of haematopoietic cells from healthy individuals and on their malignant leukaemic counterparts.\n\n\nBlueprint Land has 258 samples from 57 cell types in the latest release. It is still in expansion and we will continue to add data to this Land (including eventually the ChIP-seq data). Blueprint Land is a great tool to look into different gene expression categorized by different cell lines.\n\n\nDiseaseLand Collection\n\u00b6\n\n\nImmunoLand and CVMLand\n\u00b6\n\n\nHistorically, ImmunoLand (focused on immunological and inflammatory disease) and CVMLand (cardiovascular and metabolic disease) were maintained as separate \"Lands\". As OmicSoft continued to add content, including projects focusing on neurological diseases, mood disorders, infectious diseases, etc., this explicit division became  less meaningful.\n\n\nNow, all non-oncology disease studies are in \nDiseaseLand\n, and sub-stratified by \"collection\" (Immuno or CVM). Subscribers to DiseaseLand may choose to subscribe to either collection, or both, but will always find the data in \nDiseaseLand\n.\n\n\nHundreds of new projects are added to DiseaseLand every quarter, and it is a customer-driven expanding database (If you have other disease areas that you are interested to add into ImmunoLand, please let us know by e-mailing Omicsoft support at \nsupport@omicsoft.com\n). Currently, DiseaseLand has more than 85,000 human samples and 25,000 mouse samples, across different cell types and tissues.\n\n\nOmicsoft has carefully curated both sample level data and \"comparison\" level data, allowing users to easily search and visualize data using common queries: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, etc. Expression data are reprocessed from raw files and normalized to a common standard, which dramatically improves cross-project comparisons.\n\n\nImmunoLand Collection\n\u00b6\n\n\nThe \nImmunoLand\n collection contains datasets retrieved from several public projects, including GEO (Gene Expression Omnibus), SRA (Sequence Read Archive), and ArrayExpress.\n\n\nAs the name implies, ImmunoLand is an immune-focused  database containing data from multiple data types (RNA-Seq, Expression, more), with a focus on immune-related diseases: Asthma/Respiratory Diseases, Arthritis, Allergies, COPD, IBD, Psoriasis, SLE (systemic lupus erythematosus), Multiple Sclerosis, Neurodegenerative Diseases, and Infectious Diseases.\n\n\nCVMLand\n\u00b6\n\n\nCVMLand mainly focuses on Cardiovascular  and metabolic disease: diabetes mellitus, glucose intolerance, infectious disease, islet autoantibody positive, lipid metabolism disorder, and nutrition disorders.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#introduction",
            "text": "In this tutorial we will explore several Lands in the \"DiseaseLand\" collection: Body Map (GTEx and Blueprint), DiseaseLand (Human and Mouse curated disease-centric studies), scLand (Human and Mouse single-cell RNA studies), and LINCS (Cell line pharmacologic perturbation using the Broad L1000 profiling system). Each Land has its own advantages, and all serve as great tools for exploring high impact disease-centric studies. Further details are available in the DiseaseLand release White Paper.   To get the access to these lands, user should first connect to a server:   And then click the  Land  tab and click on \"Select Land\":",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#body-map-collection",
            "text": "In the current release,  Body Map  includes two lands: GTEx and Blueprint. Samples in the Body Map collection are from normal tissue; these Lands are great for answering questions such as:\n* In what tissue is my gene expressed?\n* Which transcripts are usually expressed from that gene for my tissue of my interest?\n* Are there any genes with differential transcript usage between tissues, etc.",
            "title": "Body Map Collection"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#gtex",
            "text": "The data in GTEx Land come from the Genotype Tissue Expression (GTEx) program, which aims to study human gene expression and regulation in multiple tissues. GTEx is a map of normal tissue, revealing the genetic variation, gene expression, and other molecular phenotypes in specific human tissues.\nIt is a great tool to provide biological interpretations of disease related genetic variations.\nCurrently, GTEx covers microarray and RNA-Seq expression data for nearly 10,000 samples.",
            "title": "GTEx"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#blueprint",
            "text": "The Blueprint dataset contains RNA-Seq data from a European epigenetic study  link , which focused on distinct types of haematopoietic cells from healthy individuals and on their malignant leukaemic counterparts.  Blueprint Land has 258 samples from 57 cell types in the latest release. It is still in expansion and we will continue to add data to this Land (including eventually the ChIP-seq data). Blueprint Land is a great tool to look into different gene expression categorized by different cell lines.",
            "title": "Blueprint"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#diseaseland-collection",
            "text": "",
            "title": "DiseaseLand Collection"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#immunoland-and-cvmland",
            "text": "Historically, ImmunoLand (focused on immunological and inflammatory disease) and CVMLand (cardiovascular and metabolic disease) were maintained as separate \"Lands\". As OmicSoft continued to add content, including projects focusing on neurological diseases, mood disorders, infectious diseases, etc., this explicit division became  less meaningful.  Now, all non-oncology disease studies are in  DiseaseLand , and sub-stratified by \"collection\" (Immuno or CVM). Subscribers to DiseaseLand may choose to subscribe to either collection, or both, but will always find the data in  DiseaseLand .  Hundreds of new projects are added to DiseaseLand every quarter, and it is a customer-driven expanding database (If you have other disease areas that you are interested to add into ImmunoLand, please let us know by e-mailing Omicsoft support at  support@omicsoft.com ). Currently, DiseaseLand has more than 85,000 human samples and 25,000 mouse samples, across different cell types and tissues.  Omicsoft has carefully curated both sample level data and \"comparison\" level data, allowing users to easily search and visualize data using common queries: Treated vs Control, Disease vs Normal, Responder vs Non-Responder, etc. Expression data are reprocessed from raw files and normalized to a common standard, which dramatically improves cross-project comparisons.",
            "title": "ImmunoLand and CVMLand"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#immunoland-collection",
            "text": "The  ImmunoLand  collection contains datasets retrieved from several public projects, including GEO (Gene Expression Omnibus), SRA (Sequence Read Archive), and ArrayExpress.  As the name implies, ImmunoLand is an immune-focused  database containing data from multiple data types (RNA-Seq, Expression, more), with a focus on immune-related diseases: Asthma/Respiratory Diseases, Arthritis, Allergies, COPD, IBD, Psoriasis, SLE (systemic lupus erythematosus), Multiple Sclerosis, Neurodegenerative Diseases, and Infectious Diseases.",
            "title": "ImmunoLand Collection"
        },
        {
            "location": "/tutorials/DiseaseLand/Introduction/#cvmland",
            "text": "CVMLand mainly focuses on Cardiovascular  and metabolic disease: diabetes mellitus, glucose intolerance, infectious disease, islet autoantibody positive, lipid metabolism disorder, and nutrition disorders.",
            "title": "CVMLand"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/",
            "text": "Body Map\n\u00b6\n\n\nGTEx\n\u00b6\n\n\nGTEx shows  data from tissue profiling experiments, and is a good tool to visualize gene expression variation within and across tissues.\n\n\nIn this section, we will provide an overview of GTEx, including how to search a gene in GTEx, how to restrict gene expression queries to certain tissues, and how to visualize this gene expression in Genome Browser.\n\n\nGeneral View\n\u00b6\n\n\nOnce the GTEx data are loaded, users can select the \nSamples\n view under the \"select view\" tab. This displays the number of samples for each tissue, colored by Tissue Detail Type.\n\n\n\n\nSome of the tissues are broken down by color to show the detailed type of tissues. If you want to see the sample numbers for detailed tissue types, click Grouping - Tissue, and select Tissue Detail Type:\n\n\n\n\nThe view will plot each sample by detailed tissue type category:\n\n\n\n\nGene Search\n\u00b6\n\n\nLet\u2019s search for a gene to see its expression across different tissues. The gene used in this tutorial is \nserpinb7\n, which encodes a member of a family of proteins functioning as protease inhibitors.\n\n\nWhen you start to input a gene name, the search box will show the auto-complete feature (more than 2 letters):\n\n\n\n\nSelect \nserpinB7\n from the list, or complete the entry and select \nSearch\n. The user can see the expression level of serpinb7 across all the GTEx tissues:\n\n\n\n\nIt is clear that serpinb7 is highly expressed in Skin. The user can use the Filter pane (left-hand side) to select Skin as the only Tissue type in Meta Data:\n\n\n\n\nThis will leads to a gene expression view focused on Skin Tissue:\n\n\n\n\nThen user can group the data by tissue detail type to take a further look,\n\n\n\n\nThe view will show serpinb7 expression in both Sun Exposed Skin and Not Sun Exposed Skin:\n\n\n\n\nTranscript and Exon View\n\u00b6\n\n\nThe RNA-Seq data on this Land is not only available at the gene level, but also available at the exon and transcript level. If the user wants to figure out which transcript has a high level of expression for the\nserpinb7 gene, it can be done with the Transcript FPKM (Multi-Transcript Chart)?:\n\n\n\n\n\n\nThe results demonstrate that there are four transcripts for serpinb7, among which the second one has very high expression level in skin tissue (uc010dqg4).\n\n\nThen if user wants to quickly visualize the expression of these transcripts at the exon level, just select the GenomeBrowser view:\n\n\n\n\nThe GenomeBrowser view plots coverage level of each exon for visible samples, by the specified \nGrouping\n. All transcripts in the gene model for the gene are shown at the top of the view, ranked by expression (highest expression on the top). Opacity of the transcripts indicates relative level of expression. In this view, we can tell that uc010dqg.4 is the most highly expressed:\n\n\n\n\nYou can also directly visualize RNAseq coverage, in the \nOmicSoft Genome Browser\n.\n\n\nSwitch back to the \nGene FPKM\n View, and select some samples of interest in the plot (e.g. some samples near median); multiple groups of samples can be selected by holding down \nCtrl\n.\n\n\n\n\nClick on Browse Selected Samples? in the \nAction\n pane, and select Open RNA Seq BAS files For Selection? (see the OmicSoft wiki to learn more about BAS files):\n\n\n\n\nThen select SubjectID? (View data from each Subject as a separate track) and click OK:\n\n\n\n\nNow the user can see expression of the gene SERPINB7 in these samples:\n\n\n\n\nMove the mouse to the subject ID label on the left, and click on Show Exon Junction?,\n\n\n\n\nThen the Exon junction will be available in the genome browser view:\n\n\n\n\nThis also reveals the differential expression of splice variants.\n\n\nBlueprint\n\u00b6\n\n\nThe data in Blueprint land are categorized by different haematopoietic cell lineages, so it\u2019s a great tool to look into the gene expression variation across related cell types. The ChIP-Seq data from Blueprint are not available yet in Blueprint Land, but we have processed all of the RNA-Seq data from Blueprint, and new data will be updated every quarter.\n\n\nFor this section, we will search for a gene named BLK in Blueprint Land. (the Blk gene is involved in B-lymphocyte development, differentiation and signaling.)\n\n\n\n\nThe Gene FPKM view shows that BLK gene has a very high expression level in B cells, which makes sense as it plays an important role in B-lymphocyte development, differentiation and signaling.\n\n\nSimilar to GTEx Land, you can also select samples and browse them in the Genome Browser to visualize the gene expression across different cell lines.",
            "title": "Body Map"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#body-map",
            "text": "",
            "title": "Body Map"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#gtex",
            "text": "GTEx shows  data from tissue profiling experiments, and is a good tool to visualize gene expression variation within and across tissues.  In this section, we will provide an overview of GTEx, including how to search a gene in GTEx, how to restrict gene expression queries to certain tissues, and how to visualize this gene expression in Genome Browser.",
            "title": "GTEx"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#general-view",
            "text": "Once the GTEx data are loaded, users can select the  Samples  view under the \"select view\" tab. This displays the number of samples for each tissue, colored by Tissue Detail Type.   Some of the tissues are broken down by color to show the detailed type of tissues. If you want to see the sample numbers for detailed tissue types, click Grouping - Tissue, and select Tissue Detail Type:   The view will plot each sample by detailed tissue type category:",
            "title": "General View"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#gene-search",
            "text": "Let\u2019s search for a gene to see its expression across different tissues. The gene used in this tutorial is  serpinb7 , which encodes a member of a family of proteins functioning as protease inhibitors.  When you start to input a gene name, the search box will show the auto-complete feature (more than 2 letters):   Select  serpinB7  from the list, or complete the entry and select  Search . The user can see the expression level of serpinb7 across all the GTEx tissues:   It is clear that serpinb7 is highly expressed in Skin. The user can use the Filter pane (left-hand side) to select Skin as the only Tissue type in Meta Data:   This will leads to a gene expression view focused on Skin Tissue:   Then user can group the data by tissue detail type to take a further look,   The view will show serpinb7 expression in both Sun Exposed Skin and Not Sun Exposed Skin:",
            "title": "Gene Search"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#transcript-and-exon-view",
            "text": "The RNA-Seq data on this Land is not only available at the gene level, but also available at the exon and transcript level. If the user wants to figure out which transcript has a high level of expression for the\nserpinb7 gene, it can be done with the Transcript FPKM (Multi-Transcript Chart)?:    The results demonstrate that there are four transcripts for serpinb7, among which the second one has very high expression level in skin tissue (uc010dqg4).  Then if user wants to quickly visualize the expression of these transcripts at the exon level, just select the GenomeBrowser view:   The GenomeBrowser view plots coverage level of each exon for visible samples, by the specified  Grouping . All transcripts in the gene model for the gene are shown at the top of the view, ranked by expression (highest expression on the top). Opacity of the transcripts indicates relative level of expression. In this view, we can tell that uc010dqg.4 is the most highly expressed:   You can also directly visualize RNAseq coverage, in the  OmicSoft Genome Browser .  Switch back to the  Gene FPKM  View, and select some samples of interest in the plot (e.g. some samples near median); multiple groups of samples can be selected by holding down  Ctrl .   Click on Browse Selected Samples? in the  Action  pane, and select Open RNA Seq BAS files For Selection? (see the OmicSoft wiki to learn more about BAS files):   Then select SubjectID? (View data from each Subject as a separate track) and click OK:   Now the user can see expression of the gene SERPINB7 in these samples:   Move the mouse to the subject ID label on the left, and click on Show Exon Junction?,   Then the Exon junction will be available in the genome browser view:   This also reveals the differential expression of splice variants.",
            "title": "Transcript and Exon View"
        },
        {
            "location": "/tutorials/DiseaseLand/BodyMap/#blueprint",
            "text": "The data in Blueprint land are categorized by different haematopoietic cell lineages, so it\u2019s a great tool to look into the gene expression variation across related cell types. The ChIP-Seq data from Blueprint are not available yet in Blueprint Land, but we have processed all of the RNA-Seq data from Blueprint, and new data will be updated every quarter.  For this section, we will search for a gene named BLK in Blueprint Land. (the Blk gene is involved in B-lymphocyte development, differentiation and signaling.)   The Gene FPKM view shows that BLK gene has a very high expression level in B cells, which makes sense as it plays an important role in B-lymphocyte development, differentiation and signaling.  Similar to GTEx Land, you can also select samples and browse them in the Genome Browser to visualize the gene expression across different cell lines.",
            "title": "Blueprint"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/",
            "text": "DiseaseLand\n\u00b6\n\n\nWhile the GTEx and Blueprint collections serve as atlases of gene expression, DiseaseLand provides expression data from thousands of curated studies focusing on diverse diseases. In addition, you have access to precomputed comparisons from each study:\nTreated vs Control, Disease vs Normal, Responder vs Non-Responder, where each comparison includes fold changes, raw p-values, adjusted p-values, sample IDs that generated the comparison, ranks, etc.\n\n\nDiseaseLand studies are separated by whether the study was performed in Human (HumanDisease_B37) or Mouse (MouseDisease_B38); the B37/B38 extension indicates the genome build used as the reference library.\n\n\nIn this tutorial, \nHumanDisease_B37\n will be used, but many more studies can be found in MouseDisease_B38.\n\n\nSample View\n\u00b6\n\n\nAfter opening DiseaseLand, the Sample Distribution view will be available, from which you can see how many samples are available for each disease.\n\n\n\n\nBy default, each sample is grouped by \nDiseaseCategory\n, which uses a controlled vocabulary to categorize each sample in Land by the type of disease (for more detailed categorization of diseases, use \nDiseaseState\n). Each sample is colored by \nTissueCategory\n (\nTissue\n provides a more specific description of the tissue source of each sample).\n\n\nIn the Sample Meta Data, we have a fully controlled vocabulary for most fields:\n\n\n\n\n\n\nProjectName, PlatformName, Organism, SampleSource, SampleType\n\n\n\n\n\n\nTissueCategory, Tissue, CellType\n\n\n\n\n\n\nDiseaseCategory, DiseaseState, DiseaseStage, Symptom, SamplePathology\n\n\n\n\n\n\nTreatment, Response, Transfection, SamplingTime\n\n\n\n\n\n\nEthnicity, Gender, Title, Description,\n\n\n\n\n\n\netc.\n\n\n\n\n\n\n\n\nWith these data, user can easily filter the data by each categories, for instance, data can be filtered by different DiseaseCategory.\n\n\n\n\nComparison View\n\u00b6\n\n\nNearly every DiseaseLand project includes at least one comparison between samples within the project, comparing groups of Case and Control samples across all genes, to identify differentially expressed genes. A comparison is based on grouping of samples based one or more metadata columns (e.g. \nDiseaseState\n or \nTreatment\n), so that all \nCase\n samples in a \nComparison\n will share the same metadata term (factor), but will differ from the \nControl\n samples.\n\n\nTo see an overview of available comparisons, Select the \ncomparisons View\n in the Land:\n\n\n\n\nThe user will be able to see all comparisons, classified by \nCase.TissueCategory\n:\n\n\n\n\nSelect the samples for \nCase.Skin\n. The detailed comparison table will appear in the detail window, from which you can find the comparison details, like \nComparison Type\n, \nCategory\n, \nContrast\n, \netc\n.\n\n\n\n\nInstead of using t-test for all comparisons, Omicsoft statisticians/bioinformaticians work with curation scientists and select the best experimental factors to include in the analysis for each project. We also consider block effects, match samples, and random effects during mathematical modeling. For microarray expression data, linear models are used for log2 transformed intensity and DESeq2 is used for RNA-Seq counting data.\n\n\nDownload Comparison Data\n\u00b6\n\n\nIf the user is interested in particular comparisons, they can download the comparison set to local projects or text files for further analysis. DiseaseLand provides the option to download a set of comparison data for several interesting genes, or for all genes.\n\n\nFor instance, if you are interested in comparisons related to diabetes, use the main Comparison View to identify interesting comparisons, then create a comparison set for diabetes first, and then download the comparison data.\n\n\nHere are the steps to create a comparison set. Open the Comparison view (from the main Land View), and filter the \nCase.Diseasecategory\n for diabetes:\n\n\n\n\n\n\nThe \nComparisons View\n will show a bar plot of comparisons that used Diabetes samples in the \nCase\n set.\n\n\n\n\nSelect the \"Disease vs. Normal\" comparisons for hematopoietic system. The details window shows the number of comparisons available related to diabetes. Click on \nCreate ComparisonSet\n, and choose \"Create Comparison Set From Selection\":\n\n\n\n\nInput the name and tags for this comparison set (you can input whatever content you like):\n\n\n\n\nOnce the comparison set is created, it should be able to be seen from Manage | Comparisons | Manage Comparison Sets:\n\n\n\n\n\n\nThe next step is to download the comparison data. As the following image shows, users can download the data to local analysis or text files, both with the option to download selected genes across all comparisons, or download selected comparisons across all genes:\n\n\n\n\nAnd\n\n\n\n\nIn this tutorial we will just show the example of downloading selected genes across all comparisons (in the comparison set) to local analysis. Be sure to open a local project in Analysis first.\n\n\n\n\n\n\n\n\nChoose the comparison set just created;\n\n\n\n\n\n\nSelect the data format you want to downland;\n\n\n\n\n\n\nInput the genes you are interested in (here we used genes associated with developing type 2 diabetes, including TCF7L2, PPARG, FTO, KCNJ11, NOTCH2, WFS1, IGF2BP2, SLC30A8, JAZF1, HHEX);\n\n\n\n\n\n\nInput the output name and click \nDownload\n.\n\n\n\n\n\n\nOnce the download is finished, switch to the \nAnalysis\n tab, and the table view will show the relative gene expression value for the selected genes across all of the comparisons:\n\n\n\n\nBe sure to try the other options to download comparison data to text file, or download all genes for these comparisons.\n\n\nGene Views\n\u00b6\n\n\nIf we do a gene search for \nserpinb7\n in DiseaseLand, the default view that appears is the \nComparison - Disease vs. Normal\n view, which quickly shows all \nDisease vs. Normal\n comparisons (\ne.g.\n Psoriasis vs. Normal Control), categorized by different diseases.\n\n\nAs shown in the figure below, each circle indicates one Comparison: Log2 Fold Change between Case and Control is plotted on the X-axis, and the size of the circle indicates the P-value (significance) (larger circles are more significant).\n\n\n\n\nFrom the comparison view, it should be clear to the user that this gene is upregulated in several comparisons related to IBD (inflammatory bowel disease), but down-regulated in several cancers.\n\n\nDrag the mouse over one or more spots and select them. This will bring up the comparison details at sample level, which shows the comparisons, genes, meta data information, and a box-plot that shows the sample-level comparison, in this case for ulcerative colitis (UC) vs. normal control.\n\n\n\n\nDouble-click on the box plot in the right corner to expand the plot so that user can see a full window of the expression profile for \nserpinb7\n in this sample, which demonstrates the original comparison data composing the dot in comparison view. There is an obvious up-regulation for this gene in ulcerative colitis (UC) samples vs. normal control:\n\n\n\n\nIf the user clicks on the \"+\" symbol to the left of the Details window, a \"Selection Details\" window will pop out from the left corner, and you can view additional details at Gene level, probeset level, and project level. If you select gene level, you can see table view for the comparison in the Details window, as you can see below, we also have a fully controlled vocabulary for the comparison data:\n\n\n\n\nThe data includes ProjectName, PlatformName, ComparisonType, ComparisonCategory, ComparisonContrast, Fold Change [log2], PValue, Adjusted PValue,\nComparisonModel, SampleDataMode, Case.DiseaseState, Case.SampleSource, Case.Tissue, Case.CellType, Case.SampleIDs, Control.DiseaseState, Control.SampleSource, Control.Tissue, Control.CellType, Control.SampleIDs, etc.\n\n\nClick on the Comparison Details (ProbeSet Level), the detailed information will show which probe set was displayed for this gene:\n\n\n\n\nClick on Comparison Details (Project Level) to get more information regarding the project itself:\n\n\n\n\nAnd the detail window will show all the information related to the project, like authors, study type, title of the project, etc.\n\n\n\n\nIn the \nFilter\n pane, Click on the Comparison tab.  All of the displayed data can be filtered by various types of categories for categorical data (e.g. Case.DiseaseState, Control.Tissue, etc), and by different Cutoffs for numerical data (Fold-Change, Sample Size, P-value, etc):\n\n\n\n\n\n\nNow click on the Select View Tab. By default, the \nDisease vs. Control\n comparisons are displayed, but there are many comparison types available in ImmunoLand: Disease vs. Normal, Disease1 vs. Disease2, CellType1 vs. CellType2, Treatment vs. Control, Treatment1 vs. Treatment2, Responder vs. NonResponder, etc.\n\n\n\n\nExplore these different Comparison Views to learn more about the different comparison types.\n\n\nProject View for all samples\n\u00b6\n\n\nIf the user is interested in a specific microarray project, it can be selected in the view for Expression Intensity (project View)?:\n\n\n\n\nInitially, the view will show one chart for each available array project:\n\n\n\n\nThe user can click on the sample tab, then expand the filter categories to view Meta Data, and click on the symbol to the left of \"DiseaseCategory\". The user can filter for diseases by keywords, for example \"skin\", which will show \"skin and connective tissue disease\".\n\n\n\n\nThe data will be immediately filtered down to only show charts matching the filter criteria:\n\n\n\n\nBesides project information, there are also other filters available for the comparison, like project Description, contact information, platform information, publication information, and project name.\n\n\n\n\n\n\n\n\n\n\nClick on the \nReset All Filters\n button to reset all the filters:\n\n\n\n\nSimilarly, users can browse RNA-seq data and filter to studies of choice:\n\n\n\n\nThis opens >150 charts in the project view for RNA-seq, with the project and platform name in the title of each chart:\n\n\n\n\nYou can also view RNAseq and microarray expression data across projects, grouped by one or more metadata columns.\nAs we demonstrated in GTEx and blueprint, the user can get views for DiseaseLand RNA-seq data like Gene FPKM, Transcript FPKM, and Genome Browser view for Exon Details:\n\n\n\n\nSelect Gene FPKM view: The view will show gene expression levels across different disease categories:\n\n\n\n\nAnd ArrayStudio allows the user to compare the gene expression across different datasets. Select skin disease to filter the disease again:\n\n\n\n\nAnd then group the data by Sample Pathology:\n\n\n\n\nThese samples will be separated to lesional and non-lesional, from which we can see a pattern for increased expression of \nserpinb7\n in lesional samples.\n\n\n\n\nSamples can be profiled by multiple metadata factors, using \nSpecify Multiple Profile Columns\n:\n\n\n\n\nSelect \nDiseaseState\n and \nSamplePathology\n.\n\n\n\n\nThe \nGene FPKM\n plot will now subset expression of each sample by the Disease (e.g. psoriasis, atopic dermatitis, etc.) and the pathology of the sample (lesional or non-lesional):\n\n\n\n\nAlternative Splicing Detection\n\u00b6\n\n\nWith the former result, you might be interested to find a list of genes with alternative splicing between the lesional and non-lesional samples. How can you find these genes? The basic logic is to create a Sample Set including lesional and non-lesional samples, upload this sample set to the Land, and analyze the alternative splicing through the \nsample grouping => splicing\n function in the analysis:\n\n\n\n\nThe first step is to create the right sample set. Recreate the View made in an earlier section (Gene FPKM view for serpinb7), where the samples were filtered by skin and connective tissue disease, and the view was grouped by sample pathology (filtering for lesional and non-lesional):\n\n\n\n\nThen we can choose \nCreate SampleSet\n, then select all samples and \nCreate SampleSet from Selection\n (This will create a SampleSet containing all selected samples that passed your \nfilter\n criteria). Give the SampleSet a name, and provide at least one tag for the sample set, then click Upload:\n\n\n\n\nNow go back to do the analysis. Select \nAnalytics | Integration Analysis | Sample Grouping=>Splicing\n:\n\n\n\n\n\n\n\n\nSelect the SampleSet you just created (restrict the analysis to these samples)\n\n\n\n\n\n\nChoose SamplePathology from the meta data (compare samples by this metadata column)\n\n\n\n\n\n\nUse RNASeq_Transcript as the data (contains transcript-level information)\n\n\n\n\n\n\nProvide a name for the result set\n\n\n\n\n\n\nclick on Send To Queue?:\n\n\n\n\n\n\n\n\nThis analysis will be submitted for a server job:\n\n\n\n\nWhen complete, this analysis will return a result table. Open the results in \nAnalytics | Open Result Sets\n. Find the one with your output name.\n\n\n\n\n\n\nThe results should look similar to below:\n\n\n\n\nBy sorting with Transcript PValue, SerpinB7 appeared as one of the most significant high level splicing genes:\n\n\n\n\nAnd the alternative splicing can be visualized in Genome Browser. Go back to the Gene FPKM view and select several samples from lesional and non-lesional (hold the 'ctrl' keyboard button to select multiple sample groups):\n\n\n\n\nThese results can be visualized in the browser:\n\n\n\n\n\n\nAnd select SamplePathology as the grouping factor:\n\n\n\n\nBased on the genome browser view, user can easily tell the alternative splicing pattern compared between lesional and non-lesional transcripts (marked in green circle):\n\n\n\n\nActually, as we can see from the Integration Analysis view, besides alternative splicing, similar methods can be applied to compare the Expression level, Copy Number, and Mutation between the pre-defined sample sets, based on the corresponding data availability:\n\n\n\n\nThese Analytic functions can be used to quickly identify differences between customized sample groups.\n\n\nClinical Association For DiseaseCategory\n\u00b6\n\n\nClinical Significance - Group Association\n can quickly scan \nall\n clinical variables in DiseaseLand to find the association of each clinical variable with your selected grouping metadata column.\n\n\nBecause this calculation can be quite complicated, it is recommended that you first filter down to samples of interest (e.g. DiseaseCategory or TissueCategory), then open this View.\n\n\n\n\n\n\nThe association table is dynamic. Using SampleSets and Omic Data Queries, you can create a custom cohort to separate the groups to compare.\n\n\nHere are the steps to create a custom query:\n\n\n\n\nSeparate Expression intensity of Serpinb7 into three groups based on percentile. Specifically, specify two breakpoints (33% and 67%, separated by commas), then label the three groups that are created by the two breakpoints (low,mid,high) (You can specify any number of breakpoints, as long as you provide a label for each group):\n\n\n\n\nThen group the association with the custom query:\n\n\n\n\nUser can also filter the metadata to get a more specific correlation:\n\n\n\n\nFind Genes with Similar Expression Pattern\n\u00b6\n\n\nIn order to find genes with similar expression pattern with the searched gene, the user can either compare genes at the \nComparison\n level (i.e. fold-change between case and control) or the \nExpression\n level (e.g. compare Gene FPKM levels in each sample). To look for genes that have similar patterns of up- and down-regulation with your gene of interest, select Comparison Correlations view:\n\n\n\n\nFor instance, this is the dynamic correlation comparison view for serpinb7 gene, which shows that IL12B is the most highly correlated gene to serpinb7 (As additional data are added to DiseaseLand, these correlations may change in rank):\n\n\n\n\nClick on View Correlation Table, for the detailed information for these genes:\n\n\n\n\nUsers can also specify the disease type for a smaller sample, for instance, just focus on the disease type related to Psoriasis:\n\n\n\n\nFiltering for psoriasis samples reveals several genes with strong correlations with SerpinB7.\n\n\nBesides the dynamic correlation at the comparison level, DiseaseLand also can correlate at the gene expression level, using \nIntegration|RNA-Seq-Expression => RNA-Seq-Expression\n:\n\n\n\n\nThis view will show the genes with similar expression levels compared to serpinb7:\n\n\n\n\nExplore Related Comparisons\n\u00b6\n\n\nAfter searching for a gene of interest, such as Serpinb7, certain \nComparisons\n may show significant differential expression of this gene. You can explore these Comparisons to see the up- and down-regulation of \nall\n genes, to get a global perspective on these results.\n\n\nSelect view of Disease vs. Normal for serpinb7 gene:\n\n\n\n\nGroup the data by Case.DiseaseCategory:\n\n\n\n\nFrom the comparison view we can find that an upregulation of gene expression for the samples related to IBD. What other genes are upregulated in these samples besides serpinb7? What else is changing in IBD?\n\n\n\n\nSelect several comparisons for IBD (or comparisons from IBD and from other diseases), then go to Browse Selected Comparisons? on the bottom-left corner:\n\n\n\n\nThe default view is a set of \nvolcano plots\n, one per Comparison, with log2(fold change) on the X-axis and -log10(RawPValue) as the Y-axis (for each project):\n\n\n\n\nFor each comparison, genes that are significantly differentially expressed will be higher on the Y-axis, with up-regulation to the right, and down-regulation to the left.\n\n\nGo to the \nSelect View\n tab, where there are several options:\n\n\n\n\nVenn Diagram\n shows how the significant genes correlated with each comparison (up to four comparisons per Venn Diagram):\n\n\n\n\nUse the \nCutoff\n Filter tab to control the significance cutoffs (fold-change, P-value, etc) for genes in the Venn Diagram view, as well as the Gene, pathway, project, etc.\n\n\n\n\nThe Comparison Table contains the full \nInference Report\n for selected comparisons; the user can see a matrix with all the PValue and fold changes, for all the genes curated for the selected samples.\n(Not all the platforms have every gene, so some of them are missing in the table). This is a useful table if the user wants to analyze it outside of the software. For example, users with a license for QIAGEN Ingenuity Pathway Analysis (IPA) can directly send these results to IPA with a single click:\n\n\n\n\nThe \nprincipal component\n view shows a generalized distribution of all comparisons selected:\n\n\n\n\nThe \nSummary Statistics\n view shows which gene is most up/down-regulated, how many genes have significant changes for their expressions, etc:\n\n\n\n\nThe \nSignificant Genes\n view shows each gene whose expression is up- or down- regulated; and user can sort to organize the result, such as by \nUp-Regulated Count\n:\n\n\n\n\nThen user can select the genes with the highest up-regulated count and create a gene set from the selection:\n\n\n\n\nInput names and tags for the GeneSet:\n\n\n\n\nGeneSets are a convenient way to group collections of interesting genes. The user can search with the newly created gene set:\n\n\n\n\nAnd filter the result with IBD disease in Case.DiseaseCategory:\n\n\n\n\nThen heatmap of comparison clearly shows an up-regulation pattern for these genes:\n\n\n\n\nGene Set Analysis\n\u00b6\n\n\nIf user has followed the previous step (Gene Expression Based on Disease/Comparison) to generate a gene set (named as IBD upregulation), user can directly search in the land:\n\n\n\n\nIf there is no gene set already created, the user can also directly search with multiple genes:\n\n\n\n\nAnd paste genes: CHI3L1,CD55,CFB,IL8,TIMP1,PLAU,NAMPT,CXCL1,ADM,IL1RN\n\n\n\n\nFollowing the Gene set search or searching with multiple genes, ArrayStudio provides a function for identifying Comparisons within the Land that share lists of significant genes with the input set, named \nGene Set Analysis\n:  \n\n\n\n\nFor each Land Comparison, a set of significant genes are identified, and Gene Set Analysis performs a Fisher-exact test for the overlap of your input GeneSet and each Land GeneSet to generate p-values for each comparison. Significant overlaps will be plotted to the right, which might reveal unexpected similarities between your input GeneSet and Land Comparisons.\n\n\nIn this view, the X-axis represents the Log10 of P-Value resulted from Fisher-exact test, and Y-axis stands for the Disease Category (the user can also use Specify Profile Column? under Task tab to regroup the comparisons with other metadata columns):\n\n\n\n\nIf the user selects one of the dots, the detailed window will show the P-value, up/down-regulated gene#, and the project information.\n\n\n\n\nDiseaseLand also allows for the creation of GeneSets with other columns, like \"Fold Change\", \"Raw PValue\", \"Adjusted PValue\", etc. An example gene set is shown here:\n\n\n\n\nUsers can save an inference table from their local analysis as a .txt file and load them to the Land as a gene set, by going to \nManage|Genes|Manage Gene Sets\n:\n\n\n\n\nThen Add the Geneset like this:\n\n\n\n\nIn the MetaData section, load the txt file saved earlier (you can use your own table):\n\n\n\n\nOnce it's done, go to DiseaseLand without searching any gene, and open the view of Gene Set Analysis (Plot or Table),\n\n\n\n\nAnd choose the Geneset just created. Because P-value and/or Fold-change was provided, GeneSet Analysis uses a Wilcoxon test. For detailed information of the Geneset analysis and the underlying statistics, please refer to our wiki: \nhttp://www.arrayserver.com/wiki/index.php?title=Comparison.GeneSetAnalysis\n.   \n\n\n\n\nPathway Search\n\u00b6\n\n\nUsers can also search with Pathways in DiseaseLand for a list of genes:\n\n\n\n\nAs the window shows, we provide Positional gene sets, Curated gene sets, Motif gene set, Computational gene sets, GO gene sets, Oncogenic signatures, and Immunologic signatures:\n\n\n\n\nSelect the gene set of interest, and click OK. Genes in this curated pathway will be searched, and the view will show a Heatmap of Comparison for Disease vs. normal for all the genes in the gene set, categorized by disease type and tissue type.",
            "title": "DiseaseLand"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#diseaseland",
            "text": "While the GTEx and Blueprint collections serve as atlases of gene expression, DiseaseLand provides expression data from thousands of curated studies focusing on diverse diseases. In addition, you have access to precomputed comparisons from each study:\nTreated vs Control, Disease vs Normal, Responder vs Non-Responder, where each comparison includes fold changes, raw p-values, adjusted p-values, sample IDs that generated the comparison, ranks, etc.  DiseaseLand studies are separated by whether the study was performed in Human (HumanDisease_B37) or Mouse (MouseDisease_B38); the B37/B38 extension indicates the genome build used as the reference library.  In this tutorial,  HumanDisease_B37  will be used, but many more studies can be found in MouseDisease_B38.",
            "title": "DiseaseLand"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#sample-view",
            "text": "After opening DiseaseLand, the Sample Distribution view will be available, from which you can see how many samples are available for each disease.   By default, each sample is grouped by  DiseaseCategory , which uses a controlled vocabulary to categorize each sample in Land by the type of disease (for more detailed categorization of diseases, use  DiseaseState ). Each sample is colored by  TissueCategory  ( Tissue  provides a more specific description of the tissue source of each sample).  In the Sample Meta Data, we have a fully controlled vocabulary for most fields:    ProjectName, PlatformName, Organism, SampleSource, SampleType    TissueCategory, Tissue, CellType    DiseaseCategory, DiseaseState, DiseaseStage, Symptom, SamplePathology    Treatment, Response, Transfection, SamplingTime    Ethnicity, Gender, Title, Description,    etc.     With these data, user can easily filter the data by each categories, for instance, data can be filtered by different DiseaseCategory.",
            "title": "Sample View"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#comparison-view",
            "text": "Nearly every DiseaseLand project includes at least one comparison between samples within the project, comparing groups of Case and Control samples across all genes, to identify differentially expressed genes. A comparison is based on grouping of samples based one or more metadata columns (e.g.  DiseaseState  or  Treatment ), so that all  Case  samples in a  Comparison  will share the same metadata term (factor), but will differ from the  Control  samples.  To see an overview of available comparisons, Select the  comparisons View  in the Land:   The user will be able to see all comparisons, classified by  Case.TissueCategory :   Select the samples for  Case.Skin . The detailed comparison table will appear in the detail window, from which you can find the comparison details, like  Comparison Type ,  Category ,  Contrast ,  etc .   Instead of using t-test for all comparisons, Omicsoft statisticians/bioinformaticians work with curation scientists and select the best experimental factors to include in the analysis for each project. We also consider block effects, match samples, and random effects during mathematical modeling. For microarray expression data, linear models are used for log2 transformed intensity and DESeq2 is used for RNA-Seq counting data.",
            "title": "Comparison View"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#download-comparison-data",
            "text": "If the user is interested in particular comparisons, they can download the comparison set to local projects or text files for further analysis. DiseaseLand provides the option to download a set of comparison data for several interesting genes, or for all genes.  For instance, if you are interested in comparisons related to diabetes, use the main Comparison View to identify interesting comparisons, then create a comparison set for diabetes first, and then download the comparison data.  Here are the steps to create a comparison set. Open the Comparison view (from the main Land View), and filter the  Case.Diseasecategory  for diabetes:    The  Comparisons View  will show a bar plot of comparisons that used Diabetes samples in the  Case  set.   Select the \"Disease vs. Normal\" comparisons for hematopoietic system. The details window shows the number of comparisons available related to diabetes. Click on  Create ComparisonSet , and choose \"Create Comparison Set From Selection\":   Input the name and tags for this comparison set (you can input whatever content you like):   Once the comparison set is created, it should be able to be seen from Manage | Comparisons | Manage Comparison Sets:    The next step is to download the comparison data. As the following image shows, users can download the data to local analysis or text files, both with the option to download selected genes across all comparisons, or download selected comparisons across all genes:   And   In this tutorial we will just show the example of downloading selected genes across all comparisons (in the comparison set) to local analysis. Be sure to open a local project in Analysis first.     Choose the comparison set just created;    Select the data format you want to downland;    Input the genes you are interested in (here we used genes associated with developing type 2 diabetes, including TCF7L2, PPARG, FTO, KCNJ11, NOTCH2, WFS1, IGF2BP2, SLC30A8, JAZF1, HHEX);    Input the output name and click  Download .    Once the download is finished, switch to the  Analysis  tab, and the table view will show the relative gene expression value for the selected genes across all of the comparisons:   Be sure to try the other options to download comparison data to text file, or download all genes for these comparisons.",
            "title": "Download Comparison Data"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#gene-views",
            "text": "If we do a gene search for  serpinb7  in DiseaseLand, the default view that appears is the  Comparison - Disease vs. Normal  view, which quickly shows all  Disease vs. Normal  comparisons ( e.g.  Psoriasis vs. Normal Control), categorized by different diseases.  As shown in the figure below, each circle indicates one Comparison: Log2 Fold Change between Case and Control is plotted on the X-axis, and the size of the circle indicates the P-value (significance) (larger circles are more significant).   From the comparison view, it should be clear to the user that this gene is upregulated in several comparisons related to IBD (inflammatory bowel disease), but down-regulated in several cancers.  Drag the mouse over one or more spots and select them. This will bring up the comparison details at sample level, which shows the comparisons, genes, meta data information, and a box-plot that shows the sample-level comparison, in this case for ulcerative colitis (UC) vs. normal control.   Double-click on the box plot in the right corner to expand the plot so that user can see a full window of the expression profile for  serpinb7  in this sample, which demonstrates the original comparison data composing the dot in comparison view. There is an obvious up-regulation for this gene in ulcerative colitis (UC) samples vs. normal control:   If the user clicks on the \"+\" symbol to the left of the Details window, a \"Selection Details\" window will pop out from the left corner, and you can view additional details at Gene level, probeset level, and project level. If you select gene level, you can see table view for the comparison in the Details window, as you can see below, we also have a fully controlled vocabulary for the comparison data:   The data includes ProjectName, PlatformName, ComparisonType, ComparisonCategory, ComparisonContrast, Fold Change [log2], PValue, Adjusted PValue,\nComparisonModel, SampleDataMode, Case.DiseaseState, Case.SampleSource, Case.Tissue, Case.CellType, Case.SampleIDs, Control.DiseaseState, Control.SampleSource, Control.Tissue, Control.CellType, Control.SampleIDs, etc.  Click on the Comparison Details (ProbeSet Level), the detailed information will show which probe set was displayed for this gene:   Click on Comparison Details (Project Level) to get more information regarding the project itself:   And the detail window will show all the information related to the project, like authors, study type, title of the project, etc.   In the  Filter  pane, Click on the Comparison tab.  All of the displayed data can be filtered by various types of categories for categorical data (e.g. Case.DiseaseState, Control.Tissue, etc), and by different Cutoffs for numerical data (Fold-Change, Sample Size, P-value, etc):    Now click on the Select View Tab. By default, the  Disease vs. Control  comparisons are displayed, but there are many comparison types available in ImmunoLand: Disease vs. Normal, Disease1 vs. Disease2, CellType1 vs. CellType2, Treatment vs. Control, Treatment1 vs. Treatment2, Responder vs. NonResponder, etc.   Explore these different Comparison Views to learn more about the different comparison types.",
            "title": "Gene Views"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#project-view-for-all-samples",
            "text": "If the user is interested in a specific microarray project, it can be selected in the view for Expression Intensity (project View)?:   Initially, the view will show one chart for each available array project:   The user can click on the sample tab, then expand the filter categories to view Meta Data, and click on the symbol to the left of \"DiseaseCategory\". The user can filter for diseases by keywords, for example \"skin\", which will show \"skin and connective tissue disease\".   The data will be immediately filtered down to only show charts matching the filter criteria:   Besides project information, there are also other filters available for the comparison, like project Description, contact information, platform information, publication information, and project name.      Click on the  Reset All Filters  button to reset all the filters:   Similarly, users can browse RNA-seq data and filter to studies of choice:   This opens >150 charts in the project view for RNA-seq, with the project and platform name in the title of each chart:   You can also view RNAseq and microarray expression data across projects, grouped by one or more metadata columns.\nAs we demonstrated in GTEx and blueprint, the user can get views for DiseaseLand RNA-seq data like Gene FPKM, Transcript FPKM, and Genome Browser view for Exon Details:   Select Gene FPKM view: The view will show gene expression levels across different disease categories:   And ArrayStudio allows the user to compare the gene expression across different datasets. Select skin disease to filter the disease again:   And then group the data by Sample Pathology:   These samples will be separated to lesional and non-lesional, from which we can see a pattern for increased expression of  serpinb7  in lesional samples.   Samples can be profiled by multiple metadata factors, using  Specify Multiple Profile Columns :   Select  DiseaseState  and  SamplePathology .   The  Gene FPKM  plot will now subset expression of each sample by the Disease (e.g. psoriasis, atopic dermatitis, etc.) and the pathology of the sample (lesional or non-lesional):",
            "title": "Project View for all samples"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#alternative-splicing-detection",
            "text": "With the former result, you might be interested to find a list of genes with alternative splicing between the lesional and non-lesional samples. How can you find these genes? The basic logic is to create a Sample Set including lesional and non-lesional samples, upload this sample set to the Land, and analyze the alternative splicing through the  sample grouping => splicing  function in the analysis:   The first step is to create the right sample set. Recreate the View made in an earlier section (Gene FPKM view for serpinb7), where the samples were filtered by skin and connective tissue disease, and the view was grouped by sample pathology (filtering for lesional and non-lesional):   Then we can choose  Create SampleSet , then select all samples and  Create SampleSet from Selection  (This will create a SampleSet containing all selected samples that passed your  filter  criteria). Give the SampleSet a name, and provide at least one tag for the sample set, then click Upload:   Now go back to do the analysis. Select  Analytics | Integration Analysis | Sample Grouping=>Splicing :     Select the SampleSet you just created (restrict the analysis to these samples)    Choose SamplePathology from the meta data (compare samples by this metadata column)    Use RNASeq_Transcript as the data (contains transcript-level information)    Provide a name for the result set    click on Send To Queue?:     This analysis will be submitted for a server job:   When complete, this analysis will return a result table. Open the results in  Analytics | Open Result Sets . Find the one with your output name.    The results should look similar to below:   By sorting with Transcript PValue, SerpinB7 appeared as one of the most significant high level splicing genes:   And the alternative splicing can be visualized in Genome Browser. Go back to the Gene FPKM view and select several samples from lesional and non-lesional (hold the 'ctrl' keyboard button to select multiple sample groups):   These results can be visualized in the browser:    And select SamplePathology as the grouping factor:   Based on the genome browser view, user can easily tell the alternative splicing pattern compared between lesional and non-lesional transcripts (marked in green circle):   Actually, as we can see from the Integration Analysis view, besides alternative splicing, similar methods can be applied to compare the Expression level, Copy Number, and Mutation between the pre-defined sample sets, based on the corresponding data availability:   These Analytic functions can be used to quickly identify differences between customized sample groups.",
            "title": "Alternative Splicing Detection"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#clinical-association-for-diseasecategory",
            "text": "Clinical Significance - Group Association  can quickly scan  all  clinical variables in DiseaseLand to find the association of each clinical variable with your selected grouping metadata column.  Because this calculation can be quite complicated, it is recommended that you first filter down to samples of interest (e.g. DiseaseCategory or TissueCategory), then open this View.    The association table is dynamic. Using SampleSets and Omic Data Queries, you can create a custom cohort to separate the groups to compare.  Here are the steps to create a custom query:   Separate Expression intensity of Serpinb7 into three groups based on percentile. Specifically, specify two breakpoints (33% and 67%, separated by commas), then label the three groups that are created by the two breakpoints (low,mid,high) (You can specify any number of breakpoints, as long as you provide a label for each group):   Then group the association with the custom query:   User can also filter the metadata to get a more specific correlation:",
            "title": "Clinical Association For DiseaseCategory"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#find-genes-with-similar-expression-pattern",
            "text": "In order to find genes with similar expression pattern with the searched gene, the user can either compare genes at the  Comparison  level (i.e. fold-change between case and control) or the  Expression  level (e.g. compare Gene FPKM levels in each sample). To look for genes that have similar patterns of up- and down-regulation with your gene of interest, select Comparison Correlations view:   For instance, this is the dynamic correlation comparison view for serpinb7 gene, which shows that IL12B is the most highly correlated gene to serpinb7 (As additional data are added to DiseaseLand, these correlations may change in rank):   Click on View Correlation Table, for the detailed information for these genes:   Users can also specify the disease type for a smaller sample, for instance, just focus on the disease type related to Psoriasis:   Filtering for psoriasis samples reveals several genes with strong correlations with SerpinB7.  Besides the dynamic correlation at the comparison level, DiseaseLand also can correlate at the gene expression level, using  Integration|RNA-Seq-Expression => RNA-Seq-Expression :   This view will show the genes with similar expression levels compared to serpinb7:",
            "title": "Find Genes with Similar Expression Pattern"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#explore-related-comparisons",
            "text": "After searching for a gene of interest, such as Serpinb7, certain  Comparisons  may show significant differential expression of this gene. You can explore these Comparisons to see the up- and down-regulation of  all  genes, to get a global perspective on these results.  Select view of Disease vs. Normal for serpinb7 gene:   Group the data by Case.DiseaseCategory:   From the comparison view we can find that an upregulation of gene expression for the samples related to IBD. What other genes are upregulated in these samples besides serpinb7? What else is changing in IBD?   Select several comparisons for IBD (or comparisons from IBD and from other diseases), then go to Browse Selected Comparisons? on the bottom-left corner:   The default view is a set of  volcano plots , one per Comparison, with log2(fold change) on the X-axis and -log10(RawPValue) as the Y-axis (for each project):   For each comparison, genes that are significantly differentially expressed will be higher on the Y-axis, with up-regulation to the right, and down-regulation to the left.  Go to the  Select View  tab, where there are several options:   Venn Diagram  shows how the significant genes correlated with each comparison (up to four comparisons per Venn Diagram):   Use the  Cutoff  Filter tab to control the significance cutoffs (fold-change, P-value, etc) for genes in the Venn Diagram view, as well as the Gene, pathway, project, etc.   The Comparison Table contains the full  Inference Report  for selected comparisons; the user can see a matrix with all the PValue and fold changes, for all the genes curated for the selected samples.\n(Not all the platforms have every gene, so some of them are missing in the table). This is a useful table if the user wants to analyze it outside of the software. For example, users with a license for QIAGEN Ingenuity Pathway Analysis (IPA) can directly send these results to IPA with a single click:   The  principal component  view shows a generalized distribution of all comparisons selected:   The  Summary Statistics  view shows which gene is most up/down-regulated, how many genes have significant changes for their expressions, etc:   The  Significant Genes  view shows each gene whose expression is up- or down- regulated; and user can sort to organize the result, such as by  Up-Regulated Count :   Then user can select the genes with the highest up-regulated count and create a gene set from the selection:   Input names and tags for the GeneSet:   GeneSets are a convenient way to group collections of interesting genes. The user can search with the newly created gene set:   And filter the result with IBD disease in Case.DiseaseCategory:   Then heatmap of comparison clearly shows an up-regulation pattern for these genes:",
            "title": "Explore Related Comparisons"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#gene-set-analysis",
            "text": "If user has followed the previous step (Gene Expression Based on Disease/Comparison) to generate a gene set (named as IBD upregulation), user can directly search in the land:   If there is no gene set already created, the user can also directly search with multiple genes:   And paste genes: CHI3L1,CD55,CFB,IL8,TIMP1,PLAU,NAMPT,CXCL1,ADM,IL1RN   Following the Gene set search or searching with multiple genes, ArrayStudio provides a function for identifying Comparisons within the Land that share lists of significant genes with the input set, named  Gene Set Analysis :     For each Land Comparison, a set of significant genes are identified, and Gene Set Analysis performs a Fisher-exact test for the overlap of your input GeneSet and each Land GeneSet to generate p-values for each comparison. Significant overlaps will be plotted to the right, which might reveal unexpected similarities between your input GeneSet and Land Comparisons.  In this view, the X-axis represents the Log10 of P-Value resulted from Fisher-exact test, and Y-axis stands for the Disease Category (the user can also use Specify Profile Column? under Task tab to regroup the comparisons with other metadata columns):   If the user selects one of the dots, the detailed window will show the P-value, up/down-regulated gene#, and the project information.   DiseaseLand also allows for the creation of GeneSets with other columns, like \"Fold Change\", \"Raw PValue\", \"Adjusted PValue\", etc. An example gene set is shown here:   Users can save an inference table from their local analysis as a .txt file and load them to the Land as a gene set, by going to  Manage|Genes|Manage Gene Sets :   Then Add the Geneset like this:   In the MetaData section, load the txt file saved earlier (you can use your own table):   Once it's done, go to DiseaseLand without searching any gene, and open the view of Gene Set Analysis (Plot or Table),   And choose the Geneset just created. Because P-value and/or Fold-change was provided, GeneSet Analysis uses a Wilcoxon test. For detailed information of the Geneset analysis and the underlying statistics, please refer to our wiki:  http://www.arrayserver.com/wiki/index.php?title=Comparison.GeneSetAnalysis .",
            "title": "Gene Set Analysis"
        },
        {
            "location": "/tutorials/DiseaseLand/DiseaseLand/#pathway-search",
            "text": "Users can also search with Pathways in DiseaseLand for a list of genes:   As the window shows, we provide Positional gene sets, Curated gene sets, Motif gene set, Computational gene sets, GO gene sets, Oncogenic signatures, and Immunologic signatures:   Select the gene set of interest, and click OK. Genes in this curated pathway will be searched, and the view will show a Heatmap of Comparison for Disease vs. normal for all the genes in the gene set, categorized by disease type and tissue type.",
            "title": "Pathway Search"
        },
        {
            "location": "/tutorials/DiseaseLand/LINCS/",
            "text": "LINCS\n\u00b6\n\n\nLINCS Land provides access to expression data of 23 cell lines, exposed to over 360 different perturbations at different concentrations, resulting in over 100,000 different samples.\n\n\nExpression profiling was performed using Broad Institute's L1000 platform, which profiles ~1,000 \"Landmark\" genes, and uses expression profiles of these genes to extrapolate the expected expression of all other genes (\"imputed genes\") in the transcriptome.\n\n\nLINCS Sample Grouping\n\u00b6\n\n\nAs groups of molecules that affect related pathways were tested, each sample was assigned a \nTreatmentGroup\n, which allows rapid identification of perturbations of interest, such as \nkinase inhibitors\n, \nRho signaling inhibitors\n, \nepigenetic modifiers\n, etc.\n\n\n\n\nLINCS Comparisons\n\u00b6\n\n\nA primary focus of LINCS is comparing expression of each perturbation to a set of control samples, so the \nComparisons\n View is especially useful here.\n\n\nTo see an overview of all comparisons in LINCS Land, click \nSelect View | Comparisons\n. Notice that there are thousands of comparisons between different perturbations (drug treatments and gene over-expression):\n\n\n\n\nIt might also be useful to \nSpecify Histogram Columns\n to \nCase.TreatmentGroup\n (you can change the \nSpecify Group Column\n to \nControl.TreatmentGroup\n).\n\n\n\n\nIdentify a \nTreatmentGroup\n of interest, then filter for that group under the \nComparison Filter:Case.TreatmentGroup\n (e.g. MAPK/ERK signaling inhibitor):\n\n\n\n\nSelect \nSpecify Histogram Columns\n and choose \nCase.Treament\n to see the different \nMAPK inhibitors\n that were tested (color by dosage):\n\n\n\n\nFurther filter for a specific treatment, and a specific dosage (perhaps the highest dosage for that treatment, e.g. 10uM for vemurafenib), then profile by Case.CellType and Color by Case.CellLine:\n\n\n\n\nClick on one or more of the comparisons to view the \nComparison Details\n; note the \nComparisonID\n:\n\n\n\n\nComparisons can be directly searched in the \nSearch bar\n:\n\n\n\n\nBut it is more convenient to select one or more comparisons, then click \nBrowse Selected Comparisons\n. In this case, select all 19 visible comparisons (i.e. 10uM vemurafenib treatments), then \nBrowse Selected Comparisons\n.\n\n\n\n\nOne \nVolcano Plot\n will be displayed for each comparison. Change the layout from \n1*1\n to \n3*3\n (or if you have a large monitor, \n5*5\n), and click \nToggle Uniform Scale Status\n, so that all Volcano plots use the same scales.\n\n\n\n\nNotice that two \nComparisons\n show exceptional responses to vemurafenib. Click the checkboxes at these plots to view \nComparison Details\n.\n\n\n\n\nNotice the two \nCase.CellLines\n; both \nHT-29\n and \nA375\n harbor the \nV600E\n mutation in \nBRAF\n, which is the target of \nVemurafenib\n.\n\n\n\n\nFilter for these two Comparisons in the \nFilter Pane\n, then switch to the \nVenn Diagram (Significant Genes)\n View:\n\n\n\n\nIn the \nFilter\n Tab, use the \nCutoff\n Filters to identify a relatively stringent cutoff that reduces the number of genes shared by the two comparisons (e.g. an adjusted P-value of 10e-8).\n\n\n\n\nCreate a \nGeneSet\n from this set of genes, then search for the GeneSet:\n\n\n\n\n\n\nSearching for multiple genes (or a GeneSet) will show a \nComparison Heatmap View\n. Filter down to \nCase.TreatmentGroup:MAPK/ERK signaling inhibitor\n, and notice that the comparisons and genes are automatically clustered.\n\n\n|LINCS_Heatmap_MAPKtreatmentGroup_png|\n\n\nNotice the large cluster of comparisons with similar expression dynamics. Select these comparisons with the mouse, and (after syncing the massive amount of information from ArrayServer), click \nFilter Selection\n in the \nAction\n pane, to filter the \nComparison Heatmap\n to these specific comparisons:\n\n\n\n\nIn addition to vemurafenib, several other drugs that are used to target tumors with  \nBRAF V600E\n show a similar gene activation/repression profile, including dabrafenib and trametinib.",
            "title": "LINCs"
        },
        {
            "location": "/tutorials/DiseaseLand/LINCS/#lincs",
            "text": "LINCS Land provides access to expression data of 23 cell lines, exposed to over 360 different perturbations at different concentrations, resulting in over 100,000 different samples.  Expression profiling was performed using Broad Institute's L1000 platform, which profiles ~1,000 \"Landmark\" genes, and uses expression profiles of these genes to extrapolate the expected expression of all other genes (\"imputed genes\") in the transcriptome.",
            "title": "LINCS"
        },
        {
            "location": "/tutorials/DiseaseLand/LINCS/#lincs-sample-grouping",
            "text": "As groups of molecules that affect related pathways were tested, each sample was assigned a  TreatmentGroup , which allows rapid identification of perturbations of interest, such as  kinase inhibitors ,  Rho signaling inhibitors ,  epigenetic modifiers , etc.",
            "title": "LINCS Sample Grouping"
        },
        {
            "location": "/tutorials/DiseaseLand/LINCS/#lincs-comparisons",
            "text": "A primary focus of LINCS is comparing expression of each perturbation to a set of control samples, so the  Comparisons  View is especially useful here.  To see an overview of all comparisons in LINCS Land, click  Select View | Comparisons . Notice that there are thousands of comparisons between different perturbations (drug treatments and gene over-expression):   It might also be useful to  Specify Histogram Columns  to  Case.TreatmentGroup  (you can change the  Specify Group Column  to  Control.TreatmentGroup ).   Identify a  TreatmentGroup  of interest, then filter for that group under the  Comparison Filter:Case.TreatmentGroup  (e.g. MAPK/ERK signaling inhibitor):   Select  Specify Histogram Columns  and choose  Case.Treament  to see the different  MAPK inhibitors  that were tested (color by dosage):   Further filter for a specific treatment, and a specific dosage (perhaps the highest dosage for that treatment, e.g. 10uM for vemurafenib), then profile by Case.CellType and Color by Case.CellLine:   Click on one or more of the comparisons to view the  Comparison Details ; note the  ComparisonID :   Comparisons can be directly searched in the  Search bar :   But it is more convenient to select one or more comparisons, then click  Browse Selected Comparisons . In this case, select all 19 visible comparisons (i.e. 10uM vemurafenib treatments), then  Browse Selected Comparisons .   One  Volcano Plot  will be displayed for each comparison. Change the layout from  1*1  to  3*3  (or if you have a large monitor,  5*5 ), and click  Toggle Uniform Scale Status , so that all Volcano plots use the same scales.   Notice that two  Comparisons  show exceptional responses to vemurafenib. Click the checkboxes at these plots to view  Comparison Details .   Notice the two  Case.CellLines ; both  HT-29  and  A375  harbor the  V600E  mutation in  BRAF , which is the target of  Vemurafenib .   Filter for these two Comparisons in the  Filter Pane , then switch to the  Venn Diagram (Significant Genes)  View:   In the  Filter  Tab, use the  Cutoff  Filters to identify a relatively stringent cutoff that reduces the number of genes shared by the two comparisons (e.g. an adjusted P-value of 10e-8).   Create a  GeneSet  from this set of genes, then search for the GeneSet:    Searching for multiple genes (or a GeneSet) will show a  Comparison Heatmap View . Filter down to  Case.TreatmentGroup:MAPK/ERK signaling inhibitor , and notice that the comparisons and genes are automatically clustered.  |LINCS_Heatmap_MAPKtreatmentGroup_png|  Notice the large cluster of comparisons with similar expression dynamics. Select these comparisons with the mouse, and (after syncing the massive amount of information from ArrayServer), click  Filter Selection  in the  Action  pane, to filter the  Comparison Heatmap  to these specific comparisons:   In addition to vemurafenib, several other drugs that are used to target tumors with   BRAF V600E  show a similar gene activation/repression profile, including dabrafenib and trametinib.",
            "title": "LINCS Comparisons"
        },
        {
            "location": "/tutorials/DiseaseLand/scLand/",
            "text": "Single Cell Lands\n\u00b6\n\n\nSingle-Cell RNA sequencing is emerging as a powerful tool for capturing cellular heterogeneity, which is useful in profiling tumors, nervous system development, detection of rare cell types, and more. Cells are sorted or captured in microfluidic devices, and individual cells are sequenced, providing unprecedented insight into the composition of tissues.\n\n\nOmicSoft\u2019s Single Cell Lands (scHuman and scMouse) contain datasets from multiple single-cell RNAseq projects. Because of the special nature of scRNA processing, both the data and metadata processing steps differ somewhat from \"standard\" Land processing.\n\n\nData are aligned with OmicSoft's OSA aligner, and each sample is analyzed to ensure that it passes certain QC parameters, such as overall alignment rate, mitochondrial mapping rate, mapped reads, and the number of genes covered (the latest filter criteria can be found at the OmicSoft wiki page \nSCLand Development Notes\n). Gene expression for most samples will be quantified by \nTranscripts Per Million (TPM)\n. RNA with \nUnique Molecular Identifiers (UMI)\n (as well as samples with a severe 3' or 5' gene coverage bias) will be quantified as \nReads Per Million (RPM)\n, which assumes that all transcripts are 1kb long.\n\n\nMetadata are processed and brought in-line with Controlled Vocabularies. Several metadata columns are especially important for single cell data, including ''Cell Number'' (whether the sample is from a single cell, 10 cells, population, etc.), ''Library Strategy'' (the method for generating the sequencing library), ''UMI'' (whether or not UMIs were used), and ''Clinical - Subject ID'' (groups together cells from a single tissue sample).\n\n\n\n\nAdditional project-specific metadata may also be in the \nClinical Variables\n; after you have filtered for samples of interest (e.g. an interesting project), be sure to explore the clinical metadata to help you partition samples and subjects by metadata.\n\n\nGene-level Views\n\u00b6\n\n\nscLands contain RNaseq data, so all of the familiar RNAseq-based Views will be available.\n\n\nIn this example, we display views when searching for the gene \"egfr\". The default View is the \nGene TPM (Project View)\n, where the RNAseq data are \ntrellised\n by ProjectName and PlatformName into separate charts:\n\n\n\n\nEither scroll down or filter for project \nGSE57872\n, sequencing of five glioblastoma tumors. Select some of the samples from the \nTreatment: None\n row, to see the metadata for these samples:\n\n\n\n\nClick the \n+\n Symbol in the \nMetadata pane\n to allow selection of different metadata types. In this case, we are interested in \nClinical metadata\n, specifically \nClinical - SubjectID\n, which uniquely identifies the subject from which the cells were isolated.\n\n\nFilter for \nCellNumber:1\n to only show expression data from single cells (not populations). Under the \nTask\n tab on the right, choose \nChange Symbol Properties\n. Change \nColor\n to \nClinical - SubjectID\n to color each sample by the source tumor:\n\n\n\n\nNow choose \nTask tab: Specify Multiple Profile Columns\n, and select both \nTreatment\n and \nClinical -SubjectID\n:\n\n\n\n\nProfiling by multiple metadata columns allows more detailed separation of data. In this case, three tumors show relatively high median expression of EGFR, while two tumors (and the induced sphere-forming culture) show lower expression:\n\n\n!|scLand_TPM_Treatment_SubjectID_png|(images/scLand_TPM_Treatment_SubjectID.png)",
            "title": "Single Cell Lands"
        },
        {
            "location": "/tutorials/DiseaseLand/scLand/#single-cell-lands",
            "text": "Single-Cell RNA sequencing is emerging as a powerful tool for capturing cellular heterogeneity, which is useful in profiling tumors, nervous system development, detection of rare cell types, and more. Cells are sorted or captured in microfluidic devices, and individual cells are sequenced, providing unprecedented insight into the composition of tissues.  OmicSoft\u2019s Single Cell Lands (scHuman and scMouse) contain datasets from multiple single-cell RNAseq projects. Because of the special nature of scRNA processing, both the data and metadata processing steps differ somewhat from \"standard\" Land processing.  Data are aligned with OmicSoft's OSA aligner, and each sample is analyzed to ensure that it passes certain QC parameters, such as overall alignment rate, mitochondrial mapping rate, mapped reads, and the number of genes covered (the latest filter criteria can be found at the OmicSoft wiki page  SCLand Development Notes ). Gene expression for most samples will be quantified by  Transcripts Per Million (TPM) . RNA with  Unique Molecular Identifiers (UMI)  (as well as samples with a severe 3' or 5' gene coverage bias) will be quantified as  Reads Per Million (RPM) , which assumes that all transcripts are 1kb long.  Metadata are processed and brought in-line with Controlled Vocabularies. Several metadata columns are especially important for single cell data, including ''Cell Number'' (whether the sample is from a single cell, 10 cells, population, etc.), ''Library Strategy'' (the method for generating the sequencing library), ''UMI'' (whether or not UMIs were used), and ''Clinical - Subject ID'' (groups together cells from a single tissue sample).   Additional project-specific metadata may also be in the  Clinical Variables ; after you have filtered for samples of interest (e.g. an interesting project), be sure to explore the clinical metadata to help you partition samples and subjects by metadata.",
            "title": "Single Cell Lands"
        },
        {
            "location": "/tutorials/DiseaseLand/scLand/#gene-level-views",
            "text": "scLands contain RNaseq data, so all of the familiar RNAseq-based Views will be available.  In this example, we display views when searching for the gene \"egfr\". The default View is the  Gene TPM (Project View) , where the RNAseq data are  trellised  by ProjectName and PlatformName into separate charts:   Either scroll down or filter for project  GSE57872 , sequencing of five glioblastoma tumors. Select some of the samples from the  Treatment: None  row, to see the metadata for these samples:   Click the  +  Symbol in the  Metadata pane  to allow selection of different metadata types. In this case, we are interested in  Clinical metadata , specifically  Clinical - SubjectID , which uniquely identifies the subject from which the cells were isolated.  Filter for  CellNumber:1  to only show expression data from single cells (not populations). Under the  Task  tab on the right, choose  Change Symbol Properties . Change  Color  to  Clinical - SubjectID  to color each sample by the source tumor:   Now choose  Task tab: Specify Multiple Profile Columns , and select both  Treatment  and  Clinical -SubjectID :   Profiling by multiple metadata columns allows more detailed separation of data. In this case, three tumors show relatively high median expression of EGFR, while two tumors (and the induced sphere-forming culture) show lower expression:  !|scLand_TPM_Treatment_SubjectID_png|(images/scLand_TPM_Treatment_SubjectID.png)",
            "title": "Gene-level Views"
        },
        {
            "location": "/tutorials/ComparisonLand/Introduction/",
            "text": "Introduction\n\u00b6\n\n\nArrayStudio\n\u00b6\n\n\nArray Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local microarray analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. The tutorial dataset is small and does not require these hardware specifications; However, processing of large numbers of whole-transcriptome table data, with thousands of samples and comparisons, can be memory-intensive.\n\n\nIt is highly recommend that the user complete the prerequisite for this tutorial: \nthe Microarray tutorial\n, as a way to learn the basics in Array Studio.\n\n\nThis tutorial assumes minimal working knowledge of Array Studio. However, an understanding of Array Studio data types, as well as the Views and Analysis modules within ArrayLands, will significantly improve your custom ComparisonLand design.\n\n\nThis tutorial also assumes a basic understanding of absolute and relative file paths, for editing .oscript files to find files on your local computer.\n\n\nTest Dataset\n\u00b6\n\n\nThis ComparisonLand tutorial will cover the importing and analysis of a small synthetic dataset of microarray expression, from 7 sample groups (56 samples).\n\n\nA .zip file containing all required text files for this analysis can be found at the following URL:\n\n\nhttp://omicsoft.com/downloads/data/Tutorial/Help/ComparisonLand.Tutorial.zip\n\n\nsimply unzip this file into a local folder, and proceed with the tutorial.",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ComparisonLand/Introduction/#introduction",
            "text": "",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/ComparisonLand/Introduction/#arraystudio",
            "text": "Array Studio runs local NGS analysis in 64-bit mode on a Windows 64-bit computer with at least 8GB of RAM. Server-based analysis allows the user to run jobs on a remote server (Linux or Windows), which usually has more computing power than a desktop computer. This tutorial is based on local microarray analysis using a Windows Workstation with 3.4GHz Intel\u00ae Core TM i7-6700 Processor (# of cores: 4; # of threads: 8) with 24GB RAM. The tutorial dataset is small and does not require these hardware specifications; However, processing of large numbers of whole-transcriptome table data, with thousands of samples and comparisons, can be memory-intensive.  It is highly recommend that the user complete the prerequisite for this tutorial:  the Microarray tutorial , as a way to learn the basics in Array Studio.  This tutorial assumes minimal working knowledge of Array Studio. However, an understanding of Array Studio data types, as well as the Views and Analysis modules within ArrayLands, will significantly improve your custom ComparisonLand design.  This tutorial also assumes a basic understanding of absolute and relative file paths, for editing .oscript files to find files on your local computer.",
            "title": "ArrayStudio"
        },
        {
            "location": "/tutorials/ComparisonLand/Introduction/#test-dataset",
            "text": "This ComparisonLand tutorial will cover the importing and analysis of a small synthetic dataset of microarray expression, from 7 sample groups (56 samples).  A .zip file containing all required text files for this analysis can be found at the following URL:  http://omicsoft.com/downloads/data/Tutorial/Help/ComparisonLand.Tutorial.zip  simply unzip this file into a local folder, and proceed with the tutorial.",
            "title": "Test Dataset"
        },
        {
            "location": "/tutorials/ComparisonLand/AddExpressionData/",
            "text": "Convert Expression Data to ALV\n\u00b6\n\n\nThe first step in creating your own ComparisonLand is to import your data into Array Studio and attach Annotation and Design metadata.\nThe resulting \n.osobj\n file will be converted to Land-compatible \n.alv\n files.\n\n\nCreate Array Studio Project\n\u00b6\n\n\nFirst, open \nArray Studio\n, and create a new distributed project:\n\n\n\n\n\n\nImport Expression Data into Array Studio\n\u00b6\n\n\nThe tutorial data are expression intensity measurements from an Affymetrix array for ~100 probesets (genes).\nEach row contains all of the measurements for one probeset, with each sample in columns.\n\n\nTo import these data, click \nAdd Data | Expression Data\n:\n\n\n\n\nThe tutorial data are tab-delimited, one gene per row, but Array Studio can import data from a variety of sources:\n\n\n\n\nIf your data have additional annotation columns (besides the ProbeSetID in the first column), you can specify them, and they will be automatically added as metadata.\nThe tutorial data do not have any extra columns, so do not select anything, and press \nOK\n:\n\n\n\n\nYou will be prompted to add a Design metadata file, but you may add one later if you prefer:\n\n\n\n\nFor this tutorial, select \nYes\n, then select \nTab delimited File\n,\nnavigate to \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and click \nOK\n without appending to the existing covariate table.\n\n\nYou will now be prompted to add Annotation metadata. Again, you may add one later, but for the tutorial dataset you can add it immediately:\n\n\n\n\nThe tutorial dataset probesets are from \nAffymetrix HG-U133A\n, which is one of many online annotations available from Array Studio.\n\n\nSelect source \nOnline annotation file\n\n\n\n\nand search for \nHG-U133A\n, which will list all matching annotations:\n\n\n\n\nSelect \nOK\n, which will automatically retrieve the annotation and attach it to the data. Click \nOK\n on the subsequent window without selecting either option.\n\n\nNow you will see the tutorial data imported as an \n-Omic\n data type, which is a tabular dataset with associated Design and Annotation data:\n\n\n\n\nIn the \nSolution Explorer\n, right-click on \nMicroArrayData\n and select \nRename\n, then rename the -Omic object to \"Brawndocin_Slurmycin.Expression\":\n\n\n\n\nYour \nSolution Explorer\n will update the object name:\n\n\n\n\nNow save the project. The \n.osobj\n file \"Brawndocin_Slurmycin.Expression.osobj\" will be used to create ComparisonLand \n.alv\n files.\n\n\nConvert Expression .OSOBJ file to Land-compatible .ALV files\n\u00b6\n\n\nNow you can convert the \n.osobj\n file to \n.alv\n files, which can be added to your ComparisonLand.\n\n\nTo do this, you will run an \nOmicScript\n (\nOscript\n) from \nArray Studio\n.\n\n\nOscripts\n are text-format files that instruct Array Studio to perform commands. All Array Studio GUI functions have associated .Oscript functions. There are additional \"Oscript-only\" functions (such as ConvertExpressionOsobj), which do not  have a GUI module window in Array Studio.\n\n\nAn example \nOscript\n is \nExtractExpressionOsobjToAlv.oscript\n, which you will find in the zipped tutorial set: ::\n\n\nBegin LandTools /Namespace=NgsLib;\nFiles \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\nComparisonLandFromExternal\\\nBrawndocin_Slurmycin.Expression.osobj\";\nReference Human.B37.3;\nGeneModel OmicsoftGene20130723;\nOptions /Action=ConvertExpressionOsobj\n/SampleIDColumn=\"Observation\"\n/MappingID=Affymetrix.HG-U133A_Human.B37.3\n/IsRatio=False /MedianNormalization=False\n/TargetMedian=0\n/OutputFolder=\n\"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ALV\";\nEnd;\n\n\n\n\n\nFor the tutorial, will need to change the input and output paths to match where your \n.osobj\n file is located,\nand where you want to output the \n.ALV\n files.\n\n\nOnce you have modified and saved the \nOscript\n file, Select \nTools | Run Script\n:\n\n\n\n\nNavigate to your modified \nExtractExpressionOsobjToAlv.oshell.oscript\n file, and click \nOK\n.\n\n\nThe output \n.ALV\n files will be found in the folder you specified.\nYou will find one file per sample:",
            "title": "Add Expression Data"
        },
        {
            "location": "/tutorials/ComparisonLand/AddExpressionData/#convert-expression-data-to-alv",
            "text": "The first step in creating your own ComparisonLand is to import your data into Array Studio and attach Annotation and Design metadata.\nThe resulting  .osobj  file will be converted to Land-compatible  .alv  files.",
            "title": "Convert Expression Data to ALV"
        },
        {
            "location": "/tutorials/ComparisonLand/AddExpressionData/#create-array-studio-project",
            "text": "First, open  Array Studio , and create a new distributed project:",
            "title": "Create Array Studio Project"
        },
        {
            "location": "/tutorials/ComparisonLand/AddExpressionData/#import-expression-data-into-array-studio",
            "text": "The tutorial data are expression intensity measurements from an Affymetrix array for ~100 probesets (genes).\nEach row contains all of the measurements for one probeset, with each sample in columns.  To import these data, click  Add Data | Expression Data :   The tutorial data are tab-delimited, one gene per row, but Array Studio can import data from a variety of sources:   If your data have additional annotation columns (besides the ProbeSetID in the first column), you can specify them, and they will be automatically added as metadata.\nThe tutorial data do not have any extra columns, so do not select anything, and press  OK :   You will be prompted to add a Design metadata file, but you may add one later if you prefer:   For this tutorial, select  Yes , then select  Tab delimited File ,\nnavigate to \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and click  OK  without appending to the existing covariate table.  You will now be prompted to add Annotation metadata. Again, you may add one later, but for the tutorial dataset you can add it immediately:   The tutorial dataset probesets are from  Affymetrix HG-U133A , which is one of many online annotations available from Array Studio.  Select source  Online annotation file   and search for  HG-U133A , which will list all matching annotations:   Select  OK , which will automatically retrieve the annotation and attach it to the data. Click  OK  on the subsequent window without selecting either option.  Now you will see the tutorial data imported as an  -Omic  data type, which is a tabular dataset with associated Design and Annotation data:   In the  Solution Explorer , right-click on  MicroArrayData  and select  Rename , then rename the -Omic object to \"Brawndocin_Slurmycin.Expression\":   Your  Solution Explorer  will update the object name:   Now save the project. The  .osobj  file \"Brawndocin_Slurmycin.Expression.osobj\" will be used to create ComparisonLand  .alv  files.",
            "title": "Import Expression Data into Array Studio"
        },
        {
            "location": "/tutorials/ComparisonLand/AddExpressionData/#convert-expression-osobj-file-to-land-compatible-alv-files",
            "text": "Now you can convert the  .osobj  file to  .alv  files, which can be added to your ComparisonLand.  To do this, you will run an  OmicScript  ( Oscript ) from  Array Studio .  Oscripts  are text-format files that instruct Array Studio to perform commands. All Array Studio GUI functions have associated .Oscript functions. There are additional \"Oscript-only\" functions (such as ConvertExpressionOsobj), which do not  have a GUI module window in Array Studio.  An example  Oscript  is  ExtractExpressionOsobjToAlv.oscript , which you will find in the zipped tutorial set: ::  Begin LandTools /Namespace=NgsLib;\nFiles \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\nComparisonLandFromExternal\\\nBrawndocin_Slurmycin.Expression.osobj\";\nReference Human.B37.3;\nGeneModel OmicsoftGene20130723;\nOptions /Action=ConvertExpressionOsobj\n/SampleIDColumn=\"Observation\"\n/MappingID=Affymetrix.HG-U133A_Human.B37.3\n/IsRatio=False /MedianNormalization=False\n/TargetMedian=0\n/OutputFolder=\n\"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\ALV\";\nEnd;  For the tutorial, will need to change the input and output paths to match where your  .osobj  file is located,\nand where you want to output the  .ALV  files.  Once you have modified and saved the  Oscript  file, Select  Tools | Run Script :   Navigate to your modified  ExtractExpressionOsobjToAlv.oshell.oscript  file, and click  OK .  The output  .ALV  files will be found in the folder you specified.\nYou will find one file per sample:",
            "title": "Convert Expression .OSOBJ file to Land-compatible .ALV files"
        },
        {
            "location": "/tutorials/ComparisonLand/ConvertInferenceData/",
            "text": "Convert Inference Data to .TLV\n\u00b6\n\n\nIf you have statistical inference data for your expression data, such as fold-change and P-value calculations,\nyou can convert these into ComparisonLand-compatible \n.tlv\n files.\n\n\nYou can also calculate statistical inferences using multiple modules within Array Studio, including DESeq, ANOVA and General Linear Model.\n\n\nFormatting the Comparison Data File\n\u00b6\n\n\nFor this tutorial, the expression data were tested by One-Way ANOVA of the six treatment sample groups (Brawndocin at 0.3, 1, 3.3, and 10uM,\nand Slurmycin at 1 and 10uM) compared to a common group of vehicle samples.\n\n\nThe resulting inference table was converted to the following tab-delimited format:\n\n\n\n\nThe first column should be the probeset/GeneID. Subsequent columns should be in the following order:\n\n\n\n\ntreat1\n.log2FC\n\n\ntreat1\n.rawPValue\n\n\ntreat1\n.adjPValue\n\n\ntreat1\n.caseMean\n\n\ntreat1\n.controlMean\n\n\ntreat2\n.log2FC\n\n\ntreat2\n.rawPValue\n\n\n...\n\n\ntreat100\n.adjPValue\n\n\ntreat100\n.caseMean\n\n\ntreat100\n.controlMean\n\n\n\n\nThe full file for this tutorial is \"Brawndocin_Slurmycin.V2.Comparison.Data.txt\".\n\n\nEach row should contain all comparisons for a single gene/probeset.\n\n\nAlso, each \ntreat\n name should be unique among the entire dataset.\n\n\nOnce you have converted your inference data into the proper format, you can proceed to formatting the \ncomparison metadata\n file.\n\n\nFormatting the Comparison Metadata file\n\u00b6\n\n\nThe \nComparison Metadata\n file is a tab-delimited file that contains the information that groups together all of the samples (in the .alv files), extracts sample metadata for filtering/grouping of comparisons, adds additional comparison metadata, and connects these to the \nComparison Data\n that you prepared in the previous section.\n\n\nThus, it is essentially that you carefully plan the metadata that should be included in your comparisons.\n\n\nThe minimum data for the \nComparison Metadata\n file are as follows:\n\n\n\n\n\n\nComparisonName\n: This should be the first column, and the names in this column should match the comparisonNames in your \nComparison Data\n file (without \".log2FC\", \"PValue\", etc).\n\n\n\n\n\n\nMetaColumns\n: A list of \nSample Metadata\n column names, indicating the metadata to include in the comparison metadata.\n\n\n\n\n\n\n\"Treatment\",\"CellType\", and \"Tissue\" \nMust\n be included in this column (and as columns in the \nSample Metadata\n file).\n\n\n\n\n\n\n\"DiseaseCategory\" is not absolutely required, but some Views group samples by this column, so will not work properly without this column.\n\n\n\n\n\n\nAny additional \nSample Metadata\n columns that are included must be consistent within a sample group. For example, if your \nCase\n samples include both HCC4006 and HCC827 cells in the \nCellLine\n column, you cannot include \nCellLine\n in your Comparison metadata.\n\n\n\n\n\n\n\n\n\n\nCaseSampleIDs\n: A delimited (',' or ';') list of Sample IDs included in this comparison, matching your \nSample Metadata\n files Sample IDs.\n\n\n\n\n\n\nControlSampleIDs\n: A delimited (',' or ';') list of Sample IDs included in this comparison, matching your \nSample Metadata\n files Sample IDs.\n\n\n\n\n\n\nTestCategory\n: A description of the type of comparison being made.\n\n\n\n\nStandard Test Categories include \"Disease vs. Normal\", \"Treatment vs. Control\", \"Treatment1 vs Treatment2\", \"Tissue1 vs. Tissue2\", \"Responder vs. Non-Responder\", \"Disease vs. Normal\", \"Disease1 vs. Disease2\", \"CellType1 vs. CellType2\", and \"Other Comparisons\".\n\n\n\n\n\n\n\n\nTlvID\n: A unique name for your comparison (i.e. unique across your entire ComparisonLand, not just the project).\n\n\n\n\n\n\nProjectName\n: A name that groups the set of comparisons.\n\n\n\n\n\n\nPlatformName\n: A description of the source NGS or Microarray platform.\n\n\n\n\n\n\nComparisonSoftware\n: The name of the software that calculated the inferences, such as \"DEseq\" or \"limma\"\n\n\n\n\n\n\nStatsModel\n: A description of the statistical model.\n\n\n\n\n\n\nSampleDataMode\n: A description of the type of underlying measured data, such as \"Expression_Intensity_Probes\" or \"RnaSeq_Transcript\".\n\n\n\n\n\n\nPlease see the tutorial file \"Brawndocin_Slurmycin.Comparison.MetaFile.txt\" for a properly-formatted example.\n\n\nRunning the Oscript to Convert Inference data to Tlv\n\u00b6\n\n\nOnce you have formatted your comparison data and metadata files, you should edit the \nOscript\n file to specify the input locations for the following files:\n\n\n\n\n\n\nComparison Data File (Brawndocin_Slurmycin.V2.Comparison.Data.txt).\n\n\n\n\n\n\nComparison MetaData File (Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt).\n\n\n\n\n\n\nSample MetaData File (Brawndocin_Slurmycin.Expression.Design.txt).\n\n\n\n\n\n\nAlso, specify the output location for the \n.tlv\n files.\n\n\nThe following \nOscript\n file can be found as \"ExtractExternalInferenceReport.oscript\": ::\n\n\n Begin ComparisonLandTools /Namespace=NgsLib;\n Files \"\";\n Reference Human.B37.3;\n GeneModel OmicsoftGene20130723;      \n Options\n /Action=ExtractExternalInferenceReport\n /ComparisonDataFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Comparison.Data.txt\"\n /SampleMetaDataFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Expression.Design.txt\"\n /ComparisonMetaFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt\"\n /OutputFolder=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\TLV\"\n /MappingID=\"Affymetrix.HT_HG-U133A_Human.B37.3\" ;\n End;\n\n\n\n\n\nUpdate the \noscript\n paths to indicate where the files are located on your local computer, then run the \nOscript\n as before in \nArray Studio\n, and check that the \n.tlv\n files have been generated in the specified folder:",
            "title": "Convert Inference Data"
        },
        {
            "location": "/tutorials/ComparisonLand/ConvertInferenceData/#convert-inference-data-to-tlv",
            "text": "If you have statistical inference data for your expression data, such as fold-change and P-value calculations,\nyou can convert these into ComparisonLand-compatible  .tlv  files.  You can also calculate statistical inferences using multiple modules within Array Studio, including DESeq, ANOVA and General Linear Model.",
            "title": "Convert Inference Data to .TLV"
        },
        {
            "location": "/tutorials/ComparisonLand/ConvertInferenceData/#formatting-the-comparison-data-file",
            "text": "For this tutorial, the expression data were tested by One-Way ANOVA of the six treatment sample groups (Brawndocin at 0.3, 1, 3.3, and 10uM,\nand Slurmycin at 1 and 10uM) compared to a common group of vehicle samples.  The resulting inference table was converted to the following tab-delimited format:   The first column should be the probeset/GeneID. Subsequent columns should be in the following order:   treat1 .log2FC  treat1 .rawPValue  treat1 .adjPValue  treat1 .caseMean  treat1 .controlMean  treat2 .log2FC  treat2 .rawPValue  ...  treat100 .adjPValue  treat100 .caseMean  treat100 .controlMean   The full file for this tutorial is \"Brawndocin_Slurmycin.V2.Comparison.Data.txt\".  Each row should contain all comparisons for a single gene/probeset.  Also, each  treat  name should be unique among the entire dataset.  Once you have converted your inference data into the proper format, you can proceed to formatting the  comparison metadata  file.",
            "title": "Formatting the Comparison Data File"
        },
        {
            "location": "/tutorials/ComparisonLand/ConvertInferenceData/#formatting-the-comparison-metadata-file",
            "text": "The  Comparison Metadata  file is a tab-delimited file that contains the information that groups together all of the samples (in the .alv files), extracts sample metadata for filtering/grouping of comparisons, adds additional comparison metadata, and connects these to the  Comparison Data  that you prepared in the previous section.  Thus, it is essentially that you carefully plan the metadata that should be included in your comparisons.  The minimum data for the  Comparison Metadata  file are as follows:    ComparisonName : This should be the first column, and the names in this column should match the comparisonNames in your  Comparison Data  file (without \".log2FC\", \"PValue\", etc).    MetaColumns : A list of  Sample Metadata  column names, indicating the metadata to include in the comparison metadata.    \"Treatment\",\"CellType\", and \"Tissue\"  Must  be included in this column (and as columns in the  Sample Metadata  file).    \"DiseaseCategory\" is not absolutely required, but some Views group samples by this column, so will not work properly without this column.    Any additional  Sample Metadata  columns that are included must be consistent within a sample group. For example, if your  Case  samples include both HCC4006 and HCC827 cells in the  CellLine  column, you cannot include  CellLine  in your Comparison metadata.      CaseSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your  Sample Metadata  files Sample IDs.    ControlSampleIDs : A delimited (',' or ';') list of Sample IDs included in this comparison, matching your  Sample Metadata  files Sample IDs.    TestCategory : A description of the type of comparison being made.   Standard Test Categories include \"Disease vs. Normal\", \"Treatment vs. Control\", \"Treatment1 vs Treatment2\", \"Tissue1 vs. Tissue2\", \"Responder vs. Non-Responder\", \"Disease vs. Normal\", \"Disease1 vs. Disease2\", \"CellType1 vs. CellType2\", and \"Other Comparisons\".     TlvID : A unique name for your comparison (i.e. unique across your entire ComparisonLand, not just the project).    ProjectName : A name that groups the set of comparisons.    PlatformName : A description of the source NGS or Microarray platform.    ComparisonSoftware : The name of the software that calculated the inferences, such as \"DEseq\" or \"limma\"    StatsModel : A description of the statistical model.    SampleDataMode : A description of the type of underlying measured data, such as \"Expression_Intensity_Probes\" or \"RnaSeq_Transcript\".    Please see the tutorial file \"Brawndocin_Slurmycin.Comparison.MetaFile.txt\" for a properly-formatted example.",
            "title": "Formatting the Comparison Metadata file"
        },
        {
            "location": "/tutorials/ComparisonLand/ConvertInferenceData/#running-the-oscript-to-convert-inference-data-to-tlv",
            "text": "Once you have formatted your comparison data and metadata files, you should edit the  Oscript  file to specify the input locations for the following files:    Comparison Data File (Brawndocin_Slurmycin.V2.Comparison.Data.txt).    Comparison MetaData File (Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt).    Sample MetaData File (Brawndocin_Slurmycin.Expression.Design.txt).    Also, specify the output location for the  .tlv  files.  The following  Oscript  file can be found as \"ExtractExternalInferenceReport.oscript\": ::   Begin ComparisonLandTools /Namespace=NgsLib;\n Files \"\";\n Reference Human.B37.3;\n GeneModel OmicsoftGene20130723;      \n Options\n /Action=ExtractExternalInferenceReport\n /ComparisonDataFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Comparison.Data.txt\"\n /SampleMetaDataFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Expression.Design.txt\"\n /ComparisonMetaFile=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\\n InputFiles\\Brawndocin_Slurmycin.V2.Comparison.MetaFile.txt\"\n /OutputFolder=\n \"Z:\\Users\\Joe\\Tutorial\\ComparisonLand\\Final\\TLV\"\n /MappingID=\"Affymetrix.HT_HG-U133A_Human.B37.3\" ;\n End;  Update the  oscript  paths to indicate where the files are located on your local computer, then run the  Oscript  as before in  Array Studio , and check that the  .tlv  files have been generated in the specified folder:",
            "title": "Running the Oscript to Convert Inference data to Tlv"
        },
        {
            "location": "/tutorials/ComparisonLand/CreateLand/",
            "text": "Add Expression and Comparison Data to Land\n\u00b6\n\n\nAfter you have successfully created \n.alv\n and \n.tlv\n files containing your expression and comparison data, respectively, you can add these data to an existing or new ArrayLand.\n\n\nCreate a New Land\n\u00b6\n\n\nIf these data will be added to a new Land, you must create this Land first.\n\n\nConnect to Array Server with administrator privileges, then click on the \nLand\n tab:\n\n\n\n\nSwitch to the \nLand\n tab, then click \nTools | Create Land\n:\n\n\n\n\nIn the window, give your Land a unique name for the server, and enter additional settings:\n\n\n\n\nIn the tutorial data set, you will find a file \"TutorialLandSettings.cfg\" that contains some basic settings.\n\n\nWhen successful, you will get the following message:\n\n\n\n\nAdd Sample and Project MetaData to Land\n\u00b6\n\n\nBefore you add your actual data to your new Land, you can add the Sample and Project MetaData.\n\n\nIn the tutorial dataset, the Sample Metadata are in \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and the Project Metadata are in \"Brawndocin_Slurmycin.V2.ProjectMetaFile.txt\".\n\n\nIn the \nLand\n tab, click \nManage | Samples | Manage Sample Meta Data\n or \nManage Project Meta Data\n:\n\n\n\n\nIn the \nSample Metadata\n and \nProject Metadata\n windows, you can add, replace, clear, and remove metadata for samples.\n\n\nTo add new sample metadata, click \nAdd/Replace\n, and navigate to the Sample Metadata file.\n\n\nIf properly imported, the window will look similar to this:\n\n\n\n\nYou should also import the project metadata file, which should result in a window like this:\n\n\n\n\nAdd .alv and .tlv files to server\n\u00b6\n\n\nIf you are processing the tutorial data, you will have generated 6 .tlv files (one per comparison between sample groups) and 56 .alv files (one per sample).\n\n\nUpload these to your Array Server, by clicking on the \nServer\n tab, then clicking \nServer File | Browse Files\n:\n\n\n\n\nNavigate to a location to store your files, and click \nUpload\n:\n\n\n\n\nNavigate to your .alv and .tlv files, and upload them to the server.\n\n\nNow switch back to the \nLand\n tab, and click \nTools | Publish To Land\n:\n\n\n\n\nNavigate to your server files and click \nSend To Queue\n:\n\n\n\n\nNote: You can only publish data one job at a time, so if you have submitted a set of files to the server for publishing, you must wait for that job to complete before submitting the next job.\n\n\nWhen all of your .alv and .tlv data have been published, the ServerJobs queue will say \"Finished\", and you can start exploring your Land.",
            "title": "Create Land"
        },
        {
            "location": "/tutorials/ComparisonLand/CreateLand/#add-expression-and-comparison-data-to-land",
            "text": "After you have successfully created  .alv  and  .tlv  files containing your expression and comparison data, respectively, you can add these data to an existing or new ArrayLand.",
            "title": "Add Expression and Comparison Data to Land"
        },
        {
            "location": "/tutorials/ComparisonLand/CreateLand/#create-a-new-land",
            "text": "If these data will be added to a new Land, you must create this Land first.  Connect to Array Server with administrator privileges, then click on the  Land  tab:   Switch to the  Land  tab, then click  Tools | Create Land :   In the window, give your Land a unique name for the server, and enter additional settings:   In the tutorial data set, you will find a file \"TutorialLandSettings.cfg\" that contains some basic settings.  When successful, you will get the following message:",
            "title": "Create a New Land"
        },
        {
            "location": "/tutorials/ComparisonLand/CreateLand/#add-sample-and-project-metadata-to-land",
            "text": "Before you add your actual data to your new Land, you can add the Sample and Project MetaData.  In the tutorial dataset, the Sample Metadata are in \"Brawndocin_Slurmycin.V2.Expression.Design.txt\", and the Project Metadata are in \"Brawndocin_Slurmycin.V2.ProjectMetaFile.txt\".  In the  Land  tab, click  Manage | Samples | Manage Sample Meta Data  or  Manage Project Meta Data :   In the  Sample Metadata  and  Project Metadata  windows, you can add, replace, clear, and remove metadata for samples.  To add new sample metadata, click  Add/Replace , and navigate to the Sample Metadata file.  If properly imported, the window will look similar to this:   You should also import the project metadata file, which should result in a window like this:",
            "title": "Add Sample and Project MetaData to Land"
        },
        {
            "location": "/tutorials/ComparisonLand/CreateLand/#add-alv-and-tlv-files-to-server",
            "text": "If you are processing the tutorial data, you will have generated 6 .tlv files (one per comparison between sample groups) and 56 .alv files (one per sample).  Upload these to your Array Server, by clicking on the  Server  tab, then clicking  Server File | Browse Files :   Navigate to a location to store your files, and click  Upload :   Navigate to your .alv and .tlv files, and upload them to the server.  Now switch back to the  Land  tab, and click  Tools | Publish To Land :   Navigate to your server files and click  Send To Queue :   Note: You can only publish data one job at a time, so if you have submitted a set of files to the server for publishing, you must wait for that job to complete before submitting the next job.  When all of your .alv and .tlv data have been published, the ServerJobs queue will say \"Finished\", and you can start exploring your Land.",
            "title": "Add .alv and .tlv files to server"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/",
            "text": "Explore ComparisonLand\n\u00b6\n\n\nArrayLands with comparisons will have different Views that are customized for different types of data:\n\n\n\n\nGene\n\n\nGene Sets\n\n\nSamples\n\n\nSampleSets\n\n\nComparisons/ComparisonSets\n\n\n\n\nIn ComparisonLands, even Gene-Level data can show special \nViews\n using your Comparison inferences.\n\n\nGene-Level data\n\u00b6\n\n\nWhen you connect to your new Land, the default View will display the number of samples,\nas derived from the Sample metadata, which should be the same as the number of .alv files you added.\n\n\n\n\nWhile this is a nice overview of your Land data, especially as you add hundreds or thousands of samples, for multiple projects or tissues, it is not very informative now.\n\n\nInstead, search for the gene \nCD58\n.\n\n\nThe default View will display the log2-fold change data from the comparisons,\nseparated by Treatment:\n\n\n\n\nClick \nSelect View\n, where you can see additional Views available for Land Gene-Level data:\n\n\n\n\nThese Views are explained in more detail in the ImmunoLand and OncoLand tutorials, in addition to the many ways to customize Views, so will not be described in detail here.\n\n\nHowever, one View to check is the \nExpression Intensity\n View:\n\n\n\n\nIn contrast to the default GeneLevel View (Comparison.Treatment vs. Control), which is displaying the log2-fold change values from the comparison data, the Expression Intensity View is displaying the expression data for each sample.\n\n\nAs you explore your ComparisonLand, it will be clearer where each source dataset is being used.\n\n\nFurthermore, you will identify additional Sample and Comparison metadata columns that will be useful\nfor grouping and filtering your data.\n\n\nThis is important to note before you begin constructing a large ComparisonLand, because the comparison metadata are contained within the .tlv files, so cannot be updated as easily as Sample Metadata; you must re-process your comparisons and over-write the .tlv files, then re-publish them to Land.\n\n\nThus, you should plan ahead for including important information about different sample groups.\n\n\nComparison-Level Data\n\u00b6\n\n\nIn addition to viewing Comparisons at the single-gene-level, you can also view all measured genes for a given comparison.\n\n\nSearch for \"Slurmycin_10um_htb-57.test1\" in the \nSearch Bar\n; you will notice that matching hits (genes, comparisons, samples) will be dynamically displayed as you type:\n\n\n\n\nThe default View is a Volcano plot, with \nEstimate\n (log2-Fold Change) on the X-axis and \nRaw P-value\n on the Y-axis.\n\n\n\n\nHowever, you can change the X- and Y-axis values, change display of the View, and add \nCutoff Lines\n in the \nTask\n tab of the \nView Controller\n:\n\n\n\n\nYou can identify similar Comparisons to your Comparison-of-Interest under \nSelect View | Gene Set Analysis (plot)\n. This analysis performs a Wilcoxon test, separating all significantly up- and down-regulated genes in your selected Comparison from insignificant genes, and compares these two lists to the set of significant genes in all other Comparisons in your Land, to identify the Comparisons that share a large number of significant genes.\n\n\nIf you did not add \nDiseaseCategory\n in your Sample Metadata file, and did not include \nDiseaseCategory\n in your comparison Metadatafile \nMetaColumns\n, the default plot will be blank, because ArrayLand is attempting to \nprofile\n by a non-existant column. This demonstrates one way that Sample and Comparison metadata columns can affect Views.\n\n\n\n\nHowever, this is a simple issue to fix. In the \nView Controller: Task tab\n, simply select \nSpecify Profile Column\n:\n\n\n\n\nThen select another Comparison Metadata column, such as \nCase.TreatmentLevel\n or \nCase.CellLine\n:\n\n\n\n\nIf using \nTreatmentLabel\n, all Comparisons with \nSlurmycin\n will be displayed in one row, and \nBrawndocin\n columns will be displayed in another.\n\n\n\n\nComparisons that are most similar to Slurmycin_10um_htb-57.test1 will be further to the right (lower P-value).\n\n\nIn the \nView Controller:Task tab\n, select \nChange Symbol\n, and change \nLabels\n to \nSelected\n By \nID\n.\n\n\n\n\nNow select the two significant comparisons:\n\n\n\n\nYou will see that the most significantly similar comparison to Slurmycin_10um_htb-57.test1 is Slurmycin_10um_htb-57.test1. However, the second-most similar comparison is Slurmycin_1um_htb-57.test1.\n\n\nComparisons of Comparisons\n\u00b6\n\n\nIn ComparisonLand, Comparisons can be grouped together, in the same way that genes or samples can be grouped.\n\n\nTo make a ComparisonSet, you can either generate a text list of ComparisonIDs, then load them into your Land as a ComparisonSet, or you can select multiple Comparisons in a View, and select \"Create ComparisonSet\" in the \nAction Window\n.\n\n\nFor example, in the main ComparisonLand Comparisons View (\nSelect View | Overview | Comparisons\n),\nclick \nSpecify Histogram Columns\n in the \nTask\n tab of the \nView Controller\n:\n\n\n\n\nand specify \"Case.Treatment\" as the Histogram column:\n\n\n\n\nNow the histogram will list each comparison, so you can easily select the four \nBrawndocin\n comparisons with your mouse:\n\n\n\n\nIn the \nAction\n Window, you can either choose to \nCreate ComparisonSet\n, or you can simply \nBrowse Selected Comparisons\n:\n\n\n\n\nIf you click \nBrowse Selected Comparisons\n, a new tab will open, displaying a Volcano Plot of each Comparison's up- and down-regulated genes. First, change the layout of charts to \"2 * 2\", then click the \"Toggle Uniform Scale\":\n\n\n\n\nYou will see all four Comparisons in a single window, with the same X- and Y-axis scaling. It is clear that increasing the dose of Brawndocin also increases the number of up- and down-regulated genes.\n\n\nSelect some of the up-regulated genes in the \nBrawndocin_10uM\n plot to see those same genes in the other plots, as well as details in the \nDetails Window\n.\n\n\n\n\nIf you wish, you can create a \nGeneSet\n of your selected genes, in the \nAction\n Window:\n\n\n\n\nFurther Directions\n\u00b6\n\n\nAs you build your ComparisonLand with real data, you will be able to identify Comparisons (e.g. treatments, diseases, cell types) that are most similar to each other, and directly visualize this similarities with Venn Diagrams, Heatmaps, and more; see the ImmunoLand tutorial for more details on these.\n\n\nCongratulations, you have successfully built your own Land from raw expression and inference data,\nconverting text quantifications to rich visualizations, ready for analysis!\n\n\nFor additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Explore ComparisonLand"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/#explore-comparisonland",
            "text": "ArrayLands with comparisons will have different Views that are customized for different types of data:   Gene  Gene Sets  Samples  SampleSets  Comparisons/ComparisonSets   In ComparisonLands, even Gene-Level data can show special  Views  using your Comparison inferences.",
            "title": "Explore ComparisonLand"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/#gene-level-data",
            "text": "When you connect to your new Land, the default View will display the number of samples,\nas derived from the Sample metadata, which should be the same as the number of .alv files you added.   While this is a nice overview of your Land data, especially as you add hundreds or thousands of samples, for multiple projects or tissues, it is not very informative now.  Instead, search for the gene  CD58 .  The default View will display the log2-fold change data from the comparisons,\nseparated by Treatment:   Click  Select View , where you can see additional Views available for Land Gene-Level data:   These Views are explained in more detail in the ImmunoLand and OncoLand tutorials, in addition to the many ways to customize Views, so will not be described in detail here.  However, one View to check is the  Expression Intensity  View:   In contrast to the default GeneLevel View (Comparison.Treatment vs. Control), which is displaying the log2-fold change values from the comparison data, the Expression Intensity View is displaying the expression data for each sample.  As you explore your ComparisonLand, it will be clearer where each source dataset is being used.  Furthermore, you will identify additional Sample and Comparison metadata columns that will be useful\nfor grouping and filtering your data.  This is important to note before you begin constructing a large ComparisonLand, because the comparison metadata are contained within the .tlv files, so cannot be updated as easily as Sample Metadata; you must re-process your comparisons and over-write the .tlv files, then re-publish them to Land.  Thus, you should plan ahead for including important information about different sample groups.",
            "title": "Gene-Level data"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/#comparison-level-data",
            "text": "In addition to viewing Comparisons at the single-gene-level, you can also view all measured genes for a given comparison.  Search for \"Slurmycin_10um_htb-57.test1\" in the  Search Bar ; you will notice that matching hits (genes, comparisons, samples) will be dynamically displayed as you type:   The default View is a Volcano plot, with  Estimate  (log2-Fold Change) on the X-axis and  Raw P-value  on the Y-axis.   However, you can change the X- and Y-axis values, change display of the View, and add  Cutoff Lines  in the  Task  tab of the  View Controller :   You can identify similar Comparisons to your Comparison-of-Interest under  Select View | Gene Set Analysis (plot) . This analysis performs a Wilcoxon test, separating all significantly up- and down-regulated genes in your selected Comparison from insignificant genes, and compares these two lists to the set of significant genes in all other Comparisons in your Land, to identify the Comparisons that share a large number of significant genes.  If you did not add  DiseaseCategory  in your Sample Metadata file, and did not include  DiseaseCategory  in your comparison Metadatafile  MetaColumns , the default plot will be blank, because ArrayLand is attempting to  profile  by a non-existant column. This demonstrates one way that Sample and Comparison metadata columns can affect Views.   However, this is a simple issue to fix. In the  View Controller: Task tab , simply select  Specify Profile Column :   Then select another Comparison Metadata column, such as  Case.TreatmentLevel  or  Case.CellLine :   If using  TreatmentLabel , all Comparisons with  Slurmycin  will be displayed in one row, and  Brawndocin  columns will be displayed in another.   Comparisons that are most similar to Slurmycin_10um_htb-57.test1 will be further to the right (lower P-value).  In the  View Controller:Task tab , select  Change Symbol , and change  Labels  to  Selected  By  ID .   Now select the two significant comparisons:   You will see that the most significantly similar comparison to Slurmycin_10um_htb-57.test1 is Slurmycin_10um_htb-57.test1. However, the second-most similar comparison is Slurmycin_1um_htb-57.test1.",
            "title": "Comparison-Level Data"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/#comparisons-of-comparisons",
            "text": "In ComparisonLand, Comparisons can be grouped together, in the same way that genes or samples can be grouped.  To make a ComparisonSet, you can either generate a text list of ComparisonIDs, then load them into your Land as a ComparisonSet, or you can select multiple Comparisons in a View, and select \"Create ComparisonSet\" in the  Action Window .  For example, in the main ComparisonLand Comparisons View ( Select View | Overview | Comparisons ),\nclick  Specify Histogram Columns  in the  Task  tab of the  View Controller :   and specify \"Case.Treatment\" as the Histogram column:   Now the histogram will list each comparison, so you can easily select the four  Brawndocin  comparisons with your mouse:   In the  Action  Window, you can either choose to  Create ComparisonSet , or you can simply  Browse Selected Comparisons :   If you click  Browse Selected Comparisons , a new tab will open, displaying a Volcano Plot of each Comparison's up- and down-regulated genes. First, change the layout of charts to \"2 * 2\", then click the \"Toggle Uniform Scale\":   You will see all four Comparisons in a single window, with the same X- and Y-axis scaling. It is clear that increasing the dose of Brawndocin also increases the number of up- and down-regulated genes.  Select some of the up-regulated genes in the  Brawndocin_10uM  plot to see those same genes in the other plots, as well as details in the  Details Window .   If you wish, you can create a  GeneSet  of your selected genes, in the  Action  Window:",
            "title": "Comparisons of Comparisons"
        },
        {
            "location": "/tutorials/ComparisonLand/ExploreComparisonLand/#further-directions",
            "text": "As you build your ComparisonLand with real data, you will be able to identify Comparisons (e.g. treatments, diseases, cell types) that are most similar to each other, and directly visualize this similarities with Venn Diagrams, Heatmaps, and more; see the ImmunoLand tutorial for more details on these.  Congratulations, you have successfully built your own Land from raw expression and inference data,\nconverting text quantifications to rich visualizations, ready for analysis!  For additional information, don\u2019t hesitate to contact Omicsoft\u2019s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Further Directions"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/",
            "text": "Introduction to GeneticsLand\n\u00b6\n\n\nGeneticsLand is a robust solution for storage, integration, querying, and visualization of big genetic datasets   up to a million samples, each with 100 million genotypes. This includes both subject-level data, such as genotypes, and summary statistics like allele frequencies and genotype-phenotype association results. In addition to the genetic data repository, GeneticsLand will dynamically join additional data at both the variant and sample level. It currently contains variant annotations from more than fifteen sources and can handle any type of sample attribute (phenotype or clinical measures, QC and tracking information, \netc.\n).\nThere are numerous tabular and graphical visualizations for exploring the data in the context of a variant, gene, genomic region, or phenotype of interest. These include standard displays like allele frequency distributions, Manhattan plots, and region plots as well as advanced views like the OmicSoft Genome Browser, all of which are highly configurable.\n\n\nDownload Demo Dataset\n\u00b6\n\n\nWe will be using a small simulated dataset during this tutorial. Please download from here:\n\nlink\n\n\nto a location that is both accessible from your client machine and Array Server\n(if you don t know which locations are accessible to Array Server, consult with your server admin).\nThis dataset consists of several files that you would be expected to generate during a typical GWAS experiment:\n\n\n\n\nSample information (demographics, phenotypes, \netc\n.)\n\n\nAssayed genotypes\n\n\nImputed allele doses\n\n\nGenotype-phenotype association results\n\n\n\n\nNote, you may begin the first few steps of the tutorial while the data are downloading.\n\n\nCreate a GeneticsLand\n\u00b6\n\n\nThis tutorial is intended as a training exercise, and thus you will begin by creating your own Land, so as not to affect any existing GeneticsLands that are actively being used by others with real data. Generally, it is best to maintain a single primary GeneticsLand, containing all of your institution s genetic data, to benefit from all of the cross-dataset integration features.\n\n\nTo create a GeneticsLand, go to the \nLand\n tab and from the \nTools\n menu, select \nCreate Land\n:\n\n\n\n\nEnter a \nLand name\n, specify the configuration (below), and tick the box to \nCreate genetics land to store variant level data\n. Then click the \nOK\n button and wait momentarily as the Land is created.::\n\n\n Description=GeneticsLandTutorial\n ReferenceLibraryID=Human.B37.3\n GeneModelID=OmicsoftGene20130723\n MutationGeneModelID=Uniprot.Ensembl75\n MaxGeneCount=500\n PrimaryGrouping=ProjectName\n SecondaryGrouping=SEX\n SubjectIDColumn=USUBJID\n VariantClassifiers=ClinVar_20170501,FunctionalMutation_20170501,1000GenomesSimple_20170501,\n ExAC_20170501,ESP6500_20170501,RegulomeDB_20170501,HaploregV4_20170501,Conservation_20170501,\n GWAVA_20170501,GRASP2_20170501,GTexEqtl_20170501,GWASCatalog_20170501,UK10K_20170501,\n Wellderly_20170501\n\n\n\n\n\n\n\n\n\nNote, if this is the first GeneticsLand ever created on this server, please log off the server and restart it to trigger downloading of the relevant reference files before proceeding (contact your server admin if you don t know how to restart it). Also note, we have specified ReferenceLibraryID=Human.B37.3 in the configuration above. All data we add to the Land in subsequent steps must also use this build.\n\n\nUser Permissions in Creating a GeneticsLand\n\u00b6\n\n\nIf you are not a member of the Array Server \nAdministrators\n group, you will not be able to create a new GeneticsLand. Please ask an Array Server Administrator to create the Land. Then, the Administrator should connect to the test GeneticsLand and using the Manage User access function, change your User permissions to allow Write/Publish (for this Land only). Permissions should also be granted for other GeneticsLand management functions, such as \nRefresh/Rebuild\n, \nManage Meta Data\n and \nManage Measurement Data\n.\n\n\n\n\n\n\nOpen a GeneticsLand\n\u00b6\n\n\nAfter the Land has been created, open it from the \nLand\n tab using the \nSelect Land\n menu to find it under the \nGeneticsLand Collection\n heading.\n\n\n\n\nAs a new Land without any samples, you will see an empty \nSample Distribution\n view like this:",
            "title": "Introduction"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/#introduction-to-geneticsland",
            "text": "GeneticsLand is a robust solution for storage, integration, querying, and visualization of big genetic datasets   up to a million samples, each with 100 million genotypes. This includes both subject-level data, such as genotypes, and summary statistics like allele frequencies and genotype-phenotype association results. In addition to the genetic data repository, GeneticsLand will dynamically join additional data at both the variant and sample level. It currently contains variant annotations from more than fifteen sources and can handle any type of sample attribute (phenotype or clinical measures, QC and tracking information,  etc. ).\nThere are numerous tabular and graphical visualizations for exploring the data in the context of a variant, gene, genomic region, or phenotype of interest. These include standard displays like allele frequency distributions, Manhattan plots, and region plots as well as advanced views like the OmicSoft Genome Browser, all of which are highly configurable.",
            "title": "Introduction to GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/#download-demo-dataset",
            "text": "We will be using a small simulated dataset during this tutorial. Please download from here: link  to a location that is both accessible from your client machine and Array Server\n(if you don t know which locations are accessible to Array Server, consult with your server admin).\nThis dataset consists of several files that you would be expected to generate during a typical GWAS experiment:   Sample information (demographics, phenotypes,  etc .)  Assayed genotypes  Imputed allele doses  Genotype-phenotype association results   Note, you may begin the first few steps of the tutorial while the data are downloading.",
            "title": "Download Demo Dataset"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/#create-a-geneticsland",
            "text": "This tutorial is intended as a training exercise, and thus you will begin by creating your own Land, so as not to affect any existing GeneticsLands that are actively being used by others with real data. Generally, it is best to maintain a single primary GeneticsLand, containing all of your institution s genetic data, to benefit from all of the cross-dataset integration features.  To create a GeneticsLand, go to the  Land  tab and from the  Tools  menu, select  Create Land :   Enter a  Land name , specify the configuration (below), and tick the box to  Create genetics land to store variant level data . Then click the  OK  button and wait momentarily as the Land is created.::   Description=GeneticsLandTutorial\n ReferenceLibraryID=Human.B37.3\n GeneModelID=OmicsoftGene20130723\n MutationGeneModelID=Uniprot.Ensembl75\n MaxGeneCount=500\n PrimaryGrouping=ProjectName\n SecondaryGrouping=SEX\n SubjectIDColumn=USUBJID\n VariantClassifiers=ClinVar_20170501,FunctionalMutation_20170501,1000GenomesSimple_20170501,\n ExAC_20170501,ESP6500_20170501,RegulomeDB_20170501,HaploregV4_20170501,Conservation_20170501,\n GWAVA_20170501,GRASP2_20170501,GTexEqtl_20170501,GWASCatalog_20170501,UK10K_20170501,\n Wellderly_20170501    Note, if this is the first GeneticsLand ever created on this server, please log off the server and restart it to trigger downloading of the relevant reference files before proceeding (contact your server admin if you don t know how to restart it). Also note, we have specified ReferenceLibraryID=Human.B37.3 in the configuration above. All data we add to the Land in subsequent steps must also use this build.",
            "title": "Create a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/#user-permissions-in-creating-a-geneticsland",
            "text": "If you are not a member of the Array Server  Administrators  group, you will not be able to create a new GeneticsLand. Please ask an Array Server Administrator to create the Land. Then, the Administrator should connect to the test GeneticsLand and using the Manage User access function, change your User permissions to allow Write/Publish (for this Land only). Permissions should also be granted for other GeneticsLand management functions, such as  Refresh/Rebuild ,  Manage Meta Data  and  Manage Measurement Data .",
            "title": "User Permissions in Creating a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Introduction_to_GeneticsLand/#open-a-geneticsland",
            "text": "After the Land has been created, open it from the  Land  tab using the  Select Land  menu to find it under the  GeneticsLand Collection  heading.   As a new Land without any samples, you will see an empty  Sample Distribution  view like this:",
            "title": "Open a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/",
            "text": "Adding Data to GeneticsLand\n\u00b6\n\n\nIn this section, you will go through the basic procedures for adding data to your GeneticsLand (Sample Metadata, control access to patient information, genotypes/imputed doses, associations, and phenotypes), as well as how to export these different data to \nArray Studio\n to perform analyses such as GWAS.\n\n\nAdd Sample MetaData to a GeneticsLand\n\u00b6\n\n\nTo avoid conflicting sample IDs, and to ensure access controls are in-place \nbefore\n restricted genetic data are added,\nit is considered  best practice  to register samples in the \nSample MetaData\n table before adding their genetic data into the Land.\n\n\nFrom the \nLand\n tab, select \nManage | Samples | Manage Sample Meta Data\n\n\n\n\nTake note of the number of samples (rows) currently in the table. Following this tutorial, the Land will be empty at this point so there will be 0 rows. Click the \nAdd/Replace\n button:\n\n\n\n\nClick \nLoad from tab delimited file\n and select the SampleMetaData.txt file from the tutorial dataset.\nPreview the metadata to ensure that you selected the proper file, then click the \nOK\n button to finish.\n\n\n\n\nNote the new number of samples   it should be the sum of the prior number and the number of new samples being registered (0 + 870 = 870 in this case). If it is less, then one or more of the new sample IDs has conflicted with an existing sample ID, which means that the old metadata were over-written for the conflicting sample(s).\n\n\nIf sample metadata were overwritten, the simplest solution is to map the new samples to new unique IDs.\nFirst, restore the appropriate metadata for the existing samples, as necessary (load from the metadata text files you had previously used). Then, re-register the new samples with new IDs. Use a \nmapping file\n when publishing the new samples  data to the Land (next steps) to ensure they are published with the new IDs and don t collide with the existing samples and their data.\n\n\n\n\nClick the \nX\n in the \nMetaData\n tab to close it, and repeat with any other open tabs.\n\n\n\n\nRe-select the Land using the \nSelect Land\n button, and the \nSample Distribution\n view should now be populated:\n\n\n\n\n\n\nThis view shows the number of samples by project, colored by sex, as indicated in the legend on the right. These groupings are the defaults (PrimaryGrouping and SecondaryGrouping) as configured when the Land was created. You can change the primary grouping using the \nGrouping\n button at the top. You can change the secondary grouping and make other adjustments to the chart by switching to the \nTask\n tab on the right.\n\n\nNote the sample attributes under the \nSample\n tab on the left, which can be used to filter the view. All of these come from the \nSample MetaData\n that you just loaded. The exception is the \nData Availability\n attributes, which displays the amount of genetic data in the Land (currently none, as we haven t added any yet).\n\n\nUsing your mouse to select a component of the chart (the males of STUDY009 here) will display the details of the relevant data points (the \nSample MetaData\n in this case) below the chart:\n\n\n\n\nThese chart configuration, filtering, and selecting mechanisms will generally behave the same across all views in the Land.\n\n\nFor more detailed explanations of how to group/filter/alter Land Views, please see the OncoLand tutorial.\n\n\nControl Data Access in GeneticsLand\n\u00b6\n\n\nIf there are any restrictions on access to data for certain projects, it is best to configure this before adding the genetic data for those projects. Select \nManage | Manage Project Access\n:\n\n\n\n\nYou will see the default access level is \nRead\n for the \nstandard users\n group (includes all users) across all GeneticsLand projects.\nYou can adjust the access for each project at the \nUser\n or \nUser group\n level.\nUsers with \nRead\n access (either individually or through a user group) will be able to see all data for samples in that project.\n\n\nNote, samples are mapped to a project using the ProjectName column in the \nSample MetaData\n table, which is a \nkey\n column.\nThis is why we had to register the samples in the \nMetaData\n before configuring this access control. The \nProject level frequency access\n is a restricted access level that will hide all sample level data (like the \nMetaData\n that we just loaded, and the genotype data we will add in the next step) but expose allele frequencies and other aggregate summary statistics calculated from those hidden samples.\n\n\n\n\nIn addition to this project level access control, there is also a higher Land level access control. To configure this, select\n\nManage | Manage User Access\n\n\n\n\n\n\nYou will see the default is for the \nstandard users\n group to have \nRead/Search\n access (amongst others). Without this basic access level, a user s project level access becomes irrelevant, as they won t be able to access the Land (it will not be listed under the \nSelect Land\n menu).\n\n\nPublish Array Genotypes to a GeneticsLand\n\u00b6\n\n\nLoading data into a GeneticsLand is done through publishing procedures\nthat\nare optimized to be multi-threaded, assuming these datasets may be very large. There are several procedures available for different data types (sequencing, non-sequencing, imputed allele doses, association results) and formats (VCF, PLINK, IMPUTE2, \netc.\n). Following the logical experimental workflow, we will first publish the assayed genotypes. In the tutorial dataset, these are from a genotype array in PLINK format.\n\n\nFrom the Land tab, select \nTools | Publish To Land\n:\n\n\n\n\nSelect the tutorial \nLand\n, set \nData type\n to \nBED\n and \nJob number\n to \n4\n (or higher if your server can handle more than 4 parallel threads). For \nFile\n, \nBrowse\n to the downloaded Callset_2016-05-26.bed file. We won t specify a \nSample File\n here (this is an option to allow adding \nSample Meta Data\n while publishing, but we have already done this).\n\n\n\n\n\n\nNote\n\n\nNote:\n\nThe File Browser will display Array Server locations,so you either need to upload the data to your Array Server folder, or navigate to a network drive location with the data.\n\n\n\n\n\n\nFor the \nPanel\n, you would normally select the array that was used to generate the data, so that its annotations can be used to resolve the alleles to VCF convention. However, this tutorial dataset is synthesized and not from any particular array, so you should instead select the \n option. This option assumes the alleles are already resolved to VCF convention and reads the REF/ALT designations from the variant ID in the PLINK bim file (IDs are CHROM:POS:REF:ALT). Tick the box to \nautomatically generate variant annotation\n.\n\n\nIn the \nSampleID Mapping\n section, note that the sample IDs have been populated from the PLINK fam file. Specifically, they are the IIDs (second column). The data will be published using these IDs as their primary sample identifiers, which is used to join to the \nSample MetaData\n we added above. The FIDs (first column of fam file) will be read and stored for future exports of the data to PLINK format, but otherwise won t be visible in the Land.\n\n\nIn some cases, the SampleIDs extracted from the file are not the IDs you want used for the Land, for example, if you determined in the prior step when adding \nSample MetaData\n that some of these IDs conflict with samples that already have data in the Land. You can load a \nmapping file\n containing two columns (column 1: Original Sample ID; column 2: Land Sample ID), either from a local file, or from the server.\n\n\n\n\nIf you use the local \nLoad\n option, the preview will display the contents of the file, NOT the effective mapping. For example, below we have only included the first two samples in the mapping file (all other samples in the PLINK dataset will be loaded using\ntheir IID). However, note the typo in the first sample (the extra \na\n at the end). This means the \nPlate1008_Well63\n sample will be loaded as-is without any mapping. For this tutorial, it is not necessary to specify any mapping as these IDs are sufficiently unique. Click the \nSend to Queue\n button to submit the job.\n\n\n\n\nAfter clicking \nSend To Queue,\n you will be taken to the \nServerJobs\n tab under the \nServer\n tab to see the status of the publish job. Note, these jobs are multi-threaded (per the specified \nJob number\n), so to avoid disk IO issues, only one \npublish\n job per server will run at a time. If another publish job is already running, you will see the status of your job as \nInQueue\n.\n\n\n\n\nIf your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if \nJob number\n set to 4, faster if higher). The Server Job \nStatus\n should be \nFinished\n, and if you scroll towards the bottom of the log, you should see a section like:\n\n\n\n\nWhere the last line indicates the number of samples that have been published. You can also confirm by logging off the server and re-connecting. Then re-open the Land, and in the default \nSample Distribution\n view in the \nSample\n tab on the left, expand the \nData Availability\n attributes to see that there are now 870 samples with \nArraySnp\n data.\n\n\n\n\nExport Array Genotypes from a GeneticsLand\n\u00b6\n\n\nIn the next section, you will import a set of imputed dose data pre-generated from the tutorial dataset, but only using a subset of the output data. If you wished to generate the full dataset, or wanted to perform GWAS on other data in GeneticsLand, you can follow the steps in this section to export GeneticsLand data. Otherwise, you can skip ahead to the next section.\n\n\nWe are going to export a subset of the genotypes that we just published to PLINK format,\nso that we can run a GWAS on these data.\nFirst, create a \nSample Set\n containing the samples you wish to export for analysis.\nReturn to the \nSample Distribution\n view by opening the Land (if not already open)\nand clicking on the \nSelect View\n button to select the \nSamples\n \nView\n, under the \nOverview\n heading.\n\n\n\n\nUse the \nSample\n attributes on the left to filter to \nSTUDY005\n, then click on \nCreate SampleSet\n:\n\n\n\n\n\n\nSelect \nCreate Sample Set From Filter\n and click \nOK\n.\n\n\n\n\nEnter \nSTUDY005\n as the \nName\n and \nSTUDY\n as the \nTag\n, then click \nUpload\n.\n\n\nNow the samples in \nSTUDY005\n can be exported as one group. SampleSets are a convenient and powerful way to sub-group Land Data for analysis.\n\n\nTo export the \nSTUDY005\n data for GWAS analysis, in the \nLand\n tab, select \nTools | Export From Land\n:\n\n\n\n\nSelect the tutorial \nLand\n, leave \nOutput\n as \nPlink BED\n, and set \nData type\n to \nGenotyped Data\n, which will exclude any imputed allele doses or genotypes from sequencing. \nBrowse\n to a location and give a name to the \nOutput file\n. For the \nVariants\n, leave the \nAll variants\n option selected. The other options allow you to \nBrowse\n to a file containing a list of variants, genes, or regions.\n\n\n\n\nFor the \nSamples\n, switch to the \nSampleSet\n and then \nChoose\n the set just created (\nSTUDY | STUDY005\n).\nThe \nSelected samples\n option allows you to \nBrowse\n to a file containing a list of sample IDs.\n\n\nUntick the box to \nInfer RS IDs from the variant definitions\n (rs IDs are not needed for GWAS) but leave the box ticked for \nRemove fully missing variants\n (these will have call rate of 0 in the selected samples, so are of no value for GWAS). You can leave the Dose to genotype threshold at 0.5 and the R2 cutoff at 0. The default dose to genotype threshold will convert all dosage values to a genotype. The R2 cutoff is the imputation quality threshold. Set to 0 to export everything. Set the \nJob number\n to \n4\n (or 64 if your Array Server uses a cluster) and click the \nSend To Queue\n button to start the job.\n\n\n\n\nYou will again be taken to the \nServerJobs\n tab under the \nServer\n tab to see the status of the export job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (5 to 10 minutes). The \nStatus\n should be \nFinished\n. You can also confirm that the expected number of samples were exported by navigating to the PLINK fam file and counting the lines it should be 412.\n\n\nPublish Imputed Allele Doses to a GeneticsLand\n\u00b6\n\n\nGeneticsLand can also contain imputed dose data, such as those that would be calculated by running Array Studio GWAS functions\n(see the GWAS tutorial for further guidance). The tutorial dataset contains a subset of imputed dose data from the tutorial GeneticsLand data, but you could run the full genotype data from the previous section through the Array Studio GWAS pipeline for additional practice.\n\n\nIn order for the data underlying association results to be explorable in the Land, we need to add the imputed allele doses that were analyzed to generate the results. The tutorial imputed data were generated by the \nminimac\n imputation module in Array Studio, and thus the imputed allele doses are in 3 VCF files   autosomes, male chrX and female chrX (thinned to ~1 million variants for the purposes of this tutorial).\n\n\nFrom the \nLand\n tab, select \nTools | Publish To Land\n:\n\n\n\n\nSelect the tutorial \nLand\n, set \nData type\n to \nVCF (imputed)\n and \nJob number\n to \n4\n (or higher if you have a server than can handle more than 4 parallel threads). For \nFile\n, \nBrowse\n to the downloaded autosome VCF file ( ThinnedAuto.vcf.gz ).\n\n\n\n\nIn the \nSampleID Mapping\n section, note the joint FID->IIDs in the VCF file have automatically be truncated to just the IID. This ensures that the data will be added to the Land under the same ID as the array genotypes from which it was derived. Unlike when initially publishing the array genotypes, where we first added the \nSample MetaData\n to ensure no sample ID conflicts, here we are intentionally publishing the data under the same IDs. Because they are different data types (genotypes vs imputed doses), they are both stored in the Land (one will not overwrite the other), and you will be able to visualize them separately.\n\n\n\n\nClick the \nSend to Queue\n button to submit the job. You will be taken to the \nServerJobs\n tab under the \nServer\n tab to see the status of the publish job.\n\n\nIf your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The \nStatus\n should be \nFinished\n and if you scroll towards the bottom of the log, you should see a section like:\n\n\n\n\nWhere the last line indicates the number of samples that have been published. Note, this is less than the 412 that were exported, due to the pre-GWAS QC, which excluded some samples. You can also confirm these imputed allele doses were published by logging off the server and re-connecting. Then re-open the Land and in the default \nSample Distribution\n view in the \nSample\n tab on the left,\nexpand the \nData Availability\n attributes to see there are now 333 samples with \nImputed Snp Dose\n data.\n\n\n\n\nRepeat this process with the remaining two VCF files (ThinnedFchrX.vcf.gz and ThinnedMchrX.vcf.gz). Note, even though we are publishing the same data type (imputed doses) for the same sample IDs, these operations won t overwrite any data already in the Land, because these VCF files contain entirely new variants (\ni.e.\n those on chromosome X, which were not present in the ThinnedAuto.vcf.gz file).\n\n\nPublish Genetic Associations to a GeneticsLand\n\u00b6\n\n\nIn addition to the subject-level genetic data generated from DNA samples, GeneticsLand can also host and present genetic association results. For this step, we are assuming a genotype-phenotype association analysis has been conducted with the \nAssociation\n module in Array Studio, and the results are already in the appropriate GTT format; these data can be found in the tutorial dataset. From the \nLand\n tab, select \nTools | Publish To Land\n:\n\n\n\n\nSelect the tutorial \nLand\n, set \nData type\n to \nAssociation Report\n and \nJob number\n to \n4\n (or higher if your server can handle more parallel threads). For \nFile\n, \nBrowse\n to the downloaded GTT file (fev1 study005.gtt).\n\n\nIn the \nSampleID Mapping\n section, note the file name has been used as the \nSample ID\n. For association results, \nSample ID\n is the name or label for the result set. This is what will be searchable and displayed in the Land, so ensure it is sufficiently descriptive. For example, if you have analyzed the same dataset multiple times and have multiple result sets (\ne.g.\n once with smoking status as a covariate and once without), you will need to ensure each association file has a unique name, and you will want the names to be descriptive enough to distinguish between them when you see them in the Land. You have the same options for mapping from the default file name to a new value as described above when publishing the array genotypes. For this tutorial, it is ok to leave the \nSample ID\n as-is.\n\n\n\n\nClick the \nSend to Queue\n button to submit the job. You will be taken to the \nServerJobs\n tab under the \nServer\n tab to see the status of the publish job.\n\n\nIf your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The \nStatus\n should be \nFinished\n, and you can confirm the set was published by starting to type the name into the search bar at the top of the Land tab to see the \nassociation\n type record found:\n\n\n\n\nAdd Phenotype Data to a GeneticsLand\n\u00b6\n\n\nIn order to aid in the interpretation of the genetic data in GeneticsLand and explore the data underlying a genetic association result, the Land will host and present sample attributes (metadata). There are currently four ways to manage phenotype or other sample measures in a GeneticsLand:\n\n\n\n\nSample Meta Data (metadata categories that can be viewed for all samples in GeneticsLand)\n\n\nSample Set Meta Data (metadata categories attached only for a selected subset of samples)\n\n\nClinical Data (extended sample metadata for clinical variables)\n\n\nManage Project Meta Data (association sets can be tied to a project and metadata organized by Project Name)\n\n\n\n\nOur objective here is to add the phenotype data that were used for the GWAS whose results we just published. These types of measures are typically not added to the \nSample MetaData\n, as they can be sparse (\ni.e.\n you may have lung function measures for a respiratory study but not for a neurology one). The \nClinical Data\n system is likely the best location for these types of data, as it is shared by all users like \nSample MetaData\n (pursuant to access controls), while a \nSample Set s\n access can be managed by its creator. However, for the sake of simplicity in this tutorial, we will use the \nSample Set MetaData\n.\n\n\nFrom the \nLand\n tab, select \nManage | Samples | Manage Sample Sets\n:\n\n\n\n\nWe will use the same sample set created to export the array genotypes.\nSelect \nSTUDY005\n and then click on the \nedit\n button:\n\n\n\n\nSwitch to the \nMetaData\n tab and select \nLoad tab delimited file\n:\n\n\n\n\nBrowse to and select the phenotypes.txt file, then click the \nUpdate\n button to finish.\n\n\n\n\nYou may now close the \nSampleSets\n tab by clicking the**X**:\n\n\n\n\nAnd if you close the other tabs and re-open the Land to the default \nSample Distribution\n view (allowing the Land to refresh with your SampleSet data), you will now see the phenotypes listed under the \nSample Set\n heading:\n\n\n\n\nNote, we are using the term  phenotype  loosely, as we have also included other sample measures like smoking status, drug treatment, and consent, which are relevant to exploring and interpreting the data and results.",
            "title": "Adding Data to GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#adding-data-to-geneticsland",
            "text": "In this section, you will go through the basic procedures for adding data to your GeneticsLand (Sample Metadata, control access to patient information, genotypes/imputed doses, associations, and phenotypes), as well as how to export these different data to  Array Studio  to perform analyses such as GWAS.",
            "title": "Adding Data to GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#add-sample-metadata-to-a-geneticsland",
            "text": "To avoid conflicting sample IDs, and to ensure access controls are in-place  before  restricted genetic data are added,\nit is considered  best practice  to register samples in the  Sample MetaData  table before adding their genetic data into the Land.  From the  Land  tab, select  Manage | Samples | Manage Sample Meta Data   Take note of the number of samples (rows) currently in the table. Following this tutorial, the Land will be empty at this point so there will be 0 rows. Click the  Add/Replace  button:   Click  Load from tab delimited file  and select the SampleMetaData.txt file from the tutorial dataset.\nPreview the metadata to ensure that you selected the proper file, then click the  OK  button to finish.   Note the new number of samples   it should be the sum of the prior number and the number of new samples being registered (0 + 870 = 870 in this case). If it is less, then one or more of the new sample IDs has conflicted with an existing sample ID, which means that the old metadata were over-written for the conflicting sample(s).  If sample metadata were overwritten, the simplest solution is to map the new samples to new unique IDs.\nFirst, restore the appropriate metadata for the existing samples, as necessary (load from the metadata text files you had previously used). Then, re-register the new samples with new IDs. Use a  mapping file  when publishing the new samples  data to the Land (next steps) to ensure they are published with the new IDs and don t collide with the existing samples and their data.   Click the  X  in the  MetaData  tab to close it, and repeat with any other open tabs.   Re-select the Land using the  Select Land  button, and the  Sample Distribution  view should now be populated:    This view shows the number of samples by project, colored by sex, as indicated in the legend on the right. These groupings are the defaults (PrimaryGrouping and SecondaryGrouping) as configured when the Land was created. You can change the primary grouping using the  Grouping  button at the top. You can change the secondary grouping and make other adjustments to the chart by switching to the  Task  tab on the right.  Note the sample attributes under the  Sample  tab on the left, which can be used to filter the view. All of these come from the  Sample MetaData  that you just loaded. The exception is the  Data Availability  attributes, which displays the amount of genetic data in the Land (currently none, as we haven t added any yet).  Using your mouse to select a component of the chart (the males of STUDY009 here) will display the details of the relevant data points (the  Sample MetaData  in this case) below the chart:   These chart configuration, filtering, and selecting mechanisms will generally behave the same across all views in the Land.  For more detailed explanations of how to group/filter/alter Land Views, please see the OncoLand tutorial.",
            "title": "Add Sample MetaData to a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#control-data-access-in-geneticsland",
            "text": "If there are any restrictions on access to data for certain projects, it is best to configure this before adding the genetic data for those projects. Select  Manage | Manage Project Access :   You will see the default access level is  Read  for the  standard users  group (includes all users) across all GeneticsLand projects.\nYou can adjust the access for each project at the  User  or  User group  level.\nUsers with  Read  access (either individually or through a user group) will be able to see all data for samples in that project.  Note, samples are mapped to a project using the ProjectName column in the  Sample MetaData  table, which is a  key  column.\nThis is why we had to register the samples in the  MetaData  before configuring this access control. The  Project level frequency access  is a restricted access level that will hide all sample level data (like the  MetaData  that we just loaded, and the genotype data we will add in the next step) but expose allele frequencies and other aggregate summary statistics calculated from those hidden samples.   In addition to this project level access control, there is also a higher Land level access control. To configure this, select Manage | Manage User Access    You will see the default is for the  standard users  group to have  Read/Search  access (amongst others). Without this basic access level, a user s project level access becomes irrelevant, as they won t be able to access the Land (it will not be listed under the  Select Land  menu).",
            "title": "Control Data Access in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-array-genotypes-to-a-geneticsland",
            "text": "Loading data into a GeneticsLand is done through publishing procedures\nthat\nare optimized to be multi-threaded, assuming these datasets may be very large. There are several procedures available for different data types (sequencing, non-sequencing, imputed allele doses, association results) and formats (VCF, PLINK, IMPUTE2,  etc. ). Following the logical experimental workflow, we will first publish the assayed genotypes. In the tutorial dataset, these are from a genotype array in PLINK format.  From the Land tab, select  Tools | Publish To Land :   Select the tutorial  Land , set  Data type  to  BED  and  Job number  to  4  (or higher if your server can handle more than 4 parallel threads). For  File ,  Browse  to the downloaded Callset_2016-05-26.bed file. We won t specify a  Sample File  here (this is an option to allow adding  Sample Meta Data  while publishing, but we have already done this).    Note  Note: \nThe File Browser will display Array Server locations,so you either need to upload the data to your Array Server folder, or navigate to a network drive location with the data.    For the  Panel , you would normally select the array that was used to generate the data, so that its annotations can be used to resolve the alleles to VCF convention. However, this tutorial dataset is synthesized and not from any particular array, so you should instead select the   option. This option assumes the alleles are already resolved to VCF convention and reads the REF/ALT designations from the variant ID in the PLINK bim file (IDs are CHROM:POS:REF:ALT). Tick the box to  automatically generate variant annotation .  In the  SampleID Mapping  section, note that the sample IDs have been populated from the PLINK fam file. Specifically, they are the IIDs (second column). The data will be published using these IDs as their primary sample identifiers, which is used to join to the  Sample MetaData  we added above. The FIDs (first column of fam file) will be read and stored for future exports of the data to PLINK format, but otherwise won t be visible in the Land.  In some cases, the SampleIDs extracted from the file are not the IDs you want used for the Land, for example, if you determined in the prior step when adding  Sample MetaData  that some of these IDs conflict with samples that already have data in the Land. You can load a  mapping file  containing two columns (column 1: Original Sample ID; column 2: Land Sample ID), either from a local file, or from the server.   If you use the local  Load  option, the preview will display the contents of the file, NOT the effective mapping. For example, below we have only included the first two samples in the mapping file (all other samples in the PLINK dataset will be loaded using\ntheir IID). However, note the typo in the first sample (the extra  a  at the end). This means the  Plate1008_Well63  sample will be loaded as-is without any mapping. For this tutorial, it is not necessary to specify any mapping as these IDs are sufficiently unique. Click the  Send to Queue  button to submit the job.   After clicking  Send To Queue,  you will be taken to the  ServerJobs  tab under the  Server  tab to see the status of the publish job. Note, these jobs are multi-threaded (per the specified  Job number ), so to avoid disk IO issues, only one  publish  job per server will run at a time. If another publish job is already running, you will see the status of your job as  InQueue .   If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if  Job number  set to 4, faster if higher). The Server Job  Status  should be  Finished , and if you scroll towards the bottom of the log, you should see a section like:   Where the last line indicates the number of samples that have been published. You can also confirm by logging off the server and re-connecting. Then re-open the Land, and in the default  Sample Distribution  view in the  Sample  tab on the left, expand the  Data Availability  attributes to see that there are now 870 samples with  ArraySnp  data.",
            "title": "Publish Array Genotypes to a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#export-array-genotypes-from-a-geneticsland",
            "text": "In the next section, you will import a set of imputed dose data pre-generated from the tutorial dataset, but only using a subset of the output data. If you wished to generate the full dataset, or wanted to perform GWAS on other data in GeneticsLand, you can follow the steps in this section to export GeneticsLand data. Otherwise, you can skip ahead to the next section.  We are going to export a subset of the genotypes that we just published to PLINK format,\nso that we can run a GWAS on these data.\nFirst, create a  Sample Set  containing the samples you wish to export for analysis.\nReturn to the  Sample Distribution  view by opening the Land (if not already open)\nand clicking on the  Select View  button to select the  Samples   View , under the  Overview  heading.   Use the  Sample  attributes on the left to filter to  STUDY005 , then click on  Create SampleSet :    Select  Create Sample Set From Filter  and click  OK .   Enter  STUDY005  as the  Name  and  STUDY  as the  Tag , then click  Upload .  Now the samples in  STUDY005  can be exported as one group. SampleSets are a convenient and powerful way to sub-group Land Data for analysis.  To export the  STUDY005  data for GWAS analysis, in the  Land  tab, select  Tools | Export From Land :   Select the tutorial  Land , leave  Output  as  Plink BED , and set  Data type  to  Genotyped Data , which will exclude any imputed allele doses or genotypes from sequencing.  Browse  to a location and give a name to the  Output file . For the  Variants , leave the  All variants  option selected. The other options allow you to  Browse  to a file containing a list of variants, genes, or regions.   For the  Samples , switch to the  SampleSet  and then  Choose  the set just created ( STUDY | STUDY005 ).\nThe  Selected samples  option allows you to  Browse  to a file containing a list of sample IDs.  Untick the box to  Infer RS IDs from the variant definitions  (rs IDs are not needed for GWAS) but leave the box ticked for  Remove fully missing variants  (these will have call rate of 0 in the selected samples, so are of no value for GWAS). You can leave the Dose to genotype threshold at 0.5 and the R2 cutoff at 0. The default dose to genotype threshold will convert all dosage values to a genotype. The R2 cutoff is the imputation quality threshold. Set to 0 to export everything. Set the  Job number  to  4  (or 64 if your Array Server uses a cluster) and click the  Send To Queue  button to start the job.   You will again be taken to the  ServerJobs  tab under the  Server  tab to see the status of the export job. If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (5 to 10 minutes). The  Status  should be  Finished . You can also confirm that the expected number of samples were exported by navigating to the PLINK fam file and counting the lines it should be 412.",
            "title": "Export Array Genotypes from a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-imputed-allele-doses-to-a-geneticsland",
            "text": "GeneticsLand can also contain imputed dose data, such as those that would be calculated by running Array Studio GWAS functions\n(see the GWAS tutorial for further guidance). The tutorial dataset contains a subset of imputed dose data from the tutorial GeneticsLand data, but you could run the full genotype data from the previous section through the Array Studio GWAS pipeline for additional practice.  In order for the data underlying association results to be explorable in the Land, we need to add the imputed allele doses that were analyzed to generate the results. The tutorial imputed data were generated by the  minimac  imputation module in Array Studio, and thus the imputed allele doses are in 3 VCF files   autosomes, male chrX and female chrX (thinned to ~1 million variants for the purposes of this tutorial).  From the  Land  tab, select  Tools | Publish To Land :   Select the tutorial  Land , set  Data type  to  VCF (imputed)  and  Job number  to  4  (or higher if you have a server than can handle more than 4 parallel threads). For  File ,  Browse  to the downloaded autosome VCF file ( ThinnedAuto.vcf.gz ).   In the  SampleID Mapping  section, note the joint FID->IIDs in the VCF file have automatically be truncated to just the IID. This ensures that the data will be added to the Land under the same ID as the array genotypes from which it was derived. Unlike when initially publishing the array genotypes, where we first added the  Sample MetaData  to ensure no sample ID conflicts, here we are intentionally publishing the data under the same IDs. Because they are different data types (genotypes vs imputed doses), they are both stored in the Land (one will not overwrite the other), and you will be able to visualize them separately.   Click the  Send to Queue  button to submit the job. You will be taken to the  ServerJobs  tab under the  Server  tab to see the status of the publish job.  If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The  Status  should be  Finished  and if you scroll towards the bottom of the log, you should see a section like:   Where the last line indicates the number of samples that have been published. Note, this is less than the 412 that were exported, due to the pre-GWAS QC, which excluded some samples. You can also confirm these imputed allele doses were published by logging off the server and re-connecting. Then re-open the Land and in the default  Sample Distribution  view in the  Sample  tab on the left,\nexpand the  Data Availability  attributes to see there are now 333 samples with  Imputed Snp Dose  data.   Repeat this process with the remaining two VCF files (ThinnedFchrX.vcf.gz and ThinnedMchrX.vcf.gz). Note, even though we are publishing the same data type (imputed doses) for the same sample IDs, these operations won t overwrite any data already in the Land, because these VCF files contain entirely new variants ( i.e.  those on chromosome X, which were not present in the ThinnedAuto.vcf.gz file).",
            "title": "Publish Imputed Allele Doses to a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#publish-genetic-associations-to-a-geneticsland",
            "text": "In addition to the subject-level genetic data generated from DNA samples, GeneticsLand can also host and present genetic association results. For this step, we are assuming a genotype-phenotype association analysis has been conducted with the  Association  module in Array Studio, and the results are already in the appropriate GTT format; these data can be found in the tutorial dataset. From the  Land  tab, select  Tools | Publish To Land :   Select the tutorial  Land , set  Data type  to  Association Report  and  Job number  to  4  (or higher if your server can handle more parallel threads). For  File ,  Browse  to the downloaded GTT file (fev1 study005.gtt).  In the  SampleID Mapping  section, note the file name has been used as the  Sample ID . For association results,  Sample ID  is the name or label for the result set. This is what will be searchable and displayed in the Land, so ensure it is sufficiently descriptive. For example, if you have analyzed the same dataset multiple times and have multiple result sets ( e.g.  once with smoking status as a covariate and once without), you will need to ensure each association file has a unique name, and you will want the names to be descriptive enough to distinguish between them when you see them in the Land. You have the same options for mapping from the default file name to a new value as described above when publishing the array genotypes. For this tutorial, it is ok to leave the  Sample ID  as-is.   Click the  Send to Queue  button to submit the job. You will be taken to the  ServerJobs  tab under the  Server  tab to see the status of the publish job.  If your user profile on the server includes your e-mail address, you will get an e-mail notification when the job is complete (~10 minutes if Job number set to 4, faster if set higher). The  Status  should be  Finished , and you can confirm the set was published by starting to type the name into the search bar at the top of the Land tab to see the  association  type record found:",
            "title": "Publish Genetic Associations to a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Adding_Data_to_GeneticsLand/#add-phenotype-data-to-a-geneticsland",
            "text": "In order to aid in the interpretation of the genetic data in GeneticsLand and explore the data underlying a genetic association result, the Land will host and present sample attributes (metadata). There are currently four ways to manage phenotype or other sample measures in a GeneticsLand:   Sample Meta Data (metadata categories that can be viewed for all samples in GeneticsLand)  Sample Set Meta Data (metadata categories attached only for a selected subset of samples)  Clinical Data (extended sample metadata for clinical variables)  Manage Project Meta Data (association sets can be tied to a project and metadata organized by Project Name)   Our objective here is to add the phenotype data that were used for the GWAS whose results we just published. These types of measures are typically not added to the  Sample MetaData , as they can be sparse ( i.e.  you may have lung function measures for a respiratory study but not for a neurology one). The  Clinical Data  system is likely the best location for these types of data, as it is shared by all users like  Sample MetaData  (pursuant to access controls), while a  Sample Set s  access can be managed by its creator. However, for the sake of simplicity in this tutorial, we will use the  Sample Set MetaData .  From the  Land  tab, select  Manage | Samples | Manage Sample Sets :   We will use the same sample set created to export the array genotypes.\nSelect  STUDY005  and then click on the  edit  button:   Switch to the  MetaData  tab and select  Load tab delimited file :   Browse to and select the phenotypes.txt file, then click the  Update  button to finish.   You may now close the  SampleSets  tab by clicking the**X**:   And if you close the other tabs and re-open the Land to the default  Sample Distribution  view (allowing the Land to refresh with your SampleSet data), you will now see the phenotypes listed under the  Sample Set  heading:   Note, we are using the term  phenotype  loosely, as we have also included other sample measures like smoking status, drug treatment, and consent, which are relevant to exploring and interpreting the data and results.",
            "title": "Add Phenotype Data to a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/",
            "text": "Explore Your Data in GeneticsLand\n\u00b6\n\n\nReview Genetic Association Results in a GeneticsLand\n\u00b6\n\n\nAfter all that setup, we are now ready to explore the data in your GeneticsLand. The tutorial dataset reflects a respiratory GWAS assessing genetic association with the FEV1 (Forced Expiratory Volume in One Second) endpoint. The primary access point for exploring the data in the Land will be the search box at the top of the \nLand\n tab. Start typing the name of the genetic association result set that we just published ( fev1 study005 ), then select the matching entry from the drop-down box:\n\n\n\n\nAssociation Annotation View\n\u00b6\n\n\nWhen you search an association, five views are available.\n\n\n\n\nThe \nAssociation Annotation\n view is the fully annotated table of all association results. The primary use case for this view is to query (filter) all results by variant attributes (\ni.e.\n all putatively functional coding variants).\n\n\n\n\nNote, these annotations were generated when the association results (GTT file) were published, and thus may be slightly out of date if new annotations have been released since then. For all other views in the Land, the most current annotations will be dynamically joined. The annotation sources were defined in the configuration when the Land was created (VariantClassifiers=ClinVar_20170501, FunctionalMutation_20170501\u2026). The specific classifiers we used for this tutorial are provided by OmicSoft. OmicSoft support (\nsupport@omicsoft.com\n) can assist you with building custom classifiers if you have proprietary or licensed annotations you wish to include.\n\n\nYou can use the variant attributes in the \nSearch Result\n tab on the left to filter. Switch to the \nTask\n tab on the right and click on \nSpecify Columns\n to configure which columns to display (by default, they are all displayed):\n\n\n\n\nIf you have filtered to a smaller number of rows (<2000 rows), new buttons will appear at the top to enable sorting and searching of the table (you can also right click on a column header to sort):\n\n\n\n\nOnce you have configured the table as you want, you can use the three buttons at the top-left to either open in a text editor, Excel, or save to a file, including an OmicSoft object file (.osobj) that can be opened in an Array Studio project (\nAnalysis\n tab) for further analysis. Alternatively, you can save the view to a file that can be re-opened later (\nFile | Save View\n) or share it for future access by you or others (\nShare | Share Land View\n). All of these options for configuring, exporting, and saving the view are common across all tabular views in the Land, and similar options are available for graphical views.\n\n\nRegion Plot View\n\u00b6\n\n\nUse the \nSelect View\n button to switch to the \nRegion Plot\n view: This view will show a Manhattan plot of the top 10,000 most significant results by p-value. With your mouse, click and drag to select the peak over chr15. This defines the center for the region plot. Note, the genome plot will disappear as the region plot is displayed. Click the \nShow Overview\n button to re-display it (and \nHide Overview\n to hide it again).\n\n\n\n\nIn addition to selecting points from the genome plot, you can also go to a specific variant, gene, or region using the \nSelect Region\n button:\n\n\n\n\nThis also allows you to set the region length (500 kb is the default). Note, specifying a variant (or coordinate using the Region option) does not set that as the  key  variant for calculating LD. The pairwise LD is always calculated relative to the variant in the region with the lowest p-value. Back in the region plot, you can choose to display or hide the pairwise LD matrix by selecting or de-selecting \npairwise LD\n.\n\n\nAlso in the region plot, you can use the \nLD Source\n and \nLD Measurement\n menus to adjust those values.\nAs the \nLD Sources\n are from 1000 Genomes, which are shallow short read data that have been statistically phased, these data are subject to switch errors, and the \nR2(Haplotype)\n may be inaccurate.\n\n\nLooking at the default \n1000G.EUR LD Source\n with \nR2\n as the \nLD Measurement\n, we see that many of the variants passing the genome wide significance threshold (PValue < 5E10 -8) appear to be in LD and thus likely represent a single causal variant.\n\n\n\n\nHowever, given the extreme significance of many of these associations (note the scale of the -Log10(PValue) Y axis), there may be additional independent signals that are less significant but still pass the genome wide PValue threshold.\n\n\nThis \nRegion Plot\n view is based on the OmicSoft Genome Browser, so you can configure display of various genomic annotation tracks. These options are available in the \nTask\n tab on the right, where you can \nManage\n the existing tracks and \nAdd Tracks\n from a variety of sources. This tab also has the option to \nExport\n the plot to an image file.\n\n\nThere are three remaining views available under \nSelect View\n. These three views are \nTop Hits\n views and the results displayed are user defined by the TopHitsN parameter. The TopHitsN parameter controls how many association results with the most significant p-values to display in these views. The default is 10,000.\n\n\nThe \nTop Hits (Genome Plot)\n view is a variation of what we have already seen. It is the same genome plot as shown in the \nRegion Plot\n view, except instead of being used to set the center of the region plot (the primary component of the \nRegion Plot\n view), the genome plot itself will be the primary component. The \nTop Hist (QQ plot)\n displays the negative logarithm of the observed (x-axis) and the expected (y-axis) P value for each SNP. This plot can be used to investigate confounders and identify true associations. Both of these views are fully interactive, such that you can use your mouse to select from the views, and give you options to explore the most significant results (filter on variant attributes, select to see details, \netc\n.) and configure the charts.\n\n\n\n\nThe \nTop Hits (Table)\n will be the fully annotated table of those same 1,000 most significant results. The output here is similar to the original \nAssociation Annotation\n view, except that the most current annotations will be dynamically joined. Select this view. To see which specific annotation versions are being reported, use the \nOptions\n button in the \nSearch Result\n tab on the left to select \nShow Annotation Sources\n:\n\n\n\n\n\n\nThis same classifier listing will be included as a header if you \nOpen as Text file\n\n\n\n\n\n\nThe first column in the \nTop Hits (Table)\n view is the \nSnp ID\n, which contains a link to the variant s views (as if you had searched for the variant from the search box at the top). Right click on the \nPValue\n column to \nSort Descending\n\n(the sort is based on the -log(PValue), so larger values are more significant).\n\n\n\n\nThen click on the \nSnp ID\n for the first row (\nrs475535\n) and continue to the next section to learn about the data and views available for this highly-significant variant.\n\n\nReview Variant Knowledge in GeneticsLand\n\u00b6\n\n\nHaving searched for rs475535, the default view that is returned is the \nAllele Frequency\n plot. Like the \nSample Distribution\n view, this is also grouped based on the PrimaryGrouping=ProjectName defined when the Land was created, and can be adjusted using the \nGrouping\n button at the top.\n\n\n\n\nNote there are actually two charts here, the first (\nGenotyped\n) being calculated from all the non-sequencing based genotypes that are in the Land (the array genotypes we published). Scroll down to see the next chart (\nImputed\n), which is calculated from all the imputed allele doses in the Land (\ni.e.\n the ones we published from the GWAS).\n\n\n\n\nIn addition to the frequency being represented on the X axis, the carrier count is also displayed to the right of the bar in parentheses. Another view available is \nGenotype Frequency\n, which is configured similarly to the \nAllele Frequency\n plot.\n\n\n\n\nThe number displayed to the right of each bar is still the carrier count (sum of heterozygotes and homozygote ALT). To get the count of each of these sub-groups, click on the \nView Filtered Table\n button at the bottom left to see the counts for each chart element.\n\n\n\n\nThere is also a special view named \nCase Control Allele Frequency\n, which is available because at least one of the columns in our phenotype file was specified as a case/control value:\n\n\n\n\nSwitch to this view under the \nSelect View\n menu and you will see that instead of being grouped by \nProject Name\n, the allele frequencies are now grouped by the case/control status for all three phenotypes that were specified as case/control:\n\n\n\n\nThe final view under the \nSummary\n heading in the \nSelect View\n menu (\nSNP Annotation\n) is the table of variant annotations. These will match what were reported in the \nTop Hits (Table)\n view when we were reviewing the association results.\n\n\n\n\nBack in the \nSelect View\n menu, select the \nAll SNPs\n option under the \nGenotypes\n heading. This will display a table of all genotypes in the Land (those we published).\n\n\n\n\nNote the \nData Type\n column, which will indicate if the genotypes came from sequencing (\nSequenced\n ), non-sequencing (\nGenotyped\n), or imputation (\nImputed\n). You can filter on this column, or there are dedicated views for each of these under the same \nGenotypes\n heading in the \nSelect View\n menu. This is the first view we have encountered with individual level data; these data can be hidden, depending on the project level access controls we configured before publishing the genetic data. If a user only had the \nProject level frequency access\n, they would have seen all the summary level information in the prior views (allele and genotype frequencies and counts) but would not see the corresponding genotypes in this table.\n\n\nSelect the last view under the Genotypes heading in the \nSelect View\n menu, \nCovariate View\n:\n\n\n\n\nThis view will plot each relevant numeric sample attribute by genotype. Note that there are three charts (one numeric column from the \nSample MetaData\n table and two from the phenotypes we added to the \nSample Set MetaData\n).\nThere are not separate charts for each genotype source (sequencing, non-sequencing, imputed). Imputed doses are converted to genotypes and plotted with all other genotypes. Scroll down to the \nFEV1\n chart, which was the endpoint analyzed for the association results we were just reviewing. We can clearly see a relationship between FEV1 and genotype. From the \nTask\n tab on the right, under \nCustomize\n, select \nShow Summary Information\n to add a PValue\n\n\n\n\nNote, this does not match the PValue reported in the association results we were just exploring (1.00E-325) for a number of different reasons. The two primary reasons being the statistical model used for the association analysis (\ni.e.\n it included covariates) and the samples included in the association analysis (this view considers all samples for which there is a genotype and FEV1 measure in the Land, while the association analysis only included a subset of samples).\n\n\nWe can filter the results using the \nSearch Result\n tab on the left to try to better emulate the association analysis. For example, we only analyzed STUDY005, so we can filter to that under \nProjectName\n (note, there is no change, as we only added these phenotype measures for STUDY005, so the samples from other projects are already missing).\n\n\nNext we can filter to those which remained in the analysis after consent check under \nSample Set | STUDY005 | GxConsent | Disease\n. This filtering did cause a change so the view defaulted back to the first chart   scroll down to \nFEV1\n again and note the PValue is now closer to the one reported in the association results.\n\n\n\n\nAnother potential source of different sample content could be the project level access controls. You can select points on the chart to display the sample details below including Sample ID. For example, select the highest FEV1 values for the AA genotype:\n\n\n\n\nSince this view could potentially expose sample identity, samples from any project where you only have \nProject level frequency access\n will be excluded from the view, and the PValue calculation will not take them into account.\n\n\nOur initial interest in this variant was piqued by it being associated with our endpoint from our association analysis.\nLet s look at what other endpoints it may be associated with. From the \nSelect View\n menu, select \nGRASP2 Table\n under \nAssociation\n:\n\n\n\n\nThis displays a table of all the records in the GRASP database (version 2) for this variant. GRASP is a collection of all published GWAS results with Pvalue < 0.05, however, as most publications only include genome wide significant results using a much more stringent PValue threshold, it should generally be considered to only contain  top hits.\n\n\nBy default, this table is sorted by PValue, so the most significant results are at the top. You can see the phenotype and link to the source paper. Here we see a potential eQTL and three likely insignificant findings. Nothing related to our lung function endpoint (not surprising given our GWAS was simulated).\n\n\nNext we can look at the \nCurated Studies (Table)\n view under the \nSelect View\n menu under the \nAssociation\n heading:\n\n\n\n\nThis is similar to the \nGRASP2 Table\n view, except the source is all the association results that have been published to the Land, and as such will be complete (no PValue thresholds applied). In our case, we have only published the results from our single GWAS, so only see that one record returned.\n\n\nReview Gene Knowledge in GeneticsLand\n\u00b6\n\n\nIf you recall from the \nSNP Annotation\n view for rs475535, this variant was in the IGDCC3 gene, so let s search that from the box at the top:\n\n\n\n\nThe default view is \nAll SNPs\n. This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association \nTop Hits (Table)\n view, the \nRS ID\n column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the \nSource\n attribute in the \nSearch Result\n tab on the left:\n\n\n\n\nThe \nCoding SNPs\n view under the same \nVariants\n heading will return the exact same columns but remove the variants (rows) that are non-coding.\n\n\n\n\nUnder the \nSelect View\n menu, note the first section of views are divided by data source (\nSequenced\n, \nGenotyped\n for non-sequencing assays, and \nImputed\n). Let s switch to the corresponding \nGene Summary\n view for \nImputed\n data:\n\n\n\n\nIf we switch to the \nVariant Annotation\n tab on the left, we see how the putatively functional variants were selected, and can modify this classification to update the chart\n\n\n\n\nIf we switch to the \nGenome Browser\n view, we can see these data summarized across the gene:\n\n\n\n\nWe see the variants in this gene plotted along the genome colored by their classification (per the \nLegend\n on the right) where the height and dot size correspond to the allele frequency. We see two tracks, one for \nAll\n (meaning all samples) and one for \nSTUDY005\n because the grouping is still the PrimaryGrouping=ProjectName we defined when creating the Land. As we currently only have imputed data from this one project published, the grouping is uninformative. Let s switch to grouping by \nRACE\n and \nETHNIC\n using the \nGrouping\n button at the top:\n\n\n\n\nNow, in addition to the \nAll\n track, we see five new tracks grouped by the RACE and ETHNIC values from the\n\nSample MetaData\n:\n\n\n\n\nNote, some of the longer labels are truncated, right click on the chart and select \nOrganize Groups\n to see the full listing and optionally re-sort.\n\n\n\n\nAs a genome browser view, you can configure the tracks and add new ones using the \nTask\n tab on the right.\n\n\nWe can also look at the allele frequency in a table view for our selected grouping (RACE+ETHNIC) using the \nGrouped Allele Frequency\n view under the \nSelect View\n menu.\n\n\n\n\nHere we see six \nAllele Frequency\n columns. The first five on the left correspond to the grouping, which is still set as \nRACE\n and \nETHNIC\n. The last one on the right is the overall frequency considering all samples including those to which you don t have access per the project level access controls. As long as you have \nProject level frequency access\n, the samples from that project will be included in calculating the allele frequencies reported here. However, if you switch to a view that reports individual level information like the \nDose Matrix\n, you would not see the samples from those projects for which you only have \nProject level frequency access\n:\n\n\n\n\nThis view is a table of the imputed ALT allele doses with samples as rows and variant as columns. The column headers take the form \nCHROM:POS:REF:ALT\n, so you know, for example, that the first column contains doses of the A allele.\n\n\nThere is also the special \nCase Control Allele Frequency\n view, where the grouping will be based on the three case/control values that were specified in the phenotype file:\n\n\n\n\nWe can also look at the variant annotations in a table view. In the \nSelect View\n menu, under \nVariants\n, select \nAll SNPs\n This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association \nTop Hits (Table)\n view, the \nRS ID\n column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the \nSource\n attribute in the \nSearch Result\n tab on the left:\n\n\n\n\nThe \nCoding SNPs\n view under the same \nVariants\n heading will return the exact same columns but remove the variants (rows) that are non-coding.\n\n\nThe final two views in the \nSelect View\n menu, \nGRASP2 Table\n and \nCurated Studies (Table)\n under the \nAssociation\n heading, are identical to what we saw when exploring rs475535, except they will contain the list of associations for every variant in the \nAll SNPs\n view (all variants in the gene).\n\n\nReview Knowledge for a Region or Variant / Gene List in GeneticsLand\n\u00b6\n\n\nIn addition to searching for one gene, you can also search for a region (up to 1 Mb) using the form \nCHROM:START-END\n in the search box. For example, if we wanted to search 15 bases up and downstream of rs475535, we could enter \n15:65632700-65632730\n. You will have all the same views as when looking at the search results for the IGDCC3 gene with one additional \nGenes in Region\n view under the \nVariants\n heading which will show a list of all genes mapping to this region.\n\n\n\n\nYou can click on the link in the \nGene Name\n column to search that gene as if you had typed it into the search bar.\n\n\nYou can also \nSearch Multiple Variants\n or genes by clicking on the drop down arrow next to the green \nSearch\n arrow at the top:\n\n\n\n\n\n\nNote the instructions above the entry box for formatting the list of variants.\n\n\nFor the \nSearch Multiple Genes\n option, the gene symbols you enter will be checked. For example, having intentionally entered a non-existent gene BRCA56:\n\n\n\n\nThe genes found sum in the upper right indicates only the single OPRM1 gene was found, and the \nRemove invalid gene symbols\n button at the bottom left appears. You can also create a re-usable \nGene Set\n, analogous to a \nSample Set\n, in that access is controlled by the creator. From the \nManage\n menu, select \nGenes | Manage Gene Sets\n\n\n\n\nSelect the \nAdd\n option to create a new \nGene Set\n\n\n\n\nEnter \nSTUDY005 Candidate Genes\n  for \nName\n and  \nSTUDY005\n  for \nTag\n\n\n\n\nSwitch to the \nMetaData\n tab and select \nLoad from tab delimited file\n to browse to the downloaded GeneList.txt file\n\n\n\n\nThe first column must contain the gene identifier and you can specify the type of identifier with the \nID type\n option (we are using \nGene_Symbol\n for this example). Note, unlike when searching for multiple genes where the symbols are validated as you enter them, any erroneous identifiers here won t be reported until you try to use the \nGene Set\n. Any additional columns are just treated as generic user notes and not used in any way. Select \nOK\n to save the \nGene Set\n. Now you can search for this \nGene Set\n by name in the search box at the top. Start typing the name and select the \nGene Set\n which is found.\n\n\n\n\nFor these multi-variant and multi-gene searches, you will get all the same views as the IGDCC3 gene search except for the \nGenome Browser\n view.\n\n\nReview Phenotype Knowledge in a GeneticsLand\n\u00b6\n\n\nWe first started exploring the data in our Land with the endpoint from our association analysis. Now let s look at some other phenotypes. Start typing  psoriasis into the search box at the top and select the result for psoriasis:\n\n\n\n\nAs a \nPhenotype\n result (as opposed to an \nassociation\n result, as we selected when we searched for the endpoint from our association analysis), this indicates the results are from GRASP. The default view is a genome plot of the top 1,000 results. This is identical to the \nTop Hits (Genome Plot)\n view we saw when exploring the endpoint from our association analysis except instead of the results coming from out single analysis, they are compiled across all the literature. Therefore, we are likely to see the same variant reported multiple times. For example, if you select the peak on the p arm of chromosome 6, we see the SNV at 31252925 is reported twice:\n\n\n\n\nAlthough, scrolling right to review the annotations, we see it is a common variant with MAF > 5% in all reference populations, is intergenic, has \nGWAVA\n scores indicating it has no functional effect, and \nHaploReg\n and \nRegulomeDB\n values confirming minimal regulator impact.\n\n\nSo even though this variant was found to be associated with psoriasis in two studies, the association is likely to be driven by a variant with more functional effects in LD with this variant. We see from the \nPlatform\n description that these studies used imputation, however, from the variant counts ~2 million, we can infer that these used reference haplotypes from HapMap, which only captures a fraction of the variation in the 1000 Genomes project.\n\n\nSo, it is possible the driving variant in LD was not imputed from HapMap.\n\n\nWe can switch to the other view, \nTop Hits (Table)\n, to explore or export these fully annotated results using the \nSelect View\n menu:\n\n\n\n\nNote, in the GRASP data, Psoriasis is categorized under Skin-related for the \nPhenotype Category\n. And if we return to our original psoriasis search results, scrolling down to the bottom of the list, we see other psoriasis phenotypes that are likely of interest.\n\n\n\n\nBy searching the broader  Skin-related category, we can get to all of these\n\n\n\n\nIf we filter in the \nSearch Result\n tab on the left to only the psoriasis related phenotypes and select the same peak on the p arm of chromosome 6, we see that same variant at 31252925 shows up again but for slightly different phenotypes.\n\n\n\n\nAlthough, note from the PMID that these are coming from the same study (19169254), which was also one of the studies we saw when looking at the  psoriasis  specific results.",
            "title": "Explore Your Data in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#explore-your-data-in-geneticsland",
            "text": "",
            "title": "Explore Your Data in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-genetic-association-results-in-a-geneticsland",
            "text": "After all that setup, we are now ready to explore the data in your GeneticsLand. The tutorial dataset reflects a respiratory GWAS assessing genetic association with the FEV1 (Forced Expiratory Volume in One Second) endpoint. The primary access point for exploring the data in the Land will be the search box at the top of the  Land  tab. Start typing the name of the genetic association result set that we just published ( fev1 study005 ), then select the matching entry from the drop-down box:",
            "title": "Review Genetic Association Results in a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#association-annotation-view",
            "text": "When you search an association, five views are available.   The  Association Annotation  view is the fully annotated table of all association results. The primary use case for this view is to query (filter) all results by variant attributes ( i.e.  all putatively functional coding variants).   Note, these annotations were generated when the association results (GTT file) were published, and thus may be slightly out of date if new annotations have been released since then. For all other views in the Land, the most current annotations will be dynamically joined. The annotation sources were defined in the configuration when the Land was created (VariantClassifiers=ClinVar_20170501, FunctionalMutation_20170501\u2026). The specific classifiers we used for this tutorial are provided by OmicSoft. OmicSoft support ( support@omicsoft.com ) can assist you with building custom classifiers if you have proprietary or licensed annotations you wish to include.  You can use the variant attributes in the  Search Result  tab on the left to filter. Switch to the  Task  tab on the right and click on  Specify Columns  to configure which columns to display (by default, they are all displayed):   If you have filtered to a smaller number of rows (<2000 rows), new buttons will appear at the top to enable sorting and searching of the table (you can also right click on a column header to sort):   Once you have configured the table as you want, you can use the three buttons at the top-left to either open in a text editor, Excel, or save to a file, including an OmicSoft object file (.osobj) that can be opened in an Array Studio project ( Analysis  tab) for further analysis. Alternatively, you can save the view to a file that can be re-opened later ( File | Save View ) or share it for future access by you or others ( Share | Share Land View ). All of these options for configuring, exporting, and saving the view are common across all tabular views in the Land, and similar options are available for graphical views.",
            "title": "Association Annotation View"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#region-plot-view",
            "text": "Use the  Select View  button to switch to the  Region Plot  view: This view will show a Manhattan plot of the top 10,000 most significant results by p-value. With your mouse, click and drag to select the peak over chr15. This defines the center for the region plot. Note, the genome plot will disappear as the region plot is displayed. Click the  Show Overview  button to re-display it (and  Hide Overview  to hide it again).   In addition to selecting points from the genome plot, you can also go to a specific variant, gene, or region using the  Select Region  button:   This also allows you to set the region length (500 kb is the default). Note, specifying a variant (or coordinate using the Region option) does not set that as the  key  variant for calculating LD. The pairwise LD is always calculated relative to the variant in the region with the lowest p-value. Back in the region plot, you can choose to display or hide the pairwise LD matrix by selecting or de-selecting  pairwise LD .  Also in the region plot, you can use the  LD Source  and  LD Measurement  menus to adjust those values.\nAs the  LD Sources  are from 1000 Genomes, which are shallow short read data that have been statistically phased, these data are subject to switch errors, and the  R2(Haplotype)  may be inaccurate.  Looking at the default  1000G.EUR LD Source  with  R2  as the  LD Measurement , we see that many of the variants passing the genome wide significance threshold (PValue < 5E10 -8) appear to be in LD and thus likely represent a single causal variant.   However, given the extreme significance of many of these associations (note the scale of the -Log10(PValue) Y axis), there may be additional independent signals that are less significant but still pass the genome wide PValue threshold.  This  Region Plot  view is based on the OmicSoft Genome Browser, so you can configure display of various genomic annotation tracks. These options are available in the  Task  tab on the right, where you can  Manage  the existing tracks and  Add Tracks  from a variety of sources. This tab also has the option to  Export  the plot to an image file.  There are three remaining views available under  Select View . These three views are  Top Hits  views and the results displayed are user defined by the TopHitsN parameter. The TopHitsN parameter controls how many association results with the most significant p-values to display in these views. The default is 10,000.  The  Top Hits (Genome Plot)  view is a variation of what we have already seen. It is the same genome plot as shown in the  Region Plot  view, except instead of being used to set the center of the region plot (the primary component of the  Region Plot  view), the genome plot itself will be the primary component. The  Top Hist (QQ plot)  displays the negative logarithm of the observed (x-axis) and the expected (y-axis) P value for each SNP. This plot can be used to investigate confounders and identify true associations. Both of these views are fully interactive, such that you can use your mouse to select from the views, and give you options to explore the most significant results (filter on variant attributes, select to see details,  etc .) and configure the charts.   The  Top Hits (Table)  will be the fully annotated table of those same 1,000 most significant results. The output here is similar to the original  Association Annotation  view, except that the most current annotations will be dynamically joined. Select this view. To see which specific annotation versions are being reported, use the  Options  button in the  Search Result  tab on the left to select  Show Annotation Sources :    This same classifier listing will be included as a header if you  Open as Text file    The first column in the  Top Hits (Table)  view is the  Snp ID , which contains a link to the variant s views (as if you had searched for the variant from the search box at the top). Right click on the  PValue  column to  Sort Descending \n(the sort is based on the -log(PValue), so larger values are more significant).   Then click on the  Snp ID  for the first row ( rs475535 ) and continue to the next section to learn about the data and views available for this highly-significant variant.",
            "title": "Region Plot View"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-variant-knowledge-in-geneticsland",
            "text": "Having searched for rs475535, the default view that is returned is the  Allele Frequency  plot. Like the  Sample Distribution  view, this is also grouped based on the PrimaryGrouping=ProjectName defined when the Land was created, and can be adjusted using the  Grouping  button at the top.   Note there are actually two charts here, the first ( Genotyped ) being calculated from all the non-sequencing based genotypes that are in the Land (the array genotypes we published). Scroll down to see the next chart ( Imputed ), which is calculated from all the imputed allele doses in the Land ( i.e.  the ones we published from the GWAS).   In addition to the frequency being represented on the X axis, the carrier count is also displayed to the right of the bar in parentheses. Another view available is  Genotype Frequency , which is configured similarly to the  Allele Frequency  plot.   The number displayed to the right of each bar is still the carrier count (sum of heterozygotes and homozygote ALT). To get the count of each of these sub-groups, click on the  View Filtered Table  button at the bottom left to see the counts for each chart element.   There is also a special view named  Case Control Allele Frequency , which is available because at least one of the columns in our phenotype file was specified as a case/control value:   Switch to this view under the  Select View  menu and you will see that instead of being grouped by  Project Name , the allele frequencies are now grouped by the case/control status for all three phenotypes that were specified as case/control:   The final view under the  Summary  heading in the  Select View  menu ( SNP Annotation ) is the table of variant annotations. These will match what were reported in the  Top Hits (Table)  view when we were reviewing the association results.   Back in the  Select View  menu, select the  All SNPs  option under the  Genotypes  heading. This will display a table of all genotypes in the Land (those we published).   Note the  Data Type  column, which will indicate if the genotypes came from sequencing ( Sequenced  ), non-sequencing ( Genotyped ), or imputation ( Imputed ). You can filter on this column, or there are dedicated views for each of these under the same  Genotypes  heading in the  Select View  menu. This is the first view we have encountered with individual level data; these data can be hidden, depending on the project level access controls we configured before publishing the genetic data. If a user only had the  Project level frequency access , they would have seen all the summary level information in the prior views (allele and genotype frequencies and counts) but would not see the corresponding genotypes in this table.  Select the last view under the Genotypes heading in the  Select View  menu,  Covariate View :   This view will plot each relevant numeric sample attribute by genotype. Note that there are three charts (one numeric column from the  Sample MetaData  table and two from the phenotypes we added to the  Sample Set MetaData ).\nThere are not separate charts for each genotype source (sequencing, non-sequencing, imputed). Imputed doses are converted to genotypes and plotted with all other genotypes. Scroll down to the  FEV1  chart, which was the endpoint analyzed for the association results we were just reviewing. We can clearly see a relationship between FEV1 and genotype. From the  Task  tab on the right, under  Customize , select  Show Summary Information  to add a PValue   Note, this does not match the PValue reported in the association results we were just exploring (1.00E-325) for a number of different reasons. The two primary reasons being the statistical model used for the association analysis ( i.e.  it included covariates) and the samples included in the association analysis (this view considers all samples for which there is a genotype and FEV1 measure in the Land, while the association analysis only included a subset of samples).  We can filter the results using the  Search Result  tab on the left to try to better emulate the association analysis. For example, we only analyzed STUDY005, so we can filter to that under  ProjectName  (note, there is no change, as we only added these phenotype measures for STUDY005, so the samples from other projects are already missing).  Next we can filter to those which remained in the analysis after consent check under  Sample Set | STUDY005 | GxConsent | Disease . This filtering did cause a change so the view defaulted back to the first chart   scroll down to  FEV1  again and note the PValue is now closer to the one reported in the association results.   Another potential source of different sample content could be the project level access controls. You can select points on the chart to display the sample details below including Sample ID. For example, select the highest FEV1 values for the AA genotype:   Since this view could potentially expose sample identity, samples from any project where you only have  Project level frequency access  will be excluded from the view, and the PValue calculation will not take them into account.  Our initial interest in this variant was piqued by it being associated with our endpoint from our association analysis.\nLet s look at what other endpoints it may be associated with. From the  Select View  menu, select  GRASP2 Table  under  Association :   This displays a table of all the records in the GRASP database (version 2) for this variant. GRASP is a collection of all published GWAS results with Pvalue < 0.05, however, as most publications only include genome wide significant results using a much more stringent PValue threshold, it should generally be considered to only contain  top hits.  By default, this table is sorted by PValue, so the most significant results are at the top. You can see the phenotype and link to the source paper. Here we see a potential eQTL and three likely insignificant findings. Nothing related to our lung function endpoint (not surprising given our GWAS was simulated).  Next we can look at the  Curated Studies (Table)  view under the  Select View  menu under the  Association  heading:   This is similar to the  GRASP2 Table  view, except the source is all the association results that have been published to the Land, and as such will be complete (no PValue thresholds applied). In our case, we have only published the results from our single GWAS, so only see that one record returned.",
            "title": "Review Variant Knowledge in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-gene-knowledge-in-geneticsland",
            "text": "If you recall from the  SNP Annotation  view for rs475535, this variant was in the IGDCC3 gene, so let s search that from the box at the top:   The default view is  All SNPs . This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association  Top Hits (Table)  view, the  RS ID  column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the  Source  attribute in the  Search Result  tab on the left:   The  Coding SNPs  view under the same  Variants  heading will return the exact same columns but remove the variants (rows) that are non-coding.   Under the  Select View  menu, note the first section of views are divided by data source ( Sequenced ,  Genotyped  for non-sequencing assays, and  Imputed ). Let s switch to the corresponding  Gene Summary  view for  Imputed  data:   If we switch to the  Variant Annotation  tab on the left, we see how the putatively functional variants were selected, and can modify this classification to update the chart   If we switch to the  Genome Browser  view, we can see these data summarized across the gene:   We see the variants in this gene plotted along the genome colored by their classification (per the  Legend  on the right) where the height and dot size correspond to the allele frequency. We see two tracks, one for  All  (meaning all samples) and one for  STUDY005  because the grouping is still the PrimaryGrouping=ProjectName we defined when creating the Land. As we currently only have imputed data from this one project published, the grouping is uninformative. Let s switch to grouping by  RACE  and  ETHNIC  using the  Grouping  button at the top:   Now, in addition to the  All  track, we see five new tracks grouped by the RACE and ETHNIC values from the Sample MetaData :   Note, some of the longer labels are truncated, right click on the chart and select  Organize Groups  to see the full listing and optionally re-sort.   As a genome browser view, you can configure the tracks and add new ones using the  Task  tab on the right.  We can also look at the allele frequency in a table view for our selected grouping (RACE+ETHNIC) using the  Grouped Allele Frequency  view under the  Select View  menu.   Here we see six  Allele Frequency  columns. The first five on the left correspond to the grouping, which is still set as  RACE  and  ETHNIC . The last one on the right is the overall frequency considering all samples including those to which you don t have access per the project level access controls. As long as you have  Project level frequency access , the samples from that project will be included in calculating the allele frequencies reported here. However, if you switch to a view that reports individual level information like the  Dose Matrix , you would not see the samples from those projects for which you only have  Project level frequency access :   This view is a table of the imputed ALT allele doses with samples as rows and variant as columns. The column headers take the form  CHROM:POS:REF:ALT , so you know, for example, that the first column contains doses of the A allele.  There is also the special  Case Control Allele Frequency  view, where the grouping will be based on the three case/control values that were specified in the phenotype file:   We can also look at the variant annotations in a table view. In the  Select View  menu, under  Variants , select  All SNPs  This table includes the annotations for all variants both known from dbSNP and that have data published to the Land (whether that be genotypes, imputed doses, or association results). Like the association  Top Hits (Table)  view, the  RS ID  column contains links that will take you directly to those variant searches as if you had typed them into the search box at the top. To filter to just the variants that have data in the Land, use the  Source  attribute in the  Search Result  tab on the left:   The  Coding SNPs  view under the same  Variants  heading will return the exact same columns but remove the variants (rows) that are non-coding.  The final two views in the  Select View  menu,  GRASP2 Table  and  Curated Studies (Table)  under the  Association  heading, are identical to what we saw when exploring rs475535, except they will contain the list of associations for every variant in the  All SNPs  view (all variants in the gene).",
            "title": "Review Gene Knowledge in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-knowledge-for-a-region-or-variant-gene-list-in-geneticsland",
            "text": "In addition to searching for one gene, you can also search for a region (up to 1 Mb) using the form  CHROM:START-END  in the search box. For example, if we wanted to search 15 bases up and downstream of rs475535, we could enter  15:65632700-65632730 . You will have all the same views as when looking at the search results for the IGDCC3 gene with one additional  Genes in Region  view under the  Variants  heading which will show a list of all genes mapping to this region.   You can click on the link in the  Gene Name  column to search that gene as if you had typed it into the search bar.  You can also  Search Multiple Variants  or genes by clicking on the drop down arrow next to the green  Search  arrow at the top:    Note the instructions above the entry box for formatting the list of variants.  For the  Search Multiple Genes  option, the gene symbols you enter will be checked. For example, having intentionally entered a non-existent gene BRCA56:   The genes found sum in the upper right indicates only the single OPRM1 gene was found, and the  Remove invalid gene symbols  button at the bottom left appears. You can also create a re-usable  Gene Set , analogous to a  Sample Set , in that access is controlled by the creator. From the  Manage  menu, select  Genes | Manage Gene Sets   Select the  Add  option to create a new  Gene Set   Enter  STUDY005 Candidate Genes   for  Name  and   STUDY005   for  Tag   Switch to the  MetaData  tab and select  Load from tab delimited file  to browse to the downloaded GeneList.txt file   The first column must contain the gene identifier and you can specify the type of identifier with the  ID type  option (we are using  Gene_Symbol  for this example). Note, unlike when searching for multiple genes where the symbols are validated as you enter them, any erroneous identifiers here won t be reported until you try to use the  Gene Set . Any additional columns are just treated as generic user notes and not used in any way. Select  OK  to save the  Gene Set . Now you can search for this  Gene Set  by name in the search box at the top. Start typing the name and select the  Gene Set  which is found.   For these multi-variant and multi-gene searches, you will get all the same views as the IGDCC3 gene search except for the  Genome Browser  view.",
            "title": "Review Knowledge for a Region or Variant / Gene List in GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Explore_Your_Data_in_GeneticsLand/#review-phenotype-knowledge-in-a-geneticsland",
            "text": "We first started exploring the data in our Land with the endpoint from our association analysis. Now let s look at some other phenotypes. Start typing  psoriasis into the search box at the top and select the result for psoriasis:   As a  Phenotype  result (as opposed to an  association  result, as we selected when we searched for the endpoint from our association analysis), this indicates the results are from GRASP. The default view is a genome plot of the top 1,000 results. This is identical to the  Top Hits (Genome Plot)  view we saw when exploring the endpoint from our association analysis except instead of the results coming from out single analysis, they are compiled across all the literature. Therefore, we are likely to see the same variant reported multiple times. For example, if you select the peak on the p arm of chromosome 6, we see the SNV at 31252925 is reported twice:   Although, scrolling right to review the annotations, we see it is a common variant with MAF > 5% in all reference populations, is intergenic, has  GWAVA  scores indicating it has no functional effect, and  HaploReg  and  RegulomeDB  values confirming minimal regulator impact.  So even though this variant was found to be associated with psoriasis in two studies, the association is likely to be driven by a variant with more functional effects in LD with this variant. We see from the  Platform  description that these studies used imputation, however, from the variant counts ~2 million, we can infer that these used reference haplotypes from HapMap, which only captures a fraction of the variation in the 1000 Genomes project.  So, it is possible the driving variant in LD was not imputed from HapMap.  We can switch to the other view,  Top Hits (Table) , to explore or export these fully annotated results using the  Select View  menu:   Note, in the GRASP data, Psoriasis is categorized under Skin-related for the  Phenotype Category . And if we return to our original psoriasis search results, scrolling down to the bottom of the list, we see other psoriasis phenotypes that are likely of interest.   By searching the broader  Skin-related category, we can get to all of these   If we filter in the  Search Result  tab on the left to only the psoriasis related phenotypes and select the same peak on the p arm of chromosome 6, we see that same variant at 31252925 shows up again but for slightly different phenotypes.   Although, note from the PMID that these are coming from the same study (19169254), which was also one of the studies we saw when looking at the  psoriasis  specific results.",
            "title": "Review Phenotype Knowledge in a GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Delete_your_GeneticsLand/",
            "text": "Delete your GeneticsLand\n\u00b6\n\n\nYou may wish to keep the Land you have created for this tutorial for additional training and testing. The datasets that were published were relatively small and will not consume much disk space on the server. When you are done with your Land and want to delete it, from the \nTools\n menu, select \nDelete Land\n\n\n\n\nConfirm it is your \nLand\n that is selected, leave the \nDelete all data types\n option selected and click \nOK\n.\n\n\n\n\nYou will be prompted to confirm you want to delete the Land. If you are sure, select \nYes\n.\n\n\n\n\nCongratulations! You are done with this tutorial, which represents just a piece of what OmicSoft Lands are capable of.\nFor additional information, don t hesitate to contact Omicsoft s support team (\nsupport@omicsoft.com\n).\n\n\nThank you for using Array Studio.",
            "title": "Delete your GeneticsLand"
        },
        {
            "location": "/tutorials/GeneticsLand/Delete_your_GeneticsLand/#delete-your-geneticsland",
            "text": "You may wish to keep the Land you have created for this tutorial for additional training and testing. The datasets that were published were relatively small and will not consume much disk space on the server. When you are done with your Land and want to delete it, from the  Tools  menu, select  Delete Land   Confirm it is your  Land  that is selected, leave the  Delete all data types  option selected and click  OK .   You will be prompted to confirm you want to delete the Land. If you are sure, select  Yes .   Congratulations! You are done with this tutorial, which represents just a piece of what OmicSoft Lands are capable of.\nFor additional information, don t hesitate to contact Omicsoft s support team ( support@omicsoft.com ).  Thank you for using Array Studio.",
            "title": "Delete your GeneticsLand"
        },
        {
            "location": "/about/Release-notes/",
            "text": "Release Notes\n\u00b6\n\n\nArraySuite 10.0\n\u00b6\n\n\nArray Suite 10.0: Accelerating Bioinformatics Research For Ten Years\n\n\nOmicSoft, now a QIAGEN company, is excited to announce Array Suite 10.0, the ten year anniversary release to its flagship software product. Array Suite provides the backbone of OmicSoft's software and data service offerings, including OncoLand, DiseaseLand and GeneticsLand. In the past ten years, Array Suite has helped numerous users from major pharma and biotech companies (as well as research instutitions) accelerate their bioinformatics and genomics research.\n\n\nFounded in 2007, OmicSoft had a vision to focus on biomarker data management, visualization, and analysis. Array Suite (Array Studio and Array Server) differs from standard desktop solutions or open source solutions, with Array Studio providing the graphical user interface for NGS and OMIC analysis and visualization and Array Server providing the enterprise back-end solution for pipelines, project management, sample/file management, data storage and OMIC data warehouse (Land database).  In January 2017, QIAGEN enhanced its portfolio with the acquisition of OmicSoft, allowing us to imagine new possibilities for integration with the larger QIAGEN bioinformatics portfolio.  We will update everyone on these enhancements, and how they will benefit our users, in the near future.\n\n\n\"Although much has changed in the past ten years, in both software and the company itself, I'm proud that OmicSoft Corporation has remained unchanged it it's fundamental desire to implement useful tools, driven by our customer's needs, in the -OMICS space.  I am confident that this will continue into the future with our acquisition by QIAGEN, and I look forward to many more years of Array Studio helping to drive exciting breakthroughs and research by our customers\" - Matt Newman, VP Business Development\n\n\nOmicSoft is extremely proud of it's customer-centric product development and customer support, and we look to continue this into the future, as we have for the past 10 years.  With our latest update, this trend continues. Array Suite 10.0 includes revolutionary updates, with multiple technology breakthroughs including: Cloud-Based Lands, Single Cell RNA-Seq support, ENCODE integration and many other updates to both analytics and framework.\n\n\nHere is a list of some of our exciting updates:\n\n\n\n\nCloud-Based Lands  \n\n\nSingle Cell RNA-Seq support  \n\n\nENCODE integration in Omicsoft genome browser  \n\n\nNew gene set analysis\n\n\nStreaming large tables  \n\n\nSmart labeling in multi-charts\n\n\nSmart caching for cloud/HTTP bam sources\n\n\nNew analytic modules including variable selection and prediction  \n\n\nSignificant improvements on plasmid-host integration \n\n\nVarious genome browser improvements",
            "title": "Release Notes"
        },
        {
            "location": "/about/Release-notes/#release-notes",
            "text": "",
            "title": "Release Notes"
        },
        {
            "location": "/about/Release-notes/#arraysuite-100",
            "text": "Array Suite 10.0: Accelerating Bioinformatics Research For Ten Years  OmicSoft, now a QIAGEN company, is excited to announce Array Suite 10.0, the ten year anniversary release to its flagship software product. Array Suite provides the backbone of OmicSoft's software and data service offerings, including OncoLand, DiseaseLand and GeneticsLand. In the past ten years, Array Suite has helped numerous users from major pharma and biotech companies (as well as research instutitions) accelerate their bioinformatics and genomics research.  Founded in 2007, OmicSoft had a vision to focus on biomarker data management, visualization, and analysis. Array Suite (Array Studio and Array Server) differs from standard desktop solutions or open source solutions, with Array Studio providing the graphical user interface for NGS and OMIC analysis and visualization and Array Server providing the enterprise back-end solution for pipelines, project management, sample/file management, data storage and OMIC data warehouse (Land database).  In January 2017, QIAGEN enhanced its portfolio with the acquisition of OmicSoft, allowing us to imagine new possibilities for integration with the larger QIAGEN bioinformatics portfolio.  We will update everyone on these enhancements, and how they will benefit our users, in the near future.  \"Although much has changed in the past ten years, in both software and the company itself, I'm proud that OmicSoft Corporation has remained unchanged it it's fundamental desire to implement useful tools, driven by our customer's needs, in the -OMICS space.  I am confident that this will continue into the future with our acquisition by QIAGEN, and I look forward to many more years of Array Studio helping to drive exciting breakthroughs and research by our customers\" - Matt Newman, VP Business Development  OmicSoft is extremely proud of it's customer-centric product development and customer support, and we look to continue this into the future, as we have for the past 10 years.  With our latest update, this trend continues. Array Suite 10.0 includes revolutionary updates, with multiple technology breakthroughs including: Cloud-Based Lands, Single Cell RNA-Seq support, ENCODE integration and many other updates to both analytics and framework.  Here is a list of some of our exciting updates:   Cloud-Based Lands    Single Cell RNA-Seq support    ENCODE integration in Omicsoft genome browser    New gene set analysis  Streaming large tables    Smart labeling in multi-charts  Smart caching for cloud/HTTP bam sources  New analytic modules including variable selection and prediction    Significant improvements on plasmid-host integration   Various genome browser improvements",
            "title": "ArraySuite 10.0"
        },
        {
            "location": "/about/Contributing/",
            "text": "Team\n\u00b6\n\n\nSupport team\n\u00b6\n\n\n\n\nGary Ge\n\n\nJoseph Pearson",
            "title": "Contributing"
        },
        {
            "location": "/about/Contributing/#team",
            "text": "",
            "title": "Team"
        },
        {
            "location": "/about/Contributing/#support-team",
            "text": "Gary Ge  Joseph Pearson",
            "title": "Support team"
        },
        {
            "location": "/example/",
            "text": "First\n\u00b6\n\n\nFor full documentation visit \nmkdocs.org\n.\n\n\nCommands\n\u00b6\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nProject layout\n\u00b6\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n\n\n\n\n\nImages, videos and table\n\u00b6\n\n\nSimple image\n\u00b6\n\n\n\n\nTest a large image\n\n\n\n\nlightbox image\n\u00b6\n\n\nTest large image with lightbox using extend theme_dir\n\n\n\n    \n\n\n\n\nlightbox gallery\n\u00b6\n\n\n\n    \n\n        \n\n            \n\n                \n\n            \n\n            \n\n                \n\n            \n\n            \n\n                \n\n            \n\n        \n\n        \n\n            \n\n                \n\n            \n\n            \n\n                \n\n            \n\n            \n\n                \n\n            \n\n        \n\n    \n\n\n\n\n\nlightbox Youtube\n\u00b6\n\n\nJustin Bieber - Love Yourself\n\n\nTestTable\n\u00b6\n\n\n\n\n\n\n\n\nHeader One\n\n\nHeader Two\n\n\nHeader One\n\n\nHeader Two\n\n\n\n\n\n\n\n\n\n\nItem One\n\n\nItem Two\n\n\nItem One\n\n\nItem Two\n\n\n\n\n\n\n\n\nExtensions\n\u00b6\n\n\nAdmonition\n\u00b6\n\n\nuse below\n\n\n!!! note\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.\n\n\n\n\nwill have:\n\n\n\n\nNote\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\n\n\n\n\n\n\nTip\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\nmore to find in \nsquidfunk\n\n\n\n\n\n\nOpen styled details\n\n\n\n\nNested details!\n\n\nAnd more content again.\n\n\n\n\n\n\n\n\nTip: we can add code here\n\n\n\"\"\" Bubble sort \"\"\"\n\n\ndef\n \nbubble_sort\n(\nitems\n):\n\n\n    \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nitems\n)):\n\n\n        \nfor\n \nj\n \nin\n \nrange\n(\nlen\n(\nitems\n)\n \n-\n \n1\n \n-\n \ni\n):\n\n\n            \nif\n \nitems\n[\nj\n]\n \n>\n \nitems\n[\nj\n \n+\n \n1\n]:\n\n                \nitems\n[\nj\n],\n \nitems\n[\nj\n \n+\n \n1\n]\n \n=\n \nitems\n[\nj\n \n+\n \n1\n],\n \nitems\n[\nj\n]\n\n\n\n\n\n\n\n\n\nSeealso\n\n\nRef1:\nRef2:\n\n\n\n\n\n\nSummary\n\n\nSummary style\n\n\n\n\n\n\nDone\n\n\nI am done\n\n\n\n\n\n\nWarning\n\n\nmy warning\n\n\n\n\n\n\nFailure\n\n\nA fail case\n\n\n\n\n\n\nDanger\n\n\nbe careful\n\n\n\n\n\n\nBug\n\n\nIt is a bug\n\n\n\n\n\n\nQuote\n\n\nsomeone said so.\n\n\n\n\nMore details\n\n\nDetails\n\u00b6\n\n\nOpen styled details\nNested details!\nAnd more content again.\nstyled details\n\n\n\n\nNote\n\n\nOpen styled details\nHello1\nHello2\n\n\nDanger\n\n\nNested details!\nAnd more content again.\n\n\n\n\nFootnotes\n\u00b6\n\n\nExample:\n\n\nLorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2]\n\n\n\n\nResult:\n\n\nLorem ipsum\n1\n dolor sit amet, consectetur adipiscing elit.\n2\n\n\nCode highlight\n\u00b6\n\n\nimport\n \ntensorflow\n \nas\n \ntf\n\n\n\n\n\nCode highlight the 3\nrd\n and 4\nth\n lines\n\n\n\"\"\" Bubble sort \"\"\"\n\n\ndef\n \nbubble_sort\n(\nitems\n):\n\n\n    \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nitems\n)):\n\n\n        \nfor\n \nj\n \nin\n \nrange\n(\nlen\n(\nitems\n)\n \n-\n \n1\n \n-\n \ni\n):\n\n\n            \nif\n \nitems\n[\nj\n]\n \n>\n \nitems\n[\nj\n \n+\n \n1\n]:\n\n                \nitems\n[\nj\n],\n \nitems\n[\nj\n \n+\n \n1\n]\n \n=\n \nitems\n[\nj\n \n+\n \n1\n],\n \nitems\n[\nj\n]\n\n\n\n\n\nMore examples of code highlight\n\n\nsmart symbols\n\u00b6\n\n\n\n\n\u2122\n\n\n\u00ae\n\n\nmore\n\n\n\n\nmeta\n\u00b6\n\n\nSee the meta and description above.\n\n\nTask list\n\u00b6\n\n\nTask List\n\n\n\n\n item 1\n\n\n item A\n\n\n item B\n\n\n item a\n\n\n item b\n\n\n item c\n\n\n\n\n\n\n item C\n\n\n\n\n\n\n item 2\n\n\n item 3\n\n\n\n\nemoji\n\u00b6\n\n\nEmojiOne \n emoji are very useful \n.\n\n\nYou can also escape \n:\n characters to escape the emoji: :smile:.\n\n\nSuper and sub using caret and tilde, and mark\n\u00b6\n\n\n\n\nunderline me\n\n\nH\n2\n0\n\n\ntext\na superscript\n\n\ndelete me\n\n\nCH\n3\nCH\n2\nOH\n\n\ntext\na subscript\n\n\nmark me\n\n\nmark\n \nme\n\n\n\n\nKeyboard using keys\n\u00b6\n\n\nTo copy, press \nCtrl\n+\nAlt\n+\nC\n for Windows or Linux or \nCmd\n+\nAlt\n+\nC\n for Mac.\n\n\nYou can also use custom key labels: \nCtrl\n+\nAlt\n+\n\u00dc\n.\n\n\nMathjax\n\u00b6\n\n\nSome Block Equations:\n\n\n\\[\n\\frac{n!}{k!(n-k)!} = \\binom{n}{k}\n\\]\n\\[\nE(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j\n\\]\n\\[3 < 4\\]\n\\[\\begin{align}\n    p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right) \\\\\n    p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right)\n\\end{align}\\]\nInline equations: \n\\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\)\n, \n\\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\)\n.\n\n\nReference\n\u00b6\n\n\nhttp://squidfunk.github.io/mkdocs-material/extensions/pymdown/\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit.\u00a0\n\u21a9\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\u00a0\n\u21a9",
            "title": "Example"
        },
        {
            "location": "/example/#first",
            "text": "For full documentation visit  mkdocs.org .",
            "title": "First"
        },
        {
            "location": "/example/#commands",
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.",
            "title": "Commands"
        },
        {
            "location": "/example/#project-layout",
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Project layout"
        },
        {
            "location": "/example/#images-videos-and-table",
            "text": "",
            "title": "Images, videos and table"
        },
        {
            "location": "/example/#simple-image",
            "text": "Test a large image",
            "title": "Simple image"
        },
        {
            "location": "/example/#lightbox-image",
            "text": "Test large image with lightbox using extend theme_dir",
            "title": "lightbox image"
        },
        {
            "location": "/example/#lightbox-gallery",
            "text": "",
            "title": "lightbox gallery"
        },
        {
            "location": "/example/#lightbox-youtube",
            "text": "Justin Bieber - Love Yourself",
            "title": "lightbox Youtube"
        },
        {
            "location": "/example/#testtable",
            "text": "Header One  Header Two  Header One  Header Two      Item One  Item Two  Item One  Item Two",
            "title": "TestTable"
        },
        {
            "location": "/example/#extensions",
            "text": "",
            "title": "Extensions"
        },
        {
            "location": "/example/#admonition",
            "text": "use below  !!! note\n    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\n    nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\n    massa, nec semper lorem quam in massa.  will have:   Note  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.    Tip  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\nmore to find in  squidfunk    Open styled details   Nested details!  And more content again.     Tip: we can add code here  \"\"\" Bubble sort \"\"\"  def   bubble_sort ( items ):       for   i   in   range ( len ( items )):           for   j   in   range ( len ( items )   -   1   -   i ):               if   items [ j ]   >   items [ j   +   1 ]: \n                 items [ j ],   items [ j   +   1 ]   =   items [ j   +   1 ],   items [ j ]     Seealso  Ref1:\nRef2:    Summary  Summary style    Done  I am done    Warning  my warning    Failure  A fail case    Danger  be careful    Bug  It is a bug    Quote  someone said so.   More details",
            "title": "Admonition"
        },
        {
            "location": "/example/#details",
            "text": "Open styled details Nested details! And more content again. styled details   Note  Open styled details Hello1\nHello2  Danger  Nested details! And more content again.",
            "title": "Details"
        },
        {
            "location": "/example/#footnotes",
            "text": "Example:  Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2]  Result:  Lorem ipsum 1  dolor sit amet, consectetur adipiscing elit. 2",
            "title": "Footnotes"
        },
        {
            "location": "/example/#code-highlight",
            "text": "import   tensorflow   as   tf   Code highlight the 3 rd  and 4 th  lines  \"\"\" Bubble sort \"\"\"  def   bubble_sort ( items ):       for   i   in   range ( len ( items )):           for   j   in   range ( len ( items )   -   1   -   i ):               if   items [ j ]   >   items [ j   +   1 ]: \n                 items [ j ],   items [ j   +   1 ]   =   items [ j   +   1 ],   items [ j ]   More examples of code highlight",
            "title": "Code highlight"
        },
        {
            "location": "/example/#smart-symbols",
            "text": "\u2122  \u00ae  more",
            "title": "smart symbols"
        },
        {
            "location": "/example/#meta",
            "text": "See the meta and description above.",
            "title": "meta"
        },
        {
            "location": "/example/#task-list",
            "text": "Task List    item 1   item A   item B   item a   item b   item c     item C     item 2   item 3",
            "title": "Task list"
        },
        {
            "location": "/example/#emoji",
            "text": "EmojiOne   emoji are very useful  .  You can also escape  :  characters to escape the emoji: :smile:.",
            "title": "emoji"
        },
        {
            "location": "/example/#super-and-sub-using-caret-and-tilde-and-mark",
            "text": "underline me  H 2 0  text a superscript  delete me  CH 3 CH 2 OH  text a subscript  mark me  mark   me",
            "title": "Super and sub using caret and tilde, and mark"
        },
        {
            "location": "/example/#keyboard-using-keys",
            "text": "To copy, press  Ctrl + Alt + C  for Windows or Linux or  Cmd + Alt + C  for Mac.  You can also use custom key labels:  Ctrl + Alt + \u00dc .",
            "title": "Keyboard using keys"
        },
        {
            "location": "/example/#mathjax",
            "text": "Some Block Equations:  \\[\n\\frac{n!}{k!(n-k)!} = \\binom{n}{k}\n\\] \\[\nE(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j\n\\] \\[3 < 4\\] \\[\\begin{align}\n    p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right) \\\\\n    p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right)\n\\end{align}\\] Inline equations:  \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) ,  \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) .",
            "title": "Mathjax"
        },
        {
            "location": "/example/#reference",
            "text": "http://squidfunk.github.io/mkdocs-material/extensions/pymdown/      Lorem ipsum dolor sit amet, consectetur adipiscing elit.\u00a0 \u21a9    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod\nnulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor\nmassa, nec semper lorem quam in massa.\u00a0 \u21a9",
            "title": "Reference"
        }
    ]
}